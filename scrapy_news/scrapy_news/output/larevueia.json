[
{"url": "https://larevueia.fr/introduction-au-nlp-avec-python-les-ia-prennent-la-parole/", "title": "Introduction au NLP avec Python", "author": "Ilyes Talbi", "date": "\n13 mai 2020\n", "content": "<div class=\"entry-content\"><p>Dans cet article on explique les bases du NLP avec Python en travaillant sur un exemple de classification de textes.</p><p>Chatbots, moteurs de recherches, assistants vocaux, les IA ont énormément de choses à nous dire. Néanmoins, la compréhension du langage, qui est une formalité pour les êtres humains, est un challenge quasiment insurmontable pour les machines. C’est d’ailleurs un domaine entier du machine learning, on le nomme NLP.</p><p>Ces dernières années ont été très riches en progrès pour le Natural Language Processing (NLP) et les résultats observés sont de plus en plus impressionnants. C’est vrai que dans mon article <em><a data-type=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" href=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" target=\"_blank\" rel=\"noreferrer noopener\">Personne n’aime parler à une IA</a></em>, j’ai été assez sévère dans ma présentation des IA conversationnelles. Malgré que les systèmes qui existent sont loin d’être parfaits (et risquent de ne jamais le devenir), ils permettent déjà de faire des choses très intéressantes.</p><h2 class=\"wp-block-heading\" id=\"du-mot-au-vecteur\" style=\"font-size:21px\"><strong>Du mot au vecteur</strong></h2><p>Pour comprendre le langage le système doit être en mesure de saisir les différences entre les mots. Pour cela, l’idéal est de pouvoir les représenter mathématiquement, on parle d’encodage. De la même manière qu’une image est représentée par une matrice de valeurs représentant les nuances de couleurs, un mot sera représenté par un vecteur de grande dimension, c’est ce que l’on appelle le <em>word embedding</em>.</p><p>Ces vecteurs sont construits pour chaque langue en traitant des bases de données de textes énormes (on parle de plusieurs centaines de Gb). En comptant les occurrences des mots dans les textes, l’algorithme peut établir des correspondance entre les mots.</p><p>Les modèles de ce type sont nombreux, les plus connus sont Word2vec, BERT ou encore ELMO. Leurs utilisations est rendue simple grâce à des modèles pré-entrainés que vous pouvez trouver facilement.</p><p>Rien ne nous empêche de dessiner les vecteurs (après les avoir projeter en dimension 2), je trouve ça assez joli !<br></p><figure class=\"wp-block-image size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"512\" height=\"297\" src=\"https://larevueia.fr/wp-content/uploads/2020/05/word2vec.png\" alt=\"word2vec, tutoriel NLP avec Python\" class=\"wp-image-446\" style=\"width:712px;height:413px\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/05/word2vec.png 512w, https://larevueia.fr/wp-content/uploads/2020/05/word2vec-300x174.png 300w\" sizes=\"auto, (max-width: 512px) 100vw, 512px\"><figcaption class=\"wp-element-caption\">Représentation graphique de mots avec Word2vec</figcaption></figure><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Cette représentation est très astucieuse puisqu’elle permet maintenant de définir une distance entre 2 mots. Vous pouvez même écrire des équations de mots comme : <em>Roi – Homme = Reine – Femme</em></p></blockquote><h2 class=\"wp-block-heading\" id=\"application-du-nlp-classification-de-phrases-sur-python\" style=\"font-size:21px\"><br><strong>Application du NLP avec Python : classification de phrases</strong></h2><p>Pré-requis : <a href=\"https://www.emil.school/articles/comment-installer-python\" target=\"_blank\" rel=\"noreferrer noopener\">Installation de Python</a></p><p>Maintenant que l’on a compris les concepts de bases du NLP, nous pouvons travailler sur un premier petit exemple. Prenons une liste de phrases incluant des fruits et légumes. Nous allons construire en quelques lignes un système qui va permettre de les classer suivant 2 catégories.</p><p>Nous verrons que faire du NLP avec Python peut être très efficace, mais il sera intéressant de voir que certaines subtilités de langages peuvent échapper au système !</p><p>Je vous conseille d’utiliser Google Collab, c’est l’environnement de codage que je préfère.</p><p><em>Voici nos données de départ :</em></p><pre class=\"wp-block-code\"><code>phrases = [\"J'ai acheté des tomates\",\n          \"La saison des oignons arrive\",\n          'Cette mangue est très bonne',\n          'Ca sent les haricots',\n          'Je crois que je vais tomber dans les pommes',\n          'Penses à acheter des carottes',\n          \"Un petit jus orange?\",\n          \"Ces fraises sont belles\",\n          \"Prend des aubergines aussi\"]</code></pre><p><br>Avant de commencer nous devons importer les bibliothèques qui vont nous servir :<br></p><pre class=\"wp-block-code\"><code># import des bibliothèques utiles\n\nfrom gensim.models import Word2Vec\nimport nltk\nfrom gensim.models import KeyedVectors\n\nfrom nltk.cluster import KMeansClusterer\nimport numpy as np \n\nfrom sklearn import cluster\nfrom sklearn import metrics</code></pre><p>Si elles ne sont pas installées vous n’avez qu’à faire <em>pip install gensim</em>, pip <em>install sklearn</em>, …<br></p><h3 class=\"wp-block-heading\" id=\"nettoyage-des-donnees\" style=\"font-size:18px\"><em><strong>              Nettoyage des données</strong></em></h3><p><br>La première étape à chaque fois que l’on fait du NLP avec Python, est de construire une pipeline de nettoyage de nos données. L’exemple que je vous présente ici est assez basique mais vous pouvez être amenés à traiter des données beaucoup moins structurées que celles-ci.</p><p>Et d’ailleurs le plus gros travail du data scientist ne réside malheureusement pas dans la création de modèle. Le nettoyage du dataset représente une part énorme du processus.</p><p>Pour nettoyage des données textuelles on retire les chiffres ou les nombres, on enlève la ponctuation, les caractères spéciaux comme les @, /, -, :, … et on met tous les mots en minuscules.</p><p>Pour cela on utiliser ce que l’on appelle les expressions régulières ou regex. Sur Python leur utilisation est assez simple, vous devez importer la bibliothèque ‘re’. Puis construire vos regex. Attention à l’ordre dans lequel vous écrivez les instructions.</p><p>Il n’y a malheureusement aucune pipeline NLP qui fonctionne à tous les coups, elles doivent être construites au cas par cas. Dans le cas qui nous importe cette fonction fera l’affaire :</p><pre class=\"wp-block-code\"><code>import re\n\ndef nlp_pipeline(text):\n\n    text = text.lower() # mettre les mots en minuscule\n\n# Retirons les caractères spéciaux :\n\n    text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)\n    text = re.sub(r\"\\&amp;\\S*\\s\", \"\", text)\n    text = re.sub(r\"\\-\", \"\", text)\n    \n    return text</code></pre><h3 class=\"wp-block-heading\" id=\"installation-d-un-modele-word2vec-pre-entraine\" style=\"font-size:18px\"><strong> </strong><br><strong><em>Installation d’un modèle Word2vec pré-entrainé :</em></strong></h3><p>Pour gagner du temps et pouvoir créer un système efficace facilement il est préférable d’utiliser des modèles déjà entraînés.</p><p>Pour cet exemple j’ai choisi un modèle Word2vec que vous pouvez importer rapidement via la bibliothèque <em>Gensim</em>. Voici le code à écrire sur Google Collab. Rien ne vous empêche de télécharger la base et de travailler en local.</p><pre class=\"wp-block-code\"><code># Import d'une base word2vec en francais deja entrainee\n\nw2v = KeyedVectors.load_word2vec_format(\nhttps://s3.us-east 2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin,\n    binary=True)</code></pre><h3 class=\"wp-block-heading\" id=\"encodage-la-transformation-des-mots-en-vecteurs-est-la-base-du-nlp\" style=\"font-size:18px\"><em><strong>              </strong></em><br><em><strong>Encodage : la transformation des mots en vecteurs</strong></em> <em>est la base du NLP</em> avec Python</h3><p>C’est l’étape cruciale du processus. Nous devons transformer nos phrases en vecteurs.</p><p>Pour cela, word2vec nous permet de transformer des mots et vecteurs. Je vais ensuite faire simplement la moyenne de chaque phrase. Sachez que pour des phrases longues cette approche ne fonctionnera pas, la moyenne n’est pas  assez robuste. Si vous avez des phrases plus longues ou des textes il vaut mieux choisir une approche qui utilise TF-IDF.<br></p><pre class=\"wp-block-code\"><code># On commence par utiliser notre pipeline définie plus haut\n\nphrases_propres = []\n\nfor phrase in phrases:\n    phrases_propres.append(nlp_pipeline(phrase))\n\n# Nous devons séparer les phrases en liste de mots\n\nphrases_split = []\n\nfor phrase in phrases_propres:\n    phrases_split.append(phrase.split(\" \"))\n\n# C'est là que Word2vec intervient\nX = []\n\nfor phrase in phrases_split:\n    vec_phrase = []\n    for mot in phrase:\n        vec_phrase.append(w2v.wv[mot])\n    X.append(np.mean(vec_phrase,0))</code></pre><hr class=\"wp-block-separator has-css-opacity\"><h3 class=\"wp-block-heading\" id=\"classification-par-la-methode-des-k-means\" style=\"font-size:18px\"><em><strong>              </strong></em><br><em><strong>Classification par la méthode des k-means :</strong></em></h3><p>Maintenant que nous avons nos vecteurs, nous pouvons commencer la classification.</p><p>En classification il n’y a pas de consensus concernant la méthode a utiliser. Vous pouvez lire l’article <a href=\"https://larevueia.fr/clustering-les-3-methodes-a-connaitre/\" target=\"_blank\" rel=\"noreferrer noopener\">3 méthodes de clustering à connaitre</a>.</p><p>Ici nous aller utiliser la méthode des k moyennes, ou k-means. Elle est d’autant plus intéressante dans notre situation puisque l’on sait déjà que nos données sont réparties suivant deux catégories.</p><p>Le code pour le k-means avec Scikit learn est assez simple :</p><pre class=\"wp-block-code\"><code>kclusterer = KMeansClusterer(2, distance=nltk.cluster.util.cosine_distance, repeats=25)\nclusters = kclusterer.cluster(X, assign_clusters=True)\nprint (clusters)\n\nfor index, phrase in enumerate(phrases):    \n    print (str(clusters[index]) + \":\" + str(phrase))\n\nkmeans = cluster.KMeans(n_clusters=2)\nkmeans.fit(X)\n  \nlabels = kmeans.labels_\ncentroids = kmeans.cluster_centers_</code></pre><p>Voici les résultats que l’on obtient :</p><pre class=\"wp-block-code\"><code>1 : J'ai acheté des tomates\n1 : La saison des oignons arrive\n0 : Cette mangue est très bonne\n1 : Ca sent les haricots\n1 : Je crois que je vais tomber dans les pommes\n1 : Penses à acheter des carottes\n0 : Un petit jus orange?\n0 : Ces fraises sont belles\n1 : Prend des aubergines aussi</code></pre><p>A part pour les pommes chaque phrase est rangée dans la bonne catégorie. Pour les pommes on a peut-être un problème dans la taille de la phrase. Comme je l’ai expliqué plus la taille de la phrase sera grande moins la moyenne sera pertinente.</p><p>Il peut être intéressant de projeter les vecteurs en dimension 2 et visualiser à quoi nos catégories ressemblent sur un nuage de points.</p><pre class=\"wp-block-code\"><code>import matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\nmodel = TSNE(n_components=2, random_state=0)\nnp.set_printoptions(suppress=True)\n\nY = model.fit_transform(X)\nplt.scatter(Y[:, 0], Y[:, 1], c=clusters, s=290,alpha=.5)\n\nplt.show()</code></pre><p>Voilà ce que l’on obtient :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"383\" height=\"248\" src=\"https://larevueia.fr/wp-content/uploads/2020/05/clusters_fruits.png\" alt=\"Nuages de points\" class=\"wp-image-462\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/05/clusters_fruits.png 383w, https://larevueia.fr/wp-content/uploads/2020/05/clusters_fruits-300x194.png 300w\" sizes=\"auto, (max-width: 383px) 100vw, 383px\"><figcaption class=\"wp-element-caption\">Nuage de points représentant les phrases de notre corpus</figcaption></figure></div><p>Je suis fan de beaux graphiques sur Python, c’est pour cela que j’aimerais aussi construire une matrice de similarité. Elle nous permettra de voir rapidement quelles sont les phrases les plus similaires.</p><pre class=\"wp-block-code\"><code>size = 10\n\n# Construction de la matrice des distances\n\nS = np.zeros((size,size))\n\nfor i in range(len(X)):\n    for j in range(len(X)):\n        S[i][j] = np.dot(X[i],X[j])/(np.linalg.norm(X[i])*np.linalg.norm(X[j]))\n\nfig, ax = plt.subplots()\nimg = ax.imshow(S)\n\n# Pour afficher les phrases\n\nx_label_list = phrases\ny_label_list = phrases\n\n# Imposons qu'ils soient tous afficher, sinon par défaut vous n'en verrez #que la moitié\n\nax.set_xticks(np.arange(10))\nax.set_yticks(np.arange(10))\n\n# Afficher les labels et le titre principal\n\nax.set_xticklabels(x_label_list,rotation='vertical',verticalalignment='top')\nax.set_yticklabels(y_label_list)\nax.set_title(\"Matrice de similarité\")\n\n# Ecrire la valeur de la similarité dans chaque case de la matrice\n\nfor i in range(len(x_label_list)):\n    for j in range(len(y_label_list)):\n        text = ax.text(j, i, round(S[j,i],3),fontsize=5,\n                       ha=\"center\", va=\"center\", color=\"w\")\n\n# Imposer un angle de rotation pour faciliter la lecture des #labels en abscisses\n\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\nplt.show()</code></pre><p>Voilà le résultat !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"461\" height=\"419\" src=\"https://larevueia.fr/wp-content/uploads/2020/05/sim_fruits.png\" alt=\"Introduction au NLP avec Python\" class=\"wp-image-465\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/05/sim_fruits.png 461w, https://larevueia.fr/wp-content/uploads/2020/05/sim_fruits-300x273.png 300w\" sizes=\"auto, (max-width: 461px) 100vw, 461px\"></figure></div><p><br>A l’échelle d’un mot ou de phrases courtes la compréhension pour une machine est aujourd’hui assez facile (même si certaines subtilités de langages restent difficiles à saisir). Néanmoins, pour des phrases plus longues ou pour un paragraphe, les choses sont beaucoup moins évidentes. Et on utilise souvent des modèles de <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" data-type=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">réseaux de neurones</a> comme les LSTM.</p><p>L’algorithme doit être capable de prendre en compte les liens entre les différents mots. Il se trouve que le passage de la sémantique des mots obtenue grâce aux modèles comme Word2vec, à une compréhension syntaxique est difficile à surmonter pour un algorithme simple. Les chatbots qui nous entourent sont très souvent rien d’autre qu’une succession d’instructions empilées de façon astucieuse.</p><p>Néanmoins, le fait que le NLP soit l’un des domaines de recherches les plus actifs en machine learning, laisse penser que les modèles ne cesseront de s’améliorer. Peut-être que nous aurons un jour un chatbot capable de comprendre réellement le langage.</p></div>"},
{"url": "https://larevueia.fr/quels-liens-entre-blockchain-et-intelligence-artificielle/", "title": "Quels liens entre blockchain et intelligence artificielle ?", "author": "Ilyes Talbi", "date": "\n24 mars 2022\n", "content": "<div class=\"entry-content\"><p>Il y a 3 ans, après la <a href=\"https://larevueia.fr/compte-rendu-de-la-tech-expo-2019-a-la-silicon-valley/\" target=\"_blank\" rel=\"noreferrer noopener\">tech expo</a> de San Francisco, je décrivais la blockchain comme une technologie prometteuse mais qui trouverait difficilement des applications en dehors du monde de la finance.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Quels liens entre blockchain et intelligence artificielle ?\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Heureusement, j’ai grandi depuis !</p><p>Le monde de la blockchain aussi d’ailleurs.</p><p>Il a tellement grandi qu’il peut maintenant nous aider à révolutionner l’intelligence artificielle; et c’est le sujet de notre article!</p><h2 class=\"wp-block-heading\">Lexique</h2><p>Comme pour toutes les technologies de pointes, il est parfois difficile de bien comprendre le lexique.  Pour clarifier cet aspect, la première section me permettra de définir les différents termes utilisés.</p><p>Vous pouvez passer si vous connaissez déjà.</p><h3 class=\"wp-block-heading\">Qu’est-ce que le web3 ?</h3><p>Plus qu’une nouvelle technologie, le web3 constitue une veritable révolution, un changement de paradigme dans le monde du web.</p><h4 class=\"wp-block-heading\">Web1, web2</h4><p>Pour mieux comprendre le web3.0, il convient de revenir dans le temps et de reprendre les différentes phases du web.</p><p>Initialement, internet était une encyclopédie en ligne qui permettait de consulter l’information mais sans contenu interactif. Le contenu se limitait aux textes ou aux images légères. La connexion était incroyablement lente, télécharger une musique vous aurez pris une journée complète.</p><p>Je suis trop jeune pour avoir connu le web1, par contre, je connais très bien le web2, ses avantages, ses limites et ses dangers.</p><p>Le web2 est le web des cookies. En plus de lire et consommer le contenu, on peut interagir avec. Les sites peuvent collecter nos données d’utilisation pour nous envoyer des publicités ciblées, on peut payer en ligne et interagir avec les autres utilisateurs.</p><p>L’amélioration des infrastructures de connexion à internet, notamment grâce à la fibre optique, la 3G et la 4G, a permis de proposer un contenu plus diversifié, avec les vidéos, les sons, des images de meilleurs qualité et même du contenu 3D.</p><p>Le web2 est l’âge des réseaux sociaux, on ne consulte plus seulement internet, on y participe.</p><p>L’augmentation considérable du nombre d’utilisateurs a entraîné une explosion de la quantité de données générées par le web2.0, à tel point que les données des internautes sont devenus la base du business model de beaucoup de géants de la tech.</p><p>Le web2.0 est le symbole de la centralisation, une poignée d’entreprises contrôlent la data, et le monde digital. Les données de plus de 80% de la population sont stockées dans les data centers de Google, d’Amazon, de Twitter, …</p><p></p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Internet is broken</em></p>\n<cite>Gavin Wood, Co-founder d’Eth</cite></blockquote><p></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Silicon Valley - Richard Hendricks speech to Congress\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/lXyeZA54bko?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div><figcaption>L’internet décentralisé selon Richard Hendricks</figcaption></figure><p>Toutes ces raisons nous poussent à nous révolter. Comme dans l’Amérique de 1776, l’heure de faire tomber les rois est arrivée…</p><p>… non jrigole…</p><p>… mais bon, on va quand même proposer une alternative au cas où 👀</p><h4 class=\"wp-block-heading\">Le web 3.0</h4><p>Le web3.0 reprend le principe du peer to peer, ou <em>décentralisation</em>, sur lequel la blockchain repose.</p><p>Plutôt que les données soient centralisées dans les data center de grosses entreprises, elles sont stockées de façon décentralisée et en plusieurs morceaux, et réparties entre tous les participants du réseaux.</p><h3 class=\"wp-block-heading\">Qu’est-ce qu’un NFT ?</h3><p>Un NFT, ou Non Fungible Token, est un actif digital qui prend la forme d’une image, un son, une vidéo, etc.</p><p>Il est rattaché à au moins un propriétaire via une identité numérique (wallet). À chaque NFT est associé des méta données qui contiennent ses informations de bases, comme les identités du propriétaire et du créateur.</p><p>Ces méta données sont inscrites dans une blockchain, qui permet de sécuriser et rendre plus transparentes les transactions de NFT.</p><p>Même si l’utilisation de base des NFT est purement artistique, ils ont énormément d’applications dans différentes industries. LVMH par exemple, associe chaque sac à main de luxe à un NFT que le propriétaire du sac transfère à l’acheteur s’il le lui revend. Cela permet de luter contre les contrefaçons.</p><p></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.therealtatooine.io/\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/03/Capture-de%CC%81cran-2022-03-17-a%CC%80-16.07.23-1024x478.png\" alt=\"Quels liens entre blockchain et intelligence artificielle ?\" class=\"wp-image-4762\" width=\"483\" height=\"226\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/03/Capture-décran-2022-03-17-à-16.07.23-1024x478.png 1024w, https://larevueia.fr/wp-content/uploads/2022/03/Capture-décran-2022-03-17-à-16.07.23-300x140.png 300w, https://larevueia.fr/wp-content/uploads/2022/03/Capture-décran-2022-03-17-à-16.07.23-768x358.png 768w, https://larevueia.fr/wp-content/uploads/2022/03/Capture-décran-2022-03-17-à-16.07.23.png 1312w\" sizes=\"auto, (max-width: 483px) 100vw, 483px\"></a></figure></div><p></p><h3 class=\"wp-block-heading\">Qu’est-ce que le metavers ?</h3><p>Le web3 et les NFT vont tous les deux contribués à la conception de <em>métavers</em>.</p><p>Les métavers, mis sous le feu des projecteurs par Zuckerberg le CEO de Meta (ex Facebook), sont des espaces virtuels qui vont créer de nouvelles formes d’interactions entre les utilisateurs.</p><p>C’est une nouvelle forme d’internet qui se rapproche plus de la réalité. On peut assister à des évènements virtuels complètement recréés en 3D (comme des concerts ou des mariages), on peut regarder des évènements sportifs de façon plus immersive, travailler entre collègues, étudier depuis chez soi avec un casque VR, etc.</p><p>C’est vrai que ça peut faire peur dit comme ça, mais bon, si on créé pas notre metavers on se baladera dans le metavers de quelqu’un d’autre (comme Baidu par exemple 👀).</p><h2 class=\"wp-block-heading\">L’IA au service de la blockchain</h2><p>Les applications de l’intelligence artificielle pour toutes les technologies qui reposent sur la blockchain sont nombreuses.</p><p>L’IA intervient dans le trading de cryptomonnaies, dans la génération de NFT ou encore pour la construction du metavers.</p><h3 class=\"wp-block-heading\">Trading de cryptomonnaies</h3><p>J’ai hésité à commencer par cette application, de peur d’alimenter encore plus le raccourci blockchain=cryptomonnaies, mais bon comme mes lecteurs sont intelligents je la met quand même 🙂</p><p>Les cryptomonnaies sont réputées pour leur forte volatilité qui rend très difficile les prédictions. Néanmoins, certaines techniques d’analyse de séries temporelles comme les LSTM permettent de prédire les tendances du marché, même si les modèles sont beaucoup moins performants que pour la bourse.</p><p>Tapez « bitcoin LSTM » sur Google.</p><h3 class=\"wp-block-heading\">Génération automatique de NFT</h3><p>Une des applications de l’intelligence artificielle utilise la génération automatique d’objets d’art digitaux. Même si la technique existe depuis longtemps, elle a pris de l’ampleur avec l’explosion des NFT, qui rendent beaucoup plus simple la revente de ses créations digitales.</p><p>En pratique on utilise souvent des <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones-gan/\" target=\"_blank\" rel=\"noreferrer noopener\">réseaux GAN</a>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"664\" height=\"452\" src=\"https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted.png\" alt=\"Quels liens entre blockchain et intelligence artificielle ?\" class=\"wp-image-4813\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted.png 664w, https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted-300x204.png 300w, https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted-535x364.png 535w\" sizes=\"auto, (max-width: 664px) 100vw, 664px\"></figure></div><h3 class=\"wp-block-heading\">Reconstruction 3D d’objets pour le metaverse</h3><p>En plus de permettre de générer des NFT, la vision par ordinateur permet de modéliser des objets du monde réelles en 3D beaucoup plus facilement.</p><p>Les metavers vont recréer un environnement qui soit le plus réaliste possible. Pour permettre cela, on doit être capable de reproduire des objets et des formes complexes de façon systématique et rapide, sans être obligé de remodéliser à chaque fois.</p><p>Aujourd’hui, les meilleurs modèles de reconstruction 3D sont capable de modéliser un objet de façon plutôt réaliste à partir de 2 ou 3 photos.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/03/acai2020-25-fig1.jpeg\" alt=\"3D reconstruction metavers\" class=\"wp-image-4816\" width=\"591\" height=\"314\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/03/acai2020-25-fig1.jpeg 493w, https://larevueia.fr/wp-content/uploads/2022/03/acai2020-25-fig1-300x159.jpeg 300w\" sizes=\"auto, (max-width: 591px) 100vw, 591px\"><figcaption class=\"wp-element-caption\">Exemple de reconstruction 3D à partir d’une seule image</figcaption></figure></div><p>J’ai parlé de la reconstruction 3D dans un <a href=\"https://larevueia.fr/focus-sur-6-sous-domaines-de-la-computer-vision-et-leurs-applications/\" target=\"_blank\" rel=\"noreferrer noopener\">précédent article</a>.</p><h2 class=\"wp-block-heading\">La blockchain au service de l’IA</h2><p>Les utilisations de l’intelligence artificielle pour la blockchain étaient faciles à trouver, l’IA étant déjà assez mâture et la recherche sur ce sujet est déjà en place.</p><p>Néanmoins, les applications de la blockchain au service de l’IA sont moins évidentes, bien qu’un domaine entier de l’intelligence artificielle, qu’on appelle <em><a href=\"https://larevueia.fr/quest-ce-que-lintelligence-artificielle-decentralisee/\" target=\"_blank\" rel=\"noreferrer noopener\">IA décentralisée</a></em> est en train de se créer.</p><p>L’IA décentralisée est issue du besoin de sécuriser les données utilisées pour entraîner un modèle. Le stockage décentralisée et crypté permet d’assurer la sécurité des données et d’éviter les falsifications ou les pertes.</p><h3 class=\"wp-block-heading\">Traçabilité des données</h3><p>La blockchain peut améliorer la traçabilité des données.</p><p>La force de la blockchain aujourd’hui réside dans sa sécurité. C’est ce qui la rend utilisable pour de grosses transactions financières.</p><p>Lorsque l’on entraîne un modèle d’intelligence artificielle, on a besoin de valider la provenance du dataset. D’une part pour mieux évaluer la qualité des données et éviter d’entraîner une IA biaisée, d’autre part pour nous assurer que les données ont été rassemblées en conformité avec les réglementations en vigueurs.</p><p>Je ne pense pas que la solution existe déjà, mais j’imagine bien une plateforme décentralisée d’échange de dataset qui fonctionnerait avec des NFT. Lorsque l’on transfère un dataset, on transfère un NFT associé.</p><p>Ce fonctionnement permettrait à tout moment de vérifier la provenance du dataset et de remonter jusqu’a sa création. Chaque action réalisée sur le dataset pourra être enregistrée et visible.</p><h3 class=\"wp-block-heading\">Sharing Updatable Models sur la blockchain</h3><p>Toujours dans l’optique de rendre l’utilisation et l’entraînement des modèles plus éthiques, la blockchain peut offrir plus de transparence quant aux modèles qui sont proposés sur les différentes plateformes et faciliter la collaboration.</p><p>Ainsi, Microsoft à créée un framework, Sharing Updatable Models, pour la maintenance collaborative de modèles de machine learning.</p><p>Le modèle de machine learning est initialement construit via un smart contract sur la blockchain Etherum et il est en accès libre, vous pouvez l’utiliser en payant les gas fee du réseau.</p><p>L’utilisateur peut ensuite modifier le modèle, ou ajouter des données d’entraînement pour le rendre plus robuste. Les modifications sont ensuite testées de façon automatisée, à partir d’un dataset de test initial qui reste lui inchangé. Si elles ont contribuées positivement aux performances du modèle l’utilisateur est récompensé, sinon il est pénalisé.</p><p>Les récompenses sont donnés soit sous formes de points sur la plateforme, soit sous forme de compensation financière. Le principe de points ressemble beaucoup à celui de Stackoverflow, et reposent sur les choix des autres utilisateurs de valider ou non les modifications proposées. Les compensations financières sont calculées via un autre smart contract public, et repose sur plusieurs critères comme le gain de performance ou la taille du dataset apporté.</p><p>Comme souvent dans le monde de la blockchain et du web3, le succès de ce type de projets repose sur la capacité à créer une communauté dévouée et de confiance.</p><p>Pour plus d’info je vous invite à lire <a href=\"https://www.microsoft.com/en-us/research/blog/leveraging-blockchain-to-make-machine-learning-models-more-accessible/\" target=\"_blank\" rel=\"noreferrer noopener\">l’article</a> de blog sur le site de Microsoft. Les plus courageux peuvent regarder le papier de recherche directement, <a href=\"https://arxiv.org/pdf/1907.07247.pdf\" target=\"_blank\" rel=\"noreferrer noopener\">Decentralized &amp; collaborative AI on blockchain</a>.</p><p></p><p>Les enjeux liés à l’intelligence artificielle et la blockchain dépassent le cadre purement technologique et vont remettre en cause toute l’économie du web. La fin des cookies implique la fin des publicités ciblées et donc la remise en cause des business model de plusieurs géants de la tech.</p><p>L’IA, comme dans tous les domaines, sera un outil important dans le nouveau monde. Aussi bien pour sa construction que pour sa maintenance.</p><p>Inversement, la blockchain va rendre l’IA plus sécurisée, plus éthique et plus collaborative, on parlera d’<em>IA décentralisée</em>. Des problèmes importants, comme l’anonymisation des données de certaines industries, qui restent jusqu’aujourd’hui difficile à traiter, pourraient être résolus via la blockchain.</p></div>"},
{"url": "https://larevueia.fr/classification-de-tweets-en-direct-avec-apache-kafka-et-tweepy/", "title": "Tutoriel Apache Kafka : classification de tweets en direct", "author": "Walid Chrimni", "date": "\n18 mai 2022\n", "content": "<div class=\"entry-content\"><p><em>Dans cet article, on vous explique comment utiliser apache Kafka pour faire de la classification de tweets en direct.</em></p><p>Depuis 3 ans, une grande quantité de tweets sur la Covid-19 a été posté sur Twitter. On y retrouve des news, des réflexions, l’expression de sentiments ou d’opinion et tant d’autres choses. Et depuis, cela ne s’arrête pas.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Le but de cet article est de tirer parti de cette quantité d’information immense et accessible afin de faire de la classification de tweets en direct, c’est-à-dire que nous allons récupérer les tweets qui ont été postés dans les dernières secondes, et les classifier selon leur topic.</p><p>Pour cela, nous allons utiliser Apache Kafka ainsi qu’une libraire python qui se nomme Tweepy. Kafka est défini par ses créateurs comme <em>une plateforme open-source de streaming d’événements distribués utilisée par des milliers d’entreprises pour des pipelines de données haute performance, des analyses en continu, l’intégration de données et des applications critiques</em>.</p><p>En d’autres termes, cela permet de mettre en contact des <em>Producers</em> (ici ceux qui tweetent) avec des <em>Consumers</em> (ici ceux qui lisent les tweets ou bien dans notre cas précis, notre algorithme qui va récupérer les tweets) via des <em>Topics</em> en temps réel. C’est un système de messagerie distribué à haut débit. C’est une technologie utilisée notamment par Twitter, Linkedin, Uber, AirBnB et Netflix.</p><p>Commençons sans plus tarder !</p><h2 class=\"wp-block-heading\">Installer Apache Kafka</h2><p>Pour installer Kafka, je vous recommande de passer par Docker. Si vous n’avez pas Docker, il suffit de télécharger et installer Docker Desktop <a href=\"https://www.docker.com/get-started/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. Une fois que l’installation est terminée, vous pouvez utiliser Docker via votre terminal de commande. D’abord, il faut copier la cellule suivante dans un fichier texte que vous nommez <code>docker-compose.yml</code></p><pre class=\"wp-block-code\"><code>version: '3'\nservices:\n  zookeeper:\n    image: confluentinc/cp-zookeeper:6.2.0\n    container_name: zookeeper\n    environment:\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n\n  broker:\n    image: confluentinc/cp-kafka:6.2.0\n    container_name: broker\n    ports:\n    # To learn about configuring Kafka for access across networks see\n    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/\n      - \"9092:9092\"\n    depends_on:\n      - zookeeper\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1</code></pre><p>Une fois que c’est fait, ouvrez votre terminal de commande, naviguez jusqu’au dossier où vous avez sauvegardé <code>docker-compose.yml</code> et lancez la commande suivante :</p><pre class=\"wp-block-code\"><code>docker-compose -f docker-compose.yml up -d\n</code></pre><p>Un téléchargement devrait se lancer. Une fois qu’il est terminé, lancez la commander <code>docker ps</code> pour vérifier que tout s’est bien lancé :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"211\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-1024x211.png\" alt=\"installation d'apache kafka\" class=\"wp-image-5162\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-1024x211.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-300x62.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-768x158.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-1536x317.png 1536w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3.png 1538w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption> Sortie obtenue avec docker ps</figcaption></figure><p>Vous pouvez également lancer Kafka via Docker en vous rendant dans l’onglet <code>Containers/Apps</code> de Docker :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"233\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/docker-1-1024x233.png\" alt=\"apache kafka est lancé\" class=\"wp-image-5163\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/docker-1-1024x233.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-300x68.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-768x175.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-1536x349.png 1536w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-2048x466.png 2048w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Onglet Containers/Apps dans docker</figcaption></figure><p>Il faut à présent créer un Topic, c’est-à-dire une catégorie où l’on va stocker les messages (ici les tweets) envoyés par le Producer. Comme nous allons récupérer des tweets sur la Covid-19, nous allons nommer notre topic <code>covid</code>. Pour ce faire, il suffit de lancer la commande suivante dans le terminal en ayant Docker lancé (vous pouvez vérifier que c’est le cas dans l’onglet Containers/Apps de Docker) :</p><pre class=\"wp-block-code\"><code>docker exec broker kafka-topics --bootstrap-server localhost:9092 --create --topic covid</code></pre><p>Un message indiquant <code>Created topic covid.</code> devrait alors s’afficher. Si vous êtes arrivé jusque là, vous avez fait le plus dur !</p><p>Afin d’interagir avec Kafka via Python, il faut télécharger une libraire qui se nomme kafka-python. Pour l’installer : <code>pip install kafka-python </code>dans le terminal de commande.</p><h2 class=\"wp-block-heading\">Tweepy et l’API Twitter</h2><p>Pour pouvoir récupérer des tweets avec Kafka et Python, il nous faut passer par l’API Twitter. Pour cela, vous devez au préalable disposer d’un compte Twitter. Il vous faudra ensuite vous rendre <a href=\"https://developer.twitter.com/en\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a> et vous connecter pour activer votre compte développeur.</p><p>Il se peut que vous ayez à remplir quelques questions rapides (prénom, pays de résidence,…) ainsi qu’à valider votre compte développeur par mail. Une fois que c’est fait, il vous est demandé de choisir le nom de votre application :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"587\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/get_keys-1024x587.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5127\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/get_keys-1024x587.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-300x172.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-768x440.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-1536x880.png 1536w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-2048x1174.png 2048w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Twitter Developer Platform</figcaption></figure><p>Dès que vous validez, vous avez accès à vos tokens de connexion à l’API. Gardez les en lieu sûr, on les utilisera juste après.</p><h2 class=\"wp-block-heading\">Récupérer les tweets en direct avec Apache Kafka</h2><p>À présent, nous allons écrire le script python qui va nous permettre de récupérer les tweets en direct. D’abord, on importe les librairies dont on aura besoin :</p><pre class=\"wp-block-code\"><code>from kafka import KafkaProducer\nimport tweepy\nimport datetime\nimport time\nimport json\n</code></pre><p>KafkaProducer va nous permettre d’envoyer les tweets à Kafka (et on les récupérera plus tard avec KafkaConsumer). Tweepy permet de se connecter à l’API Twitter. Les autres modules nous seront utiles pour certaines manipulations.</p><p>Nous allons nous connecter à l’API Twitter avec la classe <code>Client </code>de <a href=\"https://larevueia.fr/nlp-avec-python-analyse-de-sentiments-sur-twitter/\" target=\"_blank\" rel=\"noreferrer noopener\">Tweepy</a>. On aura pour cela besoin du BearerToken que vous avez mis de côté précédemment. Nous allons également initialiser un objet de la classe KafkaProducer :</p><pre class=\"wp-block-code\"><code>client = tweepy.Client(bearer_token=\"PLACER_VOTRE_BEARER_TOKEN_ICI\")\nproducer = KafkaProducer()\nquery = \"covid\"</code></pre><p>On définit également la query, c’est-à-dire le mot que l’on veut chercher dans tous les tweets. Pour nous, ce sera « covid », mais vous pouvez essayer d’autres mots ou séries de mots si vous le voulez ! Nous allons récupérer les tweets anglais puisqu’ils sont plus nombreux et que nous allons utiliser un modèle entrainé sur des tweets anglais.</p><p>Avec tweepy, on ne peut récolter que les tweets qui datent d’au moins 10 secondes. Pour être sûr de respecter ce délai (et comme j’ai rencontré des problèmes même en prenant 15 secondes), nous allons prendre 30 secondes. Nous allons donc régler le temps de début de récolte des tweets à 40 secondes du temps actuel, et la fin à 30 secondes.</p><p>On utilise la méthode <code>search_recent_tweets</code> pour récolter les tweets les plus récents. Nous sommes limités à 100 par appel de la méthode, nous allons donc nous limiter à 100 tweets. Enfin, on spécifie les champs que l’on veut récolter via le paramètre <code>tweet_fields</code> : le corps du tweet, sa date de création ainsi que sa langue :</p><pre class=\"wp-block-code\"><code>start_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=40)\nend_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=10)\n\ntweets = client.search_recent_tweets(query=query,\n                                        tweet_fields=['context_annotations', 'created_at', 'lang'], \n                                        max_results=100, \n                                        start_time=start_time,\n                                        end_time=end_time)\nstart_time = end_time\nend_time = start_time + datetime.timedelta(seconds=10)\n</code></pre><p>Puis on récupère le contenu des tweets en sélectionnant uniquement les tweets anglais, on envoie les tweets sur Kafka et on affiche un message pour indiquer que tout s’est bien passé.</p><pre class=\"wp-block-code\"><code>for i,tweet in enumerate(tweets.data):\n  if tweet.lang == 'en':\n    tweet = json.dumps(tweet.text).encode('utf-8')\n    producer.send('covid', tweet)\n    print(f'Le {i}ème tweet a été envoyé à Kafka avec succès!')\n\n    </code></pre><p>On ajoute une boucle <code>while</code> pour répéter le processus sans arrêt. On fait une pause de 10 secondes pour ne pas avoir une redondance dans les tweets récupérés : Le script complet :</p><pre class=\"wp-block-code\"><code>from kafka import KafkaProducer\nimport tweepy\nimport datetime\nimport time\nimport json\n\nclient = tweepy.Client(bearer_token='PLACER_VOTRE_BEARER_TOKEN_ICI')\nproducer = KafkaProducer()\n# producer.flush()\nquery = 'covid'\nstart_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=40)\nend_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=30)\n\nwhile True:\n\n    tweets = client.search_recent_tweets(query=query,\n                                        tweet_fields=['context_annotations', 'created_at', 'lang'], \n                                        max_results=100, \n                                        start_time=start_time,\n                                        end_time=end_time)\n    start_time = end_time\n    end_time = start_time + datetime.timedelta(seconds=10)\n\n    for i,tweet in enumerate(tweets.data):\n        if tweet.lang == 'en':\n            tweet = json.dumps(tweet.text).encode('utf-8')\n            producer.send('covid', tweet)\n        print(f'Le {i}ème tweet a été envoyé à Kafka avec succès!')\n    print('Pause de 10 secondes!')\n    time.sleep(10)</code></pre><p>En lançant le script, on obtient le message que les tweets ont bien été envoyés à Kafka. Toutes les 10 secondes, une centaine de tweet sont envoyés à Kafka au topic « covid ». Il faut maintenant les récupérer pour pouvoir les utiliser ultérieurement. <strong>Il est indispensable que ce script soit lancé lorsque vous réaliserez les parties suivantes !</strong> Je vous conseille de le lancer via le terminal de votre PC en ouvrant un terminal au niveau de votre script et en lancant <code>python nom_de_votre_script.py</code></p><h2 class=\"wp-block-heading\">Nuage de mots</h2><p>Faisons tout d’abord un nuage de mots des tweets que nous avons récupéré. Cela nous permettra de voir quels sont les mots les plus récurrents. D’abord nous allons définir une fonction pour nettoyer et préparer nos tweets. Comme d’habitude, si vous n’avez pas la librairie nltk, faites <code>pip install nltk</code>.</p><pre class=\"wp-block-code\"><code>from nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nimport string\n\ndef pre_process_tweet(tweet):\n    tokenizer = RegexpTokenizer(r'\\w+')\n    lemmatizer = WordNetLemmatizer()\n    # tokenize and remove stop words and number\n    tweet_tokens = tokenizer.tokenize(tweet)[1:]\n    tweet_tokens = [word for word in tweet_tokens if word.isalpha()]\n    tweet_tokens = [word for word in tweet_tokens if word.lower() != 'rt']\n    tweet = \" \".join([word for word in tweet_tokens if word not in stopwords.words('french')])\n\n    # remove \\n from the end after every sentence\n    tweet = tweet.strip('\\n')\n\n    # Remove any word that starts with the symbol @\n    tweet = \" \".join(filter(lambda x: x[0] != '@', tweet.split()))\n\n    # remove non utf-8 characters\n    tweet = bytes(tweet, 'utf-8').decode('utf-8','ignore')\n\n    # Remove any URL\n    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n    tweet = re.sub(r\"www\\S+\", \"\", tweet)\n\n    # remove colons from the end of the sentences (if any) after removing url\n    tweet = tweet.strip()\n    tweet_len = len(tweet)\n    if tweet_len &gt; 0:\n        if tweet[len(tweet) - 1] == ':':\n            tweet = tweet[:len(tweet) - 1]\n\n    # Remove any hash-tags symbols\n    tweet = tweet.replace('#', '')\n\n    # Convert every word to lowercase\n    tweet = tweet.lower()\n\n    # remove punctuations\n    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n\n    # trim extra spaces\n    tweet = \" \".join(tweet.split())\n\n    # lematize words\n    tweet = lemmatizer.lemmatize(tweet)\n\n    return(tweet)</code></pre><p>Parmi les opérations effectuées : tokenization, lemmatization (prendre la racine d’un mot), suppression des url, de la ponctuation, des symboles, …</p><p>Pour créer notre nuage de mots, nous allons utiliser la librairie <code>wordcloud</code>. Si elle n’est pas installée sur votre machine, faites simplement <code>pip install wordcloud.</code> Pour récupérer les tweets qui ont été envoyé sur le <em>topic </em>« covid », nous allons initialiser un <em>Consumer </em>avec le paramètre « covid » (le nom du topic) :</p><pre class=\"wp-block-code\"><code>from wordcloud import WordCloud\nfrom kafka import KafkaConsumer\nconsumer = KafkaConsumer(\"covid\")</code></pre><p>Nous allons d’abord récupérer les 50 premiers tweets et construire le wordcloud avec les mots qu’ils contiennent. Pour cela, nous allons concaténer tous les tweets dans la chaine de caractère nommée <code>total_sentences</code>. Nous allons ajouter un <em>mask</em> afin de donner à notre nuage de point la forme du logo Twitter.  Pour ce faire, télécharger l’image <a href=\"https://i.goopics.net/6jle2q.jpg\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>, nommez la « twitter_logo.jpg » et placer-là dans le même dossier que votre script/notebook. Vous pouvez vous amuser en modifiant les paramètres du nuage de mots pour obtenir des résultats differents.</p><pre class=\"wp-block-code\"><code>import numpy as np\nfrom PIL import Image\nimport json\nimport numpy as np\nfrom PIL import Image\nimport json\nimport matplotlib.pyplot as plt\n\ntotal_sentences = \"\"\ntwitter_mask = np.array(Image.open(\"twitter_logo.jpg\"))\nfor i in range(50):\n        tweet = json.loads(next(iter(consumer)).value)\n        clean_tweet = pre_process_tweet(tweet=tweet)\n        total_sentences += clean_tweet\n        total_sentences += \" \"\nwordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100, mask=twitter_mask, \ncontour_color=\"steelblue\", contour_width=0, background_color=\"white\").generate(total_sentences)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()</code></pre><p>Le code peut prendre un peu de temps à se lancer. Kafka peut parfois être capricieux, si vous utilisez une notebook, n’hésitez pas à réinstancier votre Consumer avant de lancer une cellule. J’ai effectué le nuage de mots en français pour que cela soit plus parlant (et car on n’a pas besoin d’utiliser le modèle entrainé sur les tweets anglais), mais je passerai à l’anglais à partir de maintenant. Vous devriez obtenir quelque chose semblable à ceci :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/wordcloud.png\" alt=\"Nuage de mots obtenu avec des tweets français, tweepy\" class=\"wp-image-5128\" width=\"669\" height=\"513\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/wordcloud.png 585w, https://larevueia.fr/wp-content/uploads/2022/05/wordcloud-300x230.png 300w\" sizes=\"auto, (max-width: 669px) 100vw, 669px\"><figcaption>Nuage de mots obtenu avec des tweets français</figcaption></figure></div><p>On obtient des mots qui sont bien liés au covid et qu’on a beaucoup entendus ces dernières années : morts, vaccin, olivier veran, épidémie, …</p><p>Vous n’obtiendrez pas exactement la même chose que moi car les tweets que vous allez récupérer sont différents des miens. On peut modifier le code pour actualiser le nuage de mots avec les nouveaux tweets toutes les 5 secondes :</p><pre class=\"wp-block-code\"><code>import numpy as np\nfrom PIL import Image\nimport json\nimport numpy as np\nfrom PIL import Image\nimport json\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15,8))\ntwitter_mask = np.array(Image.open(\"img_notebook/twitter_logo.jpg\"))\ntotal_sentences = \"\"\nwhile True:\n    for i in range(10):\n        tweet = json.loads(next(iter(consumer)).value)\n        clean_tweet = pre_process_tweet(tweet=tweet)\n        total_sentences += clean_tweet\n        total_sentences += \" \"\n    wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100, mask=twitter_mask, \n    contour_color=\"steelblue\", contour_width=0, background_color=\"white\").generate(total_sentences)\n\n    # plot the graph\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    plt.pause(5)\n    clear_output(wait=True)\n    plt.figure(figsize=(15,8))</code></pre><p>Il est important de noter que nous aurions pu effectuer ces manipulations et obtenir ce nuage de mots sans passer par Apache Kafka, uniquement avec l’API Twitter. Nous n’avons pas utilisé tout le potentiel de Kafka. Nous pourrions par exemple récupérer les tweets avec différents scripts donc chacun serait indépendant et aurait un but différent : créer un wordcloud dynamique, classifier les tweets, prévenir l’utilisateur dès lors qu’un certains type de tweet est détecté, ou qu’un utilisateur en particulier poste un tweet, …Il est également possible d’envoyer les tweets vers différents topics en même temps et les récupérer sur différents scripts pour différentes utilisations.</p><p>Ici, la force de Kafka que l’on utilise est que les tweets sont récupérés et envoyés dans un topic Kafka de manière indépendante de tous les autres scripts. Ainsi, en initialisant un <em>Consumer</em> avec le topic « covid », nous pouvons récupérez tous les tweets qui ont été envoyé sur Kafka peu import où l’on se trouve sur la machine.</p><h2 class=\"wp-block-heading\">Création des topics</h2><p>Nous passons maintenant à la partie Machine Learning de l’article ! Afin de déterminer les topics dans lesquels nous allons classer nos tweets, nous allons récupérer 20 000 tweets, puis, après les avoir nettoyés, nous allons déterminer les 10 sujets les plus récurrents.  Pour transformer nos tweets (qui sont des chaines de caractères), en inputs compréhensibles pour l’ordinateur (des chiffres), nous allons utiliser word2vec. Je vous en ai déjà parlé dans un article précédent <a href=\"https://larevueia.fr/quest-ce-que-le-nlp-natural-language-processing/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. Nous allons utiliser un modèle qui a été pré-entrainé sur plus de 400M de tweets anglais. Vous pouvez le télécharger <a href=\"https://mega.nz/file/h0VCxDQJ#RD11bJvp6NbEfFLGKe0H7ZGDgppz7-95LDNpep5vP2s\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a> (attention, il est assez volumineux). Pour le charger, nous utilisons gensim :</p><pre class=\"wp-block-code\"><code>model = gensim.models.KeyedVectors.load_word2vec_format('word2vec_twitter_model.bin', binary=True, unicode_errors='ignore')\n</code></pre><p>Ce modèle transforme chaque tweet en un vecteur de taille 400. Le script suivant permet de récupérer 20000 tweets. <code>tweet_embeddings</code> est un tableau qui contient l’embedding de chaque tweet, et <code>text_data</code> contient les tweets bruts.</p><pre class=\"wp-block-code\"><code># n_sample = 20000\n# tweets_embeddings = np.zeros((n_sample, 400))\n# text_data = []\n# row = 0\n\n# for tweet in consumer:\n#     if row == n_sample:\n#         break\n#     tweet = json.loads(tweet.value)\n#     clean_tweet = pre_process_tweet(tweet)\n#     embeddings = get_word2vec_embeddings(model=model, tokenizer=tokenizer, sentence=clean_tweet, k=400)\n#     if np.isnan(embeddings).sum() == 0:\n#         tweets_embeddings[row,:] = embeddings\n#         text_data.append(clean_tweet)\n#         row += 1</code></pre><p>Cette étape est relativement longue (environ 1h30). Pour la faire durer moins longtemps, vous pouvez réduire le nombre de tweets à récupérer. Vous pouvez également utiliser les tweets que j’ai moi-même récupérés. Vous pouvez télécharger <code>text_data</code> <a href=\"https://drive.google.com/file/d/1xmzMG6Xt8Rqdxgqk0HJ7kvWxw9SBPHWR/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a> et <code>tweets_embeddings</code> <a href=\"https://drive.google.com/file/d/1Lkqa-2L5-X3lukU5am17D05God28rFPt/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. Il faut ensuite les charger avec la librairie <code>pickle</code> (si vous avez Python 3.9 ou plus, pickle devrait être nativement présent, sinon <code>pip install pickle4</code> ou <code>pip install pickle-mixin</code>.</p><h2 class=\"wp-block-heading\">TF-IDF</h2><p>Afin de déterminer quels sont les topics préponderants dans nos tweets, nous allons utiliser la méthode TF-IDF. Si vous ne savez pas ce que c’est, nous en avons déjà parlé <a href=\"https://larevueia.fr/quest-ce-que-le-nlp-natural-language-processing/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. En quelques mots, TF-IDF compte de manière intelligente le nombre de fois que chaque mot apparaît dans une classe de documents. Si le mot apparaît également dans toutes les autres classes, il n’est probablement pas important (comme « le » ou « un ») et, pour cette raison, il n’est pas considéré comme « fréquent ». Cela nous permet de récupérer les topics les plus pertinents. Pour ce faire, nous allons définir trois fonctions :</p><pre class=\"wp-block-code\"><code>from sklearn.feature_extraction.text import CountVectorizer\n\ndef c_tf_idf(documents, m, ngram_range=(1, 1)):\n    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n    t = count.transform(documents).toarray()\n    w = t.sum(axis=1)\n    tf = np.divide(t.T, w)\n    sum_t = t.sum(axis=0)\n    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n    tf_idf = np.multiply(tf, idf)\n\n    return tf_idf, count\n\ndef extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n    words = count.get_feature_names()\n    labels = list(docs_per_topic.Topic)\n    tf_idf_transposed = tf_idf.T\n    indices = tf_idf_transposed.argsort()[:, -n:]\n    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n    return top_n_words\n\ndef extract_topic_sizes(df):\n    topic_sizes = (df.groupby(['Topic'])\n                     .Doc\n                     .count()\n                     .reset_index()\n                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n                     .sort_values(\"Size\", ascending=False))\n    return topic_sizes</code></pre><p>La fonction <code>c_tf_idf</code> permet d’obtenir le score TF-IDF ainsi que le nombre de mots totaux; <code>extract_top_n_words_per_topic</code> et <code>extract_topic_sizes</code> donnent respectivement les n mots avec le score TF-IDF le plus élévé et la taille de chaque topic. Pour déterminer les topics, nous utilisons un modèle K-Means de scikit-learn que nous entrainons avec nos 20000 tweets. Nous choisissons 15 clusters pour avoir 15 topics. Vous pouvez choisir plus ou moins, en fonction du nombre de topics que vous désirez.</p><pre class=\"wp-block-code\"><code>from sklearn.cluster import MiniBatchKMeans\n\nn_clusters=15\ncluster = MiniBatchKMeans(n_clusters=n_clusters, random_state=0).fit(tweets_embeddings)\n</code></pre><p>Pour chaque cluster, nous regroupons tous les tweets en un seul gros tweet afin de pouvoir effectuer le comptage TF-IDF. Ensuite, pour chaque classe, nous récupérons les n premiers mots ayant le score TF-IDF le plus élevé, puis, pour chaque classe, nous choisissons le mot ayant le score le plus bas. Cette méthode nous permet de récupérer les mots qui apparaissent souvent dans un document mais qui sont en même temps discriminants.</p><pre class=\"wp-block-code\"><code>docs_df = pd.DataFrame(text_data, columns=[\"Doc\"])\ndocs_df['Topic'] = cluster.labels_\ndocs_df['Doc_ID'] = range(len(docs_df))\ndocs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})\n\n  \ntf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(text_data))\ntop_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=10)\ntopic_sizes = extract_topic_sizes(docs_df).set_index('Topic')\ntopic_sizes.head(15)</code></pre><p>Nous pouvons voir nos 15 topics avec la taille de chaque topic (sans le label des topics pour le moment) :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/output1-1.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5143\" width=\"164\" height=\"495\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/output1-1.png 163w, https://larevueia.fr/wp-content/uploads/2022/05/output1-1-99x300.png 99w\" sizes=\"auto, (max-width: 164px) 100vw, 164px\"><figcaption>Numérotation et taille des topics</figcaption></figure></div><p>Pour obtenir le label de chaque topic, nous allons prendre l’élément avec le plus petit score TF-IDF dans <code>top_n_words</code> pour chaque topic :</p><pre class=\"wp-block-code\"><code>data = pd.DataFrame(top_n_words[0][:n_clusters])\ndata['Class'] = [0]*len(data)\nfor i in range(1,len(top_n_words)):\n  data_i = data_0 = pd.DataFrame(top_n_words[i][:1000])\n  data_i['Class'] = [i]*len(data_i)\n  data = data.append(data_i)\ndata = data.sort_values(by=1,ascending=False)\n\nfinal_data = data.drop_duplicates(subset=0).sort_values(by='Class').drop_duplicates(subset='Class',keep='last').rename(columns={0:'label', 1:'TF-IDF score'})\nfinal_data</code></pre><p>Ce qui donne les labels suivants :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"466\" height=\"682\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/output2-1.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5144\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/output2-1.png 466w, https://larevueia.fr/wp-content/uploads/2022/05/output2-1-205x300.png 205w\" sizes=\"auto, (max-width: 466px) 100vw, 466px\"><figcaption>Label et score de chaque topic</figcaption></figure></div><p>On trouve des topics assez parlant comme « vax », « laws » ou « variant », et d’autres un peu moins comme « spouse » ou « like ». C’est néanmoins assez représentatif du covid. Vous pouvez vous amusez à jouer avec le nombre de topics ainsi que le nombre de mots que vous choisissez dans la fonction <code>top_n_words</code> pour obtenir des résultats différents.</p><h2 class=\"wp-block-heading\">Visualisation des topics via PCA</h2><p>Nous pouvons faire une PCA (Analyse par Composantes Principales) pour voir comment se répartissent les différents topics. D’abord, effectuons une PCA en 2D avec scickit-learn. Nous allons faire la PCA sur les embeddings des 20 000 tweets que nous avons récupérés, puis nous allons associer à chaque embedding son topic. Pour cela, nous utilisons seaborn et scikit-learn.</p><pre class=\"wp-block-code\"><code>from sklearn.decomposition import PCA\nimport seaborn as sns\n\npca_2d = PCA(n_components=2)\npca_2d.fit(tweets_embeddings)\npca_2d_data = pd.DataFrame(pca_2d.transform(tweets_embeddings),columns=['FirstComponent','SecondComponent'])\nsns.scatterplot(x=pca_2d_data.FirstComponent,y=pca_2d_data.SecondComponent, \n                hue=[labels_to_class[cluster_label] for cluster_label in cluster.labels_])\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)</code></pre><p>On obtient un résultat assez élégant, les différents topics sont bien séparés !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA2D.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5145\" width=\"652\" height=\"321\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA2D.png 532w, https://larevueia.fr/wp-content/uploads/2022/05/PCA2D-300x148.png 300w\" sizes=\"auto, (max-width: 652px) 100vw, 652px\"><figcaption>Visualisation de la PCA en 2D</figcaption></figure></div><p>Nous pouvons également le faire en 3D pour encore mieux visualiser les embeddings. C’est un peu plus complexe que pour la 2D mais rien de très difficile à comprendre. Nous utilisons plotly :</p><pre class=\"wp-block-code\"><code>import plotly.express as px\n\npca_3d = PCA(n_components=3)\npca_3d.fit(tweets_embeddings)\npca_3d_data = pd.DataFrame(pca_3d.transform(tweets_embeddings),columns=['FirstComponent','SecondComponent','ThirdComponent'])\nx = pca_3d_data.FirstComponent\ny = pca_3d_data.SecondComponent\nz = pca_3d_data.ThirdComponent\n\ndf_3D = pd.DataFrame(columns=['x', 'y', 'z', 'label'])\ndf_3D['x'] = x\ndf_3D['y'] = y\ndf_3D['z'] = z\ndf_3D['label'] = [labels_to_class[cluster_label] for cluster_label in cluster.labels_]\n\nfig = px.scatter_3d(df_3D, x='x', y='y', z='z',\n              color='label')\n\nfig.show()</code></pre><p>Le résultat est encore meilleur ! Lorsque vous le lancez chez vous, pouvez faire bouger le plot avec la souris pour visualiser comme bon vous semble !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-1024x406.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5147\" width=\"794\" height=\"315\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-1024x406.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-300x119.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-768x305.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/PCA3D.png 1134w\" sizes=\"auto, (max-width: 794px) 100vw, 794px\"><figcaption>Visualisation de la PCA en 3D</figcaption></figure></div><p>Vous pourriez avoir l’idée d’utiliser les tweets obtenu via la PCA pour faire la classification (que nous ferons à la prochaine partie), mais cela ne fait que trop réduire l’information, et cela mène à de moins bon résultats. Vous verrez que le modèle se débrouille plutôt bien même avec 400 composantes dans l’embeddings !</p><h2 class=\"wp-block-heading\">Classification en direct des tweets</h2><p>Nous passons dorénavant à la partie Machine Learning avec laquelle vous êtes, je pense, un peu plus à l’aise ! Nous allons utiliser les clusters que nous avons déterminés dans la partie précédente, ainsi que le même MiniBatchKMeans. Chaque fois qu’un tweet est classé, nous le mettons dans un DataFrame qui contient les tweets et leur prédiction. Tous les 100 tweets, nous sauvegarderons ce DataFrame ainsi que notre modèle sous le nom « cluster ». Nous devons d’abord initialiser un Consumer avec le topic « covid ». N’oubliez pas de lancer docker et Kafka avant cette étape si ce n’est pas déjà fait (toujours dans l’onglet Containers/Apps).</p><pre class=\"wp-block-code\"><code>consumer = KafkaConsumer('covid')\n</code></pre><p>Toutes les 100 prédictions, nous affichons un message qui indique que cents tweets supplémentaires ont été classifiés. <strong>Notez bien qu’il faut lancer le script qui récupère les tweets et les envoie sur Kafka avant de lancer la cellule suivante !</strong></p><pre class=\"wp-block-code\"><code>df_predictions = pd.DataFrame(columns=['tweet', 'prediction'])\n\nfor tweet in consumer:\n    row = df_predictions.shape[0]\n    tweet = json.loads(tweet.value)\n    clean_tweet = pre_process_tweet(tweet)\n    embeddings = get_word2vec_embeddings(model=model, tokenizer=tokenizer, sentence=clean_tweet, k=400).reshape(1,-1).astype(np.double)\n    cluster.partial_fit(embeddings)\n    prediction = cluster.predict(embeddings)[0]\n    df_predictions.loc[row, 'tweet'], df_predictions.loc[row, 'prediction'] = tweet, labels_to_class[prediction]\n    sample_score_embeddings[row % 1000, :] = embeddings\n    sample_score_labels[row % 1000, :] = prediction\n    if row % 100 == 0:\n        print(f'{row} tweets ont été classifiés')\n        print(100*'-')\n        with open('cluster', 'wb') as f:\n            pickle.dump(cluster, f)\n        try:\n            df_predictions.to_excel('df_predictions.xls')\n        except:\n            pass</code></pre><p>Le script est conçu pour tourner en continu et ne pas s’arrêter, vous pouvez interrompre son exécution quand vous le voulez, ou le modifier pour qu’il s’arrête lorsque vous le désirez. Voilà un extrait de ce que j’ai obtenu :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"711\" height=\"534\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/final_output.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5155\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/final_output.png 711w, https://larevueia.fr/wp-content/uploads/2022/05/final_output-300x225.png 300w\" sizes=\"auto, (max-width: 711px) 100vw, 711px\"><figcaption>Extrait du dataframe de prédiction final</figcaption></figure></div><p>On retrouve le numéro du tweet classifié (dans l’ordre croissant d’arrivé), le tweet en question et le topic dans lequel il a été classifié.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Ceci conclu notre tutoriel de classification non supervisé de tweet en utilisant Apache Kafka. Il est important de noter que nous n’avons pas exploité Kafka à son plein potentiel dans cet article.</p><p>Nous avons seulement voulu vous introduire cette technologie. Il est possible de faire beaucoup plus, notamment en utilisant différents topics, différents consumers, différents producers, differentes applications, …</p><p>Vous pouvez vous entrainer et développer le potentiel de Kafka sur des données de vélos partagés : <a href=\"https://developer.jcdecaux.com/#/login\" target=\"_blank\" rel=\"noreferrer noopener\">https://developer.jcdecaux.com/#/login</a>. Vous obtiendrez les données de <em>Bike Sharing Systems</em> (comme Vélib à Paris) disponible partout dans le monde. On a, entre autre, le nom de la station, la ville, le nombre de vélos disponibles, le nombre de vélos maximum,… Vous pouvez vous entrainer et vous amusez avec ce jeu de données en direct!</p></div>"},
{"url": "https://larevueia.fr/lintelligence-artificielle-au-service-du-recrutement/", "title": "L’intelligence artificielle au service du recrutement", "author": "Ryan Nursoo", "date": "\n19 juillet 2022\n", "content": "<div class=\"entry-content\"><p>Depuis qu’Alan Turing a introduit la question de la capacité de réflexion des machines en 1950, le paysage technologique de l’intelligence artificielle (IA) a changé.</p><p>L’intelligence artificielle s’est développée depuis des décennies : l’IA symbolique, marquée par la conception de systèmes basés sur la logique, a connu un temps d’arrêt avant sa renaissance dans les années 1970 (<em>AI Winter</em>).</p><p>Depuis 2011, des progrès décisifs ont été réalisés dans le domaine du <a href=\"https://larevueia.fr/le-machine-learning-en-20-questions/\" target=\"_blank\" rel=\"noreferrer noopener\">machine learning</a> et les branches de l’IA qui s’appuient sur des méthodes statistiques, permettant d’améliorer la capacité des machines à faire des prédictions basées sur des données historiques.</p><p>Depuis quelques années, les RH des entreprises s’intéressent à ces nouvelles techniques. Les ressources humaines notamment, se sont armées de logiciels toujours plus performants. Mais comme toute révolution, celle-ci vient avec des aspects positifs et des aspects qui le sont moins.</p><h2 class=\"wp-block-heading\">Un milieu qui évolue</h2><p>Les ressources humaines bénéficient des nombreuses opportunités offertes par l’intelligence artificielle, que ce soit dans le recrutement, la gestion des effectifs ou la communication interne.</p><p>Ces solutions offrent par exemple la possibilité de s’affranchir de certaines tâches répétitives, d’anticiper les besoins en compétences des collaborateurs, de traiter les candidatures de manière plus pertinente ou encore d’optimiser la communication interne via des systèmes intelligents de recherche et de partage de l’information.</p><p>Beaucoup d’acteurs sont d’accord pour dire que l’IA entraîne une évolution plus que positive dans les ressources humaines. En effet : 66 % des PDG pensent que ces technologies peuvent apporter de la valeur aux RH ; 50 % des DRH reconnaissent leur capacité à modifier des aspects majeurs de leur activité ; 54 % pensent que l’IA aura un impact sur les rôles clés des organisations RH.</p><h2 class=\"wp-block-heading\">Les risques et avantages de l’utilisation de l’IA pour le recrutement</h2><p>Toute transformation numérique comporte des risques et des avantages.</p><p>Le principal risque, qui est le plus cité, est que l’IA pourrait entraîner la suppression de certains emplois. Même si le métier de RH reste humain aujourd’hui, les recruteurs interviennent de moins en moins et sont de plus en plus spécialisés.</p><p>Par ailleurs, l’utilisation de l’intelligence artificielle de façon plus éthique. Dans un précédent article nous vous avions parlé de l’entreprise japonaise <strong><em>I’m beside you</em></strong>. Ils utilisent l’intelligence artificielle pour prédire le caractère d’une personne ou pour détecter des formes d’autismes durant les entretiens qui se font en visio.</p><p>Parallèlement, l’utilisation des nouveaux outils numériques permet aux salariés d’acquérir de nouvelles compétences et de s’adapter à de nouvelles formes de travail.</p><p>En pratique, cela aide les RH à se recentrer sur les tâches les plus pertinentes, à les décharger et à se concentrer sur le capital humain. L’intelligence artificielle facilite l’adaptation d’un employé dans une organisation à différentes étapes : recrutement, évolution au sein de l’entreprise, formation.</p><p>L’IA peut être un véritable allié qui permet à l’organisation de se différencier de ses concurrents, d’attirer les talents à fort potentiel et de fidéliser les collaborateurs existants. L’intelligence artificielle est un partenaire idéal pour les employés comme pour les managers car elle les soulage de bon nombre de leurs tâches quotidiennes chronophage.</p><p>L’autonomie des collaborateurs et de l’ensemble de la fonction RH présente des avantages considérables. Investir dans l’IA est un  moyen de développer sa performance, d’affronter un environnement concurrentiel et d’apporter une touche plus humaine à la gestion des ressources humaines.</p><p>Cependant, les responsables RH doivent être conscients que l’inclusion de l’intelligence artificielle dans le processus de recrutement, doit se faire en prenant en compte le fait que c’est un processus humain.</p><p>En fait, du point de vue d’un candidat, de nombreuses préoccupations liées à l’intelligence artificielle se font ressentir, et le fait de laisser à une IA le soin de décider du sort du candidat est effrayant.</p><p>Enfin, les <a href=\"https://larevueia.fr/les-5-plus-gros-fails-de-lintelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">biais</a> de la société ont tendance à être amplifiés par l’intelligence artificielle, comme l’exemple de l’IA d’Amazon qui avait été entraînée avec des données biaisées et qui a considéré qu’il ne fallait recruter que des hommes…</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Bien que l’IA peut aider les recruteurs à différentes étapes de leur processus de recrutement, l’humain doit garder le contrôle de la décision finale.</p><p>Même si cela semble paradoxale, l’IA peut aider à rendre le recrutement plus centré sur l’humain.</p></div>"},
{"url": "https://larevueia.fr/quest-ce-quun-reseau-lstm/", "title": "Qu’est ce qu’un réseau LSTM ?", "author": "Adib Habbou", "date": "\n11 août 2022\n", "content": "<div class=\"entry-content\"><p>Un des avantages des <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">réseaux de neurones</a> réside dans la diversité des architectures existantes. Dans cet article, on parle des LSTM, une architecture de réseaux de neurones très utilisée pour le traitement du langage.</p><h2 class=\"wp-block-heading\">Réseaux Neuronaux Récurrents</h2><p>Les <strong>réseaux neuronaux récurrents</strong> sont les plus efficaces pour gérer des entrées de différentes tailles étant donné qu’ils possèdent une <strong>mémoire court terme</strong>. Ils permettent aussi une meilleure compréhension du contexte puisqu’ils peuvent traiter des paquets de données quasi simultanément.</p><p>Malheureusement, cette mémoire à court terme n’a pas une durée de vie suffisante pour certaines tâches à cause d’un problème célèbre appelé le <strong><em>Vanishing Gradient Problem</em></strong>.</p><figure class=\"wp-block-image size-large\"><img decoding=\"async\" src=\"https://www.researchgate.net/profile/Vidushi-Mishra/publication/324883736/figure/fig2/AS:621644821307392@1525223083712/Recurrent-neural-networkRNN-or-Long-Short-Term-MemoryLSTM-5616.png\" alt=\"illustration d'un réseau de neurones récurrent (RNN)\"><figcaption class=\"wp-element-caption\"><strong>Schéma d’une réseau neuronal récurrent</strong></figcaption></figure><h2 class=\"wp-block-heading\">Qu’est ce que le vanishing Gradient Problem ?</h2><p>En utilisant la rétropropagation, un réseau récurrent peut retracer les dépendances arbitraires qu’il trouve dans les données d’entrée. Cependant les <strong>gradients à long terme</strong> qui sont <strong>rétropropagés </strong>peuvent tendre vers <strong><em>zéro </em></strong>(<em>on dit qu’ils disparaissent</em>) ou peuvent tendre vers l’<strong><em>infini</em></strong> (<em>on dit qu’ils explosent</em>). Dans les deux cas on perd l’information qu’on voulait garder <em>en mémoire</em>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/1400/1*A4-H1K_bXM_SYbBc2ux-Dg.png\" alt=\"vanishing et exploding gradient\"><figcaption class=\"wp-element-caption\"><strong>Schémas de la disparition et de l’explosion du gradient</strong></figcaption></figure></div><h2 class=\"wp-block-heading\">Long Short-Term Memory</h2><h3 class=\"wp-block-heading\">Comment les LSTM permettent d’éviter le vanishing gradient ?</h3><p>Un nouveau sous-type de réseau est donc apparu pour essayer de contourner cette problématique : ce sont les réseaux <em><strong>LSTM</strong> </em>qui contiennent une mémoire à court terme capable de durer assez longtemps pour qu’on la qualifie de <strong>mémoire longue à court terme</strong>. De ce fait, on évite le problème de fuite du gradient même s’il peut arriver encore que notre gradient explose.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://www.researchgate.net/publication/341131167/figure/fig1/AS:887489082445828@1588605294853/RNN-v-s-LSTM-a-RNNs-use-their-internal-state-memory-to-process-sequences-of-inputs.jpg\" alt=\"comment les lstm résolvent le problème du vanishing gradient\"><figcaption class=\"wp-element-caption\"><strong>Comparaison entre RNN et LSTM</strong></figcaption></figure></div><h3 class=\"wp-block-heading\">Architecture des LSTM</h3><p>Une cellule d’un réseau LSTM est principalement composée d’un <strong>input gate</strong>, un <strong>output gate</strong> et un <strong>forget gate</strong>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-16-13-41-03.png\" alt=\"schèma d'un neurone lstm\"><figcaption class=\"wp-element-caption\"><strong>Schéma simplifié d’une cellule d’un réseau LSTM</strong></figcaption></figure></div><p>La principale idée derrière un LSTM est de diviser le signal qui traverse notre réseau en deux parties bien distinctes :</p><ul class=\"wp-block-list\"><li><em>Court Terme</em> à travers le <strong>hidden state</strong></li><li><em>Long Terme</em> à travers le <strong>cell state</strong></li></ul><h3 class=\"wp-block-heading\">Etapes LSTM</h3><p>Un réseau LSTM effectue durant chaque passage les 5 étapes suivantes :</p><ul class=\"wp-block-list\"><li>Détection des informations passées dans le <strong>cell state</strong> via le <strong>forget gate</strong></li><li>Choix des informations pertinentes à <em>long terme</em> à travers l’<strong>input gate</strong></li><li>Ajout des informations choisies au <strong>cell state</strong></li><li>Détection des informations importantes à <em>court terme</em> dans le <strong>cell state</strong></li><li>Génération du nouveau <strong>hidden state</strong> à travers l’<strong>output gate</strong></li></ul><p>La <strong>relation de récurrence </strong>d’un <strong><em>LSTM </em></strong>comprend donc une variable <strong>h</strong> pour le <em>hidden state</em> et une variable <strong>c </strong>pour le <em>cell state</em> :</p><p class=\"has-text-align-center\"><strong>h<sub>t</sub> , c<sub>t</sub> = f(x<sub>t </sub>, h<sub>t-1 </sub>, c<sub>t-1</sub>)</strong></p><figure class=\"wp-block-image size-large\"><img decoding=\"async\" src=\"https://i.postimg.cc/yNjdf6gF/1-7c-Mfenu76-BZCzd-KWCf-BABA.png\" alt=\"lstm, unté récurrente\"><figcaption class=\"wp-element-caption\"><strong>Cellule d’un réseau LSTM</strong></figcaption></figure><h3 class=\"wp-block-heading\">Limites du réseau</h3><p>Malgré le fait que les <strong><em>LSTM </em></strong>règlent en partie le <em><strong>Vanishing Gradient Problem</strong></em>, le modèle n’est pas pour autant parfait. En effet, il comprend de nombreux défauts parfois assez compliqués à surpasser. Parmi eux, on peut citer les problèmes d’<strong><a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">overfitting</a></strong> (<em>quand le modèle colle trop aux données d’entraînement</em>) ou encore le fait que le modèle est fortement <strong>affecté</strong> par les <strong>initialisations</strong> de poids aléatoires.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://www.educative.io/api/edpresso/shot/6668977167138816/image/5033807687188480\" alt=\"Qu'est ce qu'un réseau LSTM ?\"><figcaption class=\"wp-element-caption\"><strong>Schémas de l’overfitting et underfitting</strong></figcaption></figure></div><h2 class=\"wp-block-heading\">Applications : les LSTM pour générer de paroles de rap</h2><p>Maintenant qu’on a vu le côté théorique derrière les réseaux <strong><em>LSTM</em></strong>, il est temps de voir le côté pratique et comment ils peuvent être utilisés pour faire des choses assez originales et drôles.</p><p>Après avoir récolté les paroles de plus de 100 rappeurs français sur <strong>Genius </strong>en utilisant à la fois l’API et des techniques de Web Scraping avec <em><strong><a href=\"https://larevueia.fr/introduction-a-beautifulsoup-web-scraping-avec-python/\" target=\"_blank\" rel=\"noreferrer noopener\">BeautifulSoup</a></strong></em>, j’ai entraîné un petit réseau <em><strong>LSTM </strong></em>à générer des paroles de rap français à partir d’une petite phrase en input. Vous pouvez retrouver tout le code et le dataset utilisé sur le repo git suivant : <a href=\"https://github.com/Adib-Habbou/french-rap-lyrics-generator\" target=\"_blank\" rel=\"noreferrer noopener\">https://github.com/Adib-Habbou/french-rap-lyrics-generator</a></p><p>Le modèle s’avère être assez vulgaire et grossier, ce qui nous rappelle encore une fois qu’un modèle c’est avant tout les données sur lesquelles on l’entraîne et que si l’on ne fait pas attention aux données qu’on lui donne, on peut malheureusement se retrouver avec des résultats inattendues voire dangereux.</p><p>Comme cela s’est avéré être le cas pour l’IA de <strong><em>Microsoft </em>Tay </strong>qui est très vite devenue raciste à cause des tweets sur lesquelles le modèle a été entraîné, ou encore <strong>DALL-E</strong> d’<em><strong>OpenAI</strong></em> qui comporte un bon nombre de biais racistes et misogynes.</p><h2 class=\"wp-block-heading\">Pour aller plus loin</h2><ul class=\"wp-block-list\"><li>Un des premiers papiers scientifiques : <a href=\"https://cutt.ly/UZnNet4\" target=\"_blank\" rel=\"noreferrer noopener\">https://cutt.ly/UZnNet4</a></li><li>Librairie <em>Python </em>pour créer des <em><strong>LSTM </strong></em>: <a href=\"https://cutt.ly/NZnNg7r\" target=\"_blank\" rel=\"noreferrer noopener\">https://cutt.ly/NZnNg7r</a></li><li>Article sur l’IA raciste de Microsoft : <a href=\"https://cutt.ly/YZLQ79W\" target=\"_blank\" rel=\"noreferrer noopener\">https://cutt.ly/YZLQ79W</a></li></ul></div>"},
{"url": "https://larevueia.fr/quest-ce-que-lintelligence-artificielle-decentralisee/", "title": "Qu’est-ce que l’intelligence artificielle décentralisée ?", "author": "Ilyes Talbi", "date": "\n30 octobre 2022\n", "content": "<div class=\"entry-content\"><p>Le web2 est cassé. Et comme lui, l’IA est cassée. Monopole, biais, manque de transparence; la liste des infractions est longue.</p><p>De manière générale, le monde digital que nous avons construit, si on le juge avec détachement et objectivité, est finalement assez absurde.</p><p>On offre nos données gratuitement, les algorithmes du web savent ce que l’on aime, ce que l’on mange, comment on va s’habiller demain, les informations que l’on publie ne nous appartiennent plus, et la censure est centralisée, et contrôlée par des organisations toutes puissantes.</p><h2 class=\"wp-block-heading\">OpenAI vous veut du bien</h2><p>Ces dernières semaines, nous avons clairement vu les limites des modèles comme celui d’OpenAI ou Deepmind, qui se sont éloignés de leur mission initiale : proposer des modèles qui bénéficient à tout le monde.</p><p>Pire encore, ils utilisent les données de tout le monde, pour créer des modèles qui ne bénéficient qu’à leurs créateurs, bloquent l’accès aux outils, sous prétexte qu’ils savent mieux que nous ce qui est bien pour nous, et utilisent l’argument éthique pour le justifier…</p><p>Le cas DALL-E 2 montre le manque de transparence devenu symptomatique pour les IA d’aujourd’hui. Des modèles entraînés avec les données du peuple, pour le bien du peuple, finalement accaparés par une poignée de privilégiés.</p><p>Les artistes et photographes qui publient leurs travaux sur Instagram sont-ils au courant de ce qui se passe ?</p><p>Même si OpenAI a apporté beaucoup au monde de l’IA, beaucoup de choses ont changé ces dernières années.</p><h2 class=\"wp-block-heading\">Un monopole démesuré</h2><p>En plus de ce manque de transparence, ce sont les mêmes acteurs qui contrôlent toutes les données générées par les internautes.</p><p>Sur des sujets aussi critiques que la compréhension du langage, seuls quelques mastodontes sont capables de réellement innover : Amazon, Google, Meta et quelques autres entreprises. La course aux données et aux modèles de plus en plus larges est perdue d’avance pour la majorité des acteurs.</p><p>Les architectures des derniers modèles ne sont pas si novatrices que ça, elles consistent simplement en un empilement de couches de plus en plus grand, et l’ajout d’une quantité quasi-infinie de données. Et pour les géants cités juste avant, ni la capacité de calcul ni la quantité de données ne sont des problèmes.</p><p>Même si certaines de ces entreprises ont été rattrapées par les autorités européennes pour leur monopole sur certains sujets, elles n’ont jamais été inquiétées sur la question de la quantité de données stockées.</p><h2 class=\"wp-block-heading\">Le modèle open-source : une alternative qui a ses limites</h2><p>Le modèle open-source semble résoudre les problèmes énoncés précédemment. Pour la transparence la question ne se pose pas, les données et le travail résultant sont visibles publiquement. Concernant le monopole, il permet un accès équitable pour tous les acteurs.</p><p>C’est d’ailleurs cette approche là qu’a choisi Stability.ai, l’entreprise à l’origine du modèle stable diffusion. En plus d’être plus robuste et plus rapide, stable diffusion est complètement open-source.</p><p><a href=\"https://stability.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Stability.ai</a> a d’ailleurs annoncé une levée de fonds de 101 millions de dollars, pour mettre en place une nouvelle approche d’entreprise à impact dans le domaine de l’IA.</p><p>Mais l’open-source ne résout pas tous les problèmes.</p><p>Jusqu’ici c’était un monde à part, régi par des règles tacites et qui reposait sur la confiance et la collaboration. Sauf que des récents événements ont montré sa vulnérabilité, comme Marak Squirres qui a saboté son propre projet et causé pas mal de dégâts (on parle de dizaines de milliers de projets concernés), ou encore les débats causés par le lancement de GitHub copilot.</p><p>Concernant l’affaire Marak Squirres, les médias mainstream ont abordé le sujet en se demandant « comment sécuriser les projets open source ? », comme pour remettre en cause la fiabilité du modèle.</p><p>Nous sommes d’accord, la question se pose et elle est importante, mais l’urgence est plutôt de savoir comment rendre le monde du open source plus juste et récompenser les contributeurs les plus assidus.</p><h2 class=\"wp-block-heading\">L’intelligence artificielle décentralisée comme solution ?</h2><p>Je ne fais pas partie de ceux qui clament la décentralisation à chaque revers du modèle classique. J’analyse les évènements de façon pragmatique et rationnelle, et je suis conscient que la <a href=\"https://larevueia.fr/quels-liens-entre-blockchain-et-intelligence-artificielle\" target=\"_blank\" rel=\"noreferrer noopener\">blockchain</a> n’est pas une baguette magique solution à tous nos maux. Mais je pense que si l’on veut faire passer l’intelligence artificielle dans une nouvelle dimension, il faut du changement.</p><p>L’intelligence artificielle décentralisée est un nouveau paradigme dans lequel les données et les modèles qui en résultent appartiennent à tous les membres d’un réseau. Les données sont collectées et labellisées collectivement, et chaque membre apporte une partie de la puissance de calcul nécessaire à l’entraînement du modèle, on parle de <em>federated learning</em> ou <em>apprentissage fédéré</em>.</p><p>Le premier avantage du réseau décentralisé, est qu’il permet à chaque membre d’avoir un intérêt à ce que le réseau fonctionne bien. Si le réseau fonctionne le membre gagne, si le réseau ne fonctionne plus il perd.</p><p>Par ailleurs, les gains finaux sont partagés équitablement, chacun étant récompensé à la hauteur de son apport : l’artiste qui publie ses travaux sera gratifié pour leur utilisation, l’internaute sera payé pour ses données, le data scientist qui propose une architecture ou des solutions techniques aussi, et tout le monde peut bénéficier au réseau en apportant un espace de stockage ou de la capacité de calcul.</p><p>Enfin, d’un point de vue traçabilité aussi la blockchain a des arguments. Elle permettra de tracker avec plus de transparence les échanges de données, et donc permettra de remonter plus facilement à la source.</p><p>Contrairement à ce que certains suggèrent, ce modèle n’est pas un spin-off du communisme au service de l’intelligence artificielle, c’est simplement une alternative et un contrôle d’un capitalisme destructeur.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Pour conclure, même si cet article pose plus de questions qu’il ne donne de réponses, l’objectif est de constater les limites de l’intelligence artificielle d’aujourd’hui, et prendre conscience qu’un changement s’impose.</p><p>Même si les solutions les plus robustes sur le long terme seront celles apportées par la recherche : Comment créer des architectures de réseaux plus fiables et qui consomment moins de données ? Comment mieux assurer l’explicabilité des modèles ? Des sujets comme le self-supervised learning, largement promu par Yann Le Cun, sont la clé des problématiques actuelles.</p><p>De façon plus globale, on tend vers une convergence entre toutes les technologies disponibles aujourd’hui : l’IoT pour la récolte des données, la blockchain et la cybersecurité pour la confiance et la traçabilité, l’intelligence artificielle pour le traitement, et des technologies comme la robotique ou la réalité virtuelle pour l’interfaçage. Et il est clair que le tout sera bien plus grand que la somme de ses parties.</p></div>"},
{"url": "https://larevueia.fr/tutorial-creez-un-ai-avatar-parlant-avec-des-outils-gratuits-no-code/", "title": "Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code", "author": "Alexandre Lavallée", "date": "\n4 avril 2023\n", "content": "<div class=\"entry-content\"><hr class=\"wp-block-separator has-alpha-channel-opacity\"><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*HooQcNGGuvYRv2sTdDKBtw.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>A l’occasion du 1er avril, je me suis permis de prétendre que je devenais le <em>‘Head of AI content’</em> de la fameuse marque Balenciaga, et d’annoncer en grande pompe un partenariat entre la marque de luxe et le monde d’Harry Potter avec une <a href=\"https://www.youtube.com/watch?v=iE39q-IKOzA\" rel=\"noreferrer noopener\" target=\"_blank\">vidéo</a> soignée — sur une idée originale du créateur <a href=\"https://www.instagram.com/demonflyingfox/\" rel=\"noreferrer noopener\" target=\"_blank\">demonflyingfox</a>.</p><p>Pensant que ma supercherie était vraiment beaucoup trop grosse pour être vraie, j’ai pourtant reçu nombre de félicitations… Pourtant, tout était absolument généré par une IA, le script, la vidéo, les images, l’animation des avatars, les voix des personnages.</p><p>Au delà du côté ludique et, avouons-le, un tantinet provocateur de ce poisson d’avril, c’était avant tout la parfaite occasion pédagogique pour nous de montrer en conditions réelles comment utiliser la panoplie des <strong>outils</strong> génératifs, et les enjeux éthiques associés</p><p>Je découperais donc l’article en deux axes:</p><p>1/ <strong>Tuto</strong>: montrer toute la panoplie des outils disponibles en matière de Generative AI qui peuvent vous permettre de créer une vidéo d’un avatar animé qui s’exprime, et ce de A à Z par vous-mêmes</p><p>2/ <strong>Analyse</strong>: partager quelques réflexions en fin de ce tuto sur les questions et implications éthique de ces outils très sophistiqués qui auraient faire pâlir d’envie <a href=\"https://www.cairn.info/revue-du-mauss-2007-2-page-452.htm\" target=\"_blank\" rel=\"noreferrer noopener\">Edward Bernays</a></p><p>Etre informé sur le monde technologique qui nous entoure, c’est aussi mieux être mieux armé pour tenter d’apporter un éclairage lucide et critique du fonctionnement de ces IA multi-modales.</p><p></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Harry Potter by Balenciaga\" width=\"1250\" height=\"938\" src=\"https://www.youtube.com/embed/iE39q-IKOzA?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div></figure><p><a href=\"\"></a></p><p>Nous allons vous guider à travers les étapes simples pour décomposer le processus de création de cette vidéo ci-dessus, qui est entièrement fake. </p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Rendons à César ce qui est à César, l’idée de mixer l’univers de Balenciaga avec celui du monde de J.K Rowling, vient de cette brillante idée de l’AI-artist (<a href=\"https://www.instagram.com/demonflyingfox/\" target=\"_blank\" rel=\"noreferrer noopener\">demonflyingfox</a>) – que je trouve très mordant et efficace.</p></blockquote><p>Ce dont vous avez besoin avant d’aller plus loin:</p><ul class=\"wp-block-list\"><li>un générateur d’image AI-art (<a href=\"https://docs.midjourney.com/docs/quick-start\" rel=\"noreferrer noopener\" target=\"_blank\">Midjourney</a>, <a href=\"https://beta.dreamstudio.ai/generate\" rel=\"noreferrer noopener\" target=\"_blank\">DreamStudio</a>, <a href=\"https://www.scenario.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Scenario</a> — <a href=\"https://sourceforge.net/software/product/DreamStudio/alternatives\" rel=\"noreferrer noopener\" target=\"_blank\">voir plus de détails</a>)</li><li>un compte gratuit chez <a href=\"https://play.ht/\" rel=\"noreferrer noopener\" target=\"_blank\">play.ht</a></li><li>un compte gratuit chez <a href=\"https://www.d-id.com/\" rel=\"noreferrer noopener\" target=\"_blank\">D-ID</a></li><li>un outil gratuit super pratique comme <a href=\"https://cloud.lambdalabs.com/demos/ml/CLIP-Interrogator\" rel=\"noreferrer noopener\" target=\"_blank\">Clip Interrogator</a></li></ul><h3 class=\"wp-block-heading\">Etape 1: Image-To-Prompt </h3><h4 class=\"wp-block-heading\">objectif: Trouvez le bon prompt qui permettra de créer notre personnage </h4><p>Outils utilisés lors de cet étape:</p><ul class=\"wp-block-list\"><li><a href=\"https://cloud.lambdalabs.com/demos/ml/CLIP-Interrogator\" rel=\"noreferrer noopener\" target=\"_blank\">clip interrogator</a></li></ul><p>Je vais tout bonnement commencer par faire une capture d’écran d’un des personnages stylés dans la vidéo, prenons par exemple ce Dumbledore total new-look dans le pur jus de Balenciaga.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*GiYRX2PIWVOMxAQWfAVU3g.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>On va passer cette image dans clip interrogator — <a href=\"https://cloud.lambdalabs.com/demos/ml/CLIP-Interrogator\" rel=\"noreferrer noopener\" target=\"_blank\">ICI</a></p><p>Grosso modo, CLIP nous permet de traduire via une IA le contenu d’une image en mots. Vous lui donnez une image, il vous dit quel serait le “prompt” correspondant à utiliser dans un générateur d’AI-art comme Dall-E ou Stable diffusion etc si vous souhaitiez recréer l’image.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Pour plus de détails sur <a href=\"https://openai.com/research/clip\" rel=\"noreferrer noopener\" target=\"_blank\">CLIP</a>, je fais une aparté en fin de cet article. honnêtement c’est sans doute l’outil le plus sous-côté/méconnu du grand public, alors qu’il est absolument fondamental dans les progrès des algos Text-To-Image</p></blockquote><p>Donc dans notre exemple</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*Vrz44P_00FDaDjZaYOilBA.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>Voila un prompt que nous propose un CLIP, que nous allons nous empresser de copier/coller dans un bloc-note</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><strong>a man with a long white beard wearing a hat and sunglasses, still from the matrix (1999), flash gordon, dressed as a wizard, fantastic details full faces, elfpunk, sephiroth, willem dafoe, necro, am a naranbaatar ganbold, overlord billie eilish, jerma985, old movie </strong></p></blockquote><h3 class=\"wp-block-heading\">Etape 2: Text-To-Image</h3><h4 class=\"wp-block-heading\">Objectif: Générez l’image de notre personnage fictif, qui servira de base pour une animation vidéo future.</h4><p>Outils utilisés lors de cette étape:</p><ul class=\"wp-block-list\"><li><a href=\"https://docs.midjourney.com/docs/quick-start\" rel=\"noreferrer noopener\" target=\"_blank\">Midjourney</a></li></ul><p>Ouvrons notre générateur d’AI-art, dans le cas échéant Midjourney. Si c’est la première fois pour vous que vous utilisez cette plateforme, lisez d’abord ce <a href=\"https://docs.midjourney.com/docs/quick-start\" rel=\"noreferrer noopener\" target=\"_blank\">quick start guide</a> de Midjourney pour pasgalérer sur votre set-up.</p><p>On se rend sur discord, on tape <strong>/imagine</strong> et on copie colle notre prompt donné par CLIP lors de l’étape 1</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*0cc8xIumwDS-izBwHwTJ2w.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>notez que je rajoute quelques paramètres à la fin du prompt <strong>— ar 2:1 — q 2 — s 750 — v 5. </strong>Ce sont des paramètres qui me permettent de mieux gérer l’aspect visuel de mon image qui sera générée, pour aller plus loin c’est <a href=\"https://docs.midjourney.com/docs/parameter-list\" rel=\"noreferrer noopener\" target=\"_blank\">ici</a>.</p><p>Ok voyons le résultat.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*1s0bNRF0AkixTnmq_xsdRQ.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>OK on a notre dumbledore new-look. </p><p>Vous pouvez aussi essayer la prompt alternative suivante, si vous souhaitez donner un grain un peu plus dark et vintage à votre Dumbledore.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*fpsMU4-LSnKKlbniw1PGXg.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>Bon ici vous pouvez prendre n’importe quelle image hein, pas forcément obligé d’utiliser Midjourney, vous pourriez tout à faire un screenshot d’une image d’un personnage dans une vidéo youtube.</p><h3 class=\"wp-block-heading\">Etape 3: Text-To-Speech</h3><h4 class=\"wp-block-heading\">objectif: Créer le script + la voix de notre personnage fictif</h4><p>Outils utilisés lors de cette étape:</p><ul class=\"wp-block-list\"><li><a href=\"https://play.ht/\" rel=\"noreferrer noopener\" target=\"_blank\">play.ht</a></li></ul><p>A présent on va utiliser les fonctionnalités de play.ht pour créer le fichier audio. </p><p>En express, Play.ht est un service en ligne qui convertit du texte en audio grâce à la synthèse vocale. Il utilise des voix artificielles avancées pour lire des articles, des histoires ou d’autres types de contenu écrit, afin que tu puisses les écouter plutôt que de les lire.</p><p>On va sélectionner une voix synthétique d’IA, et lui faire dire notre texte/script.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*_nvXIs_CV-NV6nruCiLViA.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>A présent familiarisez vous un peu avec l’interface suivante. Dans notre cas, on va copier-coller une des citations de Dumbledore (<a href=\"https://bookroo.com/quotes/dumbledore\" rel=\"noreferrer noopener\" target=\"_blank\">source</a>)</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*O0MNMg9Cgy7OgXr6opEWuw.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>Avec l’outil de pré-écoute, on peut apprécier la diction de notre voix-off et l’affiner au besoin. Mais vu que c’est un compte gratuit, soyez parcimonieux avant de télécharger le résultat final de votre audio.</p><p>Nous n’avons plus qu’à télécharger notre fichier .mp3.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*B7ibbMb-TMSt-DwVxhAf0w.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*LuJtoUc26fxNdRSbijSquQ@2x.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><h3 class=\"wp-block-heading\">Etape 4: (Image+Speech)-To-Video</h3><h4 class=\"wp-block-heading\">objectif: Mixer l’image et la voix de notre personnage fictif pour créer un rendu vidéo animé avec un avatar qui parle</h4><p>Outils utilisés lors de cet étape:</p><ul class=\"wp-block-list\"><li><a href=\"https://www.d-id.com/\" rel=\"noreferrer noopener\" target=\"_blank\">D-ID</a></li></ul><p>A présent, rendons nous sur notre compte D-ID (je suis personnellement en essai gratuit). D-ID est une application web qui utilise l’animation faciale en temps réel et la synthèse vocale avancée pour créer une expérience d’IA conversationnelle immersive et réaliste. En somme, c’est un outil d’IA générative pour créer des avatars parlants en quelques clicks.</p><p>On va faire une nouvelle vidéo, et commencez par importer notre image créée lors de l’étape 2.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*7ysJ0qypQUDA0cb4oxPhdQ.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>A présent, on va uploader notre voix créée lors de l’étape 3. </p><p>Notez que vous pouvez aussi tout à fait utiliser les pre-sets existants de voix dans D-ID, c’est juste que je trouve ça un peu cher et pas forcément très flexible.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*wrd2Ybp7xdflEEXwXjV1zQ.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><p>on upload notre fichier audio, pour moi c’est le fichier <strong>Dumbledore Balenciaga Audio Script.mp3</strong></p><p>Et plus qu’à cliquer sur generate Video, et exportez votre résultat final, une vidéo .mp4 avec votre avatar parlant.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*3dPvRc3keAy87SWszBWKDg.png\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"></figure><h3 class=\"wp-block-heading\">Récap</h3><p>On aura donc successivement en moins de 5min:</p><ul class=\"wp-block-list\"><li>généré une prompt à partir d’une image cible</li><li>reproduit cette image cible dans midjourney</li><li>généré une voice-over avec un texte personnalisé</li><li>synchronisé la voice-over avec notre image pour créer une vidéo (ou notre Dumbledore nous troll superbement d’ailleurs)</li></ul><hr class=\"wp-block-separator has-alpha-channel-opacity\"><h3 class=\"wp-block-heading\">Pour aller plus loin</h3><h4 class=\"wp-block-heading\">Réflexions éthiques: le Generative AI, Edward Bernays et la fabrique du consentement</h4><p>Ce qui est intéressant à observer dans cette expérimentation, c’est qu’il est aisé de créer un contenu réaliste et faire dire ce qu’on veut à à peu près n’importe qui. J’aurais pu tout à fait également cloner la voix de n’importe qui à partir de 60 secondes d’audio, pour utiliser la voix de christopher lee ou celle de Steve Jobs — les études de <a href=\"https://valle-demo.github.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Vall-E</a> montrent que nous sommes également en train de passer un cap dans ce domaine. </p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*PxJDwxZ2KJ-eNUoJ.jpg\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"><figcaption class=\"wp-element-caption\">Vall-E: voice cloning</figcaption></figure><p>De tels outils posent nécessairement la question de la limite de leurs utilisations face à leur capacités à modeler le consentement du public. </p><p>Et c’est bien la ou je souhaite en venir. </p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*9YmfDjyrW4bP6JbZ.jpg\" alt=\"Tutorial: Créez un AI-avatar parlant avec des outils gratuits no-code\"><figcaption class=\"wp-element-caption\">edward bernays a notamment réalisé la campagne de pub Lucky Strike visant à inciter les femmes à fumer, ouvrant un nouveau public à la firme de tabac</figcaption></figure><p>Dans son livre “<a href=\"https://www.cairn.info/revue-du-mauss-2007-2-page-452.htm\" rel=\"noreferrer noopener\" target=\"_blank\">Propaganda</a>” (1928), Bernays, considéré comme le père des relations publiques modernes mais aussi au passage neveu d’un certain Sigmund Freud, soutient que le consentement du public peut être “fabriqué” ou “manipulé” par des experts en communication et en relations publiques des masses.</p><p>La thèse de Bernays est que des personnes “invisibles” qui créent le savoir et la propagande règnent sur les masses, avec le monopole du pouvoir de façonner les pensées, les valeurs et les réactions des citoyens. Selon lui, il serait alors nécessaire d’avoir un “consentement technique” — ou “engineering consent” qui signifie influencer l’opinion publique en utilisant des techniques de communication et de persuasion pour façonner les perceptions, les attitudes et les comportements des individus. Bernays voyait cette approche comme un outil nécessaire pour maintenir l’ordre social et la stabilité, étant donné que les gens sont souvent influencés par des forces irrationnelles et émotionnelles. Tout un programme donc pour ce cher Edward Bernays.</p><p>Je pense qu’il est intéressant en tout cas de percevoir à quel point ces <strong>outils</strong> d’IA génératives, qui ne sont que des <strong>artefacts</strong>, peuvent rapidement être prise à leur compte par des visées de propagande, et bien entendu pose la légitime question du copyright que ce soit pour les images ou la voix. </p><p>Si l’on fait un parallèle entre la thèse de Bernays à l’aune du <em>Generative AI</em> on peut donc au moins dénoter deux facteurs amplificateurs de chaos dans la manipulation du consentement du public:</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>💥<em> Premier facteur de Chaos : l’IA permet de diminuer les coûts des 3 types d’opérations indispensables à une propagande efficace : il est possible de simuler des auteurs instantanément et même d’usurper leur identité, de simuler leur succès (en générant de faux commentaires crédibles ou des reprises d’informations par de faux utilisateurs) et, bien entendu, de produire du contenu automatiquement.</em></p></blockquote><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>💥 <em>Deuxième facteur de Chaos : affaiblir la confiance dans le système en instaurant un doute constant. Plutôt que de provoquer l’adhésion à des fausses convictions, semer l’incertitude est souvent le premier but des propagandistes. Avec l’évolution de l’IA, tout le monde se demandera si un message particulier pourrait être inauthentique ou trompeur.</em></p></blockquote><p>Je vous invite à aller plus loin en consultant cette <a href=\"https://arxiv.org/abs/2301.04246\" rel=\"noreferrer noopener\" target=\"_blank\">étude captivante</a>, pédagogique et mesurée, réalisée des chercheurs d’OpenAI (développeurs de ChatGPT), en collaboration avec le “Georgetown’s Center for Security and Emerging Technology” et le “Stanford Internet Observatory”, ont réalisé des études pour identifier les dangers et établir les fondements d’un débat sur les régulations envisageables.</p><p>En tout cas, j’espère que cela vous apporte un peu d’esprit critique et de mises en perspective de plus en plus nécessaire sur l’utilisation de ces outils.</p><p>Pur aller plus loin:</p><ul class=\"wp-block-list\"><li><a href=\"https://davidrozado.substack.com/p/political-bias-chatgpt\" rel=\"noreferrer noopener\" target=\"_blank\">https://davidrozado.substack.com/p/political-bias-chatgpt</a></li><li><a href=\"https://arxiv.org/abs/2301.04246\" rel=\"noreferrer noopener\" target=\"_blank\">https://arxiv.org/abs/2301.04246</a></li><li><a href=\"https://youtu.be/8OpW5qboDDs\" rel=\"noreferrer noopener\" target=\"_blank\">https://youtu.be/8OpW5qboDDs</a></li></ul><hr class=\"wp-block-separator has-alpha-channel-opacity\"><p>Aparté:</p><p>Quel est le point commun entre les récentes percées de l’IA, DALL-E et de stable diffusion ?<br>Elles utilisent toutes deux des éléments de l’architecture CLIP. Par conséquent, pour comprendre le fonctionnement de ces modèles, il est indispensable de comprendre CLIP.<br>D’ailleurs, CLIP a été utilisé pour indexer des photos sur Unsplash.<br>Mais que fait CLIP et pourquoi est-ce une étape importante pour la communauté de l’IA ?</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><strong><em>CLIP est l’acronyme de Constastive Language-Image Pretraining :</em></strong><br>CLIP est un modèle open source, multimodal et sans prise de vue. Étant donné une image et des descriptions textuelles, le modèle peut prédire la description textuelle la plus pertinente pour cette image, sans optimiser pour une tâche particulière.</p></blockquote><p>Décortiquons cette description :</p><ul class=\"wp-block-list\"><li>Open Source: Le modèle est créé et mis à disposition par OpenAI. </li><li>Multi-modalité : les architectures multimodales exploitent plus d’un domaine pour apprendre une tâche spécifique. CLIP combine le traitement du langage naturel et la vision par ordinateur.</li><li>Zero-shot : L’apprentissage à partir de zéro est un moyen de généraliser sur des étiquettes inédites, sans avoir été spécifiquement entraîné à les classer. Par exemple, tous les modèles ImageNet sont formés pour reconnaître 1000 classes spécifiques. CLIP n’est pas soumis à cette limitation.</li><li>Langage contraignant : Avec cette technique, CLIP est entraîné à comprendre que les représentations similaires doivent être proches de l’espace latent, tandis que les représentations dissemblables doivent en être éloignées.</li></ul></div>"},
{"url": "https://larevueia.fr/nlp-avec-python-analyse-de-sentiments-sur-twitter/", "title": "NLP avec Python : analyse de sentiments sur Twitter", "author": "Ilyes Talbi", "date": "\n14 septembre 2020\n", "content": "<div class=\"entry-content\"><p>Dans le précédent <a data-type=\"https://larevueia.fr/introduction-au-nlp-avec-python-les-ia-prennent-la-parole/\" href=\"https://larevueia.fr/introduction-au-nlp-avec-python-les-ia-prennent-la-parole/\" target=\"_blank\" rel=\"noreferrer noopener\">tutoriel NLP</a> nous avons introduit la notion d’encodage de texte, expliqué ce qu’était un pipeline NLP pour le nettoyage de notre dataset et avons construits un outil pour classifier des phrases non labélisées. D’ailleurs je vous conseille vivement de commencer par le lire avant d’aborder celui-là, beaucoup de notions sont complémentaires. Dans cette article il est question d’analyse de sentiments.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"NLP avec Python : analyse de sentiments sur Twitter\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Avant de commencer, sachez que tous les codes et les données utilisées ici sont disponibles sur ma page <a href=\"https://github.com/IlyesTal/covid-19_sentiment_analysis\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub</a>.</p></blockquote><p>Le NLP est la discipline du machine learning liée à la compréhension du langage par les machines. Les dernières avancées dans ce domaine ont permis l’émergence d’applications intéressantes (effrayantes aussi).</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://larevueia.fr/contact/\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-1024x576.jpg\" alt=\"NLP avec Python : analyse de sentiments sur Twitter\" class=\"wp-image-4429\" width=\"465\" height=\"261\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-1024x576.jpg 1024w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-300x169.jpg 300w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-768x432.jpg 768w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-1536x864.jpg 1536w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1.jpg 1600w\" sizes=\"auto, (max-width: 465px) 100vw, 465px\"></a></figure></div><p>L’analyse de sentiments des textes en est une. Le principe est simple, en étudiant des millions de textes labellisés avec un certain sentiment, le système est capable d’associer un champ lexical précis pour chaque sentiment. En lui donnant un nouveau texte, il sera alors capable de prédire avec une bonne précision, l’état émotionnel de l’auteur au moment de l’écriture de ce texte.</p><p>Certaines organisations utilisent l’analyse de sentiments afin de pouvoir suivre en temps réel la satisfaction de leurs utilisateurs. Si un client vous envoi un mail et que votre système détecte que la personne est énervée, vous savez que vous risquez de perdre un client. Vous avez intérêt à offrir quelque chose !</p><p>L’analyse de sentiments des tweets est une des applications classiques du NLP, c’est le ‘<em>Hello World</em>‘ du NLP. Dans cet article, qui sera un peu plus ambitieux que le précédent, l’idée sera de pouvoir faire de l’analyse de sentiments d’un tweets à partir des mots utilisés en utilisant <em>TextBlob</em>. Ce qui constituera une métrique de l’angoisse globale liée au Covid-19 qui règne sur Twitter, en fonction de ce qui y est publié.</p><p>Avant d’avoir les résultats on s’attend à voir une courbe qui commence à croitre début février et qui ne décroit qu’aux alentours de fin avril.</p><p>Comme je vous l’ai expliqué dans le précédent tutoriel, en data science on traite essentiellement des vecteurs et des données numériques. Les machines ne savent pas ce qu’est un mot ou une phrase, d’où la nécessité d’encoder nos données. Pour des phrases standard l’encodage est assez facile en utilisant Word2vec ou BERT. Pour l’encodage de tweets c’est plus délicat.</p><p>La structure d’un tweet est moins organisée. Certains utilisent des emojis, l’utilisation de ponctuations est beaucoup plus présente, les fautes d’orthographes sont très courantes. Tout ceci complique le travail de nettoyage préalable, surtout lorsqu’il est question d’analyse de sentiments.</p><p>Pour contourner cela plutôt que d’encoder nous même les tweets, nous allons passer par TextBlob. Ce module a une option qui permet de mesurer le sentiment d’un texte donné. En sortie la fonction nous donne un coefficient de polarité et un coefficient de sensibilité.</p><p>C’est la polarité qui nous intéresse ici. C’est un coefficient compris entre -1 et 1. Plus la polarité est proche de -1 plus le tweet est négatif, à l’inverse une polarité proche de 1 signifie que le tweet est plutôt positif.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://opensea.io/assets/0x495f947276749ce646f68ac8c248420045cb7b5e/72801339140492550428127495057349254902305173249976114551882572743813200084993/\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/12/Capture-de%CC%81cran-2021-12-16-a%CC%80-18.19.33-1024x652.png\" alt=\"NLP avec Python : analyse de sentiments sur Twitter\" class=\"wp-image-4369\" width=\"545\" height=\"346\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/12/Capture-décran-2021-12-16-à-18.19.33-1024x652.png 1024w, https://larevueia.fr/wp-content/uploads/2021/12/Capture-décran-2021-12-16-à-18.19.33-300x191.png 300w, https://larevueia.fr/wp-content/uploads/2021/12/Capture-décran-2021-12-16-à-18.19.33-768x489.png 768w, https://larevueia.fr/wp-content/uploads/2021/12/Capture-décran-2021-12-16-à-18.19.33.png 1058w\" sizes=\"auto, (max-width: 545px) 100vw, 545px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"extraction-de-tweets\"><strong>Extraction de tweets</strong></h2><p><br>Pour faire du machine learning sur des tweets il faut des tweets 😊 Pour cela deux options se présentent. La première est d’utiliser l’API que Twitter lui-même propose. Elle permet de récupérer des tweets en ajoutant certaines conditions sur le type de tweets que vous souhaitez.</p><p>La seconde option est l’utilisation du module Python <em>Twitterscrapper.</em> Vous pouvez extraire un grand nombre de tweets en spécifiant des critères de date, de langues et en vous limitant aux tweets qui contiennent certains mots-clés. Cette option est plus simple à utiliser mais ne fonctionne pas toujours, si ça marche pour vous tant mieux !<br></p><p>J’ai choisi de récupérer les tweets entre le 1<sup>er</sup> Janvier et le 1<sup>er</sup> Juin, qui contiennent les termes ‘<em>Covid-19’</em>, ‘<em>Covid’</em>, ‘<em>Coronavirus’</em>,<em> ‘Pandémie’</em>,<em> ’épidémie’</em>, <em>’corona’</em> ou ‘<em>virus’.</em> Les tweets doivent être en français. Pour cela le code est très simple.<br></p><p>Vous devez d’abord installer le module twitterscraper. Si vous codez sur Google Colab, Kaggle ou sur un notebook Jupyter n’oubliez pas le ‘!’ :</p><pre class=\"wp-block-code\"><code>!pip install twitterscraper</code></pre><p>On importe ensuite les modules que nous allons utiliser :</p><pre class=\"wp-block-code\"><code>from twitterscraper import query_tweets\nimport datetime as dt\nimport pandas as pd</code></pre><p>Le module <em>datetime</em> va permettre de gérer les dates et les horaires de publications des tweets. Pandas (que nous avons déjà utilisé dans de précédents tutoriels) est le module Python le plus adapté pour la gestion de grandes base de données.</p><pre class=\"wp-block-code\"><code>debut = dt.date(2020,1,1)\nfin = dt.date(2020,6,1)\nmots=\"Covid-19 OR Covid OR Corona OR Pandémie OR épidémie OR Coronavirus OR virus\"\n\ntweets = query_tweets(query=mots, begindate = debut, \nenddate = fin, lang = \"fr\")\n\ntweets = pd.DataFrame(t.__dict__ for t in tweets)\n\ntweets.to_csv('tweet_covid.csv')</code></pre><p>On fixe la date de début pour l’extraction de tweets avec <em>dt.date(2020,1,1)</em> le format est <em>YYYY/MM/DD</em>. De même la ligne <em>dt.date(2020,6,1)</em> permet de fixer la date de fin d’extraction au 1er Juin.</p><p>On sélectionne les mots-clés qui doivent apparaître dans les tweets puis on commence l’extraction avec <em>query_tweets</em>. N’oubliez pas de préciser que l’on veut seulement les tweets en français.</p><p>La commande DataFrame permet d’organiser toutes nos données sur les tweets dans un tableau pandas. On exporte ensuite le dataframe au format csv. Si vous le souhaitez il est possible de l’enregistrer autre part que dans votre environnement de travail, vous n’avez qu’à spécifier le chemin.</p><p>L’extraction peut prendre du temps tout dépend de votre connexion internet. Pour vous faciliter la tache j’ai mis <a href=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" data-type=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">en ligne</a> un fichier csv avec tous les tweets qui ont été extraits. Il y en a 13000 en tout. Il devrait y’en avoir beaucoup plus, mais il semblerait que Twitter limite l’extraction pour certains mots-clés. Néanmoins pour notre étude nous pouvons nous contenter de cette base.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Pour des raisons que j’ignore l’extraction avec <em>Twitterscrapper</em> a cessé de fonctionner pour moi. J’ai donc été contraint d’utiliser l’API. Elle est un peu moins évidente à comprendre, mais le code est plutôt simple. La grosse différence c’est qu’avec <em>Tweepy</em> vous avez besoin d’un accès à un compte Twitter.</p></blockquote><p>Si vous voulez seulement utiliser les tweets déjà disponible vous n’avez qu’à télécharger le fichier CSV et sauter cette partie. Sinon, voici comment récupérer des tweets avec <em>Tweepy.</em> Cette méthode est laborieuse est beaucoup moins pratique que la précédente, mais je n’ai pas d’autres alternatives :</p><ul class=\"wp-block-list\" type=\"1\"><li>D’abord vous aurez besoin d’un compte Twitter développeur. La demande est un peu laborieuse et lente (ça fait plus d’une semaine que j’attends mes accès 🙂 ). Pour cela rendez-vous sur <a href=\"https://developer.twitter.com/\" data-type=\"https://developer.twitter.com/\" target=\"_blank\" rel=\"noreferrer noopener\">cette page</a>, renseignez les informations demandées et attendez que Twitter confirme votre demande.<br></li><li>Une fois votre compte développeur crée, il vous faudra quelques informations : <em>l’API key, l’API secret key, l’Access token, l’Access token secret. </em>Ils sont faciles à trouver depuis votre compte.<br></li><li>Enfin, voici le code qui permet d’extraire les tweets :</li></ul><pre class=\"wp-block-code\"><code>!pip install tweepy\n\nimport os\nimport tweepy as tw\n\nconsumer_key = \"CF COMPTE TWITTER\" \nconsumer_secret = \"CF COMPTE TWITTER\"\naccess_key = \"CF COMPTE TWITTER\"\naccess_secret = \"CF COMPTE TWITTER\"\n\n# Authentification :\n\nauth = tw.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\napi = tw.API(auth, wait_on_rate_limit=True)\n\nrequete = \"Covid-19 OR Covid OR Corona OR Pandémie OR épidémie OR Coronavirus OR virus\"\n\ntweets = tw.Cursor(api.search,\n                   q = requete,\n                   lang = \"fr\",\n                   since='2018-01-15').items(1000)\n\nall_tweets = [tweet.text for tweet in tweets]</code></pre><p>Pour information une des caractéristiques de Twitter que je ne comprends pas bien, est que les commentaires sont aussi considérés comme des tweets. Donc notre base comportera les tweets et leurs réponses.</p><p>Maintenant que nous avons notre base de tweets, nous pouvons commencer l’analyse à proprement parler.</p><p><em>Update !</em></p><p>Entre temps j’ai trouvé sur Medium une méthode encore plus facile !</p><p>Le module <em>Twint </em>permet de se passer de l’API de Twitter, le code est très simple. La plupart des exemples que vous trouverez sur internet sont écrits en lignes de commandes. Pour rendre l’extraction plus simple, je vous ai écrit le code Python.</p><p>Vous devez d’abord installer Twint :</p><pre class=\"wp-block-code\"><code>!pip install twint</code></pre><p>Encore une fois, n’oubliez pas ‘!’ si vous êtes sur Google Colab ou sur un Notebook Jupyter.</p><p>Ensuite vous pouvez commencer l’extraction des tweets :</p><pre class=\"wp-block-code\"><code>import twint\n\ntw = twint.Config()\n\ntw.Search = \"Covid-19 OR Corona OR Covid OR Virus OR pandémie OR épidémie OR Coronavirus\"\ntw.Since = \"2020-02-01 12:00:00\"\ntw.Custom[\"tweet\"] = [\"id\"]\ntw.Pandas = True\ntw.Lang = \"fr\"\n\ntwint.run.Search(tw)\ntweet = twint.storage.panda.Tweets_df</code></pre><p>On commence par importer twint. La syntaxe utilisée par ce module est un peu différente mais reste très simple à comprendre.</p><p>Dans <em>search </em>on définit la requête que l’on recherche, à savoir les mots clés qui nous intéressent.</p><p><em>Since </em>permet de définir une date de début d’extraction. J’ai choisi le 1er Février à midi, rien ne vous empêche de commencer encore plus tôt.</p><p>On spécifie le français comme langue. Nous aurions aussi pu considérer tous les tweets et les traduire.</p><p>Enfin on définit un nom pour l’enregistrement de notre dataframe pandas.</p><p>En pratique, Twint est très lent pour extraire les tweets. J’ai donc fixé à 1000 le nombres maximale de tweets à extraire et j’ai fait l’extraction sur 13 périodes de 10 jours de Février à Juin 2020.</p><p>On se retrouve avec un fichier constitué de 13 000 tweets en tout. Vous pouvez le <a data-type=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" href=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">télécharger ici</a>.</p><p>Si vous utilisez <em>twint</em> sur Jupyter ou Colab vous pourriez avoir cette erreur au moment de l’exécution :<em> ‘this event loopis already runing</em>‘.</p><p>Pour résoudre ce problème, vous n’avez qu’à installer ce module :</p><pre class=\"wp-block-code\"><code>pip install nest_asyncio</code></pre><p>Puis exécuter ce code :</p><pre class=\"wp-block-code\"><code>import nest_asyncio\nnest_asyncio.apply()</code></pre><h2 class=\"wp-block-heading\" id=\"nettoyage-et-construction-du-pipeline-nlp\"><strong>Nettoyage et construction du pipeline NLP</strong></h2><p><br>Une rapide inspection de la base nous permet de voir que la compréhension de certains tweets est difficile même pour des êtres-humains haha. Le nettoyage sera d’autant plus important.<br></p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Je ne vous le répéterai jamais assez, la préparation de votre dataset est l’aspect le plus important du processus, toute la construction du modèle en dépend. Une préparation faite de manière hâtive peut conduire à des résultats faux et biaisés, ce qui n’est pas souhaitable. Surtout dans le cadre d’un <a href=\"https://larevueia.fr/voici-comment-lia-peut-vous-aider-dans-votre-business/\" data-type=\"https://larevueia.fr/voici-comment-lia-peut-vous-aider-dans-votre-business/\" target=\"_blank\" rel=\"noreferrer noopener\">business</a> ou pour le traitement de problématiques de société importantes, sans parler des catastrophes que cela peut engendrer dans des domaines comme le <a href=\"https://larevueia.fr/le-droit-doit-sadapter-aux-avancees-en-intelligence-artificielle/\" data-type=\"https://larevueia.fr/le-droit-doit-sadapter-aux-avancees-en-intelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">juridique</a> ou la <a href=\"https://larevueia.fr/lintelligence-artificielle-au-service-de-la-sante/\" data-type=\"https://larevueia.fr/lintelligence-artificielle-au-service-de-la-sante/\" target=\"_blank\" rel=\"noreferrer noopener\">santé</a>…</p></blockquote><p><br>En NLP, on commence toujours par construire un pipeline de nettoyage des données. Personnellement j’utilise les Reg-ex avec le module Python <em>re </em>qui permettent de faire cela facilement.<br></p><p style=\"font-size:18px\"><em>Le nettoyage des tweets comprendra plusieurs choses :</em><br></p><ul class=\"wp-block-list\" type=\"1\"><li>Enlever les emojis : pour cela il faut un module Python spécial (si vous connaissez des approches plus simples mettez-les en commentaire ça m’intéresse)<br></li><li>Retirer la ponctuation : très facile avec les reg-ex<br></li><li>Retirer les caractères spéciaux : très facile avec les reg-ex mais tous les caractères ne seront pas retirés dans un premier temps. Les tweets sont des objets très sales !<br></li><li>Retirer les chiffres : avec une Reg-ex aussi<br></li><li>Changer les lettres majuscules en minuscules</li></ul><p>Comme d’habitude pour ne pas se tromper il vaut mieux aller du plus restrictif au moins restrictif.</p><p>Voilà à quoi ressemble notre pipeline :</p><pre class=\"wp-block-code\"><code>import re\n\ndef nlp_pipeline(text):\n\n    text = text.lower()\n    text = text.replace('\\n', ' ').replace('\\r', '')\n    text = ' '.join(text.split())\n    text = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%°\\.]*\", \"\", text)\n    text = re.sub(r\"(\\s\\-\\s|-$)\", \"\", text)\n    text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)\n    text = re.sub(r\"\\&amp;\\S*\\s\", \"\", text)\n    text = re.sub(r\"\\&amp;\", \"\", text)\n    text = re.sub(r\"\\+\", \"\", text)\n    text = re.sub(r\"\\#\", \"\", text)\n    text = re.sub(r\"\\$\", \"\", text)\n    text = re.sub(r\"\\£\", \"\", text)\n    text = re.sub(r\"\\%\", \"\", text)\n    text = re.sub(r\"\\:\", \"\", text)\n    text = re.sub(r\"\\@\", \"\", text)\n    text = re.sub(r\"\\-\", \"\", text)\n\n    return text</code></pre><p>Ce pipeline nous permet d’avoir des tweets à peu prés propres. Cela permet a TextBlob d’analyser le sentiment du tweet plus efficacement.<br></p><h2 class=\"wp-block-heading\" id=\"le-module-nlp-textblob-pour-l-analyse-de-sentiments\">Le module NLP <strong><em>TextBlob</em> pour l’analyse de sentiments</strong></h2><p><br>TextBlob est un module NLP sur Python utilisé pour l’analyse de sentiment. La fonction de TextBlob qui nous intéresse permet pour un texte donné de déterminer le ton du texte et le sentiment de la personne qui l’a écrit.</p><p>Pour chaque tweet nous aurons une métrique qui donne la polarité de ce tweet. Nous allons regrouper les tweets par jours et faire une moyenne de la polarité sur chaque jour. Nous tracerons ensuite la courbe d’évolution de la polarité ambiante.</p><p>D’abord ouvrons le fichier csv que nous avons enregistrer plus haut. Si vous avez utilisé <em>twitterscraper</em> ou twint vous n’avez pas à le faire vos tweets sont déjà stockés dans la variable <em>df</em>.</p><pre class=\"wp-block-code\"><code>tweet = pd.read_csv(\"tweet_covid.csv\")\n\ncorpus = df['tweet']\ncorpus_clean = corpus.apply(nlp_pipeline)</code></pre><p>L’instruction co<em>rpus.apply(nlp_pipeline)</em> permet d’appliquer les règles de nettoyage à chaque tweet du corpus.</p><p>Il faut maintenant installer le module TextBlob :</p><pre class=\"wp-block-code\"><code>!pip install textblob\n!pip install textblob-fr</code></pre><p>Vous devez installer les deux modules car textblob dans sa version de base n’est pas disponible pour la langue française. Si vous travaillez avec un corpus en anglais ce ne sera pas nécessaire.</p><p>On peut maintenant calculer facilement la polarité d’un tweet. Avant de le faire sur nos données, voici deux exemples :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1235\" height=\"381\" src=\"https://i2.wp.com/larevueia.fr/wp-content/uploads/2020/06/ex_tweet.png?fit=1024%2C316&amp;ssl=1\" alt=\"NLP pour l'analyse de sentiment de tweet avec Python\" class=\"wp-image-991\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet.png 1235w, https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet-300x93.png 300w, https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet-1024x316.png 1024w, https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet-768x237.png 768w\" sizes=\"auto, (max-width: 1235px) 100vw, 1235px\"><figcaption>Exemple d’analyse de sentiment de tweets, avec TextBlob</figcaption></figure><pre class=\"wp-block-code\"><code>from textblob import TextBlob\nfrom textblob_fr import PatternTagger, PatternAnalyzer\n\npolarity = []\nfor tweet in corpus_clean:\n  polarity.append(TextBlob(tweet,pos_tagger=PatternTagger(),analyzer=PatternAnalyzer()).sentiment[0])</code></pre><h2 class=\"wp-block-heading\" id=\"visualisation-des-resultats\"><strong>Visualisation des résultats</strong></h2><p><br>La partie que je préfère dans tous les projets data science c’est la visualisation des résultats. Il est bon de pouvoir construire des modèles complexes, mais ils ne servent à rien si on ne peut pas les résumé de manière simple et élégante.</p><p>Maintenant que nous avons une liste avec toutes les polarités des tweets du corpus, nous pouvons tracer une première courbe pour voir à quoi l’évolution ressemble.</p><p>Pour cela on utilise matplotlib.pyplot, c’est la librairie de référence pour le tracé de courbes sur Python :</p><pre class=\"wp-block-code\"><code>import matplotlib.pyplot as plt\n\nplt.plot(polarity)</code></pre><p><br>Avec cette commande, on obtient le tracé de l’évolution de la polarité des tweets. Comme on a 13000 tweets, cette méthode ne permet pas de voir grand chose :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"386\" height=\"248\" src=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid.png\" alt=\"Evolution des sentiments sur Twitter liés au Covid-19\" class=\"wp-image-948\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid.png 386w, https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid-300x193.png 300w\" sizes=\"auto, (max-width: 386px) 100vw, 386px\"><figcaption>Evolution de la polarité des tweets liés au Covid-19 depuis Février</figcaption></figure></div><p>Comme vous le voyez on ne peut rien tirer de ce graphe, on a plusieurs milliers de valeurs. Il faudra être moins bourrin.</p><p>La première chose que l’on peut faire est de regrouper les tweets en paquets suivant l’ordre chronologique. On conservera ensuite pour chaque groupe uniquement sa moyenne. Je décide de les regrouper par paquet de 100 tweets.</p><pre class=\"wp-block-code\"><code>group = lambda liste, size : [liste[i:i+size] for i in range(0, len(liste), size)]\n\npolarity_par_paquet = group(polarity,100)\n\nliste_moyennes = []\nfor l in polarity_par_paquet :\n  liste_moyennes.append(np.mean(l))\n\nplt.plot(liste_moyennes)</code></pre><p>On obtient la courbe suivante :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"378\" height=\"248\" src=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid_grouped.png\" alt=\"Courbe de l'évolution des sentiments des tweets sur le covid-19 depuis Février. Approche par paquet\" class=\"wp-image-961\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid_grouped.png 378w, https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid_grouped-300x197.png 300w\" sizes=\"auto, (max-width: 378px) 100vw, 378px\"><figcaption>Evolution de sentiments des tweets sur le Covid-19 (méthode 2)</figcaption></figure></div><p>Une fois de plus les résultats ne sont pas ceux attendus. Je suis un peu déçu. Je m’attendais à voir une tendance d’évolution se dégageait sur nos résultats. Il peut y avoir plusieurs raisons à cela.</p><p>D’abord, tout au long de l’épidémie, les gens étaient assez partagés sur le danger du virus. De plus, les réactions des gens face au danger ne sont pas toutes identiques. Certains préfèrent plutôt prendre les choses à la rigolade. Ces réactions contribuent à augmenter la polarité.</p><p>Des problèmes dans le modèle peuvent aussi exister. Textblob est un module très généraliste entraîné sur des tweets couvrants de nombreux sujets, il est difficilement applicable à un sujet précis.</p><p>Ces résultats peuvent être considérablement améliorés. Il suffit pour cela de construire une base de données labellisée propre à notre contexte. Si voulez savoir comment faire contactez-moi. Le travail de labellisation est assez long mais permet d’avoir de bien meilleurs performances.</p><p>Comme souvent dans les problèmes de NLP le plus difficile est de constituer une base de données propres et utilisables. C’est la plus grande partie du travail d’un ingénieur NLP. Pour cela les reg-ex sont de très bons outils qu’il est important de maîtriser (des alternatives intéressantes existent évidemment).</p><p>Même si nous n’avons pas obtenu les résultats espérés, ce tutoriel permet d’avoir une méthodologie claire pour la réalisation de ce type de projet. Le schéma sera souvent similaire :<br><br><br>           1. Constitution de la base<br>           2. Nettoyage<br>           3. Conception du modèle<br>           4. Interprétation des résultats<br></p><p>La communauté Python est très active concernant les problématiques de NLP. C’est pour cela qu’avec des connaissances simples vous pouvez faire de très belles choses. A l’image de TextBlob, qui nous a été utile dans ce tutoriel (nous auront l’occasion de l’utiliser encore), de nombreux packages Python vous permette de réaliser vos projets : NLTK, Gensim, SpaCy et d’autres.</p><p>Malgré tous ces outils dont on dispose et malgré tous les efforts de milliers de chercheurs, les défis liés au NLP sont encore difficile à résoudre. La construction de sémantiques fiables et flexibles n’est pas encore parfaitement maîtrisée. Et nous sommes encore très loin d’une vraie compréhension du langage par les IA, c’est d’ailleurs pour cela que <em><a href=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" data-type=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" target=\"_blank\" rel=\"noreferrer noopener\">‘Personne n’aime parler à une IA’</a></em>.</p></div>"},
{"url": "https://larevueia.fr/le-machine-learning-en-20-questions/", "title": "Le machine learning en 20 questions", "author": "Ilyes Talbi", "date": "\n30 août 2020\n", "content": "<div class=\"entry-content\"><figure class=\"wp-block-audio\"><audio controls src=\"https://larevueia.fr/wp-content/uploads/2021/08/Le-machine-learning-en-20-questions_mixed.mp3\"></audio></figure><p>Beaucoup de choses sont dites au sujet du <strong>machine learning</strong>. Certains le voit comme un monstre qui mène l’humanité à sa perte. D’autres comme un magicien solution à tous leurs maux. En réalité c’est beaucoup plus simple que ça (et un peu moins effrayant).</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Le machine learning en 20 questions\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"qu-est-ce-que-le-machine-learning\">Qu’est-ce que le machine learning ?</h2><p>Le machine learning est une technique qui permet aux systèmes automatiques de s’améliorer grâce aux données. Littéralement on parle <em>d’apprentissage automatique</em>.</p><p>L’explosion du volume de données et le progrès des techniques de traitement et de stockage, on permit au machine learning de s’imposer dans de nombreux domaines.</p><h2 class=\"wp-block-heading\" id=\"comment-fonctionne-le-machine-learning\">Comment fonctionne le machine learning ?</h2><p>Derrière ce nom mystérieux, se cache un fonctionnement en principe très simple. Le système s’inspire d’exemples déjà existants, regroupés dans des bases de données, pour comprendre la tâche qui lui est demandée.</p><p>Que les choses soient claires. Ce n’est pas parce que l’on parle de machines qu’il faut imaginer des robots qui suivent des cours dans une salle de classe. Le vocabulaire utilisé n’est qu’une manière imagée de décrire le processus.</p><h2 class=\"wp-block-heading\" id=\"quel-est-le-lien-entre-machine-learning-deep-learning-et-intelligence-artificielle\">Quel est le lien entre machine learning, deep learning et intelligence artificielle ?</h2><p>Comme tous les domaines polémiques, l’intelligence artificielle fait couler beaucoup d’encre. La conséquence directe de cela est l’apparition de <em>buzzwords</em> et on finit un peu par se perdre.</p><p>En réalité, le <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a> n’est qu’un sous ensemble du machine learning, lui même sous ensemble de l’intelligence artificielle. Dans un diagramme voici ce que ça donne.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-1024x576.png\" alt=\"Le machine learning en 20 questions\" class=\"wp-image-1734\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-1024x576.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-768x432.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-1536x864.png 1536w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Intelligence artificielle, machine learning, deep learning, quelle est la différence</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-applications-du-machine-learning\">Quelles sont les applications du machine learning ?</h2><p>Le machine learning s’est imposé dans un très grand nombre de domaines. Il n’y a pas réellement de limites à ce que les modèles de machine learning peuvent réaliser. Dès qu’il y a des données on peut faire du machine learning.</p><p>En finance par exemple, la volatilité des marchés boursiers semble ne pas laisser de place à la prédiction. Néanmoins, le machine learning fournit une solution. Il permet de donner des prévisions plus ou moins précises concernant l’évolution d’une action boursière.</p><p>Dans le <a href=\"https://larevueia.fr/lintelligence-artificielle-au-service-de-la-sante/\" target=\"_blank\" rel=\"noreferrer noopener\">domaine de la santé</a> aussi, l’intelligence artificielle commence à s’imposer comme un outil majeur. L’IA est régulièrement utilisée par les médecins aujourd’hui. La médecine du futur est souvent associée aux 3 P : Prévention, Prédiction, Personnalisation</p><p>C’est surtout pour l’imagerie médicale que les IA d’aujourd’hui se démarquent vraiment. Les progrès en terme de computer vision ont été impressionnants ces dernières années. Et les IA d’aujourd’hui sont au moins aussi fortes que les médecins sur des tâches comme la détection de tumeurs cancéreuses ou le calcul de l’âge osseux.</p><p>De manière plus générale, l’IA constitue une opportunité de développement sans précédent pour les entreprises. Elle permet d’établir des stratégies à plus ou moins long terme à travers des outils d’aide à la prise de décision.</p><p>Le machine learning permet de répondre à des questions comme : Dois-je me lancer dans ce projet de <a href=\"https://larevueia.fr/les-cas-dusages-de-lia-dans-limmobilier/\" target=\"_blank\" rel=\"noreferrer noopener\">construction immobilière</a> ? Est-ce que le profil de ce candidat correspond à ce poste ? Comment va évoluer le marché de la voiture électrique d’ici 2025 ? Et des millions d’autres questions propres à chaque activité.</p><h2 class=\"wp-block-heading\" id=\"quelle-est-la-difference-entre-apprentissage-supervise-et-apprentissage-non-supervise\">Quelle est la différence entre apprentissage supervisé et apprentissage non supervisé ?</h2><p>Le machine learning se divise essentiellement en deux modes d’apprentissage. L’apprentissage supervisé et l’<a href=\"https://larevueia.fr/panorama-de-l-apprentissage-non-supervise/\" target=\"_blank\" rel=\"noreferrer noopener\">apprentissage non supervisé</a>.</p><p>En apprentissage supervisé, les données dont on dispose sont labellisées. C’est à dire, les sorties du modèle sont déjà connues. C’est le cas pour les réseaux de neurones par exemple.</p><p>A l’inverse, lorsque l’on fait de l’apprentissage non supervisé, on laisse le modèle s’entraîner tout seul, sans labelliser les données. Un des algorithmes de clustering non supervisé les plus utilisés est k-means. On donne à l’algorithme tous les points de notre dataset et on a en sortie ces mêmes points regroupés en plusieurs catégories.</p><h2 class=\"wp-block-heading\" id=\"qu-est-ce-que-l-explicabilite-en-machine-learning\">Qu’est-ce que l’explicabilité en machine learning ?</h2><p>Beaucoup de modèles que l’on utilise aujourd’hui sont ce qu’on appelle des boîtes noires. Dans le sens où ils sont opaques et leur fonctionnement interne est très peu compris.</p><p>Le dilemme efficacité/<a href=\"https://larevueia.fr/explicabilite-des-modeles-ne-croyez-pas-aveuglement-ce-que-lia-vous-dit/\" target=\"_blank\" rel=\"noreferrer noopener\">explicabilité</a> est un dilemme bien connu en science des données. Bien souvent les modèles les plus efficaces sont des boîtes noires dont le fonctionnement est le moins explicable.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"638\" height=\"479\" src=\"https://larevueia.fr/wp-content/uploads/2020/06/explainability_tradeoff.jpg\" alt=\"éxplicabilité vs performance en machine learning\" class=\"wp-image-705\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/explainability_tradeoff.jpg 638w, https://larevueia.fr/wp-content/uploads/2020/06/explainability_tradeoff-300x225.jpg 300w\" sizes=\"auto, (max-width: 638px) 100vw, 638px\"><figcaption class=\"wp-element-caption\">Dilemme explicabilité/efficacité</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-etapes-d-un-projet-en-data-science\">Quelles sont les étapes d’un projet en data science ?</h2><p>Lorsque j’ai commencé à travailler sur des projets de data science, j’ai été surpris de voir que la construction du modèle ne représentait qu’une petite étape d’un long processus.</p><p>Les projets se divisent souvent de la sorte :</p><ul class=\"wp-block-list\"><li>Collecte et stockage des données</li><li>Preprocessing (nettoyage des données et études préalables)</li><li>Construction des modèles</li><li>Etudes de performances et choix du meilleur modèle</li><li>Déploiement du modèle</li></ul><h2 class=\"wp-block-heading\" id=\"comment-se-deroule-le-nettoyage-des-donnees-preprocessing\">Comment se déroule le nettoyage des données (preprocessing) ?</h2><p>Contrairement à ce que l’on pense, le nettoyage des données est la tâche principale lors d’un projet de machine learning. Et c’est dommage (d’après moi en tout cas 🙂 ), car c’est beaucoup moins amusant que la conception du modèle ! Tous ce travail que l’on fait en amont est ce que l’on appelle le <em>preprocessing</em>.</p><p>Les techniques de preprocessing dépendent du projet et du types de données que l’on étudie. Bien souvent on suit les étapes suivantes :</p><ul class=\"wp-block-list\"><li>Traitement des valeurs manquantes</li><li>Calcul de corrélations ou de variances</li><li>Réduction de la dimension</li><li>Encodage des features</li><li>Découpage des données en train/test</li></ul><h2 class=\"wp-block-heading\" id=\"comment-evaluer-un-modele\">Comment évaluer un modèle ?</h2><p>Avant de mettre un modèle en production, il y a toute une phase de validation qui débute. Et pour ne rien faciliter cette phase de validation implique d’être minutieux.</p><p>D’abord, avant d’entraîner un modèle on s’assure de séparer les données disponibles en 2. Données d’entraînements et données de tests. On parle de cross validation.</p><p>Cela permet de tester le modèle une fois entraîné, cette étape est primordiale. Elle permet de s’assurer de la fiabilité du modèle mais aussi de comparer plusieurs approches pour pouvoir déterminer la quelle est la plus intéressante.</p><h2 class=\"wp-block-heading\" id=\"comment-eviter-l-overfitting\">Comment éviter l’overfitting ?</h2><p>L’overfitting est le plus grand ennemi du data scientist. Il survient lorsque le modèle essaye de trop coller aux données. Si bien qu’il n’est plus généralisable.</p><figure class=\"wp-block-image alignwide size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"356\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/overfiting-1024x356.png\" alt=\"Qu'est-ce que l'overfitting ?\" class=\"wp-image-1801\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/overfiting-1024x356.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/overfiting-300x104.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/overfiting-768x267.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/overfiting.png 1125w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Illustration de l’overfitting dans le cas de la régression</figcaption></figure><p>Avant de savoir comment l’éviter, nous devons apprendre à le détecter.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"450\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting.png\" alt=\"Détecter l'overfitting en machine learning\" class=\"wp-image-1809\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting.png 800w, https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting-768x432.png 768w\" sizes=\"auto, (max-width: 800px) 100vw, 800px\"><figcaption class=\"wp-element-caption\">Détecter l’overfitting sur une courbe de précision</figcaption></figure></div><p>Sur cette courbe (que vous devrez toujours tracer pour vérifier les performances du modèle) on voit qu’à partir d’un certain point, notre précision sur les données de test chutent. Cela veut dire que le modèle commence à être de moins en moins efficace. On fait de l’overfitting.</p><p>Plusieurs méthodes existent pour éviter l’overfitting :</p><ul class=\"wp-block-list\"><li><a href=\"https://fr.wikipedia.org/wiki/Validation_crois%C3%A9e\" target=\"_blank\" rel=\"noreferrer noopener\">Cross validation</a></li><li>Ajouter plus de données pour l’entraînement</li><li>Early stopping (arrêter l’entrainement avant qu’ils ne se terminent)</li><li><a href=\"https://dataanalyticspost.com/Lexique/regularisation/#:~:text=Pour%20les%20r%C3%A9seaux%20de%20neurones,les%20mod%C3%A8les%20simples)%20ou%20la\" target=\"_blank\" rel=\"noreferrer noopener\">Régularisation</a> (par exemple le dropout pour les réseaux de neurones)</li></ul><p>On a un <a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">article entier</a> sur ce sujet 🙂</p><h2 class=\"wp-block-heading\" id=\"quels-sont-les-principaux-outils-utilises-en-machine-learning\">Quels sont les principaux outils utilisés en machine learning ?</h2><p>Les outils qui interviennent en machine learning sont nombreux. Pour le développement de modèle on utilise des langages de programmation objets performants comme Python ou C.</p><p>Python reste le langage de référence. Il jouit d’une communauté open source très active ce qui permet d’avoir des modules très puissants comme <a href=\"https://colab.research.google.com/drive/1yYWxg5oFk15qYW4aCsHj6kERzlZQAZzW?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">Pandas</a>, <a href=\"https://larevueia.fr/tensorflow/\" target=\"_blank\" rel=\"noreferrer noopener\">Tensorflow </a>ou <a href=\"https://scikit-learn.org/\" target=\"_blank\" rel=\"noreferrer noopener\">Scikit-learn</a>. Ils rendent les modèles de machine learning plus facile à implémenter. Ça serait beaucoup trop longs de vous énumérer tous les outils utilisés en machine learning. Si je devais en garder que 3 (pour la partie construction de modèles), je prendrais ceux là.</p><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-principales-methodes-utilisees\">Quelles sont les principales méthodes utilisées ?</h2><p>Les modèles de machine learning sont nombreux. Ceux qui ont la côte aujourd’hui sont les algorithmes de <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, ils sont fiables faciles à entraîner et donnent d’assez bons résultats la plupart du temps.</p><p>Il y a un grand nombre de méthodes en fonction de ce que l’on veut faire.</p><p>Pour le clustering :</p><ul class=\"wp-block-list\"><li>k-nn</li><li>k-means</li><li>DBScan</li><li>Régression logistique</li><li>SVM</li></ul><p>Réseaux de neurones :</p><ul class=\"wp-block-list\"><li>LSTM</li><li>CNN</li><li><a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones-gan/\" target=\"_blank\" rel=\"noreferrer noopener\">GAN</a></li><li>Auto Encoder</li><li><a href=\"https://larevueia.fr/reseaux-de-neurones-toute-lhistoire-du-perceptron/\" target=\"_blank\" rel=\"noreferrer noopener\">Perceptron</a></li></ul><p>Arbres de décisions :</p><ul class=\"wp-block-list\"><li><a href=\"https://larevueia.fr/random-forest/\" target=\"_blank\" rel=\"noreferrer noopener\">Random Forest</a></li><li>XGBoost</li><li>AdaBoost</li><li>LightGBM</li><li>CatBoost</li></ul><p>Avec tous ces algorithmes on est en droit de se demander lequel choisir. La transition avec la prochaine question est parfaite 🙂</p><h2 class=\"wp-block-heading\" id=\"comment-choisir-l-algorithme-a-utiliser\">Comment choisir l’algorithme à utiliser ?</h2><p>Le machine learning est une question de choix. Des données jusqu’à l’algorithme à utiliser, le data scientist a de nombreuses décisions à prendre. Le choix de l’algorithme à utiliser est sans doute le plus crucial.</p><p>Plusieurs critères sont à prendre en compte pour choisir un modèle :</p><ul class=\"wp-block-list\"><li>Quelle tâche souhaitez vous effectuer ? Prédiction ? Régression ? Clustering ?</li><li>Les données sont elles labellisées ?</li><li>De quel types sont les données ? Images ? Textes ? Audio ?</li><li>Quelle est la taille de votre dataset ?</li></ul><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube aligncenter wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Comment CHOISIR LE BON MODÈLE de Machine Learning ?\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/4mqKmTbAnHY?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div><figcaption class=\"wp-element-caption\">Comment choisir le bon modèle pour ses données ?</figcaption></figure><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-limites-du-machine-learning\">Quelles sont les limites du machine learning ?</h2><p>L’intelligence artificielle est souvent vu comme une baguette magique capable de tout. En réalité ce n’est pas si simple. Les modèles ont souvent besoin d’énormément de données pour pouvoir donner de bons résultats.</p><p>Dans mon article <em><a href=\"https://larevueia.fr/ce-que-lia-nest-pas/\" target=\"_blank\" rel=\"noreferrer noopener\">Ce que l’IA n’est pas</a></em>, j’explique comment le marketing a rendu l’intelligence artificielle plus impressionnante qu’elle ne l’est réellement. Les modèles d’aujourd’hui sont très limités, ils demandent beaucoup d’entraînement et sont assez peu généralisables.</p><h2 class=\"wp-block-heading\" id=\"quelles-competences-doit-avoir-un-data-scientist\">Quelles compétences doit avoir un data scientist ?</h2><p>Les data scientist sont aujourd’hui très recherchés. Un ingénieur en machine learning doit avoir des compétences aussi bien théoriques que pratiques. Il doit être un très bon statisticien, c’est indispensable pour comprendre correctement les différents algorithmes et leurs subtilités. D’un point de vu plus pratique, il doit être à l’aise avec les outils de programmation comme Python.</p></div>"},
{"url": "https://larevueia.fr/limpact-de-lia-et-des-data-centers-sur-lenvironnement/", "title": "L’impact de l’IA et des data centers sur l’environnement", "author": "Ilyes Talbi", "date": "\n9 avril 2023\n", "content": "<div class=\"entry-content\"><p>L’intelligence artificielle (IA) et les centres de données (data centers) ont considérablement stimulé le développement de l’industrie numérique ces dernières années. Cependant, cette croissance rapide a également eu un impact significatif sur l’environnement.</p><p>Les demandes en énergie des data centers et de l’IA ne cessent de croître, ce qui accentue la dépendance aux combustibles fossiles, la consommation d’eau et les émissions de gaz à effet de serre.</p><p>Cette situation préoccupe de plus en plus les entreprises et les gouvernements, qui cherchent à réduire l’empreinte carbone de leurs opérations.</p><p>Pour faire face à ce défi environnemental, des efforts considérables ont été déployés pour rendre l’utilisation de l’IA et des data centers plus efficace et plus respectueuse de l’environnement.</p><p>Cet article explore ainsi l’impact de l’IA et des data centers sur l’environnement et discutera des solutions existantes et en devenir pour réduire leur empreinte carbone.</p><h2 class=\"wp-block-heading\">Les data centers : des infrastructures énergivores</h2><p>Les data centers ont une consommation énergétique très élevée pour assurer le stockage, le traitement et la gestion des données.</p><p>En effet, ils nécessitent non seulement une énorme quantité d’électricité pour leur fonctionnement quotidien, mais également des systèmes de refroidissement sophistiqués pour éviter toute surchauffe de l’équipement informatique.</p><p>Cette consommation d’énergie est souvent couverte par des combustibles fossiles non renouvelables, ce qui contribue à l’augmentation des émissions de gaz à effet de serre.</p><p>Selon les estimations, les centres de données seraient responsables d’environ 1% de la consommation mondiale d’électricité.</p><p>Cela en fait l’un des plus grands consommateurs d’énergie dans le secteur numérique et les experts estiment que cette proportion pourrait doubler d’ici 2025.</p><p>Face à cette problématique, plusieurs acteurs du secteur travaillent sur des solutions pour optimiser la consommation énergétique des data centers.</p><p>Des stratégies telles que l’utilisation de sources d’énergie renouvelables et la consolidation des infrastructures pourraient permettre de réduire significativement leur impact environnemental.</p><h2 class=\"wp-block-heading\">L’IA une technologie gourmande en énergie</h2><p>L’intelligence artificielle (IA) est une technologie émergente qui implique une grande quantité de calculs complexes pour faire fonctionner les algorithmes.</p><p>Pourtant, la puissance de traitement nécessaire pour exécuter ces calculs est considérablement élevée, ce qui en fait une technologie gourmande en énergie.</p><p>En plus des data centers spécialisés, qui stockent et traitent les données nécessaires à l’entraînement et à l’utilisation constante de l’IA, de nombreux appareils compatibles avec l’IA, tels que les smartphones, les voitures autonomes, les drones et les robots, nécessitent également des capacités de traitement élevées qui consomment beaucoup d’énergie.</p><p>Malgré les avantages que peut offrir l’IA, l’impact environnemental de cette technologie est de plus en plus préoccupant. Les développeurs de technologies émergentes proposent des solutions pour réduire autant que possible l’impact environnemental de l’IA.</p><p>Des moyens tels que l’optimisation des algorithmes et la mise en place de choix informatiques plus économes en énergie sont envisagés pour réduire l’empreinte carbone de cette technologie prometteuse.</p><h2 class=\"wp-block-heading\">Les conséquences environnementales de l’exploitation de l’IA et des data centers</h2><p>Les impacts environnementaux de l’utilisation de l’IA et des data centers sont nombreux et variés. La forte demande énergétique de ces infrastructures numériques pourrait entraîner une augmentation significative de la production d’énergie fossile, ce qui contribuerait à l’augmentation des niveaux de gaz à effet de serre et à l’accélération du changement climatique.</p><p>De plus, les besoins en refroidissement de l’équipement informatique peuvent contribuer à la pénurie d’eau dans les régions où les ressources sont limitées. En outre, la production et la gestion des équipements technologiques peuvent avoir un impact négatif sur les ressources naturelles et sur la qualité de l’air.</p><p>Enfin, l’utilisation de l’IA peut avoir des conséquences éthiques et sociales importantes, tels que la question de la protection de données personnelles et de la préservation de la vie privée.</p><p>Il est donc essentiel de prendre en compte tous ces facteurs et d’apporter des changements significatifs pour réduire l’impact environnemental de l’exploitation de l’IA et des data centers. Des solutions efficaces doivent être mises en place, telles que l’utilisation des sources d’énergie renouvelables, la virtualisation de l’informatique et la gestion efficace de l’énergie.</p><h2 class=\"wp-block-heading\">Des solutions pour réduire l’impact de l’IA et des data centers sur l’environnement</h2><p>Des solutions sont actuellement étudiées pour réduire l’impact environnemental de l’IA et des data centers. L’une des principales initiatives consiste à utiliser des sources d’énergie renouvelables, telles que l’énergie solaire, éolienne et hydraulique. L’utilisation de l’énergie solaire pour alimenter les data centers est devenue une tendance croissante.</p><p>En outre, la virtualisation de l’informatique est une autre solution efficace pour réduire la consommation énergétique des data centers. Cela implique la consolidation des infrastructures informatiques pour un meilleur usage des ressources et une réduction des coûts.</p><p>Enfin, de nouveaux systèmes de refroidissement pour les centres de données sont également en cours de développement. Les liquides de refroidissement évaporatifs permettent de réduire considérablement la consommation d’énergie en utilisant l’air extérieur pour rafraîchir les équipements informatiques.</p><p>L’utilisation de l’IA elle-même peut également apporter une contribution significative à la réduction de la consommation d’énergie, par exemple en utilisant des algorithmes de gestion intelligente de l’énergie pour mieux gérer les systèmes de refroidissement et de chauffage.</p><p>En somme, ces solutions doivent être mises en œuvre de manière holistique, en prenant en compte tous les aspects de l’utilisation de l’IA et des data centers pour minimiser leur impact environnemental.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, l’IA et les data centers ont apporté de nombreux avantages au monde numérique, mais leur impact environnemental ne peut être ignoré. La forte consommation d’énergie et les émissions de gaz à effet de serre résultent en une empreinte carbone importante pour cette industrie.</p><p>Il est donc impératif d’opter pour des solutions éco-responsables pour minimiser l’impact environnemental de l’utilisation de l’IA et des centres de données.</p><p>Les initiatives visant à utiliser des sources d’énergie renouvelable, la virtualisation de l’informatique et les nouveaux systèmes de refroidissement sont autant de pistes permettant de réduire la consommation d’énergie et de limiter la production de gaz à effet de serre.</p><p>Les entreprises doivent également prendre des mesures pour la récupération et le recyclage de l’équipement informatique.</p><p>Le défi consiste à innover et à explorer de nouvelles solutions pour stimuler la transition vers une utilisation plus écologique des systèmes informatiques.</p><p>En investissant dans des technologies plus durables, les entreprises peuvent continuer à tirer profit des avantages de l’IA tout en faisant preuve de responsabilité écologique.</p></div>"},
{"url": "https://larevueia.fr/dans-la-course-a-lia-hardware-is-all-you-need/", "title": "Dans la course à l’IA : Hardware is all you need", "author": "Ilyes Talbi", "date": "\n24 juin 2023\n", "content": "<div class=\"entry-content\"><p>Dans l’arène technologique contemporaine, une compétition effrénée se joue, un marathon où l’Intelligence Artificielle (IA) tient le rôle de la médaille d’or tant convoitée.</p><p>Mais dans cette course, ce n’est pas tant la vitesse qui importe, mais la puissance et l’endurance. Dans le domaine de l’IA, l’endurance se mesure en termes de capacités de calcul, et la puissance en termes de capacités de traitement de données.</p><p>Autrement dit, en termes de hardware.</p><p>C’est ce que nous allons explorer aujourd’hui.</p><p>Bien loin des projecteurs, dans l’ombre des algorithmes et des ensembles de données, le matériel informatique joue un rôle déterminant dans la progression de l’IA.</p><p>Data centers titanesques et puces graphiques de pointe constituent les rouages essentiels de cette machine complexe.</p><p>Les progrès réalisés en IA ces dernières années ne sont pas uniquement dus à des modèles plus intelligents, mais à des modèles contenant toujours plus de paramètres entraînables et entraînés sur des volumes de données sans cesse croissants.</p><p>Alors, attachez vos ceintures et préparez-vous pour un voyage à travers les coulisses de la course à l’IA, où nous découvrirons que dans ce marathon technologique, le hardware est bien plus qu’un simple accessoire : il est le cœur même de la machine.</p><h2 class=\"wp-block-heading\">L’importance des data centers</h2><h3 class=\"wp-block-heading\">A quoi sert un data center ?</h3><p>Imaginez un orchestre, où chaque instrument joue un rôle crucial pour créer une harmonie parfaite. Dans l’univers de l’Intelligence Artificielle, les data centers sont le chef d’orchestre.</p><p>Les data centers, ou centres de données, sont des infrastructures dédiées où sont rassemblés des équipements de traitement et de stockage de données. Ces véritables cerveaux numériques sont essentiels pour gérer, traiter et distribuer d’énormes volumes de données, et donc, pour la mise en œuvre de l’IA.</p><p>Ces centres de données ne sont pas simplement des entrepôts remplis de serveurs, mais des écosystèmes technologiques complexes, où chaque composant, du serveur à la puce, du routeur au système de refroidissement, joue un rôle dans la gestion efficace des données.</p><p>Sans ces architectures sophistiquées, le traitement des grands volumes de données nécessaires à l’entraînement des modèles d’IA serait une tâche herculéenne, voire impossible.</p><h3 class=\"wp-block-heading\">Un meilleur hardware dans les data centers permet d’améliorer notre façon de faire de l’IA</h3><p>Mais ce n’est pas tout. Les data centers sont en constante évolution. Au fur et à mesure que l’IA progresse, la demande en capacité de calcul augmente, et les data centers doivent s’adapter.</p><p>Les améliorations du hardware dans les data centers, qu’il s’agisse de serveurs plus puissants, de mémoires plus rapides ou de systèmes de refroidissement plus efficaces, ont été des facteurs clés de l’évolution de l’IA.</p><p>En somme, le rôle des data centers dans le domaine de l’IA est comparable à celui du chef d’orchestre dans un orchestre : sans lui, chaque instrument pourrait être performant, mais l’harmonie serait absente. Il n’y a pas de symphonie sans chef, et il n’y a pas d’IA sans data centers.</p><p>C’est ici que la vraie magie de l’IA prend vie, où les données sont transformées en informations, où les bits deviennent de la connaissance. Les data centers sont le cœur palpitant de l’IA, orchestrant le rythme auquel avance cette révolution technologique.</p><h2 class=\"wp-block-heading\">Le rôle crucial des GPUs</h2><p>Dans l’orchestre des data centers, si le chef d’orchestre est la structure organisatrice, alors les GPUs, ou unités de traitement graphique, sont les violons solistes, les véritables stars du spectacle. Sans ces GPUs, l’entraînement des modèles de <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, une sous-catégorie de l’IA, serait tout simplement impensable.</p><p>Les GPUs, initialement conçus pour le rendu graphique dans les jeux vidéo, se sont avérés exceptionnellement efficaces pour le calcul parallèle – la capacité d’exécuter plusieurs calculs simultanément. Cette caractéristique s’est révélée être une aubaine pour le deep learning, qui nécessite des opérations matricielles massives, une tâche pour laquelle les GPUs sont parfaitement adaptés.</p><p>Les GPUs sont donc devenus une pierre angulaire de l’entraînement des modèles d’IA. Ils permettent de traiter rapidement des volumes énormes de données, d’accélérer les temps d’entraînement et d’optimiser les performances des modèles. Sans eux, l’entraînement d’un seul modèle d’IA pourrait prendre des mois, voire des années.</p><p>Et comme les data centers, les GPUs ont également évolué. Les constructeurs, conscients de leur importance croissante dans le domaine de l’IA, ont développé des GPUs de plus en plus puissants, capables de traiter des volumes de données toujours plus importants et de soutenir des modèles d’IA de plus en plus complexes.</p><p>Et aujourd’hui, les maestros du monde des GPUs pour le deep learning, sont incontestablement, Nvidia.</p><p>En fin de compte, l’impact des GPUs sur l’efficacité et la vitesse de l’IA est incontestable. Ils sont les violons solistes de notre orchestre, jouant la mélodie du deep learning avec une virtuosité sans précédent. Sans les GPUs, le concert de l’IA ne serait qu’un murmure. Avec eux, il devient une symphonie.</p><h2 class=\"wp-block-heading\">Toujours plus de paramètres, toujours plus de data</h2><p>Reprenons notre analogie musicale. Si les data centers sont le chef d’orchestre et les GPUs les violons solistes, alors les modèles d’IA sont la partition musicale. C’est à travers eux que la symphonie de l’IA prend forme. Cependant, ces partitions sont devenues de plus en plus complexes au fil du temps, gagnant en longueur et en détails.</p><p>Au cours des dernières années, une tendance claire s’est dégagée dans le développement des modèles d’IA : une augmentation constante du nombre de paramètres et une soif insatiable de données. Ces modèles gigantesques, tels que <a href=\"https://larevueia.fr/introduction-a-gpt-3-lun-des-modeles-de-nlp-les-plus-avances/\" target=\"_blank\" rel=\"noreferrer noopener\">GPT-3</a> de <a href=\"https://openai.com/\" target=\"_blank\" rel=\"noreferrer noopener\">OpenAI</a> avec ses 175 milliards de paramètres, GPT-4 en a potentiellement des dizaines de trillions, semblent suivre la loi de Moore de l’IA, doublant (ou faisant x100) en taille tous les 16 mois environ. Cette croissance exponentielle a été rendue possible grâce aux améliorations constantes du hardware.</p><p>Cependant, cette course au gigantisme soulève des questions d’ordre économique. Les entreprises qui possèdent les moyens de calcul nécessaires pour entraîner ces monstres de puissance ont un avantage compétitif considérable. On peut craindre une concentration de pouvoir entre les mains de quelques géants technologiques, avec le risque de créer des monopoles dans le domaine de l’IA.</p><p>Par ailleurs, cette tendance à la croissance n’est pas sans susciter des divergences stratégiques au sein de la communauté de l’IA.</p><p>D’un côté, il y a ceux qui poussent à l’augmentation de la taille des modèles, convaincus que la route vers l’IA généralisée passe par toujours plus de données et de paramètres. De l’autre, il y a des voix dissidentes, comme celle de Yann LeCun, lauréat du prix Turing et pionnier du deep learning, qui plaide pour une approche plus frugale. LeCun propose de se tourner vers des modes d’apprentissage plus intelligents, tels que le self-supervised learning. Il souligne que contrairement à une machine, un enfant n’a pas besoin de voir des milliers d’images d’une girafe pour comprendre le concept de girafe.</p><p>Quelle que soit la voie que nous choisissons de suivre, une chose est certaine : le rôle du hardware restera central. Qu’il s’agisse de soutenir la croissance exponentielle des modèles ou de rendre possible des approches d’apprentissage plus sophistiquées, le hardware est et restera le chef d’orchestre de la symphonie de l’IA.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, l’importance du hardware dans la course à l’IA est indéniable. Comme nous l’avons vu, les data centers sont le chef d’orchestre qui régit l’orchestre de l’IA, tandis que les GPUs sont les virtuoses solistes qui jouent la mélodie du deep learning. Quant aux modèles d’IA, ils sont la partition complexe et toujours plus longue sur laquelle se joue la symphonie de l’IA.</p><p>Cependant, il est important de souligner que cette course technologique n’est pas sans conséquences. L’un des enjeux les plus pressants est l’impact environnemental de cette augmentation constante de la puissance de calcul. Les data centers consomment une quantité d’énergie colossale, et leur empreinte carbone est loin d’être négligeable. Il est donc essentiel de prendre en compte cet aspect dans notre quête de l’IA.</p><p>Finalement, que nous choisissions de suivre la voie de la croissance exponentielle des modèles ou celle de l’apprentissage plus frugal, une chose est certaine : le hardware sera toujours au cœur de l’IA. Alors que nous continuons à explorer les possibilités offertes par l’IA, n’oublions pas l’importance de l’infrastructure qui la rend possible. Après tout, dans la course à l’IA, le hardware n’est pas seulement un accessoire : c’est le véritable cœur de la machine.</p></div>"},
{"url": "https://larevueia.fr/comment-lia-transforme-le-domaine-de-la-sante/", "title": "Comment l’IA transforme le domaine de la santé ?", "author": "Ilyes Talbi", "date": "\n13 janvier 2023\n", "content": "<div class=\"entry-content\"><p>L’intelligence artificielle a conquis la plupart des domaines de la connaissance. Les modèles d’aujourd’hui savent parler, cuisiner, dessiner, et apprennent à soigner.</p><p>L’intelligence artificielle intervient à plusieurs endroits pour la médecine : de la découverte de nouveaux médicaments, à l’aide pour la recherche en passant par le diagnostic.</p><p>Dans cet article, j’ai voulu regrouper le maximum d’informations sur l’IA en santé. Ce document peut faire office d’état de l’art non-exhaustif, avec des références et un guide de lecture pour le futur de l’IA dans la santé.</p><h2 class=\"wp-block-heading\">NLP et santé</h2><p>Les modèles de NLP sont de plus en plus robustes, ils permettent de saisir des subtilités de langage, et comprendre la sémantique des phrases.</p><p>Pour le NLP, il y a clairement un avant et un après GPT, le large langage model proposé par OpenAI. Et comme tous les domaines, le monde de la santé devrait beaucoup bénéficier de ces progrès.</p><p>Dans cette section on explore les différents projets de NLP dans la santé, même s’il n’y a pas de révolution, les prochaines années devraient voir de jolies initiatives émerger.</p><h3 class=\"wp-block-heading\">L’OCR pour l’analyse d’ordonnances</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances.webp\" alt=\"Comment l'IA transforme le domaine de la santé ?\" class=\"wp-image-7974\" width=\"719\" height=\"275\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances.webp 1024w, https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances-300x115.webp 300w, https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances-768x294.webp 768w\" sizes=\"auto, (max-width: 719px) 100vw, 719px\"></figure></div><p>Les médecins ont leur façon à eux d’écrire, ils se comprennent plutôt bien entre eux et les pharmaciens n’ont pas l’air d’éprouver de difficultés à déchiffrer les ordonnances.</p><p>Néanmoins, il est clair que l’on peut faire beaucoup mieux niveau process et fiabilité. En attendant le passage au tout numérique (fortement remis en question par la cyber-attaque subie par un hôpital récemment), l’OCR (Optical Characters Recognition) semble être une solution intéressante pour mieux déchiffrer les prescriptions médicales.</p><p>Il est utile de noter que l’OCR restera utile même après le passage au tout numérique, puisqu’il permettra d’extraire des données plus facilement ou encore de générer des rappels pour la prise de médicaments de façon automatique (notamment pour les personnes âgées).</p><p>J’ai mis ce sujet dans la rubrique NLP car je suis convaincu que la partie liée au traitement de l’image ne sera bientôt plus un problème en OCR, le problème réside dans la compréhension et le traitement du texte résultant : notamment sur la classification des types (par exemple nom du médecin/nom du médicament/adresse, etc.).</p><h3 class=\"wp-block-heading\">Diagnostiquer des maladies par la voix</h3><p>Owkin travaille avec 12 partenaires sur un projet de diagnostic des maladies via la voix. Pour mener à bien ce travail, le financement disponible s’élève à 14 M d’euros.</p><p>2 questions me viennent à l’esprit concernant ce projet :</p><ul class=\"wp-block-list\"><li>D’abord, j’avoue que je suis un peu dubitatif. C’est sans doute à cause de mon ignorance du monde de la santé, mais je ne vois pas comment un modèle pourrait détecter une pathologie simplement en utilisant la voix du patient. Comment est-ce que ça va marcher ?</li><li>Et si ça marche, comment assurer le secret médical ? On pourrait prédire la maladie d’une personne au téléphone ou grâce à une vidéo d’elle…</li></ul><figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\"><blockquote class=\"twitter-tweet\" data-width=\"550\" data-dnt=\"true\"><p lang=\"en\" dir=\"ltr\">Today, we are launching Voice as a Biomarker of Health － a $14 million <a href=\"https://twitter.com/NIH?ref_src=twsrc%5Etfw\">@NIH</a>-funded project to use <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a> to help doctors diagnose cancer, depression and other diseases from the human voice.<br><br>Learn more at <a href=\"https://t.co/B5tZPHLhwP\">https://t.co/B5tZPHLhwP</a> <a href=\"https://t.co/9J8XBfGTE8\">pic.twitter.com/9J8XBfGTE8</a></p>— Owkin (@OwkinScience) <a href=\"https://twitter.com/OwkinScience/status/1569703379881926657?ref_src=twsrc%5Etfw\">September 13, 2022</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> </div></figure><h3 class=\"wp-block-heading\">Les limites de Google traduction</h3><p>La situation dans laquelle un patient et un médecin ne parle pas la même langue est plus fréquente qu’on ne le pense.</p><p>Dans ces cas-là, on utilise souvent des modèles de traduction généralistes comme Google traduction. Le problème c’est que ces modèles n’ont pas été entraînés pour le médical et peuvent conduire à des erreurs graves de traduction.</p><p>Un exemple d’erreur faites par Google traduction (pas en situation réelle heureusement), est la traduction de “votre enfant s’adapte” à “votre enfant est mort”. Je te laisse voir le papier en réf qui décrit l’étude faite et recense quelques-unes des erreurs graves de traduction faites par Google traduction.</p><p>Afin d’accélérer la prise en charge et limiter le risque d’erreur, des modèles de traduction entraînés spécialement pour le médical émergent.</p><p>Des références sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://www.bmj.com/content/349/bmj.g7392\" target=\"_blank\" rel=\"noreferrer noopener\">Google traduction pour la santé</a></li><li>Le site de <a href=\"https://www.aalia.tech/\" target=\"_blank\" rel=\"noreferrer noopener\">Aalia.tech</a>, une startup française qui travaille sur ce sujet</li><li><a href=\"https://www.presse-citron.net/google-traduction-est-toujours-un-risque-pour-la-medecine/\" target=\"_blank\" rel=\"noreferrer noopener\">Un article de presse-citron</a></li></ul><h2 class=\"wp-block-heading\">Vision par ordinateur et santé</h2><p>Même si le NLP commence à contribuer énormément à la discipline, c’est clairement la vision par ordinateur qui est aujourd’hui l’outil de prise de décision le plus utilisé dans le médical.</p><p>Dans cette partie, j’ai sélectionné des projets intéressants qui utilisent la vision par ordinateur.</p><h3 class=\"wp-block-heading\">Vision par ordinateur pour l’imagerie médicale</h3><p>Une des applications les plus matures de la vision par ordinateur, est l’analyse d’imagerie médicale.</p><p>Les meilleurs modèles actuels sont capables de diagnostiquer un cancer avec une meilleure précision que les médecins.</p><p>On peut aussi utiliser des modèles similaires pour la détection d’anomalies, c’est la même technique qui est utilisée que dans l’industrie.</p><p>Par ailleurs, des méthodes de traitement des imageries médicales sont utilisées pour réaliser des tâches moins intéressantes et automatisables comme le calcul de l’âge osseux.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.24.01.png\" alt=\"Comment l'IA transforme le domaine de la santé ?\" class=\"wp-image-7975\" width=\"368\" height=\"372\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.24.01.png 582w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.24.01-297x300.png 297w\" sizes=\"auto, (max-width: 368px) 100vw, 368px\"></figure></div><p>Enfin, pendant la crise du covid, une équipe de chercheurs Chinois a développé un modèle de vision par ordinateur pour diagnostiquer le covid à partir du scanner thoracique.</p><p>Des références sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://www.usine-digitale.fr/article/en-chine-des-medecins-utilisent-la-vision-par-ordinateur-pour-depister-le-coronavirus.N936199\" target=\"_blank\" rel=\"noreferrer noopener\">Dépistage du covid</a></li><li>Un <a href=\"https://www.thelancet.com/journals/landig/article/PIIS2589-7500(20)30160-6/fulltext\" target=\"_blank\" rel=\"noreferrer noopener\">état de l’art</a> de The Lancet sur l’IA pour l’imagerie médicale</li></ul><h3 class=\"wp-block-heading\">Améliorer le taux de réussite des fécondations im-vitro</h3><p>J’ai été étonné d’apprendre que la vision par ordinateur était utilisée pour le traitement d’images d’embryons, pour faciliter la prise de décision avant une fécondation in-vitro.</p><p>Avant une fécondation in-vitro, les embryons sont cultivés en laboratoire, et le médecin doit choisir le ou les embryons à injecter dans l’utérus de la patiente (1 ou 2 embryons au maximum). Cette phase de prise de décision est très critique, et elle est à l’origine de la majorité des échecs de l’opération.</p><p>Les modèles de vision par ordinateur vont permettre d’avoir une analyse plus pragmatique et systématique que le médecin.</p><p>Une des entreprises de référence sur ce sujet est Imvitro. C’est une jeune start-up Parisienne qui a développé une plateforme SaaS à destination des médecins pour calculer un score qui exprime le potentiel de réussite de la fécondation.</p><p>Des références sur le sujet :</p><ul class=\"wp-block-list\"><li>Le site <a href=\"https://im-vitro.com/fr/\" target=\"_blank\" rel=\"noreferrer noopener\">d’Imvitro</a></li><li>Mon <a href=\"https://larevueia.fr/lintelligence-artificielle-pour-la-fecondation-in-vitro/\" target=\"_blank\" rel=\"noreferrer noopener\">article</a> sur le sujet</li><li><a href=\"https://hal.archives-ouvertes.fr/hal-02882052/document\" target=\"_blank\" rel=\"noreferrer noopener\">Un papier en français</a></li></ul><h2 class=\"wp-block-heading\">Le deep learning pour la découverte de nouveaux traitements</h2><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-1024x899.png\" alt=\"Comment l'IA transforme le domaine de la santé ?\" class=\"wp-image-7976\" width=\"499\" height=\"438\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-1024x899.png 1024w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-300x263.png 300w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-768x674.png 768w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-1536x1348.png 1536w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-168x147.png 168w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03.png 1600w\" sizes=\"auto, (max-width: 499px) 100vw, 499px\"></figure></div><p>Un des modèles les plus en vogue dans le monde de la biologie est AlphaFold. Le modèle d’intelligence artificielle a été capable de prédire la structure de toutes les molécules connues à partir de leurs acides aminés.</p><p>Ce modèle a permis de faire de grandes avancées dans la recherche de nouveaux traitements assistée par intelligence artificielle. En aidant à comprendre les interactions entre les bactéries et les structures anti-bactériennes, AlphaFold pourrait aider à découvrir de nouveaux antibiotiques, même si une étude du MIT disponible en référence à nuance cette affirmation.</p><p>Des références sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe\" target=\"_blank\" rel=\"noreferrer noopener\">AlphaFold</a> reveals the structure of the universe</li><li><a href=\"https://news.mit.edu/2022/alphafold-potential-protein-drug-0906\" target=\"_blank\" rel=\"noreferrer noopener\">L’étude du MIT</a></li></ul><h2 class=\"wp-block-heading\">La question éthique</h2><p>Dès qu’on traite des données, et quelque soit le domaine, l’aspect éthique est un gros sujet, c’est d’autant plus vrai dans la santé.</p><p>D’abord, on traite des données personnelles sensibles, ce qui implique des mesures de sécurité avancées. Je suis assez surpris de voir que certains acteurs du monde de la santé en France utilisent des solutions de cloud non-souverain, à l’heure du cloud act (la réglementation américaine qui permet au gouvernement d’imposer aux entreprises de livrer leurs données).</p><p>Même d’un point de vue juridique, la définition d’une donnée de santé n’est pas très bien définie. Avec la multiplication des sources de données, ces questions se posent : est-ce que les données de ma montre connectées sont des données de santé ? le temps passé devant l’écran ? la distance que j’ai parcourue à pied cette semaine ? etc.</p><p>Par ailleurs, les modèles entraînés doivent être explicables. En deep learning, les modèles sont opaques et peu interprétables. C’est une caractéristique qu’on accepte en général, mais en santé, quand on doit diagnostiquer la maladie d’une personne, le modèle doit nous expliquer sa prédiction.</p><p>Des références sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://larevueia.fr/explicabilite-des-modeles-ne-croyez-pas-aveuglement-ce-que-lia-vous-dit/\" target=\"_blank\" rel=\"noreferrer noopener\">Mon article sur l’explicabilité des modèles</a></li><li><a href=\"https://arxiv.org/abs/2206.15363\" target=\"_blank\" rel=\"noreferrer noopener\">Why we do need Explainable AI for Healthcare</a></li></ul><h2 class=\"wp-block-heading\">Conclusion : IoT + Blockchain + IA X santé</h2><p>Je me suis fait un délire en mode “formule magique” sur ce titre, je trouvais ça stylé ahah 🙂</p><p>Je ne suis pas expert du domaine, je ne suis pas devin, mais je vois bien le domaine de l’IA dans la santé prendre les directions qui s’énoncent dans cette partie.</p><p>D’abord, la robotique sera un grand sujet pour les années à venir. On voit déjà des systèmes automatisés dans les hôpitaux.</p><p>De nombreuses tâches pourraient être automatisées, pour accorder plus de temps aux personnels soignants et se concentrer sur l’essentiel : le contact humain.</p><p>L’avenir de la santé sera technologique, l’objectif sera de regrouper les techniques disponibles aujourd’hui, les agréger pour résoudre les problèmes actuels.</p><p>Avec l’IoT pour la collecte et l’agrégation des données, la blockchain pour la sécurisation et la traçabilité, et l’intelligence artificielle pour le traitement, le tout sera beaucoup plus grand que la somme de ses parties.</p></div>"},
{"url": "https://larevueia.fr/travailler-en-tant-que-freelance-data-scientist-en-etant-etudiant/", "title": "Travailler en tant que freelance data scientist en étant étudiant", "author": "Ilyes Talbi", "date": "\n26 avril 2021\n", "content": "<div class=\"entry-content\"><p>Durant ma dernière année à <a href=\"https://isup.sorbonne-universite.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">l’ISUP</a> j’ai eu la chance d’être freelance data scientist et étudiant en même temps. Cette experience inhabituelle m’a été très bénéfique. Dans cet article je vous présente pourquoi et comment vous lancer.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Travailler en tant que freelance data scientist en étant étudiant\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"quels-sont-les-avantages-a-commencer-en-etant-etudiant\">Quels sont les avantages à commencer en étant étudiant ?</h2><p>Lorsqu’on est étudiant on n’a pas grand chose à perdre, c’était mon cas. Le fait de se mettre en freelance ne peut être que bénéfique (si on gère les choses proprement). En dehors de l’impact qu’une telle experience peut avoir sur votre CV, les bénéfices sont nombreux.</p><h3 class=\"wp-block-heading\" id=\"monter-en-competences\">Monter en compétences</h3><p>En data science rien n’est plus formateur que de travailler sur des projets concrets. Les projets scolaires vous permettront d’appréhender les outils utilisés mais donnent une vision biaisée de ce qu’est le travail de data scientist en entreprise. En tant que data scientist freelance, vous devrez répondre à la volonté de votre client et adapter votre façon de travailler.</p><p>Par exemple, j’avais pour habitude de travailler uniquement sur Python, une fois que mon code était écrit je l’exécutais sur un IDE que je savais utiliser. Evidemment lorsque vous êtes freelance vous devez proposer un outil complet au client, les codes ne suffisent plus. C’était l’occasion pour moi de travailler sur le déploiement de modèles et m’intéresser à l’architecture data.</p><p>Au delà de l’aspect technique, on apprend énormément de choses sur la gestion de projets en general. En tant que freelance vous êtes en charge de tout :</p><ul class=\"wp-block-list\"><li>Trouver des missions</li><li>Convaincre les clients</li><li>Rédiger des devis</li><li>Réaliser la mission</li><li>Présenter votre travail</li><li>Rédiger la facture et gérer la comptabilité</li></ul><p> <span style=\"font-size: revert; color: initial;\">C’est un travail énorme qu’il ne faut pas négliger mais qui m’a permis d’apprendre énormément.</span></p><h3 class=\"wp-block-heading\" id=\"rencontrer-des-personnes-interessantes-et-se-faire-des-contacts\">Rencontrer des personnes intéressantes et se faire des contacts</h3><p>Réussir une mission est le meilleur moyen de se faire des contacts qui nous font confiance. Quelque soit le chemin que vous emprunterez après vos études, les contacts sont importants. Ce qui me plait vraiment dans le travail de freelance c’est qu’on rencontre tous les jours des gens formidables issus de diverses horizons. Et à chaque rendez-vous, même s’il n’aboutit pas sur une collaboration, on apprend beaucoup.</p><h3 class=\"wp-block-heading\" id=\"financer-ses-etudes\">Financer ses études</h3><p>Même si ma démarche était surtout motivée par l’envie d’apprendre, je me suis rendu compte rapidement qu’économiquement aucun job étudiant ne pouvait rivaliser avec le fais d’être freelance. En tant que débutant vous pouvez facturer jusqu’à 500€ H.T. la journée. Même lorsque vous retirez les impôts et les cotisations URSAAF il vous reste un très bon salaire ! Vu le travail qu’il demande, ce salaire est amplement mérité.</p><h2 class=\"wp-block-heading\" id=\"comment-trouver-les-premieres-missions\">Comment trouver les premières missions ?</h2><p>Une fois que vous êtes convaincus que cette expérience ne peut que vous être bénéfique, vous devez trouver vos premières missions.</p><p>Les premières missions sont les plus difficiles à trouver. Personnellement j’ai eu un peu de chance. Dès que j’ai annoncé sur LinkedIn que je me mettais en freelance j’ai été contacté par plusieurs personnes et j’ai pu commencer mes premières missions.</p><p>Vous devez chercher vos premières missions dans votre propre réseau, c’est le meilleur moyen de commencer.</p><p>Vous pouvez aussi passer par des plateformes de mise en relation comme <a href=\"https://www.malt.fr/profile/ilyestalbi\" target=\"_blank\" rel=\"noreferrer noopener\">Malt</a>. J’ai trouvé deux missions sur cette plateforme et à chaque fois tout s’est bien passé.</p><p>Sur Malt vous devez attendre qu’un client trouve votre profil et vous envoie une demande de devis. Si vous préférer choisir vos missions vous pouvez passer par <a href=\"https://www.upwork.com/\" target=\"_blank\" rel=\"noreferrer noopener\">UpWork</a>. Les clients publient une offre de mission et si la mission vous intéresse vous pouvez postuler.</p><p>Une fois que vous avez pris contact avec un client potentiel vous devez le convaincre de vous choisir vous et pas quelqu’un d’autre. Cette étape est un peu plus compliquée, soyez convaincants ! Si ça vous intéresse je peux vous fournir des exemples de propositions commerciales qui m’ont aidées à convaincre (<a href=\"https://www.linkedin.com/in/ilyes-talbi-ba2451135/\" target=\"_blank\" rel=\"noreferrer noopener\">contactez-moi</a>).</p><h2 class=\"wp-block-heading\" id=\"3-conseils-pour-reussir\">3 conseils pour réussir</h2><p>Je suis freelance seulement depuis l’été dernier mais j’ai déjà quelques conseils à vous donner pour bien démarrer.</p><h3 class=\"wp-block-heading\" id=\"n-ayez-pas-peur-de-rater-une-mission\">N’ayez pas peur de rater une mission</h3><p>Parmi les craintes que j’avais quand je me suis lancé, il y avait la peur de rater une mission. C’est le cas pour n’importe quel freelance à ses débuts et cette crainte est encore plus grande lorsque vous êtes étudiant.</p><p>Cette crainte est naturelle mais elle ne doit pas vous bloquer. Le risque de rater une mission est réel mais si ça arrive on doit être en mesure de trouver une solution avec le client (j’espère quand même que ça ne m’arrivera pas ni à vous 🙂 ; on n’est pas obligé d’échouer pour apprendre mais au pire dites vous que l’échec permet d’apprendre).</p><h3 class=\"wp-block-heading\" id=\"ne-bradez-pas-vos-tarifs-sous-pretexte-que-vous-etes-etudiants\">Ne bradez pas vos tarifs sous prétexte que vous êtes étudiants</h3><p>Pour trouver des missions vous devez être surs de vous. Le prix est un gage de qualité et d’assurance pour le client. Paradoxalement, un prix trop faible risque de le faire fuir. Et même si vous êtes étudiants vous prévoyez de rendre un travail de qualité et méritez d’être payé au bon prix.</p><h3 class=\"wp-block-heading\" id=\"soyez-organises\">Soyez organisés</h3><p>En tant que freelance et étudiant vous devez conjuguer votre vie professionnelle et votre vie d’étudiant. Il est important d’être organisé pour ne pas compromettre vos études.</p><p>Pour m’organiser au mieux j’ai gardé une checklist à jour de ce que j’avais à faire, ça permet de ne pas perdre le fil et se retrouvé débordé. Pour ça j’utilise <a href=\"https://www.notion.so/\" target=\"_blank\" rel=\"noreferrer noopener\">Notion</a>, un outil formidable pour s’organiser.</p><p>J’ai aussi synchronisé mon emploi du temps des cours avec mon Google agenda, pour avoir tout ce que j’avais à faire au même endroit et ne pas me tromper au moment de proposer un créneau à un client.</p><p>En dehors de l’organisation de son temps, il faut gérer l’aspect émotionnel. Lorsque j’ai commencé les missions freelance, j’avais de moins en moins de motivation pour travailler sur les projets de ma fac. Gardez en tête que vos études doivent rester votre preoccupation centrale.</p><p></p><p>Voilà pour ma petite expérience personnelle. Je ne garantis pas que ce soit la fête pour vous aussi, mais je suis sûr que la vie de freelance data scientist et étudiant pourra vous bénéficier à vous aussi !</p></div>"},
{"url": "https://larevueia.fr/comment-lia-de-tiktok-a-embrase-la-france/", "title": "Comment l’IA de Tiktok a embrasé la France", "author": "Ilyes Talbi", "date": "\n2 juillet 2023\n", "content": "<div class=\"entry-content\"><p><em>Avant de commencer ce post, j’aimerais dire que, même s’il parle des émeutes, il n’a rien de politique. Je ne donnerais pas mon avis sur la question, je propose simplement un décryptage <strong>algorithmique</strong> de la situation.</em></p><p>Depuis 2019 avec La revue IA, j’explique la même chose : le premier danger des IA ça n’est pas Terminator et les robots tueurs qui vont prendre le contrôle de l’humanité. Le premier danger des IA c’est leurs utilisations dans les réseaux sociaux.</p><h2 class=\"wp-block-heading\">Les dangers des IA des réseaux sociaux</h2><p>Les algorithmes des gros réseaux sociaux comme Facebook, Tiktok ou Instagram, sont conçus de la même manière à l’origine.</p><p>Ils ont un seul objectif, une seule métrique à optimiser, c’est le temps que vous passez sur la plateforme. Ils doivent donc trouver le type de contenus qui vous plait et vous proposer des choses similaires.</p><p>Pour l’instant je ne vous apprend rien.</p><p>Pour trouver le bon contenu pour vous, plusieurs stratégies sont utilisées :</p><p>L’algo de Tiktok va regarder le temps que vous passez sur chaque vidéo, et grâce à ça il va determiner si ces contenus vous plaisent ou non.</p><p>L’algo d’Instagram est très sensible aux nombres de fois que le bouton « Copier le lien » est utilisé. Car si une vidéo permet de ramener des gens sur la plateforme elle dessert bien l’objectif attendu.</p><p>L’algo de Facebook est encore un peu plus vicieux. Il va dans le détail de vos émotions. En fonction des emojis de réactions que vous utilisez, il va savoir quel contenu vous rend heureux, quel contenu vous rend triste, quel contenu vous met en colère, etc.</p><p>En plus de poser des questions sur la privacy des données (qui n’existe plus d’ailleurs mais c’est un autre sujet), on peut s’inquiéter des addictions que ces algos peuvent causer.</p><p>Mais le problème dont je veux parler est pire encore !</p><p>Les utilisateurs de chaque plateforme sont regroupés sous forme de <a href=\"https://larevueia.fr/clustering-les-3-methodes-a-connaitre/\">clusters</a> qui ont les mêmes préférences sur des sujets différents (on peut être dans le même cluster sur le foot mais sur des clusters différents en politique).</p><p>Et plus un cluster aime un type de contenu, plus ce contenu va lui être proposé, ce qui engendre la polarisation de chacun des clusters :</p><ul class=\"wp-block-list\"><li>les gens qui aiment Messi vont l’aimer encore plus et encore plus detester Ronaldo, et inversement</li><li>les personnes de gauche vont devenir de plus en plus extrêmes, et pareil pour la droite</li><li>etc.</li></ul><p>Ce problème est appelé, dans le domaine des probabilités, « la fixation ». Pour illustrer ça j’aime bien prendre l’exemple suivant :</p><p>Imaginez une urne, qui contient 10 boules rouges et 10 boules bleues.</p><p>Vous tirez une boule au hasard :</p><p>🔵 Si elle est bleue vous remettez la boule et en ajoutez 2 bleues dans l’urne<br>🔴 Si elle est rouge vous faites pareil mais en ajoutant des boules rouges cette fois</p><p>Si vous faites l’expérience un nombre suffisamment grand de fois, il n’y a qu’une seule issue possible : la probabilité de choisir une des 2 couleurs va tendre vers 1.</p><p>Si maintenant :</p><ul class=\"wp-block-list\"><li>l’urne est votre feed YouTube</li><li>les boules bleues des vidéos de droite</li><li>les boules rouges des vidéos de gauche</li></ul><p>Au bout de quelques heures passées sur la plateforme, les vidéos proposées seront largement polarisées.</p><p>Ce qui se traduira par des comportements toujours plus extrémistes et <a href=\"https://www.youtube.com/watch?v=utWMGi8HTjY\">polarisés</a>.</p><h2 class=\"wp-block-heading\">Quel est le lien entre l’IA de Tiktok et les émeutes ?</h2><p>En terme de polarisation, l’IA de Tiktok est pire que celle de YouTube, et un feed Tiktok peut vous donner beaucoup d’informations sur les centres d’intérêts d’une personne.</p><p>Les « émeutiers », s’informent et échangent principalement sur Tiktok. L’IA de Tiktok en terme de polarisation est pire que celle de YouTube, et a causé une compétition entre quartier.</p><p>Les émeutiers cherchent à savoir quel quartier est le plus « chaud ».</p><ul class=\"wp-block-list\"><li>Chaque quartier va former un cluster d’utilisateurs proches. En conséquence, le fil d’actualité de chacun des membres de ce cluster se ressemble beaucoup</li></ul><ul class=\"wp-block-list\"><li>Donc quand une vidéo faite par un membre d’un cluster A apparaît dans le fil d’un membre d’un cluster B, il y a de forte chance que tous le cluster B ait vu la même vidéo</li></ul><ul class=\"wp-block-list\"><li>La gravité des actes commis est corrélée avec le succès d’un post. Car l’IA de Tiktok regarde le temps passé sur un contenu et le nombre de copies du lien. Donc on a un lien mathématique entre la « popularité » d’un cluster d’émeutiers et la gravité de leurs actions</li></ul><p>Comme la plupart sont uniquement sur Tiktok, il ne voit pas ce qui se passe dans les autres clusters, ils sont dans un sous groupe fermé de Tiktok et l’algorithme ne leur montrera pas les vidéos d’appels, celles faites par les politiciens ou quoi que ce soit d’autres.</p><p>Evidemment, Tiktok n’est pas le seul facteur responsable de ces émeutes, c’est simplement un catalyseur dangereux.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, il faut garder à l’esprit que l’IA, dans son rôle omniprésent sur les réseaux sociaux, peut potentiellement catalyser et amplifier les divisions dans la société.</p><p>Les algorithmes des réseaux sociaux, conçus pour maximiser l’engagement, peuvent mener à une polarisation extrême et à des comportements radicaux.</p><p>L’IA de TikTok est particulièrement dangereuse, d’ailleurs l’utilisation de Tiktok est limitée à 45 minutes pour les jeunes chinois de moins de 18 ans et le contenu est plus éducatif. A méditer pour nos politiciens…</p></div>"},
{"url": "https://larevueia.fr/mes-lectures-de-lete/", "title": "Mes lectures de l’été", "author": "Ilyes Talbi", "date": "\n14 août 2021\n", "content": "<div class=\"entry-content\"><p>Les éditions ENI m’ont gentiment envoyé 3 ouvrages pour apprendre la data science et le machine learning, je vous en parle dans cet article.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Mes lectures de l'été\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>On n’a pas encore de référence absolue en français pour l’apprentissage du machine learning/deep learning mais ces 3 livres sont assez intéressants et peuvent constituer d’excellentes portes d’entrées dans le monde de la data science.</p><h2 class=\"wp-block-heading\" id=\"data-scientist-et-langage-r\">Data scientist et langage R</h2><p>J’ai plutôt pour habitude d’utiliser Python pour mes projets de data science. C’est le langage que je connais le mieux, on a un grand nombre de packages aussi robustes les uns que les autres et des tutoriels et des cours très complets et bien écrits. Malgré ça je reste convaincu que la connaissance du langage R doit rester une de vos priorités.</p><p>D’abord, R est un langage conçu spécialement pour les statistiques et sera donc toujours plus intéressant que n’importe quelle autre langage lorsque vous devez faire des stats. Pour les mêmes raisons c’est un langage qui va vous permettre de manipuler des datasets plus facilement.</p><p>R est aussi un langage très demandé par les recruteurs dans les grandes entreprises et bénéficie, tout comme Python, d’une large communauté qui oeuvre pour améliorer les outils et les packages disponibles. Dans tous les cas, apprendre R vous permettra d’ajouter un outil à votre boîte à outils.</p><p>J’espère vous avoir convaincu d’apprendre R!</p><p>Si c’est le cas, le livre Data Scientist et langage R, écrit par Henri et Eva Laude pourrait vous être d’une grande aide. Dans ce livre les auteurs ont voulu proposer un support<meta charset=\"utf-8\">de formation complet et détaillé aux data science avec le langage R. Le livre couvre à la fois toutes les méthodes de bases de data science et les bases du langage R, il vous montre ensuite comment appliquer R pour exploiter ces méthodes.</p><p>Le livre est assez gros et je vous conseille donc de prendre la version numérique qui sera beaucoup plus simple à consulter. Vous pouvez vous le procurer directement sur le <a href=\"https://www.editions-eni.fr/livre/data-scientist-et-langage-r-autoformation-aux-bases-de-l-intelligence-artificielle-dans-l-univers-de-la-data-3e-edition-9782409030994\" target=\"_blank\" rel=\"noreferrer noopener\">site de l’éditeur</a>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.editions-eni.fr/livre/data-scientist-et-langage-r-autoformation-aux-bases-de-l-intelligence-artificielle-dans-l-univers-de-la-data-3e-edition-9782409030994\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-842x1024.jpeg\" alt=\"Mes lectures de l'été\" class=\"wp-image-4036\" width=\"318\" height=\"386\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-842x1024.jpeg 842w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-247x300.jpeg 247w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-768x934.jpeg 768w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-1263x1536.jpeg 1263w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL.jpeg 1315w\" sizes=\"auto, (max-width: 318px) 100vw, 318px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"intelligence-artificielle-vulgarisee\">Intelligence artificielle vulgarisée</h2><p>Le <a href=\"https://www.editions-eni.fr/livre/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735?gclid=CjwKCAjw092IBhAwEiwAxR1lRiw1AdUlLhRrOM9uKsdBdjLBX4biKvdzed5ItrKxadAG6jMLZtbB1RoCDNwQAvD_BwE\" target=\"_blank\" rel=\"noreferrer noopener\">second livre</a>, écrit par Aurélien Vannieuwenhuyze, vous aidera à comprendre les concepts fondamentaux en machine learning et deep learning de façon plus pratique et en s’attardant un peu moins sur la théorie et les concepts mathématiques sous-jacents. Ce livre peut être un excellent moyen de se plonger au coeur du monde de la data science.</p><p>Ce livre convient très bien aux débutants ou à ceux qui veulent revoir leurs classiques.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://www.editions-eni.fr/livre/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735?gclid=CjwKCAjw092IBhAwEiwAxR1lRiw1AdUlLhRrOM9uKsdBdjLBX4biKvdzed5ItrKxadAG6jMLZtbB1RoCDNwQAvD_BwE\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/08/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735_XL.jpeg\" alt=\"Mes lectures de l'été\" class=\"wp-image-4039\" width=\"298\" height=\"353\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/08/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735_XL.jpeg 518w, https://larevueia.fr/wp-content/uploads/2021/08/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735_XL-253x300.jpeg 253w\" sizes=\"auto, (max-width: 298px) 100vw, 298px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"python-pour-la-data-science\">Python pour la data science</h2><p>Le dernier livre, écrit par Amandine Velt, va vous permettre de progresser en data science avec Python, à travers des quiz, des exemples de projets concrets et en jouant avec des datasets variés.</p><p>Il ne sera pas question de machine learning ou d’entraînements de modèles dans cet ouvrage, par contre vous pourrez parcourir toutes les compétences nécessaires pour faire du preprocessing de data : slicing de matrices avec NumPy, manipulation de tableaux de données avec Pandas et visualisation avec Matplotlib et Seaborn.</p><p>On a souvent tendance à croire que le machine learning se limite à l’entraînement de modèles, sauf que ce travail ne représente qu’environ 10% du travail d’un data scientist. Une grande partie du travail repose sur du nettoyage de données, un peu de statistiques et de la visualisation. <a href=\"https://www.editions-eni.fr/livre/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263\" target=\"_blank\" rel=\"noreferrer noopener\">Ce livre</a> vous aidera à developper les techniques essentielles de manipulation de datasets.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://www.editions-eni.fr/livre/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/08/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263_XL.jpeg\" alt=\"Mes lectures de l'été\" class=\"wp-image-4038\" width=\"307\" height=\"371\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/08/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263_XL.jpeg 506w, https://larevueia.fr/wp-content/uploads/2021/08/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263_XL-248x300.jpeg 248w\" sizes=\"auto, (max-width: 307px) 100vw, 307px\"></a></figure></div></div>"},
{"url": "https://larevueia.fr/vivatech-2022-france-is-un-peu-ai/", "title": "Vivatech 2022 : France is (un peu) AI", "author": "Ilyes Talbi", "date": "\n25 juin 2022\n", "content": "<div class=\"entry-content\"><p>La semaine dernière, j’étais au salon Viva technologie à Paris. Le plus grand évènement de la tech en France.</p><p>Beaucoup d’innovations ont été présentées, plusieurs pays étaient représentés, et j’ai rencontré pas mal de start-up prometteuses.</p><p>Le salon était plutôt bien organisé et il y avait quelques conférences intéressantes, notamment celle de Yann LeCun sur le futur de l’intelligence artificielle (par contre l’appli du salon fonctionnait moyennement).</p><p>Même si j’ai toujours un peu de mal avec les évènements trop généralistes, car <em>qui trop embrasse, mal étreint</em>, l’évènement m’a globalement bien plu.</p><p>J’ai sélectionné 5 start-ups parmi toutes celles que j’ai vu, je vous en parle dans cet article.</p><h2 class=\"wp-block-heading\">I’m beside you : comment assurer la santé mentale des employées, même à distance ?</h2><p>Bon c’est innovant mais ça fait un peu peur 😅</p><p>La startup Japonaise I’m beside you a développé des modèles de vision par ordinateur et de traitements du langage, capables de décrire avec précision l’état émotionnel d’un employé.</p><p>Les modèles sont utilisés en temps réel sur les applications de visioconférence comme Google meet ou Teams. Et les données sont visibles par les managers des équipes via des tableaux de bords personnalisés.</p><p>Même si ça part d’une bonne intention, qui est d’assurer la sécurité mentale des employés, l’utilisation de système de reconnaissance faciale et le fait que les données soient visibles par les mangers posent problème d’un point de vue éthique.</p><h2 class=\"wp-block-heading\">Digantara : le GPS indien des satellites</h2><p>Comme chaque année, Viva tech sélectionne un pays star pour présenter ses innovations pendant le salon. Cette année, c’était l’Inde qui était à l’honneur. L’écosystème startup indien est très développé, notamment dans des villes comme Bengalore.</p><p>Sur des sujets comme l’intelligence artificielle, l’Inde est en train de devenir une référence internationale.</p><p>J’ai rencontré la startup <a href=\"https://www.digantara.co.in/\" target=\"_blank\" rel=\"noreferrer noopener\">Digantra</a>. Ils conçoivent un GPS pour satellites qui repose sur l’intelligence artificielle. Leurs modèles permettent de prédire à chaque instant, la position de tous les satellites. Il est utilisé par de nombreux clients comme des agences de télécommunication ou des chaînes de télévision.</p><h2 class=\"wp-block-heading\">3DFascination : le scanner 3D à taille humaine</h2><p>Dans mon article sur l’<a href=\"https://larevueia.fr/quels-liens-entre-blockchain-et-intelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">Intelligence artificielle au service de la blockchain</a>, j’ai parlé de comment la reconstruction 3D en vision par ordinateur pourrait être utilisée pour construire le metaverse.</p><p>Pendant le salon j’ai rencontré la startup <a href=\"https://3dfascination.com/\" target=\"_blank\" rel=\"noreferrer noopener\">3DFascination</a>, qui produit un scanner à taille humaine. Je me suis même fait scanner 🙂</p><figure class=\"wp-block-video\"><video controls src=\"https://larevueia.fr/wp-content/uploads/2022/06/WhatsApp-Video-2022-06-18-at-14.50.52.mp4\"></video></figure><h2 class=\"wp-block-heading\">MyDataModels rend les IA moins gourmandes en données</h2><p>Une des grosses limitations de l’Intelligence artificielle d’aujourd’hui, est la quantité de données requise pour l’entraînement de modèles. En plus d’être un désastre pour l’environnement, la course aux modèles gourmands en données, a créée un club très fermé de grandes entreprises. Ces entreprises monopolisent la data, et ont les meilleurs résultats.</p><p>J’ai déjà abordé le problème dans de précédents articles. J’ai dit que de nouvelles approches comme l’IA décentralisée pouvaient être pertinentes.</p><p>Mais la solution ultime, serait de pouvoir entraîner des modèles fiables avec très peu de données. C’est ce que la startup française MyDataModels fait. Ils travaillent sur de nombreux domaines et ont développés une plateforme SaaS pour faciliter le preprocessing des données, l’entraînement des modèles et le déploiement. <a href=\"https://www.mydatamodels.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Je vous laisse regarder ça</a>.</p><h2 class=\"wp-block-heading\">High wind : améliorer les systèmes d’appels d’urgences grâce à l’intelligence artificielle</h2><p><a href=\"https://www.highwind-ems.com/fr/a-propos/\" target=\"_blank\" rel=\"noreferrer noopener\">High wind</a> est une autre startup française dans l’intelligence artificielle. Ils conçoivent une plateforme intelligente pour le traitement des appels d’urgences.</p><p>Plusieurs modèles de <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a> sont utilisés. Ils vont, par exemple, permettre d’analyser automatiquement le ton de la voix de la personne, l’émotion sur le visage ou encore des photos de la scène, pour essayer de déterminer la criticité de l’urgence.</p><p>Un des modèles permet de déterminer la gravité d’une plaie à partir d’une photo. L’idée est de pouvoir prioriser de façon plus robuste les interventions en fonction de la gravité.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En bref, le salon regroupait pas mal d’acteurs de différents horizons, pour le networking c’est parfait.</p><p>Il est tout de même triste de voir que des sujets importants, comme la question de la souveraineté des grandes entreprises françaises, ont été ignorés. Pour faire court : tout le monde s’en moque.</p><p>Enfin, on voit dans les derniers salons généralistes que l’intelligence artificielle prend moins de place, au profit de technologie comme la blockchain. La table ronde avec Vitalik et CZ a été l’intervention phare de l’évènement, tandis que sur l’intelligence artificielle j’ai trouvé que les conférences étaient moins pertinentes que d’habitude.</p></div>"},
{"url": "https://larevueia.fr/annoter-et-labelliser-des-series-temporelles/", "title": "Annoter et labelliser des séries temporelles", "author": "Ilyes Talbi", "date": "\n24 novembre 2022\n", "content": "<div class=\"entry-content\"><p><em>Cet article a été rédigé par <strong>Julien Muller</strong>, CTO de <a href=\"https://ezako.com/fr/\" target=\"_blank\" rel=\"noreferrer noopener\">Ezako</a>.</em></p><p>Chez Ezako nous sommes des experts des données de type séries temporelles. Les séries temporelles sont des données de type spécifiques qui se différencient largement d’autres types de données de par leur production, leur usage et leurs propriétés.</p><p>Ces données font partie de notre quotidien. On peut par exemple penser au suivi d’une température, à un ECG ou au courant d’un composant électronique.</p><p>Les données peuvent être suivies à des fins de monitoring (pour des serveurs), de prédiction (dans la finance) ou de maintenance prédictive (dans l’industrie).</p><p>Les cas d’applications sont extrêmement ouverts, et les nouveaux cas d’usages apparaissent constamment avec l’invention de nouveaux objets, tels que les IOT et la digitalisation des chaînes de production.</p><p>Les séries temporelles ont des spécificités techniques, qui les différencient des autres types de données, on peut constater notamment :</p><ul class=\"wp-block-list\"><li>Suite de valeurs qui évoluent au cours du temps</li><li>Souvent un grand nombre de points (généré par des machines), tant en fréquence qu’en nombre de séries </li><li>Souvent un grand déséquilibre de labels et/ou de classes. Par exemple, le nombre de point en anomalie est très faible par rapport aux données normales</li></ul><h2 class=\"wp-block-heading\"><strong>La labellisation ou l’annotation pour les séries temporelles</strong></h2><p>C’est l’action d’enrichir une ou plusieurs séries temporelles ou d’ajouter des métadonnées sur des séries. Elle s’effectue point par point, pour une période, ou pour une série entière.</p><p>Le type de label et les techniques utilisées vont dépendre directement de l’objectif recherché. En effet, on labellise dans un but spécifique et précis. Une labellisation pour maintenance prédictive n’est pas la même que pour classifier différents états d’un système. Dans le premier cas, le label sera peut-être une durée de vie restante point par point, et dans le second, une simple classe comme “ON”, “OFF”, “SWITCHING” …</p><h3 class=\"wp-block-heading\"><strong>Pourquoi labeliser ?</strong></h3><p>Pour apporter plus d’informations sur les séries temporelles qui sont à notre disposition. L’objectif peut être la classification, formaliser la compréhension d’un comportement, apprendre des anomalies pour les détecter ou les expliquer.</p><p>En Machine Learning, l’intérêt est presque évident. En effet, pour le data scientist, adresser une problématique supervisée est bien plus facile qu’une non supervisée. A jeu de données équivalent, les résultats des approches supervisées sont incroyablement meilleurs que non supervisées.</p><p><strong>Pourquoi? </strong></p><p>D’abord parce que les 2 approches ne sont pas à armes égales. Les approches supervisées disposent de beaucoup plus d’informations que celles non supervisées.</p><p>Ensuite, les approches non supervisées proposent des qualités qui sont censées dépasser les approches supervisées. Par exemple, un algorithme de détection d’anomalies non supervisé devrait être à même de détecter des anomalies inconnues. Mais des approches hybrides peuvent également atteindre cet objectif.</p><p>On peut considérer différents types d’approches hybrides entre le non supervisé et le supervisé:</p><ul class=\"wp-block-list\"><li>Modèle non-supervisé</li><li>Apprentissage non supervisé, et évaluation de la qualité de détection sur la base des données labellisées (évaluation supervisée)… autres actions supervisées</li><li>Semi-supervisé: Approches telles que les algorithmes non supervisés qui font des hypothèses sur les données : par exemple un auto encodeur qui considère que tout un jeu d’apprentissage est normal. Ou plus généralement, des algorithmes qui utilisent un ensemble restreint d’annotations.   </li><li>Self-supervised, ou le modèle effectue un apprentissage en 2 étapes, il constitue ses propres pseudo labels et apprend sur ses propres labels. Un exemple simple est l’IA qui joue aux échecs contre elle-même.</li><li>approche totalement supervisée</li></ul><p>En pratique en Machine learning, avoir un jeu de données labéllisé est avantageux parce que cela permet d’évaluer plusieurs approches supervisées clairement avec des métriques telles que la précision, le rappel, le f-score, etc.</p><p>Toutefois, un écueil commun à ces dernières doit être adressé: le risque de sur-apprentissage ou <a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">overfitting</a>. Ce risque est d’autant plus présent lorsque l’on a peu de labels, mais en être conscient permet de mettre en place des mécanismes qui le mitigent, telle que la validation croisée “k-fold cross validation”.</p><p>Si malgré cela  on est confronté à une situation de sur-apprentissage, on pourra changer d’approche et passer par exemple de modèles supervisés à des modèles à apprentissage non supervisé et une optimisation des hyper paramètres. Mais l’approfondissement de ce point mérite un article en soi!</p><h2 class=\"wp-block-heading\"><strong>Comment labelliser?</strong></h2><p>On peut penser à différentes approches pour annoter son jeu de données. Entre autre:</p><ul class=\"wp-block-list\"><li>Approche manuelle</li><li>L’expertise métier</li><li>Un peu de code (python)</li><li>Avec un outil de labellisation comme Upalgo Labeling</li></ul><p>Nous pouvons faire un petit cas pratique avec un fichier csv de timeseries de 50 000 lignes. Ce fichier comporte une colonne de timestamp et 4 capteurs. Les capteurs de vibration présentent des pics importants que nous souhaitons annoter pour créer un modèle de classification. L’objectif est de créer une nouvelle colonne contenant un texte de classe “pic haut”, “pic bas” ou “normal”.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"327\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.11.22-1024x327.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6850\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.11.22-1024x327.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.11.22-300x96.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.11.22-768x245.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.11.22-1536x490.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.11.22.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><h3 class=\"wp-block-heading\">L’approche manuelle</h3><p>Pour l’approche manuelle, nous allons utiliser excel. Après avoir importé le fichier CSV, excel propose une fonctionnalité de graphique, bien pratique pour faciliter le travail. Néanmoins, elle se révèle peu utilisable. Sur les  50 000 points, nous n’avons pu afficher que 5 000 points simultanément.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.12.46-1024x672.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6851\" width=\"693\" height=\"455\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.12.46-1024x672.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.12.46-300x197.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.12.46-768x504.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.12.46-1536x1008.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.12.46.png 1600w\" sizes=\"auto, (max-width: 693px) 100vw, 693px\"></figure></div><p>Créer une colonne “label” est très simple, mais la tâche s’avère difficile. Il faut repérer sur le graphique le timestamp des pics pour les chercher ensuite dans le tableau et annoter la colonne. Puis passer aux 5 000 points suivants. Une fois cette tâche effectuée, le tableau est exportable au format CSV.</p><h3 class=\"wp-block-heading\">L’expertise métier</h3><p>Pour cet exemple simpliste, on peut imaginer que l’expert métier nous a indiqué que les pics sont souvent grands, donc on va poser une limite et l’automatiser. Le langage d’implémentation a peu d’importance, python ou autre, pour des raisons graphiques, nous avons utilisé une formule excel :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.13.49-1024x99.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6852\" width=\"691\" height=\"67\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.13.49-1024x99.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.13.49-300x29.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.13.49-768x75.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.13.49-1536x149.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.13.49.png 1600w\" sizes=\"auto, (max-width: 691px) 100vw, 691px\"></figure></div><p>Si cette solution a l’avantage d’être très compacte et rapide à mettre en œuvre, elle montre rapidement ses limites. En effet, les pics n’étant pas constitués d’une seule valeur, on a une labellisation de faible qualité. Pour le pattern suivant, on s’attend à avoir une 15aine de points en “pic bas”, mais le résultat est assez erratique.</p><p>De plus, cette règle n’est applicable qu’à ce jeux de donnée précis, et doit être redéfinie pour un nouveau jeu de donnée même si il s’agit aussi de retrouver des pics dans la donnée :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.14.48-1024x690.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6853\" width=\"589\" height=\"397\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.14.48-1024x690.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.14.48-300x202.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.14.48-768x517.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.14.48-1536x1035.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.14.48.png 1588w\" sizes=\"auto, (max-width: 589px) 100vw, 589px\"></figure></div><p>Bien sûr, on peut repasser sur chaque événement et valider les données, mais cela sera long. De plus, on fait une hypothèse métier forte en positionnant une limité à 2, ce qui amènera probablement à ignorer les événements de petite taille.</p><h3 class=\"wp-block-heading\">La labellisation de séries temporelles avec Python</h3><p>On va ici essayer d’exploiter les capacités de pandas pour faire une labellisation rapide de meilleure qualité. Cela adressera une partie des limites de l’approche précédente, en particulier la prédéfinition d’un seuil d’anomalie.</p><p>On identifie que les pics sont des valeurs aberrantes localement, c’est à dire que tous les pics n’ont pas la même amplitude, nous définissons donc un algorithme qui cherche à isoler les pics en déterminant la moyenne ainsi que l’écart type normal sur des fenêtres glissantes pour ensuite déterminer un seuil variable en fonction de ces paramètres :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"257\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.16.19-1024x257.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6854\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.19-1024x257.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.19-300x75.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.19-768x193.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.19-1536x386.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.19.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure><p>Le choix de la taille de la fenêtre et du nombre de déviation à la moyenne qui déclenche la séparation reste à paramétrer lors de l’exécution de l’algorithme de la “rolling_std”, ici le couple (100,5) n’est pas l’unique bon paramétrage, mais un parmi d’autres. L’étape qui suit consiste à créer la colonne ‘class’ et lui attribuer les annotations calculées.</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"245\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.16.31-1024x245.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6855\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.31-1024x245.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.31-300x72.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.31-768x183.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.31-1536x367.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.16.31.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure><p>Puis on plot le résultat :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.17.51-1024x741.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6856\" width=\"678\" height=\"490\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.17.51-1024x741.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.17.51-300x217.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.17.51-768x556.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.17.51-1536x1111.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.17.51.png 1600w\" sizes=\"auto, (max-width: 678px) 100vw, 678px\"></figure></div><p>On procédera par la suite à la transformation des annotations numériques qui séparaient nos données en deux classes (0,10) équivalentes à (normal, pic) en triplet (normal, pic_haut, pic_bas).</p><p>L’ensemble de ce code est dans un notebook en annexe.</p><p>On constate une labellisation de plutôt bonne qualité et plus généralisable que la règle métier fixe pour la détection de pics dans les données, si on fait confiance à l’algorithme utilisé, on reporte donc la responsabilité sur le développeur et la martingale qu’il a identifié.</p><h3 class=\"wp-block-heading\">Utilisation de l’outil de labellisation Upalgo Labeling</h3><p>Upalgo Labeling est un outil avec une interface graphique permettant de visualiser les séries temporelles et de labelliser rapidement les séries avec une validation humaine. Cela permet d’avoir plus de finesse dans l’annotation tout en garantissant un travail plus rapide.</p><p>Voici les étapes d’une bonne annotation avec l’outil :</p><p><strong><em>Etape 1 :</em></strong> Dans l’outil Upalgo Labeling il est possible de visualiser et de labelliser manuellement un événement:</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.18.55-1024x692.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6857\" width=\"636\" height=\"429\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.18.55-1024x692.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.18.55-300x203.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.18.55-768x519.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.18.55.png 1222w\" sizes=\"auto, (max-width: 636px) 100vw, 636px\"></figure></div><p>Il est aussi possible d’utiliser la fonctionnalité automatique de proposition de zones à annoter, elle permettra de fournir rapidement plusieurs labels de qualité :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.20.24-1024x635.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6858\" width=\"641\" height=\"396\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.20.24-1024x635.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.20.24-300x186.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.20.24-768x476.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.20.24-404x250.png 404w\" sizes=\"auto, (max-width: 641px) 100vw, 641px\"></figure></div><p><strong><em>Etape 2 :</em> </strong>Puis on demande à Upalgo Labeling de propager les classes “pic haut” et “pic bas” préalablement définis, ce qui finalise l’annotation de l’ensemble du fichier :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.21.45-1024x681.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6859\" width=\"676\" height=\"449\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.21.45-1024x681.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.21.45-300x200.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.21.45-768x511.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.21.45.png 1206w\" sizes=\"auto, (max-width: 676px) 100vw, 676px\"></figure></div><p><strong><em>Etape 3 :</em> </strong>On peut exporter le résultat dans un fichier CSV contenant une nouvelle colonne “label” :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.22.37-1024x443.png\" alt=\"Annoter et labelliser des séries temporelles\" class=\"wp-image-6860\" width=\"628\" height=\"271\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.22.37-1024x443.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.22.37-300x130.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.22.37-768x332.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-24-à-09.22.37.png 1198w\" sizes=\"auto, (max-width: 628px) 100vw, 628px\"></figure></div><p>Ici, on constate que l’expert a un total contrôle sur ce qu’il l’annote, ce qui garantit une meilleure qualité de label.</p><h2 class=\"wp-block-heading\"><strong>Conclusion</strong></h2><p>On peut constater qu’avec les approches assistées d’outils tels que excel, l’annotation des séries temporelles est possible, mais sera assez besogneuse.</p><p>Une approche programmatique en s’appuyant sur l’expertise métier sera rapide, mais montre des lacunes assez évidentes.</p><p>L’approche python est déjà nettement plus intelligente mais demande un effort et des connaissances en programmation.</p><p>L’utilisation d’un outil comme Upalgo Labeling est beaucoup plus efficace et facile. Cela permet une annotation automatique et rapide sans avoir à coder des algorithmes dédiées.</p><p>Néanmoins il existe avec ces outils un risque de biais. Pour lever ce risque il est important d’utiliser beaucoup de datasets, et une confirmation humaine.</p></div>"},
{"url": "https://larevueia.fr/introduction-a-limage-stitching-avec-opencv/", "title": "Introduction à l’image stitching avec OpenCV", "author": "Ilyes Talbi", "date": "\n16 février 2023\n", "content": "<div class=\"entry-content\"><p>L’image stitching, est une technique de traitement d’images qui permet de combiner plusieurs images en une seule image panoramique.</p><p>Cette technique est utilisée pour créer de grandes images à partir de plusieurs images plus petites, en utilisant des modèles de features matching pour trouver les points communs entre les images et les assembler de manière cohérente.</p><p>L’image stitching est souvent utilisée pour créer des panoramas, mais elle peut également être utilisée pour combiner des images de différents angles de vue pour créer une image 3D ou pour créer des images de haute résolution à partir de plusieurs images de basse résolution.</p><p>Cette technique est largement utilisée dans de nombreux domaines, notamment la photographie, la cartographie, la robotique et la réalité augmentée.</p><p>Dans cet article, je vous explique comment fonctionne l’image stitching, je vous parle de ses applications et on verra comment faire de l’image stitching avec Python et OpenCV.</p><h2 class=\"wp-block-heading\">Quelles sont les applications de l’image stitching ?</h2><p>L’image stitching est largement utilisé dans plusieurs applications.</p><ul class=\"wp-block-list\"><li>Image stitching et photomosaïques : cette technique est celle qui est utilisée dans les smartphones pour créer des panoramas à partir de plusieurs images prises de différents angles.</li><li>Mapping et surveillance : elle permet la création de cartes et de modèles en 3D à partir de photos aériennes ou satellites. Elle est très utiles pour les images extra large, qui ne peuvent pas être prises en une seule fois</li><li>Réalité virtuelle et augmentée : l’image stitching est utilisé pour la création de mondes virtuels en combinant des images pour créer des scènes immersives plus rapidement</li><li>Inspection industrielle : elle permet l’évaluation de la qualité et de l’état des équipements industriels en combinant des images prises de différents angles</li><li>Imagerie médicale : pour la reconstruction de modèles en 3D et la visualisation de données médicales telles que des scanners ou des IRM</li><li>Analyse de la biologie cellulaire : pour la reconstruction de modèles en 3D des structures cellulaires à partir de plusieurs images prises à différents angles et profondeurs</li><li>Imagerie scientifique : l’image stitching va aussi beaucoup aider pour l’analyse de grandes quantités d’images pour l’étude de la morphologie, de la dynamique et de la distribution des objets dans différents domaines scientifiques tels que l’astronomie, la microscopie électronique et la microscopie confocale</li></ul><h2 class=\"wp-block-heading\">Comment faire de l’image stitching avec Python et OpenCV ?</h2><p>Dans cette section, nous allons voir ensemble comment faire de l’image stitching avec Python et OpenCV.</p><p>La technique repose sur des modèles d’extraction de features qui sont beaucoup utilisés en <a href=\"https://larevueia.fr/focus-sur-6-sous-domaines-de-la-computer-vision-et-leurs-applications/\" target=\"_blank\" rel=\"noreferrer noopener\">computer vision</a>, comme le modèle SIFT.</p><p>C’est d’ailleurs ce modèle que nous allons utiliser dans ce tutoriel.</p><h3 class=\"wp-block-heading\">Choix de l’image à recoller</h3><p>Pour ce tutoriel, j’ai choisi de travailler avec cette image générées par stable diffusion :</p><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"512\" height=\"768\" src=\"https://larevueia.fr/wp-content/uploads/2023/02/paysage_image_stitching.jpeg\" alt=\"Introduction à l'image stitching avec OpenCV\" class=\"wp-image-8033\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/02/paysage_image_stitching.jpeg 512w, https://larevueia.fr/wp-content/uploads/2023/02/paysage_image_stitching-200x300.jpeg 200w\" sizes=\"auto, (max-width: 512px) 100vw, 512px\"></figure><p>J’ai commencé par couper l’image en 2 verticalement, en laissant une petite bande commune.</p><p>Je l’ai fait en utilisant ce code là sur <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noreferrer noopener\">OpenCV</a> :</p><pre class=\"wp-block-code\"><code>import cv2\n\n# import de image\nimg = cv2.imread(\"./paysage_image_stitching.jpeg\")\nheight, width = img.shape[:2]\n\n# calcul du point central de l'image\nmidpoint = int(width / 2)\n\n# division de l'image en 2 parties en gardant une bande de 60 px commune\nleft_part = img[:, :midpoint + 60]\nright_part = img[:, midpoint:]\n\n# Enregistrement des images\ncv2.imwrite(\"./left_part.jpg\", left_part)\ncv2.imwrite(\"./right_part.jpg\", right_part)</code></pre><p>Après l’execution de ce code on obtient les 2 images suivantes :</p><figure class=\"wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-8 is-layout-flex wp-block-gallery-is-layout-flex\"><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"316\" height=\"768\" data-id=\"8034\" src=\"https://larevueia.fr/wp-content/uploads/2023/02/left_part.jpg\" alt=\"Image de gauche pour l'image stitching avec python\" class=\"wp-image-8034\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/02/left_part.jpg 316w, https://larevueia.fr/wp-content/uploads/2023/02/left_part-123x300.jpg 123w\" sizes=\"auto, (max-width: 316px) 100vw, 316px\"></figure><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"256\" height=\"768\" data-id=\"8035\" src=\"https://larevueia.fr/wp-content/uploads/2023/02/right_part.jpg\" alt=\"Image de droite pour l'image stitching avec python\" class=\"wp-image-8035\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/02/right_part.jpg 256w, https://larevueia.fr/wp-content/uploads/2023/02/right_part-100x300.jpg 100w\" sizes=\"auto, (max-width: 256px) 100vw, 256px\"></figure></figure><p>Maintenant qu’on a 2 images de base sur lesquelles faire l’image stitching, entrons dans le vif du sujet.</p><h3 class=\"wp-block-heading\">Image stitching avec OpenCV</h3><p>On commence par importer les librairies necéssaires :</p><pre class=\"wp-block-code\"><code>import cv2\nimport numpy as np</code></pre><p>On va maintenant définir de la fonction « FindMatches ».</p><p>Cette fonction prend en entrée deux images et utilise la méthode SIFT (Scale-Invariant Feature Transform) pour trouver les points clés et les descripteurs dans les images.</p><p>Il utilise également un « Brute Force Matcher » pour trouver des correspondances entre les points clés des images. Il s’agit simplement de tester toutes les paires possibles de matchs pour conserver les meilleures, en utilisant un threshold.</p><pre class=\"wp-block-code\"><code>def FindMatches(BaseImage, SecImage):\n\n    # Using SIFT to find the keypoints and decriptors in the images\n    Sift = cv2.SIFT_create()\n    BaseImage_kp, BaseImage_des = Sift.detectAndCompute(cv2.cvtColor(BaseImage, cv2.COLOR_BGR2GRAY), None)\n    SecImage_kp, SecImage_des = Sift.detectAndCompute(cv2.cvtColor(SecImage, cv2.COLOR_BGR2GRAY), None)\n\n    # Using Brute Force matcher to find matches.\n    BF_Matcher = cv2.BFMatcher()\n    InitialMatches = BF_Matcher.knnMatch(BaseImage_des, SecImage_des, k=2)\n\n    # Applying ratio test and filtering out the good matches.\n    GoodMatches = []\n    for m, n in InitialMatches:\n        if m.distance &lt; 0.75 * n.distance:\n            GoodMatches.append([m])\n\n    return GoodMatches, BaseImage_kp, SecImage_kp</code></pre><p>On va maintenant définir une fonction qui va permettre de trouver les éventuelles projections à faire une fois qu’un match est trouvé. Ceci se produit quand les images à recoller ne sont pas exactement sur le même plan.</p><p>Cette fonction prend en entrée les matches trouvés et les points clés des images de droite et de gauche. Et elle utilise les correspondances pour trouver la matrice d’homographie entre les images, qui décrit la transformation entre les images.</p><pre class=\"wp-block-code\"><code>def FindHomography(Matches, BaseImage_kp, SecImage_kp):\n    # If less than 4 matches found, exit the code.\n    if len(Matches) &lt; 4:\n        print(\"\\nNot enough matches found between the images.\\n\")\n        exit(0)\n\n    # Storing coordinates of points corresponding to the matches found in both the images\n    BaseImage_pts = []\n    SecImage_pts = []\n    for Match in Matches:\n        BaseImage_pts.append(BaseImage_kp[Match[0].queryIdx].pt)\n        SecImage_pts.append(SecImage_kp[Match[0].trainIdx].pt)\n\n    # Changing the datatype to \"float32\" for finding homography\n    BaseImage_pts = np.float32(BaseImage_pts)\n    SecImage_pts = np.float32(SecImage_pts)\n\n    # Finding the homography matrix(transformation matrix).\n    (HomographyMatrix, Status) = cv2.findHomography(SecImage_pts, BaseImage_pts, cv2.RANSAC, 4.0)\n\n    return HomographyMatrix, Status</code></pre><p>On défini maintenant la fonction GetNewFrameSizeAndMatrix ci-dessous.</p><p>Elle calcule la nouvelle taille et la matrice de transformation pour l’image qui sera recadrée. La taille de l’image est déterminée en multipliant la largeur et la hauteur d’origine de l’image par le ratio de la nouvelle taille sur la taille originale.</p><p>La matrice de transformation est calculée à partir de la position et de l’orientation de l’objet. Tout d’abord, la fonction calcule le centre de l’objet en utilisant les coordonnées x et y du coin supérieur gauche de l’objet et sa largeur et sa hauteur. Ensuite, elle calcule l’angle de rotation de l’objet en utilisant la valeur de l’orientation. La matrice de transformation est construite en utilisant ces informations.</p><p>La matrice d’homographie est une matrice 3×3 qui est utilisée pour transformer l’image. Elle comprend des valeurs de rotation, de translation et de mise à l’échelle.</p><p>Les valeurs de rotation sont déterminées en utilisant l’angle de rotation de l’objet. Les valeurs de translation sont calculées en utilisant la position du centre de l’objet. Les valeurs de mise à l’échelle sont déterminées en utilisant le rapport de la nouvelle taille sur la taille originale de l’image.</p><p>En fin de compte, la fonction renvoie la nouvelle taille de l’image ainsi que la matrice de transformation qui sera utilisée pour recadrer l’image.</p><pre class=\"wp-block-code\"><code>def GetNewFrameSizeAndMatrix(HomographyMatrix, Sec_ImageShape, Base_ImageShape):\n    # Reading the size of the image\n    (Height, Width) = Sec_ImageShape\n\n    # Taking the matrix of initial coordinates of the corners of the secondary image\n    # Stored in the following format: [[x1, x2, x3, x4], [y1, y2, y3, y4], [1, 1, 1, 1]]\n    # Where (xi, yi) is the coordinate of the i th corner of the image.\n    InitialMatrix = np.array([[0, Width - 1, Width - 1, 0],\n                              [0, 0, Height - 1, Height - 1],\n                              [1, 1, 1, 1]])\n\n    # Finding the final coordinates of the corners of the image after transformation.\n    # NOTE: Here, the coordinates of the corners of the frame may go out of the\n    # frame(negative values). We will correct this afterwards by updating the\n    # homography matrix accordingly.\n    FinalMatrix = np.dot(HomographyMatrix, InitialMatrix)\n\n    [x, y, c] = FinalMatrix\n    x = np.divide(x, c)\n    y = np.divide(y, c)\n\n    # Finding the dimentions of the stitched image frame and the \"Correction\" factor\n    min_x, max_x = int(round(min(x))), int(round(max(x)))\n    min_y, max_y = int(round(min(y))), int(round(max(y)))\n\n    New_Width = max_x\n    New_Height = max_y\n    Correction = [0, 0]\n    if min_x &lt; 0:\n        New_Width -= min_x\n        Correction[0] = abs(min_x)\n    if min_y &lt; 0:\n        New_Height -= min_y\n        Correction[1] = abs(min_y)\n\n    # Again correcting New_Width and New_Height\n    # Helpful when secondary image is overlaped on the left hand side of the Base image.\n    if New_Width &lt; Base_ImageShape[1] + Correction[0]:\n        New_Width = Base_ImageShape[1] + Correction[0]\n    if New_Height &lt; Base_ImageShape[0] + Correction[1]:\n        New_Height = Base_ImageShape[0] + Correction[1]\n\n    # Finding the coordinates of the corners of the image if they all were within the frame.\n    x = np.add(x, Correction[0])\n    y = np.add(y, Correction[1])\n    OldInitialPoints = np.float32([[0, 0],\n                                   [Width - 1, 0],\n                                   [Width - 1, Height - 1],\n                                   [0, Height - 1]])\n    NewFinalPonts = np.float32(np.array([x, y]).transpose())\n\n    # Updating the homography matrix. Done so that now the secondary image completely\n    # lies inside the frame\n    HomographyMatrix = cv2.getPerspectiveTransform(OldInitialPoints, NewFinalPonts)\n    \n    return [New_Height, New_Width], Correction, HomographyMatrix</code></pre><p>Maintenant, nous devons assembler les images. Pour cela, nous utiliserons la matrice d’homographie pour déformer la 2ème image, pour qu’elle puisse se coller sur l’image de base.</p><p>On utilise pour ça la fonction « warpPerspective » dans OpenCV. Cette fonction prend les arguments suivants :</p><ul class=\"wp-block-list\"><li>L’image source, qui est l’image de droite dans notre cas</li><li>La matrice d’homographie que nous avons calculée précédemment</li><li>Les dimensions de l’image de sortie</li><li>Des indicateurs pour l’interpolation</li></ul><p>Voici le code pour assembler les images :</p><pre class=\"wp-block-code\"><code>def StitchImages(BaseImage, SecImage):\n    # Finding matches between the 2 images and their keypoints\n    Matches, BaseImage_kp, SecImage_kp = FindMatches(BaseImage, SecImage)\n\n    # Finding homography matrix.\n    HomographyMatrix, Status = FindHomography(Matches, BaseImage_kp, SecImage_kp)\n\n    # Finding size of new frame and correction matrix\n    [New_Height, New_Width], Correction, NewHomographyMatrix = GetNewFrameSizeAndMatrix(HomographyMatrix, SecImage.shape, BaseImage.shape)\n\n    # Warping the secondary image onto the base image using homography matrix\n    WarpedImage = cv2.warpPerspective(SecImage, NewHomographyMatrix, (New_Width, New_Height))\n\n    # Combining the base and secondary image\n    BaseImage[Correction[1]:Correction[1] + WarpedImage.shape[0], Correction[0]:Correction[0] + WarpedImage.shape[1]] = WarpedImage\n\n    return BaseImage</code></pre><p>Pour utiliser ces fonctions en situation concrète pour assembler 2 images, il ne reste plus qu’à faire ceci :</p><pre class=\"wp-block-code\"><code># Reading in two images\nBaseImage = cv2.imread('image1.jpg')\nSecImage = cv2.imread('image2.jpg')\n\n# Stitching the images together\nStitchedImage = StitchImages(BaseImage, SecImage)\n\n# Displaying the final image\ncv2.imshow('Stitched Image', StitchedImage)\ncv2.waitKey(0)\ncv2.destroyAllWindows()</code></pre><h2 class=\"wp-block-heading\">Conclusion</h2><p>Dans ce tutoriel, nous avons appris à réaliser l’image stitching à partir de deux images en utilisant la bibliothèque OpenCV en Python.</p><p>Nous avons commencé par faire de l’extraction de features sur les deux images, puis nous avons utilisé l’algorithme RANSAC pour estimer la matrice d’homographie qui permet de projeter une image sur l’autre. Enfin, nous avons fusionné les deux images en utilisant la fonction warpPerspective d’OpenCV.</p><p>Si vous voulez réaliser l’image stitching sur plus que deux images, il sera facile d’adapter ce code de cette façon :</p><ul class=\"wp-block-list\"><li>Choisissez une image de base à laquelle vous souhaitez ajouter d’autres images</li><li>Pour chaque image supplémentaire, calculez la matrice d’homographie qui correspond à la transformation de l’image pour l’ajuster à la base</li><li>Combinez les matrices d’homographie des différentes images pour obtenir une matrice globale</li><li>Utilisez cette matrice globale pour projeter toutes les images sur la base</li><li>Enfin, fusionnez toutes les images en une seule image en utilisant des méthodes comme la moyenne pondérée ou la fusion pyramidale</li></ul></div>"},
{"url": "https://larevueia.fr/quest-ce-que-locr-optical-character-recognition/", "title": "Qu’est-ce que l’OCR (Optical Character Recognition) ?", "author": "Ilyes Talbi", "date": "\n17 novembre 2022\n", "content": "<div class=\"entry-content\"><p>L’optical Character Recognition ou OCR, est une technique de traitements des images qui permet de détecter et reconnaitre le texte contenu dans une image.</p><p>Même si l’OCR n’a pas attendu le deep learning pour se développer, les récentes avancées sur ce domaine ont permis d’améliorer de façon considérable les temps de traitement et la précision.</p><p>Dans cet article, on explique le fonctionnement des méthodes d’OCR, et on présente certaines applications de cette technique.</p><h2 class=\"wp-block-heading\">Comment fonctionne l’Optical Character Recognition ?</h2><p>L’OCR est une des techniques d’analyse d’images les plus anciennes.</p><h3 class=\"wp-block-heading\">Les méthodes classiques</h3><p>Les méthodes classiques reposaient quasiment exclusivement sur des mathématiques et permettaient déjà d’avoir des résultats exploitables.</p><p>La méthode la plus simple consiste à détecter les contours du caractère, en identifiant les pixels ou on a un changement brusque d’intensité. On va ensuite calculer une distance mathématique entre la matrice résultante, et des matrices de références pré-définies pour chaque caractère.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-17-a%CC%80-00.47.15-1024x514.png\" alt=\"Qu'est-ce que l'OCR (Optical Character Recognition) ?\" class=\"wp-image-6796\" width=\"586\" height=\"293\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-17-à-00.47.15-1024x514.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-17-à-00.47.15-300x150.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-17-à-00.47.15-768x385.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-17-à-00.47.15-1536x770.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-décran-2022-11-17-à-00.47.15.png 1600w\" sizes=\"auto, (max-width: 586px) 100vw, 586px\"></figure></div><p>Dans une forme un peu plus avancée, mais toujours en gardant le même esprit, on peut travailler avec des méthodes de gradients, qui sont largement utilisées pour la détection de contour en général.</p><h3 class=\"wp-block-heading\">L’arrivée des CNN</h3><p>Les <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">réseaux de neurones</a> de convolutions ont fait considérablement avancer le domaine de l’OCR. Les techniques d’aujourd’hui sont beaucoup plus performantes et robustes. Même si elles sont gourmandes en données d’entraînement et en capacité de calcul.</p><p>Avec les CNN, on laisse le modèle trouver les caractéristiques et les pattern tout seul, on lui donne uniquement les images brutes sans aucune information sur les contours. En l’alimentant avec plusieurs images représentants la lettre a, on le laisse comprendre seul ce qui caractérise la lettre a en trouvant les similarités. C’est le travail qu’il fera dans la phase d’entraînement.</p><p>Dans la phase de détection, le modèle va rechercher dans ce qu’il aura appris les caractéristiques du caractère qu’il doit prédire.</p><h3 class=\"wp-block-heading\">Quels outils utiliser pour faire de l’OCR ?</h3><p>Les solutions qui permettent de faire de l’OCR sont nombreuses :</p><ul class=\"wp-block-list\"><li><strong><a href=\"https://github.com/tesseract-ocr/tesseract\" target=\"_blank\" rel=\"noreferrer noopener\">Tesseract</a> :</strong> c’est une solution open-source proposée par Google, c’est de loin la plus utilisée, la plus légère et la plus simple à prendre en main</li><li><strong>GOCR</strong></li><li><strong>Kraken</strong> (rien à voir avec la plateforme de crypto ahah)</li></ul><h2 class=\"wp-block-heading\">Quelles sont les applications de l’OCR ?</h2><p>L’OCR est un des domaines de la vision par ordinateur les plus actifs et qui se renouvèle le plus. Ceci s’explique par le fait qu’il soit facile à mettre en place et à forte valeur ajoutée dans beaucoup de domaines.</p><h3 class=\"wp-block-heading\">Tri automatisé du courrier</h3><p>Une des applications les plus connues de l’OCR est la lecture automatisée des adresses postales pour le tri des courriers.</p><p>Chaque année, La Poste distribue plus de 14 milliards de lettres et colis à travers la France. Pour trier rapidement et efficacement ces colis, et donc permettre une distribution plus rapide du courier, La Poste mise sur l’OCR. Des modèles performants permettent de détecter et lire les adresses qu’elles soient manuscrites ou non, pour les classer.</p><p>C’est pour la reconnaissance de chiffres manuscrits que les CNN ont été proposés initialement. Et jusqu’à aujourd’hui, l’un des premiers projets que l’on réalise lorsque l’on veut apprendre la vision par ordinateur et celui fait sur la base MNIST qui regroupe des images des chiffres manuscrits de 0 à 9.</p><h3 class=\"wp-block-heading\">KYC (Know Your Customer)</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"400\" height=\"294\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/passport-ocr.jpeg\" alt=\"L'OCR pour le contrôle automatisée d'identité\" class=\"wp-image-6791\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/passport-ocr.jpeg 400w, https://larevueia.fr/wp-content/uploads/2022/11/passport-ocr-300x221.jpeg 300w\" sizes=\"auto, (max-width: 400px) 100vw, 400px\"></figure></div><p>Lorsque vous créez un compte bancaire en ligne ou que vous faites une démarche administrative, il vous est demandé de prendre en photo votre carte d’identité ou autres documents. Se sont souvent des techniques d’OCR qui sont utilisées pour faire une vérification d’identité automatisée.</p><p>Elles permettent d’extraire vos informations (nom, prénom, date et lieu de naissance, adresse, etc.).</p><h3 class=\"wp-block-heading\">L’OCR pour la gestion des documents administratifs</h3><p>L’OCR peut aider dans la gestion des documents administratifs. A l’échelle d’une famille déjà la quantité de documents à traiter est assez énorme, je vous laisse imaginer ce que c’est à l’échelle d’une grande entreprise.</p><p>Pour faciliter le traitement du courier, des modèles d’OCR peuvent servir de premier tri qui permet de distribuer le courier plus facilement et de façon automatisée à chaque service.</p><p>Les modèles les plus performants peuvent en plus de détecter et reconnaitre le texte, comprendre ce que dit le message, le résumé et envoyer un note simplifiée ou ajouter une tâche. On pourrait même imaginer un système dans lequel la deadline est reconnue automatiquement et ajoutée à un calendrier.</p><h3 class=\"wp-block-heading\">Traduction des panneaux et affichages et de signalisation</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/image.png\" alt=\"l'OCR pour la traduction\" class=\"wp-image-6793\" width=\"581\" height=\"326\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/image.png 950w, https://larevueia.fr/wp-content/uploads/2022/11/image-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/image-768x432.png 768w\" sizes=\"auto, (max-width: 581px) 100vw, 581px\"></figure></div><p>Google a proposé il y a plusieurs années une application qui permet de traduire un texte en utilisant la caméra. Cette application m’a pas mal servie pendant mes voyages et c’est un exemple parfait d’utilisation de l’OCR.</p><h3 class=\"wp-block-heading\">Application de l’OCR dans le domaine du retail</h3><p>Dans le domaine du retail aussi l’OCR est de plus en plus utilisée.</p><p>Les entreprises de l’agroalimentaires qui ont des contrats avec des grands distributeurs comme Carrefour, ont des clauses assez strictes sur le positionnement de leurs produits. Le simple fait d’avoir une bouteille ou un paquet de gâteau disposé à l’envers dans le rayon constitue un manque à gagner pour l’entreprise, et donc des contrôles assez réguliers sont éféctués.</p><p>L’OCR, et la vision par ordinateur en général, vont permettre de vérifier si les produits sont correctement disposés et si la marque de l’entreprise et bien lisible.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>L’OCR est une technique assez simple à mettre en oeuvre, peu couteuse et qui peut faire gagner beaucoup de temps. C’est ce qui fait que c’est une des techniques de traitement d’images les plus utilisées et les plus appréciées.</p></div>"},
{"url": "https://larevueia.fr/clippinggpt-lia-bresilienne-qui-a-surpasse-gpt-4/", "title": "ClippingGPT : l’IA brésilienne qui a surpassé GPT-4", "author": "Ilyes Talbi", "date": "\n26 juin 2023\n", "content": "<div class=\"entry-content\"><p><em><em>Article original « <a href=\"https://medium.com/@rafael_pinheiro/building-with-gpt-for-education-how-we-built-an-ai-tutor-that-aced-the-most-complex-exam-in-latam-19fabf8b746b\" target=\"_blank\" rel=\"noreferrer noopener\">Building with GPT for education: how we built an AI tutor that passed one of the toughest exams</a> «  rédigé par <a href=\"https://www.linkedin.com/in/rafaelpinheirocosta\" target=\"_blank\" rel=\"noreferrer noopener\">Rafael Pinheiro Costa</a> et traduit par <a href=\"https://www.linkedin.com/in/a%C3%A9lia-maury-b77278223?trk=contact-info\" target=\"_blank\" rel=\"noreferrer noopener\">Aelia Maury</a>.</em></em></p><hr class=\"wp-block-separator has-alpha-channel-opacity\"><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Clipping est une startup qui aide les candidats à exceller dans des examens hautement compétitifs. Avec un taux d’approbation de 94% à l’examen « Brazilian Diplomatic Career Examination », nous construisons avec l’IA et les interfaces conversationnelles dans l’éducation depuis 2018, lorsque nous avons remporté les Bot Awards Brazil en tant que meilleur chatbot pour l’éducation aux côtés de marques telles que Magazina Luiza, PagSeguro et Rock in Rio.</em></p><p><em>Plus tôt cette année, nous avons lancé notre système de correction automatique pour les questions de dissertation, un algorithme propriétaire développé dans le cadre d’un projet de recherche en collaboration avec le Département d’informatique  de l’Université de Minas Gerais (UFMG) et le Parc technologique de Bell Horizonte (BHTEC) où nous sommes également une entreprise résidente. Maintenant, nous lançons </em><strong><em>ClippingGPT</em></strong><em> (bêta), un tuteur IA qui aide les étudiants à réaliser leur plein potentiel grâce à un tutorat personnalisé.</em></p></blockquote><p>Beaucoup de personnes nous ont contacté pour obtenir des détails sur la manière dont nous avons formé un modèle qui a non seulement réussi l’examen d’entrée dans la carrière diplomatique, mais aussi <strong>surpassé <a href=\"https://larevueia.fr/gpt-4/\" target=\"_blank\" rel=\"noreferrer noopener\">GPT-4</a> de 26% dans cet examen particulier</strong>, réputé comme l’un des plus difficile en Amérique latine. J’ai donc pensé que ce serait une excellente occasion de documenter et de partager ce cas.</p><p><strong>TLDR :</strong></p><p>a) Le principal problème de l’utilisation de ChatGPT et des LLM dans l’éducation n’est pas la triche, mais les risques de désinformation pendant le processus d’apprentissage en raison d’hallucinations.</p><p>b) Il est possible d’atténuer ces risques en formant un modèle sur une base de connaissances externe afin d’améliorer l’exactitude des réponses.</p><p>c) Après avoir formé ClippingGPT sur une base de connaissances externe, nous avons validé sa réussite à l’examen d’entrée de carrière diplomatique, surpassant les autres candidats et GPT-4.</p><p>d) Le fait qu’une IA formée sur une base de connaissances externe ait réussi avec brio l’un des examens les plus difficiles démontre le potentiel des LLM pour construire des tuteurs intelligents dans le domaine de l’éducation.</p><p>J’espère que cet article pourra être utile à ceux qui s’intéressent à l’exploration de l’utilisation responsable de l’IA dans les contextes éducatifs.</p><h2 class=\"wp-block-heading\"><strong>Le problème des LLMs dans l’éducation</strong></h2><p>Bien que GPT et les grands modèles de langage (LLMs) représentent une avancée significative dans le domaine de l’IA, leur utilisation dans l’éducation pose de nombreux défis.</p><p>Cela est principalement dû au fait que les LLMs tels que <a href=\"https://larevueia.fr/chatgpt/\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> fonctionnent en tant que modèles de langage plutôt que comme bases de connaissances, ce qui rend difficile de confirmer l’exactitude des informations qu’ils fournissent.</p><h3 class=\"wp-block-heading\"><strong>Hallucinations</strong></h3><p>En termes simples, ces modèles statistiques reconnaissent des motifs dans les séquences de mots et prévoient les mots suivants en se basant sur leurs données d’entraînement. Au lieu d’évaluer la véracité des informations, le système est conçu pour anticiper comment une question serait répondue.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>ChatGPT écrit parfois des réponses qui semblent plausibles, mais qui sont incorrectes ou sans signification (OpenAI, sur les limites de ChatGPT).</em></p></blockquote><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"500\" height=\"213\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_GXzsUk3FoCIQ0wwujUPUJQ.gif\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8424\"></figure></div><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Bien que les modèles de langage soient impressionnants en termes de fluidité, ils ont tendance à générer de fausses déclarations. Celles-ci vont des inexactitudes subtiles aux hallucinations extravagantes [1].</em></p></blockquote><p>Lorsqu’il s’agit d’apprendre une nouvelle compétence ou de préparer un examen à enjeux élevés, le fait de sembler plausible est contre-productif, voire dangereux.</p><p>Une grande partie des discussions actuelles sur l’impact de ChatGPT dans l’éducation porte sur la tricherie, mais les risques de <strong>désinformation généralisée lors de l’apprentissage</strong> sont bien plus préoccupants.</p><p><em>GPT-4 présente des limitations similaires aux modèles GPT précédents. Plus important encore, il n’est toujours pas entièrement fiable (il « hallucine » des faits et commet des erreurs de raisonnement). Il convient d’être très prudent lors de l’utilisation des sorties du modèle de langage, en particulier dans des contextes à enjeux élevés (Rapport technique GPT-4, OpenAI)[2]</em>.</p><p>GPT-4 a obtenu un taux de précision de 60 % sur le référentiel TruthfulQA, un test couvrant différentes catégories conçu pour <strong>mesurer la véracité d’un grand modèle de langage</strong> (LLM).</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"400\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_FXo63GlBfxb8fX6wO8WYeA.webp\" alt=\"Précision sur des questions adverseriales, TruthfulQA mc1\" class=\"wp-image-8426\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_FXo63GlBfxb8fX6wO8WYeA.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_FXo63GlBfxb8fX6wO8WYeA-300x167.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"><figcaption class=\"wp-element-caption\">Malgré les avancées, les LLMs restent peu fiables.</figcaption></figure></div><h3 class=\"wp-block-heading\"><strong>Contenu obsolète</strong></h3><p>Les informations obsolètes posent un autre problème. En général, GPT-4 ne dispose pas de connaissances sur les événements survenus après la coupure de la grande majorité de ses données de pré-entraînement en septembre 2021.</p><p>La base de connaissances de ChatGPT n’a pas été mise à jour de GPT 3.5 à GPT-4. De nouvelles mises à jour ne seront pas disponibles prochainement, car OpenAI a confirmé que l’entreprise ne forme pas GPT-5 et « ne le fera pas de sitôt ».</p><h3 class=\"wp-block-heading\"><strong>Biais linguistique</strong></h3><p>Le biais linguistique est également important.</p><p>GPT a tendance à générer davantage d’hallucinations dans des langues autres que l’anglais, en raison de la prédominance de l’anglais dans ses ensembles de données d’entraînement.</p><p>Pourquoi est-ce un problème ? Sur les près de 8 milliards de personnes dans le monde, seulement 5 % utilisent l’anglais comme langue maternelle. Il y a des angles morts dans les données d’entraînement de GPT et la plupart de ses utilisateurs sont significativement impactés par cela.</p><p>Essayez d’approfondir des sujets tels que l’histoire, la politique internationale, etc. Il suffit de quelques prompts (sollicitations) pour repérer des résultats préoccupants.</p><p>GPT-4 n’a pas réussi à fournir une réponse précise à une question assez simple sur l’histoire du Brésil.</p><p><em>Des biais linguistiques se manifestent car la majorité du contenu sur Internet est en anglais ou dans quelques autres langues dominantes, ce qui rend les grands modèles de langage plus performants dans ces langues. Cela peut entraîner des performances biaisées et un manque de soutien pour les langues à ressources limitées [3].</em></p><h3 class=\"wp-block-heading\"><strong>Les LLM ne sont qu’un point de départ</strong></h3><p>Il est peu probable qu’une solution aux hallucinations, au contenu obsolète et aux biais se produise rapidement. Et c’est tout à fait normal !</p><p>En réalité, ce sont plus des fonctionnalités que des bugs.</p><p>Les LLM, tels que ChatGPT, ont été <strong>conçus comme un point de départ</strong> pour d’autres modèles plus petits qui résolvent des problèmes plus spécifiques.</p><p>Le potentiel de GPT et d’autres grands modèles de langage réside dans le fait que leurs modèles génériques permettent à d’autres de <strong>construire des systèmes plus petits reposant sur une base de connaissances externe</strong> afin de résoudre des problèmes spécifiques.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Nous arrivons à la fin de l’époque de ces modèles géants</em></p>\n<cite><em>Sam Altman, PDG d’OpenAI, le 13 avril</em></cite></blockquote><p>Nous avons développé ClippingGPT pour valider le potentiel des modèles plus petits dans les environnements éducatifs.</p><p>Dans la section suivante, nous détaillons notre hypothèse.</p><h2 class=\"wp-block-heading\"><strong>ClippingGPT : Tester une hypothèse sur l’utilisation des LLM dans l’éducation</strong></h2><p>Notre hypothèse :</p><p><em>Un modèle plus petit formé sur une base de connaissances spécifique et à jour surpasse GPT-4 dans l’examen d’entrée de carrière diplomatique au Brésil ?</em></p><p><strong>Pourquoi l’examen d’entrée de carrière diplomatique brésilienne ?</strong></p><p>(1) <strong>Nous disposons déjà des données prétraitées nécessaires pour le test </strong>: Clipping a été une référence pour les examens complexes au Brésil depuis plus de 5 ans et nous disposons de données exclusives prétraitées pour la construction d’une base de connaissances externe solide pour l’expérience.</p><p>(2) <strong>Il s’agit de l’un des examens les plus complexes en Amérique latine</strong> : L’examen d’entrée de carrière diplomatique est généralement considéré par les étudiants brésiliens comme l’examen le plus éprouvant et sélectif, composé d’épreuves écrites évaluant des connaissances approfondies dans une vaste gamme de matières, comprenant des domaines tels que : la politique internationale, l’histoire du Brésil, la géographie, le droit constitutionnel et le droit international public, l’économie, l’anglais, le français, l’espagnol et la langue portugaise.</p><p>(3) <strong>Être à jour est une partie essentielle de cet examen</strong> : les candidats sont censés <strong>se tenir au courant</strong> des développements dans les domaines susmentionnés, notamment en ce qui concerne les derniers événements en politique internationale.</p><p>(4) <strong>La majorité des connaissances est basée sur des textes en langue non anglaise</strong> : cette contrainte constitue un cas intéressant d’utilisation au-delà de l’ensemble de données centré sur l’anglais sur lequel GPT a été formé.</p><p><strong>La méthodologie : comment avons-nous procédé ?</strong></p><p>(1) Nous avons utilisé GPT-4 pour générer des réponses aux questions d’examen de rédaction contenues dans l’examen de rédaction officiel administré aux candidats à la carrière diplomatique en 2022 ;</p><p>(2) Ensuite, nous avons demandé à un groupe d’enseignants spécialisés dans la préparation des candidats à l’examen diplomatique d’évaluer les réponses sans savoir préalablement qu’elles étaient générées par notre modèle d’IA (notation aveugle) ;</p><p>(3) Nous avons formé ClippingGPT sur une base de connaissances externe et généré avec notre modèle de nouvelles réponses au même examen, puis nous avons répété le processus de l’étape 2 (notation aveugle) ;</p><p>(4) Enfin, nous avons comparé le score final obtenu par ClippingGPT selon 2 paramètres : a) les scores obtenus par GPT-4 ; b) les scores obtenus par les candidats ayant été approuvés lors du dernier examen en 2022.</p><p><strong>Les résultats : ce que nous avons découvert ?</strong></p><p>Les résultats globaux de ClippingGPT sont les suivants :</p><ul class=\"wp-block-list\"><li>23e place ;</li><li>score de 597,79 ;</li><li>surclassement de 26 % par rapport à GPT-4.</li></ul><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"226\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_6x90t81lZo3jKt8zIOZtmA.webp\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8428\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_6x90t81lZo3jKt8zIOZtmA.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_6x90t81lZo3jKt8zIOZtmA-300x94.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"><figcaption class=\"wp-element-caption\"><em>ClippingGPT se classe à la 23e place parmi les 35 premiers candidats approuvés à l’examen d’entrée de carrière diplomatique.</em></figcaption></figure><p>Quant à GPT-4, il a obtenu un score de 473,8, se classant à la 177e place et n’ayant pas réussi à se hisser parmi les 35 candidats approuvés.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"693\" height=\"368\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_rgzgK4DkX7MV9mz1yVjm5Q.webp\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8430\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_rgzgK4DkX7MV9mz1yVjm5Q.webp 693w, https://larevueia.fr/wp-content/uploads/2023/06/1_rgzgK4DkX7MV9mz1yVjm5Q-300x159.webp 300w\" sizes=\"auto, (max-width: 693px) 100vw, 693px\"><figcaption class=\"wp-element-caption\"><em>Diagramme en barres de GPT-4 avec ClippingGPT dans les questions du dernier examen de rédaction officiel.</em></figcaption></figure></div><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"400\" height=\"371\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_lZJ17kr1VoWUtbjsAdpWzA.webp\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8432\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_lZJ17kr1VoWUtbjsAdpWzA.webp 400w, https://larevueia.fr/wp-content/uploads/2023/06/1_lZJ17kr1VoWUtbjsAdpWzA-300x278.webp 300w\" sizes=\"auto, (max-width: 400px) 100vw, 400px\"><figcaption class=\"wp-element-caption\"><em>Aperçu de la comparaison dans le diagramme radar de GPT-4 avec ClippingGPT dans les questions du dernier examen de rédaction officiel en 2022.</em></figcaption></figure></div><p><strong>Quelques informations sur les résultats :</strong></p><p>(1) La plus grande différence entre GPT-4 et ClippingGPT se situe dans les domaines de la géographie et de l’histoire du Brésil. Dans ces deux matières, une grande partie du contenu nécessaire pour répondre aux questions demande aux candidats une maîtrise de la littérature spécifique mettant en évidence des faits et des arguments locaux et régionaux peu susceptibles de figurer dans l’ensemble de données utilisé pour former GPT-4. Il peut y avoir une corrélation ou cela peut signifier que notre modèle a <strong>surmonté certains angles morts </strong>dans des sujets spécifiques, ce qui a conduit à de meilleures performances. La précision s’est considérablement améliorée. Cependant, les hallucinations n’ont pas été complètement éliminées.</p><p>(2) Le français et l’espagnol sont des valeurs aberrantes avec une plus petite variation. Dans le cas de cet examen de rédaction particulier, la structure diffère, les candidats sont invités à traduire et à résumer. Contrairement aux autres examens, <strong>aucune connaissance externe n’est requise</strong>. Cela explique les scores similaires.</p><p>(3) Pour l’examen de langue portugaise, un résultat curieux. Tant ClippingGPT que GPT-4 ont obtenu des scores <strong>inférieurs à la moyenne </strong>des candidats admis. Selon Guilherme Aguiar, titulaire d’un doctorat en langue portugaise et chargé d’évaluer les examens de langue portugaise : « <em>Les réponses au test de langue portugaise </em><strong><em>impressionnent par leur cohérence interne de l’argumentation</em></strong><em>, même si les textes présentent une série de </em><strong><em>déficiences structurelles et grammaticales qui compromettent le score obtenu</em></strong><em>, qui reste néanmoins dans la plage de notes de passage »</em>. Cela peut s’expliquer par le fait que les essais sont évalués selon des règles conservatrices de ponctuation, de régence de certains verbes et noms, ainsi que d’autres normes qui ne font pas consensus parmi les experts en grammaire, et qui ont joué un rôle dans les résultats, nous le croyons.</p><p>💡<em>Opportunité : De nouvelles avancées peuvent être réalisées grâce à des mesures pratiques visant à réduire les hallucinations, telles que l’ajustement de la température du modèle (proche de 0), l’ingénierie des instructions (nous avons utilisé différentes instructions pour chaque sujet), la chaîne de réflexion, etc. [4]</em></p><p>Dans la section suivante, nous abordons plus en détail sur le plan technique la manière dont nous avons entraîné GPT avec des connaissances supplémentaires pour atteindre les résultats mentionnés ci-dessus.</p><ol class=\"wp-block-list\"><li><strong>ClippingGPT : construction d’un modèle d’IA pour l’éducation</strong></li></ol><p>Comme dans ChatGPT, notre utilisateur peut interagir de manière conversationnelle avec le modèle. La principale différence réside dans le fait que nous l’avons entraîné à effectuer un <strong>rappel factuel dans une base de connaissances propriétaire fiable</strong> avant de renvoyer les réponses. Cela augmente la probabilité que sa réponse finale soit cohérente et correcte.</p><p><em>ClippingGPT fournit une réponse précise à la question sur l’histoire du Brésil à laquelle GPT-4 n’a pas réussi à répondre correctement.</em></p><p>Les techniques <em>d’embeddings</em> et de <em>fine-tuning</em> sont utilisées pour entraîner GPT sur des données distinctes, mais elles servent à des fins différentes et impliquent des méthodes d’entraînement différentes. Le <em>fine-tuning</em> est plus adapté pour enseigner au modèle un <em>style</em>, tandis que les <em>embeddings</em> sont recommandés comme moyen d’enseigner au modèle des <em>connaissances</em>. Dans notre cas d’utilisation, nous cherchions à éviter les hallucinations et le contenu obsolète. Il s’agit principalement d’un <strong>problème lié aux connaissances.</strong></p><p>Par conséquent, les <em>embeddings</em> semblaient être l’approche naturelle. En résumé, <em>l’embedding</em> consiste à transformer du <strong>texte en nombres</strong>, ce qui permet à GPT de comprendre les relations entre les mots et d’identifier des schémas dans une série de mots pour prédire les mots suivants. En termes plus simples, c’est ainsi que GPT construit progressivement des réponses, allant des plus basiques aux plus sophistiquées. Les <em>embeddings</em> sont également extrêmement utiles pour stocker et récupérer des informations grâce à la similarité sémantique.</p><p>Notre modèle a été construit en utilisant des « embeddings » pour rappeler les connaissances.</p><p><strong>Étape 1 : Création d’embeddings pour une base de connaissances</strong></p><p>Tout d’abord, nous avons préparé la base de connaissances à partir de laquelle nous voulons que notre modèle puise des informations fiables et actuelles. Ce faisant, nous prévoyons que les réponses seront obtenues à partir d’une <strong>source de confiance</strong>, ce qui permettra de <strong>réduire la possibilité d’inexactitudes.</strong></p><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"247\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_9yPAVpN_BV7hmj1wlddjCg.webp\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8435\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_9yPAVpN_BV7hmj1wlddjCg.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_9yPAVpN_BV7hmj1wlddjCg-300x103.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"></figure><p>Pendant le traitement des données, nous avons :</p><p>– divisé les documents en sections (morceaux) ;</p><p>– transformé chaque morceau en embedding à l’aide de l’API OpenAI ;</p><p>– stocké les embeddings dans une base de données vectorielle (nous avons utilisé Redis) ;</p><p>💡<em> Opportunité : Si vous utilisez la reconnaissance optique de caractères (OCR) pour certains documents, le nettoyage des données devient extrêmement important. Des informations clés telles que les dates et les nombres peuvent être compromises lors de l’étape de traitement.</em></p><p><strong>Étapes 2 et 3 : recherche et fourniture de réponses</strong></p><p>À un niveau élevé, voici comment fonctionne le modèle :</p><p>1. Dans un premier temps, il récupère des informations pertinentes par rapport à la requête de l’utilisateur.</p><p>2. Ces informations sont ensuite ajoutées à la requête de l’utilisateur.</p><p>3. Enfin, la requête enrichie est envoyée à l’API pour générer une réponse.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"345\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ImpkSQ3V18wwqVkxhA2OFQ.webp\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8437\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ImpkSQ3V18wwqVkxhA2OFQ.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_ImpkSQ3V18wwqVkxhA2OFQ-300x144.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"></figure></div><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"258\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ruLWGvcHM3BBZXT1Efl7mw.webp\" alt=\"ClippingGPT : l'IA brésilienne qui a surpassé GPT-4\" class=\"wp-image-8438\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ruLWGvcHM3BBZXT1Efl7mw.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_ruLWGvcHM3BBZXT1Efl7mw-300x108.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"></figure></div><p><strong>Étape 2</strong> : Lorsque l’utilisateur <strong>pose une question</strong> à ClippingGPT, celui-ci traite l’entrée de l’utilisateur et la transforme en un vecteur à l’aide de l’API d’Embeddings d’OpenAI. Il analyse ensuite la distance entre le vecteur de la requête de l’utilisateur et les vecteurs de différentes sections. Ensuite, il classe ces sections en fonction de leur pertinence, indiquant où la réponse potentielle peut être trouvée.</p><p><strong>Étape 3</strong> : Le modèle intègre ces <strong>sections pertinentes en tant que contexte</strong> dans un message envoyé à GPT. Cette requête enrichie est ensuite envoyée à l’API de Complétion d’OpenAI, qui génère et renvoie la réponse.</p><p>💡<em> Opportunité : Diverses méthodes, telles que HyDE [5], Dera [6] et Reflexion [7], peuvent améliorer les résultats. Notre plan est d’itérer ces techniques en incorporant des modifications mineures dans l’architecture ci-dessus.</em></p><ol class=\"wp-block-list\"><li><strong>Conclusion et prochaines étapes</strong></li></ol><p>Dans le domaine de l’éducation, la principale préoccupation liée à l’utilisation de ChatGPT et d’autres LLM réside dans les <strong>risques de désinformation liés aux hallucinations</strong>, aux informations obsolètes et biaisées lors de l’apprentissage. Ces risques, bien qu’importants, peuvent être atténués, comme notre expérience avec ClippingGPT l’a démontré.</p><p><em>Former un modèle sur une base de connaissances externe peut considérablement améliorer l’exactitude des réponses de l’IA.</em></p><p>Pour les prochaines étapes, nous allons <strong>itérer sur d’autres techniques pour améliorer continuellement notre modèle</strong> (Hyde, Dera, Reflections, etc.), tout en explorant de nouvelles approches pour aborder les hallucinations.</p><p><strong>References:</strong></p><p>[1] S Lin, J Hilton, O Evans. <a href=\"https://arxiv.org/pdf/2109.07958.pdf\"><em>TruthfulQA: Measuring How Models Mimic Human Falsehoods</em></a><em>. </em>2021</p><p>[2] <a href=\"https://arxiv.org/abs/2303.08774\">OpenAI. <em>GPT-4 Technical Report.</em> 2023.</a></p><p>[3] E Ferrara. <a href=\"https://arxiv.org/pdf/2304.03738.pdf\"><em>Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models. </em></a><em>2023</em></p><p>[4] V Dibia. <a href=\"https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination\"><em>Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models. </em></a><em>2023</em></p><p>[5] Gao, Luyu, et al. <em>HYDE: </em><a href=\"https://arxiv.org/pdf/2212.10496.pdf\"><em>Precise Zero-Shot Dense Retrieval without Relevance Labels.</em></a> 2022</p><p>[6] Nair, Schumacher, Tso, Kannan. <a href=\"https://arxiv.org/pdf/2303.17071.pdf\"><em>DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents</em></a><em>.</em> 2023</p><p>[7] Shinn, Labash, Gopinath. <a href=\"https://arxiv.org/pdf/2303.11366.pdf\"><em>Reflexion: an autonomous agent with dynamic memory and self-reflection</em></a>. 2023</p></div>"},
{"url": "https://larevueia.fr/comment-faire-de-la-segmentation-dimages-avec-python/", "title": "Comment faire de la segmentation d’images avec Python ?", "author": "Ilyes Talbi", "date": "\n23 avril 2023\n", "content": "<div class=\"entry-content\"><p>La segmentation d’images est un enjeu crucial dans le domaine de la <a href=\"https://larevueia.fr/focus-sur-6-sous-domaines-de-la-computer-vision-et-leurs-applications/\" target=\"_blank\" rel=\"noreferrer noopener\">vision par ordinateur</a>, permettant une compréhension plus fine des éléments qui constituent une image.</p><p>Dans cet article, je vous propose de découvrir comment faire de la segmentation d’images avec Python en utilisant Segment Anything Model (SAM), un modèle de développé par Meta.</p><p>Alors que l’actualité technologique est dominée par les modèles d’intelligence artificielle générative tels que ChatGPT, il est important de ne pas négliger le domaine de la vision par ordinateur, qui reste un sujet très actif et riche en innovations.</p><p>Et je ne dis pas ça uniquement en tant que computer vision engineer !</p><p>La vision par ordinateur englobe un large éventail d’applications et de techniques permettant de traiter et d’analyser des images pour en extraire des informations pertinentes.</p><p>Ces avancées trouvent des applications dans divers domaines, tels que la santé, la sécurité, l’automatisation industrielle, la robotique et bien d’autres.</p><p>La segmentation d’images, en particulier, est une technique essentielle pour améliorer la compréhension de notre environnement visuel, en détectant et en classifiant les différents objets et éléments présents dans une image.</p><p>Ainsi, même à l’ère des modèles génératifs, la vision par ordinateur continue d’occuper une place de choix dans le paysage de l’IA et du traitement de l’information visuelle.</p><h2 class=\"wp-block-heading\">Comment fonctionne la segmentation d’images ?</h2><p>La segmentation d’images est un processus qui consiste à diviser une image en plusieurs régions ou segments, qui partagent des caractéristiques similaires, dans le but d’extraire des informations pertinentes et de simplifier l’analyse de l’image.</p><p>En pratique, faire de la segmentation d’image revient mathématiquement à faire de la classification ou du clustering sur les pixels de l’image.</p><p>Il existe différents types de segmentations :</p><ul class=\"wp-block-list\"><li><strong>Segmentation basée sur la couleur :</strong> Cette méthode utilise les informations de couleur pour séparer les différents objets ou régions d’une image. Les pixels ayant des couleurs similaires sont regroupés ensemble.</li><li><strong>Segmentation basée sur la texture :</strong> Cette méthode utilise les informations de texture pour identifier les régions dans une image. Les textures sont analysées à l’aide de diverses techniques, comme les matrices de co-occurrence, les filtres de Gabor, ou les descripteurs de texture locaux.</li><li><strong>Segmentation basée sur l’intensité :</strong> Cette méthode segmente une image en fonction des variations d’intensité ou de niveaux de gris. Les contours des objets sont souvent identifiés par la détection des gradients d’intensité ou par la détection des points de rupture dans l’histogramme de l’image.</li><li><strong>Segmentation basée sur la forme :</strong> Cette approche utilise les informations de forme pour séparer les objets ou les régions d’une image. Des méthodes de reconnaissance de formes, telles que les descripteurs de Fourier ou les moments invariants, sont souvent utilisées.</li><li><strong>Segmentation sémantique :</strong> Cette méthode vise à attribuer une étiquette sémantique à chaque pixel de l’image, pour classer les objets ou les régions en fonction de leur signification dans le monde réel.</li><li><strong>Segmentation par régions :</strong> Cette approche consiste à regrouper les pixels voisins ayant des caractéristiques similaires, pour former des régions homogènes. Les algorithmes courants incluent la croissance de région, la fusion de région, ou la segmentation par eau-forte.</li><li><strong>Segmentation par contours :</strong> Cette méthode se concentre sur la détection des contours des objets ou des régions dans une image. Les techniques courantes incluent la détection de Canny, la transformée de Hough ou la détection de contours actifs (snakes).</li><li><strong>Segmentation par deep learning :</strong> Ces dernières années, les réseaux de neurones profonds, tels que les réseaux de neurones convolutifs (CNN) et les réseaux de neurones récurrents (RNN), ont été largement utilisés pour la segmentation d’images. Les approches courantes incluent la segmentation sémantique avec les réseaux entièrement convolutifs (FCN), la segmentation par instance avec les réseaux Mask R-CNN et la segmentation d’objets avec les réseaux U-Net.</li></ul><h2 class=\"wp-block-heading\">Comment fonctionne le modèle SAM : Segment Anything Model ?</h2><p>Le modèle de référence pour la segmentation d’images est Segment Anything Model. Proposé par Meta en Avril 2023, il permet, comme son nom l’indique, de faire la segmentation de tous les objets présents dans une image.</p><p>La puissance de cet outil, est qu’il a compris de façon générale la notion d’objet, il peut donc faire de la généralisation zero-shot, en d’autres termes il est capable de détecter un objet même lorsqu’il ne l’a jamais vu dans son dataset d’entraînement.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-1024x713.png\" alt=\"Segmentation d'images en utilisant SAM et Python\" class=\"wp-image-8284\" width=\"601\" height=\"418\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-1024x713.png 1024w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-300x209.png 300w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-768x535.png 768w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47.png 1132w\" sizes=\"auto, (max-width: 601px) 100vw, 601px\"></figure></div><p>Le modèle utilise un réseau de neurones convolutifs (CNN) pré-entraîné pour la classification d’images et une approche appelée « zero-shot segmentation ». L’architecture du modèle est basée sur dees travaux antérieurs de Meta AI, tels que <a href=\"https://github.com/facebookresearch/MaskFormer\" target=\"_blank\" rel=\"noreferrer noopener\">MaskFormer</a> et ViT-Mixer.</p><p>La segmentation est effectuée en deux étapes : d’abord, le modèle génère un masque initial pour chaque objet, puis il affine ce masque en utilisant des informations de contexte et de forme.</p><p>L’objectif principal de ce modèle est de réduire la dépendance à des jeux de données de segmentation annotées spécifiques à chaque domaine, qui sont coûteux et chronophages.</p><p>SAM a été entraîné sur une base de données open source de <a href=\"https://segment-anything.com/dataset/index.html\" target=\"_blank\" rel=\"noreferrer noopener\">11 million d’images</a> et évalué en utilisant plusieurs jeux de données de segmentation d’images standard, tels que COCO, ADE20K et PASCAL VOC et d’après Meta il surpasse les modèles concurrents en termes de précision et de polyvalence.</p><h2 class=\"wp-block-heading\">Faire de la segmentation d’images avec Python</h2><p>Les codes qui ont été produits par Meta pour SAM sont complètements open-source, ce qui permet d’utiliser le modèle facilement depuis Python.</p><p>Je propose d’utiliser <a href=\"https://larevueia.fr/15-astuces-pour-google-colab/\" target=\"_blank\" rel=\"noreferrer noopener\">Google colab</a> pour ça, pour avoir un GPU et accélérer le traitement de l’image.</p><p>On commence par cloner le projet SAM sur le répertoire de travail :</p><pre class=\"wp-block-code\"><code>!git clone 'https://github.com/facebookresearch/segment-anything.git'</code></pre><p>Si vous n’êtes pas dans un notebook vous pouvez retirer le « ! » et lancer les lignes sur votre terminal.</p><p>On va ensuite entrer à l’intérieur du dossier cloné :</p><pre class=\"wp-block-code\"><code>%cd segment-anything</code></pre><p>On doit encore installer les poids du modèle qui ne sont pas dans le repo github :</p><pre class=\"wp-block-code\"><code>!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth</code></pre><p>On charge le modèle et on l’initialise :</p><pre class=\"wp-block-code\"><code>import torch\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nMODEL_TYPE = \"vit_h\"\n\n\nfrom segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\nCHECKPOINT_PATH = \"./sam_vit_h_4b8939.pth\"\nsam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)</code></pre><p>On peut maintenant lancer la segmentation sur une image de test. Celle que j’ai choisi s’appelle « sample.jpg »:</p><pre class=\"wp-block-code\"><code>mask_generator = SamAutomaticMaskGenerator(sam)\nIMAGE_PATH = \"./sample.jpg\"</code></pre><p>Pour la visualisation du résultat on va utiliser la librairie Supervision développée par Roboflow. On commence par l’installer :</p><pre class=\"wp-block-code\"><code>!pip install supervision</code></pre><p>On lit l’image avec OpenCV et on la converti en RGB, puis on génère les masques grâce à SAM :</p><pre class=\"wp-block-code\"><code>import cv2\nimport supervision as sv\n\nimage_bgr = cv2.imread(IMAGE_PATH)\nimage_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n\nsam_result = mask_generator.generate(image_rgb)</code></pre><p>Enfin, la visualisation du résultat :</p><pre class=\"wp-block-code\"><code>mask_annotator = sv.MaskAnnotator()\n\ndetections = sv.Detections.from_sam(sam_result=sam_result)\n\nannotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n\nsv.plot_images_grid(\n    images=[image_bgr, annotated_image],\n    grid_size=(1, 2),\n    titles=['source image', 'segmented image']\n)</code></pre><p>Et voilà le travail :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"351\" src=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-1024x351.png\" alt=\"Exemple de segmentation d'images en utilisant SAM et Python\" class=\"wp-image-8288\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-1024x351.png 1024w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-300x103.png 300w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-768x263.png 768w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-1536x527.png 1536w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div></div>"},
{"url": "https://larevueia.fr/comment-generer-des-images-avec-stable-diffusion/", "title": "Comment générer des images avec stable diffusion ?", "author": "Ilyes Talbi", "date": "\n25 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Tandis que des entreprises comme OpenAI sont en train progressivement de perdre leur objectif principal de vue, d’autres comme Stability.ai, qui s’est fait connaitre grâce à stable diffusion, pourraient reprendre le flambeau.</p><p>L’été 2022 nous aura montré le vrai visage d’OpenAI. Une organisation censée faire de la recherche pour le bien commun… Non seulement le modèle DALL-E 2 a été entraîné avec les données d’artistes, de créateurs de contenus, et d’internautes qui n’ont rien demandés, mais en plus ils ont décidé de faire payer et de limiter l’accès.</p><p>Heureusement, de brillants chercheurs nous ont proposé un modèle similaire, plus léger, plus performant et surtout open source. Il s’agit de stable diffusion.</p><p>Je vous parle de son fonctionnement dans cet article, et on verra comment créer des images en utilisant Google Colab.</p><h2 class=\"wp-block-heading\">Comment fonctionne Stable diffusion ?</h2><p>Stable diffusion est un modèle proposé par CompVis, Stability.ai et LAION. C’est le premier projet de génération d’images complètement open source.</p><h3 class=\"wp-block-heading\">Qu’est-ce que la génération d’images</h3><p>Avant d’expliquer les particularité de stable diffusion, laissez moi rappeler ce qu’est la génération d’images.</p><p>Malgré le sentiment de deception que j’ai à l’égard d’OpenAI, je reconnais tout le travail qu’ils ont fait pendant toutes ces années. C’est eux qui nous ont permis d’entrer dans l’ère des images générées par intelligence artificielle.</p><p>Les modèles les plus connus de génération d’images sont <a href=\"https://larevueia.fr/dall-e-generation-des-images-a-partir-de-textes/\" target=\"_blank\" rel=\"noreferrer noopener\">DALL-E</a>, Craiyon, Imagen, Midjourney, et maintenant Stable diffusion.</p><p>Le concept est toujours le même, il s’agit de transformer un texte en image. Le modèle va essayer de comprendre du mieux possible la requête entrée, et construire son image à partir de là.</p><p>La tâche est très complexe, puisque elle est à cheval entre la vision par ordinateur et le NLP.</p><h3 class=\"wp-block-heading\">Comment ça fonctionne et pourquoi les résultats sont si impressionnants ?</h3><p>Le modèle a été entraîné sur le dataset LAION-5B, qui contient quasiment 5 milliards de paires image/texte, disponible en plusieurs langues.</p><p>L’entraînement a duré 150000 heures, et a été réalisé en utilisant 256 GPU Nvidia A100. Le coût total de l’entrainement est de 600,000€ selon Wikipedia.</p><p>C’est un modèle de diffusion, dans le sens où la création de l’image se fait en débruitant progressivement une image. C’est aussi comme ça que ce fait l’entrainement du modèle. On utilise des <a href=\"https://larevueia.fr/introduction-aux-auto-encodeurs/\" target=\"_blank\" rel=\"noreferrer noopener\">auto-encodeurs</a>, pour bruiter l’image d’un côté du réseau, et la débruiter de l’autre.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"636\" height=\"177\" src=\"https://larevueia.fr/wp-content/uploads/2022/09/diffusion_process.png\" alt=\"auto-encodeur utilisé pour stable diffusion\" class=\"wp-image-6534\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/09/diffusion_process.png 636w, https://larevueia.fr/wp-content/uploads/2022/09/diffusion_process-300x83.png 300w\" sizes=\"auto, (max-width: 636px) 100vw, 636px\"></figure></div><p>Pour la partie comprehension de l’image, le modèle utilise un réseau avec une architecture U-Net qui contient 860M de paramètres, et un modèle de langage avec 123M de paramètres.</p><h2 class=\"wp-block-heading\">Générer des images avec Stable diffusion</h2><p>Vous pouvez utiliser stable diffusion facilement avec <a href=\"https://colab.research.google.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Google Colab</a>, en activant l’exécution sur GPU. Vous pourriez le faire en local mais je vous le déconseille si vous n’avez pas de GPU.</p><p>Commencez par installer la librairie <em>diffusers</em> :</p><pre class=\"wp-block-code\"><code>!pip install diffusers==0.3.0 transformers scipy ftfy</code></pre><p>Pour lancer ce code il vous faudra créer un compte sur Hugging face, c’est très rapide. Vous trouverez ensuite un access token dans vos paramètres.</p><p><strong>⚠️ Votre token doit rester secret</strong></p><pre class=\"wp-block-code\"><code>YOUR_TOKEN = \"<em>VOTRE_TOKEN</em>\"</code></pre><p>La librairie diffusers permet d’importer le modèle, les poids et toutes les dépendances très facilement :</p><pre class=\"wp-block-code\"><code>from diffusers import StableDiffusionPipeline\nimport torch\n\n# vous trouverez votre token ici : https://huggingface.co/settings/tokens\npipe = StableDiffusionPipeline.from_pretrained(\n\"CompVis/stable-diffusion-v1-4\", \nuse_auth_token=YOUR_TOKEN\n)</code></pre><p>Si vous êtes sur Colab et que vous avez bien activé l’option GPU (<em>Exécution</em> puis <em>Modifier le type d’exécution</em>), ou si vous avez un GPU Nvidia sur votre ordinateur, vous devez activer l’option avec cette ligne :</p><pre class=\"wp-block-code\"><code>pipe.to(\"cuda\")</code></pre><p>Enfin, vous pouvez générer n’importe qu’elle image en changeant la variable <em>prompt</em> ci-dessous :</p><pre class=\"wp-block-code\"><code>prompt = \"tech article illustration, concept art\"\n\nwith torch.autocast(\"cuda\"):\n    image = pipe(prompt)[\"sample\"][0]\n\nimage.save(f\"generated_image.png\")</code></pre><p>Avec le GPU de Google Colab l’image met moins de 10 secondes à être générée, sans GPU ça risque de prendre quelques minutes.</p><p>C’est d’ailleurs ce code qui a généré l’illustration principale de cette article 🙂</p><p>Vous pouvez retrouver les codes utilisés pour cet article <a href=\"https://huggingface.co/blog/stable_diffusion\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Pour en savoir plus sur le projet je vous invite à vous rendre sur le <a href=\"https://github.com/CompVis/stable-diffusion\" target=\"_blank\" rel=\"noreferrer noopener\">github</a> du projet.</p><p>Pour conclure, il faut savoir que l’open source a ses avantages, mais peut aussi avoir des limitations. Même si on est forcé d’accepter la license d’utilisation qui interdit l’exploitation du modèle pour générer du contenu offensant, techniquement rien n’empêche les utilisateurs de le faire.</p><p>D’ailleurs, dans une interview avec Sentdex, le CEO de Stability.ai expliquait qu’il considérait le fait d’ajouter des restrictions techniques comme étant liberticide, et condamnait l’avis d’OpenAI qui pense mieux connaitre que l’utilisateur ce qui est bien pour lui.</p><p>Néanmoins, je pense que cette approche est plus viable sur le long terme. En donnant un accès libre au modèle, on favorise la recherche et le développement communautaire, notamment concernant les biais.</p></div>"},
{"url": "https://larevueia.fr/pourquoi-utiliser-python-pour-le-deep-learning/", "title": "Pourquoi utiliser Python pour le deep learning ?", "author": "Ilyes Talbi", "date": "\n17 janvier 2024\n", "content": "<div class=\"entry-content\"><p>Le <a href=\"https://larevueia.fr/deep-learning/\">deep learning</a> ou apprentissage profond est une méthode d’apprentissage automatique qui se base sur des architectures de réseaux de neurones artificiels profonds pour traiter et modéliser des données de grande complexité.</p><p>Avant de plonger dans les détails de cette approche, il est important de comprendre le concept des <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\">réseaux de neurones</a>.</p><p>Ces réseaux s’inspirent de la structure du cerveau humain, sans toutefois en être des reproductions exactes, et sont constitués d’unités mathématiques organisées en couches successives.</p><p>En progressant à travers ces couches, les informations sont transformées et des caractéristiques de plus en plus abstraites sont extraites.</p><p>À la différence d’autres méthodes traditionnelles d’apprentissage automatique, où l’extraction de caractéristiques doit souvent être manuellement orchestrée, le deep learning est reconnu pour sa capacité à apprendre ces caractéristiques de manière autonome.</p><p>Il est très pertinent pour des applications où les relations entre les données sont complexes et difficilement définissables par l’humain, comme la reconnaissance d’images ou la traduction automatique.</p><p>Pour entraîner des modèles de deep learning performants on doit suivre plusieurs étapes allant de la collecte de données, à l’analyse de performances du modèle en passant par l’entraînement du modèle.</p><p>Dans cet article, on va voir pourquoi Python c’est imposé comme le langage de référence pour le deep learning et pour la data en général.</p><h2 class=\"wp-block-heading\">Python est un langage simple et cohérent</h2><p>La première raison de l’utilisation de python pour le deep learning est l’expérience de développement que propose ce language.</p><p>La simplicité et la cohérence de Python facilitent l’apprentissage et l’implémentation du code, permettant ainsi aux développeurs de se concentrer davantage sur la résolution des problèmes de machine learning plutôt que sur la syntaxe du langage.</p><p>La syntaxe intuitive de Python favorise une meilleure lisibilité et une maintenance simplifiée du code, rendant le processus de développement plus fluide et efficace.</p><p>Voici quelques exemples illustrant la simplicité et la cohérence de Python :</p><ul class=\"wp-block-list\"><li><strong>Syntaxe Lisible</strong> : Python a une syntaxe claire et concise, ce qui facilite la lecture et la compréhension du code. Par exemple, l’impression d’un texte se fait simplement avec <code>print(\"Texte\")</code>.</li></ul><ul class=\"wp-block-list\"><li><strong>Indentation</strong> : L’indentation en Python est non seulement une bonne pratique, mais elle est obligatoire, ce qui encourage l’écriture d’un code propre et bien structuré.</li></ul><ul class=\"wp-block-list\"><li><strong>Code Concis</strong> : Avec Python, vous pouvez écrire des fonctions complexes en moins de lignes de code par rapport à d’autres langages comme Java ou C++. Par exemple, une liste de compréhension peut être créée en une seule ligne : <code>squares = [x**2 for x in range(10)]</code>.</li></ul><p>La simplicité et la cohérence de Python réduisent la courbe d’apprentissage pour les nouveaux développeurs et permettent une transition plus facile vers des projets de machine learning complexes.</p><h2 class=\"wp-block-heading\">Python est indépendant de tous les OS</h2><p>L’indépendance de la plateforme de Python signifie qu’il peut fonctionner sur divers systèmes d’exploitation comme Windows, MacOS, et Linux sans nécessiter de modifications majeures du code.</p><p>Cela permet aux développeurs de travailler sur des projets de machine learning et de deep learning dans des environnements variés, facilitant ainsi la collaboration et le partage des ressources entre les équipes.</p><p>Cette caractéristique fait de Python un choix populaire pour les projets qui nécessitent une portabilité entre différentes plateformes système.</p><h2 class=\"wp-block-heading\">Python contient énormément de librairies et de frameworks</h2><p>La diversité des bibliothèques et cadres (frameworks) en Python offre aux développeurs un large éventail d’outils pour le machine learning et le deep learning.</p><p>Des bibliothèques comme TensorFlow, Keras, et PyTorch fournissent des fonctionnalités avancées pour la création et l’entraînement de modèles.</p><p>D’autres bibliothèques comme Scikit-learn, Pandas, et NumPy facilitent la manipulation de données et l’analyse.</p><p>Cette riche collection d’outils accélère le développement, simplifie l’expérimentation et contribue à l’efficacité des projets de machine learning et deep learning.</p><h2 class=\"wp-block-heading\">Python a une très grande communauté</h2><p>La grande communauté de Python contribue activement au développement et à la maintenance de ces bibliothèques et frameworks.</p><p>Cette communauté propose des corrections de bugs, des améliorations, et partage des ressources éducatives, ce qui facilite l’apprentissage et l’utilisation de ces outils.</p><p>L’engagement de la communauté assure que les bibliothèques restent à jour, performantes et adaptées aux exigences changeantes du domaine du machine learning et du deep learning.</p><h2 class=\"wp-block-heading\">Quelques chiffres et ressources sur Python pour le deep learning</h2><p>La diversité des bibliothèques et des frameworks en Python est souvent mise en avant, et plusieurs sources listent les bibliothèques les plus populaires et utiles pour le machine learning et le deep learning.</p><p>Python propose un large éventail de bibliothèques pour diverses applications. Par exemple, certains articles listent les « Top 30 » ou « Top 10 » des bibliothèques Python à connaître, mentionnant des bibliothèques comme TensorFlow, Keras, PyTorch, Scikit-learn, Pandas et NumPy parmi d’autres : ​<a href=\"https://www.mygreatlearning.com/blog/open-source-python-libraries/#:~:text=Top%2030%20Python%20Libraries%20To,for%20writing%20codes%20from%20scratch\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>1</sup></a>​​ <a href=\"https://www.turing.com/kb/best-python-libraries-for-ml-in-2023#:~:text=Top%2010%20Python%20machine%20learning,An%20overview%20of%20machine%20learning\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>2</sup></a> ​​<a href=\"https://www.stratascratch.com/blog/top-18-python-libraries-a-data-scientist-should-know/#:~:text=Maximize%20your%20data%20science%20potential,which%20have%20too%20many\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>3</sup></a>​.</p><p>Quant à la taille de la communauté Python, une source mentionne que la taille de la communauté Python est de 15,7 millions, bien que le contexte de ce chiffre ne soit pas entièrement clair ​<a href=\"https://www.statista.com/topics/9361/python/#:~:text=Python%20community%20Python%20was%20founded,7m\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>4</sup></a>​.</p><p>Il existe des enquêtes annuelles menées auprès des développeurs Python qui permettent d’obtenir des insights sur la communauté, bien que des chiffres spécifiques sur la taille de la communauté n’aient pas été fournis dans l’extrait disponible​ <a href=\"https://blog.adafruit.com/2023/10/03/python-developers-survey-2022-results-python-community-thepsf/#:~:text=October%203%2C%202023%20AT%204%3A04,Python%20Software%20Foundation%20and%20JetBrains\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>5</sup></a> ​.</p><p>Ces informations illustrent la richesse des ressources disponibles en Python et la vaste communauté qui soutient son écosystème, ce qui en fait une plateforme attrayante pour le développement en machine learning et en deep learning.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>La montée en puissance du deep learning et du machine learning est indéniable, et Python s’est positionné comme un pilier central dans ce domaine, grâce à ses caractéristiques intrinsèques et à l’écosystème robuste qu’il a bâti autour de ces technologies.</p><p>Sa simplicité, sa cohérence, et son indépendance vis-à-vis des systèmes d’exploitation rendent l’apprentissage et le développement dans ce domaine beaucoup plus accessibles.</p><p>La richesse des bibliothèques et frameworks disponibles accélère la mise en œuvre des projets, permettant aux développeurs d’explorer, d’innover et de déployer des solutions efficaces.</p><p>La grande communauté de Python, active et engagée, assure un support continu, des améliorations constantes des outils existants et une mise à jour régulière face aux défis émergents du domaine.</p><p>L’interaction entre la simplicité de Python et la complexité inhérente du machine learning et du deep learning crée un environnement propice à l’exploration, à l’apprentissage et à l’innovation, faisant de Python un choix de prédilection pour les professionnels et les organisations cherchant à tirer profit de la puissance du machine learning et du deep learning.</p></div>"},
{"url": "https://larevueia.fr/yolo-nas/", "title": "Tout ce qu’il faut savoir sur YOLO-NAS", "author": "Adib Habbou", "date": "\n4 mai 2023\n", "content": "<div class=\"entry-content\"><p>La détection d’objet en temps réel est une technique d’intelligence artificielle qui permet de détecter et d’identifier des objets dans une vidéo ou une séquence d’images en temps réel. Cela implique l’utilisation de techniques de vision par ordinateur et d’apprentissage automatique, telles que les réseaux de neurones convolutionnels, pour analyser en temps réel les images.</p><p>Pour ce faire, les algorithmes de détection d’objet recherchent des modèles spécifiques dans les images, tels que la forme, la couleur, la texture et la taille des objets, afin de les identifier avec précision.</p><p>Ces dernières années, le modèle <strong><a href=\"https://larevueia.fr/top-5-des-projets-open-source-dintelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">YOLO</a> </strong>(You Only Look Once) a connu un grand succès dans ce domaine en permettant une détection rapide et précise des objets sur une image ou une vidéo.</p><p>Cependant, malgré ses performances impressionnantes, <strong>YOLO </strong>présentait certaines limites en termes de précision.</p><p>C’est pourquoi de nombreux chercheurs se sont intéressés aux recherches automatiques d’architectures neuronales, abréviée <strong>NAS </strong>pour Neural Architecture Search en anglais, afin d’améliorer les performances de <strong>YOLO </strong>tout en conservant sa rapidité d’exécution.</p><p>Ce modèle de détection d’objet en temps réel a été développée par une équipe de chercheurs de l’université de Pékin en Chine et améliorer en collaboration avec l’entreprise <strong>Deci AI</strong>.</p><h2 class=\"wp-block-heading\">C’est quoi un Neural Architecture Search ?</h2><p>L’architecture <strong>NAS </strong>est une méthode d’apprentissage automatique qui permet d’automatiser la recherche de la meilleure architecture de <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\">réseau de neurones</a> pour une tâche donnée.</p><p>Contrairement aux réseaux de neurones classiques, où l’architecture est définie à l’avance, l’architecture <strong>NAS </strong>est générée automatiquement en utilisant des algorithmes d’optimisation tels que la recherche par renforcement (Reinforcement Search) ou la recherche en grille (Grid Search). Cette approche permet d’obtenir des architectures plus performantes que celles conçues manuellement.</p><p>Pour entrer plus dans le détail, on peut voir ici sur la première image une représentation séquentielle d’un <strong>CNN </strong>et en dessous une représentation séquentielle de l’arborescence d’une cellule qui va donc servir à trouver l’architecture la plus optimale.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://lilianweng.github.io/posts/2020-08-06-nas/NAS-search-space.png\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><h2 class=\"wp-block-heading\">Ça marche comment YOLO NAS ?</h2><p><strong>YOLO NAS</strong> est une version améliorée du modèle <strong>YOLO</strong>, qui utilise un <strong>NAS </strong>pour optimiser la recherche de la meilleure architecture de réseau de neurones pour la détection d’objets en temps réel. Le principe de la recherche d’architecture pour <strong>YOLO </strong>consiste à générer plusieurs architectures candidates et à les entraîner sur des données d’apprentissage.</p><p>Un algorithme de sélection est ensuite utilisé pour déterminer la meilleure architecture en fonction de critères tels que la précision, la couverture d’objets et le temps d’exécution. Les résultats obtenus par<strong> YOLO NAS</strong> montrent une amélioration significative des performances par rapport à <strong>YOLO </strong>classique, avec une précision accrue de <strong>2%</strong> et une réduction de l’erreur de localisation de <strong>15%</strong>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://deci.ai/wp-content/uploads/2023/05/YOLO-NAS-Launch-Business-Blog2.jpg\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><h2 class=\"wp-block-heading\">Est-ce que YOLO NAS est performant ?</h2><p>Pour évaluer les performances de <strong>YOLO NAS</strong>, plusieurs comparaisons ont été réalisées avec les modèles les plus performants à ce jour en termes de détection d’objets en temps réel, tels que <strong>RetinaNet</strong>, <strong>Faster R-CNN</strong> ou <strong>Single-Shot Detector</strong>. Les résultats montrent que <strong>YOLO NAS </strong>est capable de rivaliser voire de dépasser ces modèles en termes de précision, tout en conservant une vitesse d’exécution similaire.</p><p>Les avantages de <strong>YOLO NAS</strong> par rapport à ces modèles sont son architecture plus légère, son adaptation à des scènes complexes et sa capacité de détection d’objets de petite taille. Bien que le modèle<strong> </strong>présente de nombreux avantages, il présente cependant quelques inconvénients. L’un des principaux étant sa difficulté à détecter des objets très proches, ce qui peut entraîner une confusion entre des objets voisins. De plus, le modèle peut avoir des difficultés à distinguer des objets similaires, comme des voitures de couleur similaire, ce qui peut entraîner des erreurs de détection.</p><p>Il reste toutefois plus performants que les anciennes versions de YOLO comme on peut le voir dans la vidéo ci-dessous :</p><figure class=\"wp-block-video\"><video controls src=\"https://larevueia.fr/wp-content/uploads/2023/05/%F0%9F%8E%AF-mark-freeman-ii-on-linkedin-yolonas-computervision-ai-data-datascience-ml-deeplearning-python.mp4\"></video></figure><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Source : Mark Freeman (LinkedIn)</em></p></blockquote><p><strong>YOLO NAS</strong> réussit également à surpasser toutes les versions déjà existantes de <strong>YOLO </strong>en proposant une meilleure précision et une latence plus faible.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*11VfHXRB2KEefut1rrSy4g.png\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><p>De plus, <strong>YOLO NAS</strong> dépasse assez largement la <em>Mean Average Precision </em>des anciennes versions de <strong>YOLO</strong>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://pbs.twimg.com/media/FvNkFTfaAAIA2sf?format=png&amp;name=large\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><h2 class=\"wp-block-heading\">Conclusion</h2><p><strong>YOLO NAS</strong> a permit de surpasser les performances du modèle <strong>YOLO </strong>classique, mais il lui reste tout de même un bon nombre de point à améliorer.</p><p>Grâce aux avancées dans la recherche d’architectures et dans l’entraînement des modèles de détection d’objets en temps réel, l’utilisation de réseaux de neurones à architecture <strong>NAS </strong>comme <strong>YOLO NAS</strong> offre des perspectives passionnantes pour des applications innovantes dans de nombreux domaines en partant de la conduite autonome pour arriver à la vérification de conformité aux normes de sécurité en passant par la recherche et sauvetage.</p><h2 class=\"wp-block-heading\">Pour aller plus loin</h2><p>Repo GitHub de Deci AI : <a href=\"https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md\">https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md</a></p><p>Article Medium sur YOLO NAS : <a href=\"http://How%20YOLO%20NAS%20is%20leaving%20YOLO%20V8%20in%20the%20dust!\">https://augmentedstartups.medium.com/how-yolo-nas-is-leaving-yolov8-in-the-dust-and-why-you-need-to-know-about-it-87f67a844bcb</a></p><p>Article sur les NAS : <a href=\"https://lilianweng.github.io/posts/2020-08-06-nas/\">https://lilianweng.github.io/posts/2020-08-06-nas/</a></p><p>Notebook d’Intro à YOLO NAS : <a href=\"https://colab.research.google.com/drive/1q0RmeVRzLwRXW-h9dPFSOchwJkThUy6d#scrollTo=m0SkK3bjMOqH\">https://colab.research.google.com/drive/1q0RmeVRzLwRXW-h9dPFSOchwJkThUy6d#scrollTo=m0SkK3bjMOqH</a></p></div>"},
{"url": "https://larevueia.fr/comment-fonctionne-les-rag-retrieval-augmented-generation-en-intelligence-artificielle/", "title": "Comment fonctionnent les RAG (Retrieval Augmented Generation) en intelligence artificielle ?", "author": "Ilyes Talbi", "date": "\n16 juin 2024\n", "content": "<div class=\"entry-content\"><p>Depuis l’arrivée de ChatGPT et la démocratisation des LLM, Large Language Models, les nombre de cas d’usage concrets en entreprises ne cesse de croitre. On voit de plus en plus l’intérêt de ces modèles et de l’intelligence artificielle générative en général dans un contexte professionnel, notamment pour de la productivité ou de l’automatisation.</p><p>Malgré cet engouement on sent qu’il reste encore beaucoup de travail pour assurer une adoption plus large de ces outils là. Les entreprises n’ont pas réellement besoin de modèles de langages généralistes, elles ont besoin de modèles de langages spécialisés sur certains corps de métier bien spécifique et qui soient capable de comprendre le contexte en temps réel.</p><p>Actuellement, une des solutions les plus prometteuses à ce problème se base sur les systèmes de RAG, Retrieval Augmented Generation.</p><h2 class=\"wp-block-heading\" id=\"h-qu-est-ce-que-la-retrieval-augmented-generation-rag\">Qu’est-ce que la Retrieval Augmented Generation (RAG) ?</h2><p>Avant d’explique le fonctionnement des RAG expliquons rapidement le fonctionnement d’un modèle de langage classique.</p><p>Un LLM est un modèle de réseau de neurones basé sur les <a href=\"https://larevueia.fr/introduction-aux-reseaux-de-neurones-transformers/\" target=\"_blank\" rel=\"noreferrer noopener\">Transformers</a> dont l’objectif est de compléter une séquence de mot. Mathématiquement il s’agit de construire une distribution de probabilité sur les mots d’un vocabulaire et d’associer à chaque mot sa probabilité d’être le prochain dans la séquence.</p><p>Pour faire cela, les textes sont transformés en tokens mathématiques pour pouvoir être traités de manière vectorielle et compris par le réseau de neurones.</p><p>Cette explication brève a simplement pour objectif de rappeler qu’un LLM n’a aucune composante de logique ou de compréhension dans sa version de base. C’est la qualité des données d’entrées qui permette de feindre une logique et une compréhension sémantique.</p><p>Ce fonctionnement entraîne une baisse importantes des performances dans pas mal de situations. Si je demande à un LLM « Qui a gagné la dernière coupe du monde ? », son fonctionnement fait qu’il essayera de me donner le nom d’un pays qui est mathématiquement souvent associé à la notion de « coupe du monde » dans son dataset. Il répondra probablement « Brésil » ou « France », mais sans aucune compréhension.</p><p>De la même manière, si je demande à un LLM de me donner le résultat de l’opération 1 + 1, certes il me répondre 2 dans son premier message, mais si je lui explique dans le message suivant que la réponse est 3 il demandera pardon et confirmera que la réponse est bien 3.</p><p>Ce phénomène a un nom, c’est l’hallucination. Elle existe surtout dans les premiers modèles de LLM, dans leurs versions brutes. Aujourd’hui ce problème est un peu atténué mais reste présent.</p><p>Les modèles de RAG permettent de faire en sorte que la réponse fournie par le LLM soit consolider par une base qui contient du contexte fiable sur le sujet en question.</p><p>Lorsque je pose ma question au modèle de langage avec un pipeline de RAG intégré, l’algorithme va d’abord transformer ma question en tokens mathématiques pour la vectoriser. Il va ensuite faire une recherche sémantique dans la base de contexte pour trouver des paragraphes qui seraient proches mathématiquement (il s’agit de calculer des distances entre des vecteurs). Une fois qu’il a trouvé des paragraphes qui pourraient permettre de donner une réponse plus précise et fiable, il reformule le prompt initial de l’utilisateur en y ajoutant le contexte trouvé. C’est comme ça que la réponse finale est fournie à l’utilisateur.</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-1024x576.png\" alt=\"Comment fonctionne les RAG ? Langchain.\" class=\"wp-image-8758\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-1024x576.png 1024w, https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-768x432.png 768w, https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain.png 1200w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Le fonctionnement des RAG (Source : <a href=\"https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2\">Towards data science</a>)</figcaption></figure><p>Les systèmes basés sur des pipelines de RAG sont assez performants et permettent de créer des assistants plus fiables et capable d’intégrer de nouvelles bases de connaissances en continu. Concernant le second point, on parle aussi de real-time training, <a href=\"https://larevueia.fr/llm-et-apprentissage-en-temps-reel/\" target=\"_blank\" rel=\"noreferrer noopener\">apprentissage en temps réel</a>.</p><h2 class=\"wp-block-heading\" id=\"h-quelles-sont-les-applications-de-la-retrieval-augmented-generation-rag\">Quelles sont les applications de la Retrieval Augmented Generation (RAG) ?</h2><p>Les pipelines de RAG sont utiles à chaque fois que l’on cherche à créer un assistant qui soit fiable concernant l’information qu’il donne à l’utilisateur. C’est ce qui a rendu cette technique largement utilisée en entreprise.</p><h3 class=\"wp-block-heading\" id=\"h-resume-de-reunions-interactif\">Résumé de réunions interactif</h3><p>Parmi les cas d’usage les plus intéressants on trouve les résumeur de réunions interactif. Les RAG permettent de poser des questions sur la base de transcription qui ont été faites automatiquement pendant une réunion.</p><p>Des outils comme <a href=\"https://fireflies.ai/\">Fireflies.ai</a> par exemple, permettent de poser des questions du type : « qu’est ce que Martin a dit concernant les nouvelles features qui doivent être lancées ? ». Et le modèle peut non seulement vous donner une réponse fiable, mais il pourra aussi vous donner ses sources en intégrant dans sa réponse l’extrait audio du passage qui répond à la question.</p><h3 class=\"wp-block-heading\" id=\"h-documentation-interne-en-entreprise\">Documentation interne en entreprise</h3><p>La documentation interne en entreprise est l’autre gros sujets que les RAG permettent de traiter.</p><p>C’est le besoin qui revient le plus souvent quand on discute avec les grosses entreprises : construire un système de documentation interne fiable et qui permet de vraiment trouver l’information.</p><p>Pourquoi la documentation interne en entreprise est un problème aujourd’hui ?</p><ul class=\"wp-block-list\"><li>On perd du temps en recherchant les informations</li><li>On refait/recode des choses qui ont déjà été faites</li><li>On met en danger la sécurité des données de l’entreprise en se les partageant n’importe où : Whatsapp/Gmail/WeTransfer/etc.</li></ul><p>Les LLM (et les modèles d’IA en général) vont permettre une interaction plus naturelle avec les données d’une entreprise et faire gagner énormément de temps à travers des pipelines de RAG.</p><p>Des outils comme <a href=\"https://dust.tt/\" target=\"_blank\" rel=\"noreferrer noopener\">Dust</a>, permettent d’agréger toutes les bases de connaissances d’une entreprise au même endroit, via des interactions de type chat. On peut connecter le Github, le Slack, les emails, le Google Drive et tout un tas d’autres outils au pipeline de RAG pour centraliser l’information.</p><h3 class=\"wp-block-heading\" id=\"h-assistant-au-contact-des-clients\">Assistant au contact des clients</h3><p>Lorsque l’on met un assistant au contact d’un client la qualité des réponses fournies doit être irréprochable. On ne peut pas se permettre de laisser un assistant se tromper sur le prix d’une prestation ou sortir de son cadre d’intervention.</p><p>Dans ce cas précis, les RAG vont amener de la pertinence aux réponses fournies en extrayant le contexte de l’entreprise directement dans les bases de connaissances.</p><p>La possibilité d’avoir un apprentissage en temps réel est très intéressante pour ce cas d’usage et permet de traiter plus facilement les données changeantes en continu.</p><p>Par exemple, si on est un site de e-commerce qui vend des t-shirts, il est impossible de ré-entraîner un modèle de langage à chaque fois que les produits, les prix ou le stock évoluent, on doit pouvoir faire ce travail facilement et sans intervention humaine sur les pipelines algorithmiques et les modèles.</p><h2 class=\"wp-block-heading\" id=\"h-quelles-sont-les-limites-aux-systemes-de-rag-actuellement\">Quelles sont les limites aux systèmes de RAG actuellement ?</h2><p>Malgré les avancées significatives apportées par les systèmes de Retrieval Augmented Generation, il est important de reconnaître qu’ils comportent des limites non négligeables.</p><p>Premièrement, la qualité et l’actualité des données dans la base de contexte sont cruciales ; un corpus désuet ou de faible qualité peut conduire à des réponses inexactes ou trompeuses.</p><p>De plus, ces systèmes peuvent souffrir d’une latence plus élevée due au processus de récupération des informations pertinentes, ce qui peut être problématique dans des applications nécessitant une réponse en temps réel.</p><p>Enfin, il existe un risque de sur-spécialisation où le système devient tellement affiné sur une niche spécifique qu’il perd de sa capacité à généraliser ou à s’adapter à de nouvelles tâches ou domaines, ce qui limite son utilité pour des applications plus générales ou en constante évolution.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>En conclusion, au-delà des systèmes de RAG, il est essentiel de mentionner l’essor des techniques de « function calling » qui révolutionnent la manière dont les modèles de langage interagissent avec des fonctions externes pour accomplir des tâches spécifiques.</p><p>Cette approche s’inscrit dans la continuité des modèles de RAG. Elle permet aux modèles de langage de non seulement comprendre et générer du texte, mais également d’exécuter des fonctions programmées qui étendent leurs capacités au-delà de la simple génération de texte.</p><p>C’est dans ce contexte que des outils comme <a href=\"https://larevueia.fr/langchain-le-guide-essentiel/\" target=\"_blank\" rel=\"noreferrer noopener\">Langchain</a> ont émergés. Langchain est une plateforme open-source qui facilite la mise en place de pipelines de RAG en permettant aux développeurs de facilement intégrer et orchestrer ces fonctionnalités avancées dans des applications concrètes.</p><p>Cela ouvre la voie à des modèles de langage encore plus puissants et adaptatifs, capables de fournir des réponses non seulement contextuelles mais également actionnables, en tirant parti de bases de données dynamiques et de fonctions spécifiques selon les besoins des utilisateurs.</p></div>"},
{"url": "https://larevueia.fr/llm-et-apprentissage-en-temps-reel/", "title": "LLM et apprentissage en temps réel", "author": "Claire Nouet", "date": "\n27 août 2023\n", "content": "<div class=\"entry-content\"><p><em>– <strong>Utilisateur :</strong> « ChatGPT, qui a gagné la coupe du monde en 2022 ? »</em><br>– <em><strong>ChatGPT :</strong> « Je suis désolé, mais ma dernière mise à jour de connaissances date de septembre 2021, ce qui signifie que je n’ai pas d’informations sur les événements survenus après cette date. »</em></p><p><em>On a tous été confrontés un jour ou l’autre à ce problème. Heureusement Claire Nouet, co-fondatrice de <a href=\"https://pathway.com/\">Pathway</a>, a la solution. Et c’est le sujet de cet article.</em></p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p class=\"has-medium-font-size\"><strong>A propos de Pathway</strong></p><p class=\"has-medium-font-size\"><em>Pathway développe une technologie d’intelligence artificielle en temps réel. L’apprentissage en temps réel est rendu possible par un moteur de traitement de données, qui alimente les larges modèles de langage et les modèles d’apprentissage automatique.</em></p><p class=\"has-medium-font-size\"><em>Ces modèles sont automatiquement mis à jour. L’équipe, dirigée par Zuzanna Stamirowska, est composée d’experts de premier plan dans le domaine de l’intelligence artificielle. Parmi eux figurent le CTO Jan Chorowski, co-auteur de Geoff Hinton et Yoshua Bengio, ainsi que le Business Angel Lukasz Kaiser (OpenAI), co-auteur de Tensor Flow et également connu comme le « T » dans ChatGPT.</em></p></blockquote><p>Les larges modèles de langage (LLM) sont la première technologie ayant abouti commercialement qui soit capable de transformer des volumes importants de données d’apprentissage, permettant à une machine d’agir en imitant ce qu’elle a vu dans les données.</p><p>Les LLMs sont entraînés sur des données statiques, ce qui rend l’utilisation d’un contexte obligatoire pour pouvoir prendre en compte des informations nouvelles ou corrigées.</p><p>La taille du contexte étant limitée, il est important de n’inclure que les informations les plus pertinentes lors d’une requête, ce qui rend l’utilisation des bases de données vectorielles intéressante.</p><p>Dans cet article, on explique les notions de contexte et on présente une approche vectorielle permettant de contourner ces effets et améliorer les sorties proposées.</p><h2 class=\"wp-block-heading\" id=\"h-les-llms-et-la-delicate-gestion-des-mises-a-jour\"><strong>Les LLMs et la délicate gestion des mises à jour</strong></h2><p>Les modèles d’apprentissage automatique qui ont été entrainés sur des bases statiques ne peuvent pas s’adapter à des changements arrivant en temps réel.</p><p>En effet, en raison de la complexité de la gestion des données temps réel, les modèles d’apprentissage automatique sont généralement entraînés sur des données statiques, y compris les LLMs tels que GPT-4 (un des modèles utilisés par ChatGPT).</p><p>Cela signifie que leur connaissance est limitée à un moment donné dans le passé.</p><p>Contrairement aux humains, les machines ne sont pas dans un état d’apprentissage continu et ne peuvent donc pas « oublier » de manière itérative les informations qui leur ont été enseignées précédemment lorsqu’elles ne sont plus à jour ou si elles s’avèrent inexactes.</p><p>Il est extrêmement difficile de concevoir des systèmes efficaces qui combinent à la fois les flux de données historiques et ceux des données en continu.</p><p>L’exercice est devenu encore plus complexe depuis l’entrée en scène de l’intelligence artificielle générative qui nécessite un apprentissage rapide et sécurisé du contexte afin d’apporter de la valeur et de garantir la confiance des utilisateurs. </p><h2 class=\"wp-block-heading\" id=\"h-le-fine-tuning-ne-suffit-pas\"><strong>Le fine-tuning ne suffit pas</strong></h2><p>Le <a href=\"https://larevueia.fr/fine-tuner-chatgpt-grace-a-lapi-dopenai/\" target=\"_blank\" rel=\"noreferrer noopener\">fine-tuning</a> est la spécialisation d’un modèle pré-entraîné grâce à un entraînement superficiel sur des données additionnelles et spécifiques à un problème donné.</p><p>Le fine-tuning permet de personnaliser un modèle et de lui faire prendre en compte des mises à jour dont le modèle initial n’avait pas connaissance.</p><p>Néanmoins cette technique d’apprentissage souffre du même souci que l’entraînement standard d’un modèle : elle se base sur un ensemble de données statiques, ce qui rend difficile une mise à jour en temps réel, et elle ne permet pas d’oublier des informations.</p><p>Une “fake news” qui serait retirée de l’ensemble des documents d’entraînement ne serait pas oubliée par le modèle pour autant. Il faudrait refaire le fine-tuning depuis le modèle d’origine à chaque requête, ce qui est coûteux.</p><h2 class=\"wp-block-heading\" id=\"h-le-contexte-un-facteur-cle\"><strong>Le contexte : un facteur clé</strong></h2><p>Les LLM sont entraînés sur des données statiques. Lorsqu’il est nécessaire d’inclure de nouvelles connaissances qui n’ont pas été “vues” par un LLM au cours de son entraînement, la solution consiste à introduire des connaissances nouvelles dans le <strong>contexte</strong> du LLM.</p><p>Cela signifie intégrer ces informations nouvelles dans la question (le “prompt”). Le LLM utilise ensuite ces connaissances dans leur contexte.</p><p>Les <a href=\"https://arxiv.org/abs/2212.10559\">LLM apprennent bien avec des connaissances “In-context »</a> et l’étendue des choses qu’ils peuvent analyser de cette manière est étonnamment grande.</p><h2 class=\"wp-block-heading\" id=\"h-les-defis-lies-a-l-apport-de-nouvelles-connaissances-a-un-llm-nbsp\"><strong>Les défis liés à l’apport de nouvelles connaissances à un LLM </strong></h2><p>Un LLM n’a aucun moyen de transférer les connaissances de son contexte dans sa « mémoire à long terme ». Ce que vous montrez au LLM est donc perdu à la fin de votre échange.</p><p>Par ailleurs, le contexte doit rester assez court, sous peine de voir le LLM se <a href=\"https://arxiv.org/abs/2307.03172v2\">comporter de manière étrange</a>.</p><p>Alors qu’un modèle LLM pré-entraîné pèse des dizaines de gigaoctets, son contexte est limité à quelques milliers de tokens qui peuvent être introduits pendant la discussion. Cela correspond au mieux à quelques pages de texte. </p><p><strong><em>De fait, déterminer les informations les plus récentes et les plus exactes à présenter à un LLM dans son contexte est devenu l’un des véritables défis de la création d’applications d’intelligence artificielle en entreprise.</em></strong></p><h2 class=\"wp-block-heading\" id=\"h-gerer-le-contexte-en-temps-reel\"><strong>Gérer le contexte en temps réel</strong></h2><p>L’un des principaux problèmes à résoudre pour certains besoins métier est de construire des systèmes capables de traiter l’information de manière intelligente et en temps réel, par exemple pour assembler, traiter et enrichir les données.</p><p>Cela inclut la recherche de documents, pour retrouver des bribes d’informations pertinentes parmi des milliards de documents qui traînent dans les entrepôts de données : textes, PDF, wikis internes, courriels, messages sur Teams ou flux de données circulant dans les systèmes de l’entreprise.</p><p>Une gestion du contexte en temps réel ouvre la porte à de nombreux cas d’usage :</p><ul class=\"wp-block-list\"><li>Pouvoir poser des questions à un LLM en utilisant une base de connaissances (privée ou non) fréquemment mise à jour.</li><li>Obtenir des données structurées en direct à partir de flux temps réel de documents.</li><li>Surveiller les flux d’informations en temps réel à l’aide d’un LLM : actualités et réseaux sociaux, détection de fake news, perturbations des transports…</li></ul><p>Supposons que vous récupériez des mails dans un fil de discussion, ainsi que des courriels sémantiquement liés à celui-ci. Par exemple, si quelqu’un écrit « Comment avez-vous pu gâcher cela ? », vous ne voulez pas d’exemples sémantiquement liés à « gâcher », vous voulez des documents sémantiquement liés au gâchis (« cela »). Vous devez donc combiner différents types de raisonnement, ce qu’il est difficile de faire dans une base de données vectorielle.</p><h2 class=\"wp-block-heading\" id=\"h-les-base-de-donnees-vectorielles-une-necessite\"><strong>Les base de données vectorielles – une nécessité ?</strong></h2><p>Malgré son entraînement poussé, GPT-4 peut ne pas reconnaître certains éléments spécifiques au contexte. Pour y parvenir, la solution consiste donc à ajouter des documents pertinents au contexte : lorsqu’un utilisateur envoie une requête, les documents qui lui sont les plus similaires sont récupérés et ajoutés au contexte du LLM.</p><p>C’est là que le rôle d’une base de données vectorielle devient crucial.</p><p>Les bases de données vectorielles permettent une recherche rapide des similarités dans de très grands ensembles de données.</p><p>Une base de données vectorielle repose sur un index vectoriel pour organiser et rechercher rapidement les documents.</p><p>En plus de l’index, la base de données fournit toutes les fonctionnalités d’une base de données classique. Ces fonctionnalités ont un coût, et il peut être judicieux de se contenter d’utiliser l’index au lieu de la base de données complète. </p><p>Pour les applications LLM, recourir à des index vectoriels peut simplifier l’architecture par rapport aux bases de données vectorielles complètes en attachant les vecteurs au stockage déjà existant. Le choix entre index et bases de données dépend des besoins spécifiques, de l’infrastructure existante et des exigences plus larges de l’entreprise.</p><h2 class=\"wp-block-heading\" id=\"h-utiliser-une-base-de-donnees-vectorielles-complete-ou-uniquement-des-index-vectoriels-nbsp\"><strong>Utiliser une base de données vectorielles complète ou uniquement des index vectoriels ? </strong></h2><p>Les bases de données vectorielles sont utiles lorsque l’on a besoin de toutes les fonctionnalités d’une base de données complète, et quand une ou plusieurs des conditions suivantes sont réunies :</p><ul class=\"wp-block-list\"><li>Vous avez un besoin spécifique de travailler avec des données vectorielles à grande échelle. </li><li>Vous créez une application autonome spécialement conçue pour les vecteurs</li><li>Vous ne prévoyez pas d’utiliser vos données stockées dans d’autres types d’applications.</li></ul><p>Les index vectoriels sont utiles lorsqu’on a besoin uniquement d’un index auquel on va pouvoir rajouter les opérations spécifiques au cas d’usage envisagé (ce qui donnera une solution plus rapide d’exécution), et que l’une ou plusieurs des conditions suivantes sont réunies : </p><ul class=\"wp-block-list\"><li>Vous ne voulez pas faire confiance à une nouvelle technologie pour le stockage de vos données</li><li>Votre stockage existant est facile d’accès depuis Python.</li><li>Votre recherche de similarité n’est qu’une capacité parmi d’autres besoins de BI et de bases de données plus vastes. </li><li>Vous avez besoin de la possibilité d’attacher des vecteurs (utilisés pour indexer) aux documents existants.</li><li>Vous avez besoin d’une façon unifiée de traiter les pipelines pour votre équipe d’ingénierie des données.</li><li>Vous avez besoin de structures d’index et de graphes sur les données pour vous aider dans vos <a href=\"https://github.com/pathwaycom/llm-app\">applications LLM</a> et avoir des pipelines pour vos LLM en production. </li><li>Vous avez besoin d’une sortie augmentée ou d’un contexte augmenté provenant d’autres sources</li><li>Vous voulez créer des règles à partir de votre corpus qui peuvent s’appliquer à vos données transactionnelles.</li></ul><figure class=\"wp-block-table\"><table><tbody><tr><td><strong>Zoom sur les bases de données vectorielles</strong><br><br>Une base de données vectorielle stocke les données sous forme de vecteurs numériques dans un espace de coordonnées. C’est avec ces coordonnées que seront calculées les similarités entre les documents. <br><br>Les vecteurs les plus proches représentent les points de données les plus similaires. Le choix de la similarité (cosinus, Jaccard, etc.) est donc important car c’est la similarité qui déterminera les documents retournés lors d’une recherche.<br><br>Contrairement aux bases de données relationnelles, les bases de données vectorielles sont optimisées pour les recherches de similarités plutôt que pour les requêtes ou transactions complexes. L’extraction de vecteurs similaires prend quelques millisecondes au lieu de quelques minutes, même pour des milliards de points de données.<br><br>Les bases de données vectorielles construisent des index pour interroger efficacement les vecteurs en fonction de leur proximité. Cette méthode est quelque peu analogue à celle utilisée par les moteurs de recherche textuelle pour indexer les documents en vue d’une recherche rapide.</td></tr></tbody></table></figure><h2 class=\"wp-block-heading\" id=\"h-simplifier-l-architecture-tout-en-ameliorant-le-contexte\"><strong>Simplifier l’architecture tout en améliorant le contexte</strong></h2><p>Une solution comme <a href=\"https://github.com/pathwaycom/pathway\" target=\"_blank\" rel=\"noreferrer noopener\">Pathway</a> s’adapte automatiquement aux changements et constitue ainsi un outil efficace et performant pour l’indexation de documents en temps réel et la réponse aux requêtes.</p><p>Une fois que le corpus est pré-traité et l’index créé, Pathway détecte automatiquement tout changement dans le répertoire des documents et met à jour l’index vectoriel en conséquence.</p><p>Cette réactivité en temps réel garantit que les réponses de l’application sont toujours basées sur les informations les plus récentes et les plus pertinentes disponibles. </p><p>L’architecture de l’application <a href=\"https://github.com/pathwaycom/llm-app\">LLM App</a> de Pathway repose sur le stockage de documents existant dans l’entreprise – aucune base de données vectorielle n’est nécessaire, grâce à son index vectoriel intégré en mémoire, qui s’adapte automatiquement aux volumes de requêtes, et peut-être persistant en cas de besoin.</p><p>Elle réduit également la complexité et les coûts de l’infrastructure, tout en garantissant la synchronisation avec le corpus de documents.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\"><strong>Conclusion</strong></h2><p>La recherche vectorielle offre aux développeurs de nouvelles possibilités. Au fur et à mesure que les modèles et les techniques s’améliorent, il faudra désormais s’attendre à ce que les bases de données vectorielles ou les index vectoriels fassent partie intégrante de la stack d’applications.</p></div>"},
{"url": "https://larevueia.fr/fine-tuner-chatgpt-grace-a-lapi-dopenai/", "title": "Fine-tuner ChatGPT grâce à l’API d’OpenAI", "author": "Ilyes Talbi", "date": "\n23 août 2023\n", "content": "<div class=\"entry-content\"><p>OpenAI a rendu possible le fine tuning de ChatGPT, via la version GPT-3.5, en août 2023.</p><p>Dans cet article je t’explique tout ce que tu dois savoir et je t’offre même un petit notebook Google colab à la fin pour que tu puisses le faire toi même.</p><p>Avant de rentrer dans le vif du sujet, je vais reprendre les bases, expliquer ce qu’est le fine-tuning et quand est-ce qu’il sera utile dans ce cas là.</p><p>Je donnerais des infos sur le pricing de l’API de ChatGPT pour cette partie (je te rassure c’est pas très cher ahah).</p><p>Ensuite je te donne le code python pour :</p><ul class=\"wp-block-list\"><li><strong><em>préparer ton dataset</em></strong></li><li><strong><em>fine-tuner ChatGPT sur ce dataset</em></strong></li><li><strong><em>utiliser ton modèle</em></strong></li></ul><h2 class=\"wp-block-heading\">Ce qu’il faut savoir</h2><p>Avant de commencer le fine-tuning du modèle, je vais expliquer ce que c’est, quand est-ce qu’il est utile. Je parlerais aussi des spécificités liées à l’API de ChatGPT et de son pricing.</p><h3 class=\"wp-block-heading\">Qu’est-ce que le fine-tuning et quand est-ce utile ?</h3><p>En <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, le fine tuning fait référence à une technique où un modèle pré-entraîné sur une grande base de données est ensuite légèrement réentraîné (ou affiné) sur un ensemble de données plus petit et spécifique à une tâche donnée.</p><p>Cette méthode est particulièrement utile lorsque l’on dispose de peu de données pour une tâche spécifique, car elle permet de bénéficier des connaissances générales acquises par le modèle lors de son entraînement initial sur une grande base de données.</p><p>Dans le cas de ChatGPT et des LLM en général, le fine tuning sera utile dans les cas où le prompting ne suffit pas et où le modèle a besoin de plus de connaissances spécifiques.</p><p>OpenAI précise que le fine-tuning doit rester la dernière option, lorsque le prompting classique n’a pas suffit.</p><h3 class=\"wp-block-heading\">Combien faut-il de données ?</h3><p>Cette question est important, malheureusement je n’ai pas de réponse.</p><p>Ni moi ni personne d’ailleurs, il y a un gros débat dans la communauté des chercheurs en deep learning sur les quantités de données necéssaires pour le fine tuning d’un modèle.</p><p>OpenAI fixe à 10 le nombre minimal d’exemples (un exemple est une paire question – réponse), mais suggère de donner entre 50 et 100 paires question / réponse pour avoir de meilleurs résultats.</p><h3 class=\"wp-block-heading\">Pricing de l’API pour le fine-tuning</h3><p>Voici le pricing donné par OpenAI sur son site :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-1024x279.png\" alt=\"Fine-tuner ChatGPT grâce à l'API d'OpenAI\" class=\"wp-image-8548\" style=\"width:640px;height:174px\" width=\"640\" height=\"174\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-1024x279.png 1024w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-300x82.png 300w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-768x209.png 768w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-1536x419.png 1536w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45.png 1600w\" sizes=\"auto, (max-width: 640px) 100vw, 640px\"></figure></div><p>Une époque d’entraînement coûte 0.008$ pour 1000 tokens (environ 750 mots).</p><p>Donc un entraînement sur un dataset de 75000 mots (environ 100k tokens), couterait autour de 0,80$ par époque. Pour commencer à avoir des résultats on va faire 3 époques en moyenne ce qui fait 2,40$.</p><p>Il faut remarquer aussi que le coût d’inférence est environ 2 fois plus cher sur un modèle fin-tuné que sur le modèle de base.</p><p>OpenAI propose des outils qui permettent d’évaluer les coûts de fine-tuning et d’inférence sur ces modèles.</p><h2 class=\"wp-block-heading\">Fine-tuner ChatGPT via Python et l’API d’OpenAI</h2><p>Maintenant qu’on connaît le principe du fine-tuning et les spécificités introduites par OpenAI pour ChatGPT, on peut rentrer dans le vif du sujet.</p><h3 class=\"wp-block-heading\">Installation et import des librairies</h3><p>Pour que ça soit plus simple je te conseille d’utiliser Google Colab. Mais tous les codes proposés fonctionnent en local.</p><p>On commence par installer la librairie d’OpenAI puis importer le module :</p><pre class=\"wp-block-code\"><code>!pip install openai\nimport openai</code></pre><h3 class=\"wp-block-heading\">Setup de la clé API</h3><p>Maintenant, il faut se rendre sur son espace perso OpenAI pour générer une clé API, et la copier-coller ici :</p><pre class=\"wp-block-code\"><code>openai.api_key = \"VOTRE_CLE_API\"</code></pre><p>Tu peux générer une clé API <a href=\"https://platform.openai.com/\">ici</a> en allant dans « Personal » puis « View API keys ».</p><p>Sur l’espace perso on peut aussi contrôler la facturation et fixer des limites de budget. Je conseille de le faire au cas où tu ferais une erreur dans ton code.</p><h3 class=\"wp-block-heading\">Préparation du dataset</h3><p>On va maintenant préparer notre dataset.</p><p>Pour cela il faut 2 choses :</p><ul class=\"wp-block-list\"><li><strong><em>créer un message system qui permet de définir le rôle de l’assistant</em></strong></li><li><strong><em>créer des paires de questions réponses</em></strong></li></ul><p>Pour le message system il suffit de décrire l’assistant que l’on souhaite au final, OpenAI donne l’exemple suivant :</p><pre class=\"wp-block-code\"><code>Marv is a factual chatbot that is also sarcastic.</code></pre><p>En ajoutant les paires questions / réponses le fichier d’entraînement doit ressembler à ça :</p><pre class=\"wp-block-code\"><code>{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n\n{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n\n{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}</code></pre><p>Il faut le mettre dans un fichier .txt avec un exemple par ligne.</p><p>On change ensuite l’extension en .jsonl .</p><p>Donc le fichier de data doit être au format json lines (.jsonl), avec un exemple par ligne.</p><p>Je rappel qu’il faut au minimum 10 exemples.</p><p>J’ai appelé mon fichier « ./train.jsonl », je vérifie que mon fichier est bon en l’enregistrant sur le server d’OpenAI, ce code va me donner un id de fichier qui sera utilisé au moment de l’entraînement :</p><pre class=\"wp-block-code\"><code>openai.File.create(\n  file=open(\"./train.jsonl\", \"rb\"),\n  purpose='fine-tune'\n)</code></pre><h3 class=\"wp-block-heading\">Fine-tuner ChatGPT</h3><p>Une fois que le dataset est prêt et que l’on a notre id de fichier, on lance le fine-tuning de cette manière :</p><pre class=\"wp-block-code\"><code>openai.FineTuningJob.create(training_file=\"VOTRE_FILE_ID\", model=\"gpt-3.5-turbo\")</code></pre><p>Le fine-tuning prend un peu de temps mais le code s’execute en arrière plan sur les serveurs d’OpenAI. Tu recevras un email avec l’id du modèle une fois celui-ci entraîné.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-1024x500.png\" alt=\"Fine-tuner ChatGPT grâce à l'API d'OpenAI\" class=\"wp-image-8554\" style=\"width:662px;height:323px\" width=\"662\" height=\"323\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-1024x500.png 1024w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-300x146.png 300w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-768x375.png 768w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-1536x749.png 1536w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13.png 1600w\" sizes=\"auto, (max-width: 662px) 100vw, 662px\"></figure></div><p>Une fois le ou le(s) modèle(s) entraîné(s), on peut retrouver les informations avec ce code :</p><pre class=\"wp-block-code\"><code>openai.FineTuningJob.list(limit=10)</code></pre><h3 class=\"wp-block-heading\">Utilisation du modèle fine-tuné</h3><p>Une fois l’email reçu avec l’id de modèle (la partie avec les étoiles sera incluse dans l’email), on peut l’utiliser comme ça :</p><pre class=\"wp-block-code\"><code>completion = openai.ChatCompletion.create(\n  model=\"ft:gpt-3.5-turbo-************\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello! Descripe yourself in simple words\"}\n  ]\n)\n\nprint(completion.choices[0].message)</code></pre><p>Voilà, tu sais maintenant comment fine-tuner ChatGPT, j’espère que tu vas pouvoir créer des choses intéressantes, n’hésite pas à me contacter sur <a href=\"https://www.linkedin.com/in/ilyes-talbi/\" target=\"_blank\" rel=\"noreferrer noopener\">Linkedin</a> si besoin.</p><p>Et comme promis, voici le lien du <a href=\"https://colab.research.google.com/drive/1ZA1RrHJc8B3ighY57mdaQHKFI4weW5P9?usp=sharing\">Colab</a>.</p></div>"},
{"url": "https://larevueia.fr/api-midjourney/", "title": "Comment utiliser l’API de Midjourney avec Python ?", "author": "Ilyes Talbi", "date": "\n4 mai 2024\n", "content": "<div class=\"entry-content\"><p>Dans cet article je vous explique comment utiliser l’API de Midjourney dans vos codes Python grâce au service <a href=\"https://www.mymidjourney.ai/\">MyMidjourney</a>.</p><p>La génération d’images est devenue en quelques mois une des techniques les plus performantes et abouties en <a href=\"https://larevueia.fr/introduction-a-lintelligence-artificielle-generative/\">IA générative</a>. Son principe est simple : transformer un texte (ou un prompt) en image.</p><p>De nombreux outils sont disponibles sur le marché, comme Dalle-3, Stable diffusion ou encore Leonardo. Mais le plus performant et impressionnant aujourd’hui est de loin Midjourney.</p><p>La plupart des outils mentionnés sont disponibles sous forme d’API faciles à intégrer en Python. Dalle-3 via la librairie <a href=\"https://pypi.org/project/openai/0.26.5/\">openai</a>. De même stable diffusion et Leonardo sont disponibles sans problème avec des API officielles.</p><p>Midjourney est utilisable exclusivement sur Discord et il n’y a ni d’API ni de web app accessible pour cet outil. Une stratégie assez curieuse de la part des fondateurs de Midjourney mais qui a quand même l’air de bien payer pour le moment.</p><p>Certains services ont émergés pour résoudre ce problème et proposent des API non-officielle de Midjourney qui sont codées à l’aide de bot qui permettent l’automatisation de l’utilisation de Discord.</p><h2 class=\"wp-block-heading\">Fonctionnement de l’API de Midjourney</h2><p>L’API de Midjourney proposée par MyMidjourney fonctionne via l’automatisation de tâches sur la plateforme Discord.</p><p>Lorsqu’une requête est envoyée c’est le comportement d’un utilisateur de Midjourney qui est simulé. Exactement comme si quelqu’un tapait sur Discord la requête « <em><strong>/imagine prompt</strong></em>« .</p><p>Il faut ensuite simuler le fait d’appuyer sur un des boutons de l’UI :</p><ul class=\"wp-block-list\"><li>U1, U2, U3, U4, pour upscaler une des images</li><li>V1, V2, V3, V4, pour faire varier une des images</li></ul><p>Une fois que ces étapes sont réalisées il ne reste plus qu’à récupérer le lien de l’image et la télécharger.</p><h2 class=\"wp-block-heading\">Pricing de l’API de Midjourney</h2><p>La tarification de MyMidjourney offre aux utilisateurs une gamme de plans adaptés à leurs besoins, avec des fréquences de paiement mensuelles ou annuelles.</p><p>Le Plan Standard à 30 $ par mois fournit un point de départ complet pour explorer l’API de Midjourney, offrant des capacités de génération d’images complètes avec jusqu’à 100 générations par mois, un processus d’installation facile et des instructions d’utilisation claires.</p><p>Pour ceux qui ont des besoins plus importants pour l’API de Midjourney, le Plan Pro à 45 $ par mois débloque des fonctionnalités avancées telles que des générations illimitées, la possibilité d’utiliser son propre compte Discord/Midjourney, et la gestion de plusieurs comptes pour une meilleure gestion.</p><p>MyMidjourney offre la possibilité d’avoir un serveur dédié qui offre un service prioritaire avec une infrastructure dédiée, un support rapide et efficace, et des files d’attente de traitement plus rapides pour des générations d’images accélérées.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"692\" src=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-1024x692.png\" alt=\"pricing de l'API de Midjourney\" class=\"wp-image-8741\" style=\"width:771px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-1024x692.png 1024w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-300x203.png 300w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-768x519.png 768w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-1250x845.png 1250w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02.png 1265w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Les utilisateurs peuvent choisir d’utiliser leur propre compte Midjourney ou de bénéficier de l’assistance de MyMidjourney pour en configurer un. Il convient de noter que des frais supplémentaires s’appliquent lorsque plusieurs comptes Discord sont liés au système.</p><p>Enfin, les quotas de génération d’images varient en fonction du plan Midjourney de l’utilisateur lors de la liaison, avec une limite de 600 générations par mois dans le cas contraire.</p><h2 class=\"wp-block-heading\">Utilisation de l’API de Midjourney avec Python</h2><p>Vous allez avoir besoin d’une clé API pour lancer des requêtes sur MyMidjourney. Il faudra pour cela créer votre compte sur <a href=\"https://www.mymidjourney.ai/\" rel=\"nofollow\">leur site</a>. Puis cliquer sur votre image de profil en haut à droite, puis « Setup » :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"237\" height=\"198\" src=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.27.06.png\" alt=\"Rubrique setup MyMidjourney\" class=\"wp-image-8739\" style=\"width:237px;height:auto\"></figure></div><p>Une fois dans la page setup vous trouverez la rubrique « Your MyMidjourney Token », c’est votre clé API. Copiez-là et garder la secrète (dans un fichier .env de préférence) :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"513\" src=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-1024x513.png\" alt=\"Votre clé API pour l'API de Midjourney\" class=\"wp-image-8738\" style=\"width:604px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-1024x513.png 1024w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-300x150.png 300w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-768x385.png 768w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32.png 1053w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Comme évoquer à la première partie, la génération d’une image se fait en plusieurs étapes. Ces étapes correspondent à plusieurs endpoints qu’il faut appeler un par un :</p><ul class=\"wp-block-list\"><li>Le premier permet de lancer la génération de l’image :<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/imagine</li><li>Il prend en entrée un prompt et nécessite votre clé API</li><li>Il vous renverra un id de génération qu’il faut conserver</li></ul></li><li>Le second endpoint permet de vérifier le status de la génération :<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/message/{message_id}</li><li>Il prend en entrée un message ID qui correspond à l’ID de la génération obtenu après l’appel du premier endpoint, et nécessite une clé API aussi</li><li>Ils vous renverra les informations sur le status de la génération (en attente, en cours, échec ou terminée)</li></ul></li><li>Le troisième endpoint permet de simuler un clic comme lorsque l’on utilise Midjourney via Discord :<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/button</li><li>Il prend en entrée le message id et le nom du bouton sur lequel on veut cliquer</li><li>Il renverra une réponse de status</li></ul></li><li>Enfin, le dernier endpoint de l’API de Midjourney permet de récupérer l’URL de l’image générée<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/message/{message_id}</li><li>Il prend en entrée le message id et renvoi l’URL de l’image générée</li></ul></li></ul><p>Pour coder ça en python, on commence par les imports et définir les liens des endpoints :</p><pre class=\"wp-block-code\"><code>import requests\nimport time\n\n# Constants\nGENERATION_API_URL = \"https://api.mymidjourney.ai/api/v1/midjourney/imagine\"\nRESULTS_API_URL = \"https://api.mymidjourney.ai/api/v1/midjourney/message/\"\nBUTTON_API_URL = \"https://api.mymidjourney.ai/api/v1/midjourney/button\"\n</code></pre><p>On va maintenant définir le header qui contient la clé API une bonne fois pour toutes :</p><pre class=\"wp-block-code\"><code>AUTHORIZATION_TOKEN = \"VOTRE CLÉ pour l'API de Midjourney\"\n# Headers for requests\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": AUTHORIZATION_TOKEN\n}</code></pre><p>On écrit aussi, une bonne fois pour toutes, la fonction qui permet d’appeler les différents endpoints :</p><pre class=\"wp-block-code\"><code>def make_request(url, method='get', data=None):\n    try:\n        if method == 'post':\n            response = requests.post(url, json=data, headers=HEADERS)\n        else:\n            response = requests.get(url, headers=HEADERS)\n        response.raise_for_status()\n        print(f\"Request successful: {response.json()}\")\n        return response.json()\n    except requests.exceptions.RequestException as e:\n        print(f\"Request error: {e}\")\n        return None</code></pre><p>Les appels des différents endpoints sont faits de cette manière :</p><pre class=\"wp-block-code\"><code># Lancer la génération\ndef launch_generation(prompt):\n    data = {\"prompt\": prompt}\n    response = make_request(GENERATION_API_URL, 'post', data)\n    if response:\n        print(f\"Request successful: {response}\")\n        return response.get(\"messageId\")\n    else:\n        print(\"Request failed\")\n        return None\n\n# Récupérer de le status de génération\ndef get_status_from_message_id(message_id):\n    url = RESULTS_API_URL + message_id\n    response = make_request(url)\n    if response:\n        print(f\"Request successful: {response}\")\n        return response.get(\"status\")\n    else:\n        print(\"Request failed\")\n        return None\n\n# Cliquer sur un bouton\ndef click_button(message_id, button):\n    data = {\n        \"messageId\": message_id,\n        \"button\": button\n    }\n    response = make_request(BUTTON_API_URL, 'post', data)\n    if response:\n        print(f\"Request successful: {response}\")\n        return response.get(\"messageId\")\n    else:\n        print(\"Request failed\")\n        return None\n\n# Récupérer l'URL de l'image\ndef get_image_from_message_id(message_id):\n    url = RESULTS_API_URL + message_id\n    response = make_request(url)\n    if response:\n        print(f\"Request successful: {response}\")\n    else:\n        print(\"Request failed\")\n    return response.get(\"uri\") if response else None</code></pre><p>Comme l’API de Midjourney n’a pas de webhook, on doit utiliser des boucles while et des time.sleep pour attendre la fin de chaque étape, j’ai décidé de le coder de cette manière :</p><pre class=\"wp-block-code\"><code>def generate_image_my_midjourney(prompt):\n\n    prompt += \" --v 6.0 --ar 16:9\"\n    message_id = launch_generation(prompt)\n    if not message_id:\n        return \"Failed to launch image generation\"\n\n    # Wait for the status to be 'DONE'\n    while True:\n        status = get_status_from_message_id(message_id)\n        if status == \"DONE\":\n            break\n\n    # Click the button and wait for the new message ID\n    message_id_after_click = None\n    while not message_id_after_click:\n        message_id_after_click = click_button(message_id, \"U1\")\n\n    print(\"Sleeping 10 seconds\")\n    time.sleep(10)\n    # Retrieve the final image URI\n    uri = None\n    while not uri:\n        uri = get_image_from_message_id(message_id_after_click)\n\n    return uri</code></pre><p>À la première ligne j’ajoute :  » –v 6.0 –ar 16:9″ c’est la syntaxe qui permet de spécifier des paramètres à l’API de Midjourney pour la génération.</p><p>Ici par exemple je lui demande d’utiliser Midjourney V6 et de générer des images avec un ratio de 16:9.</p><p>Pour générer une image on va simplement appeler cette dernière fonction avec le prompt voulu et on récuperera en quelques secondes l’output sous forme d’URL :</p><pre class=\"wp-block-code\"><code>generate_image_my_midjourney(\"Mbappé inside the Parc des Princes\")</code></pre><p>Si vous avez des problèmes de blocage de prompt trop régulièrement, vous pouvez mettre à jour la liste des mots bannis par l’API de Midjourney avec cette syntaxe :</p><pre class=\"wp-block-code\"><code>import requests\n\n# Bearer token for authorization\nbearer_token = \"VOTRE CLÉ API\"\n\n# URL for the API endpoint\nurl = 'https://api.mymidjourney.ai/api/v1/discord/banwords/save'\n\n# Headers including the authorization token\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {bearer_token}'\n}\n\n# Liste des mots que vous voulez bannir, la liste peut être vide comme ici\nban_words = [\n]\n\n# Data payload to be sent\npayload = {\n    'list': ban_words\n}\n\n# Making the POST request\nresponse = requests.post(url, json=payload, headers=headers)\n\n# Check if the request was successful\nif response.status_code == 200:\n    print(\"Ban list updated successfully!\")\n    print(\"Updated list:\", response.json())\nelse:\n    print(\"Failed to update ban list.\")\n    print(\"Status Code:\", response.status_code)\n    print(\"Response:\", response.text)\n</code></pre><h2 class=\"wp-block-heading\">Conclusion</h2><p><em>Disclaimer : l’API de Midjourney que j’ai présenté ici n’est pas officielle et pensez à vérifier que les conditions d’utilisation de Midjourney et Discord vous permettent de l’utiliser.</em></p><p>Cette API est assez performante globalement et le pricing est plutôt raisonnable lorsque l’on compte l’utiliser assez régulièrement.</p><p>Je vous ai montré uniquement la génération d’image dans cet article mais sachez que toutes les fonctionnalités de Midjourney sont proposées sous forme d’API, comme l’inpainting par exemple.</p><p>L’expérience de developpement n’est pas optimale puisqu’on n’a pas de webhook disponible et on doit multiplier les appels vers les différents endpoints. Mais au final, quand on comprend le rôle de chaque endpoint on s’en sort plutôt bien.</p></div>"},
{"url": "https://larevueia.fr/les-cas-dusages-de-lia-dans-limmobilier/", "title": "Les cas d’usages de l’IA dans l’immobilier", "author": "Ilyes Talbi", "date": "\n11 mars 2025\n", "content": "<div class=\"entry-content\"><p>L’intelligence artificielle transforme en profondeur le secteur immobilier, de l’estimation d’un bien jusqu’à l’aménagement urbain.</p><p>L’adoption de l’IA dans l’immobilier s’accélère. Selon JLL, seules 7 % des sociétés immobilières utilisaient l’IA en 2024, on atteindrait <strong>10 % d’ici fin 2025</strong>. (<a href=\"https://www.flatsy.fr/blog/intelligence-artificielle-immobilier/\" target=\"_blank\" rel=\"noreferrer noopener\">Flatsy</a>).</p><p>L’objectif de cet article est de proposer un tour d’horizon des principaux usages de l’IA dans l’immobilier. On proposera des exemples concrets, les tendances actuelles et les perspectives d’avenir.<a href=\"https://www.flatsy.fr/blog/intelligence-artificielle-immobilier/#:~:text=Au%20cours%20des%20cinq%20derni%C3%A8res,d%E2%80%99ici%20fin%202025\" target=\"_blank\" rel=\"noreferrer noopener\"></a></p><h2 class=\"wp-block-heading\" id=\"h-evaluation-et-estimation-des-prix-des-biens\">Évaluation et estimation des prix des biens</h2><p>Évaluer précisément la valeur d’un bien immobilier est un défi complexe. L’IA apporte des solutions <strong>d’estimation automatisée</strong> très performantes. En analysant une multitude de données (ventes récentes, localisation, caractéristiques du bien, tendances du marché), les algorithmes peuvent fournir des estimations de prix <em>fiables et objectives</em>​.</p><p>Ces systèmes surpassent souvent l’expertise humaine en précision. Grâce à leur capacité à croiser des centaines de critères sans biais d’interprétation​, tout en optimisant le temps d’analyse.</p><p>Aux États-Unis, la plateforme <a href=\"https://www.zillow.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Zillow</a> utilise un <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">réseau de neurones</a> (l’outil <em>Zestimate</em>) pour estimer la valeur des maisons en tenant compte de la saisonnalité et des tendances locales​.</p><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"494\" src=\"https://larevueia.fr/wp-content/uploads/2025/03/zillow.webp\" alt=\"L'IA dans l'immobilier : la plateforme Zillow\" class=\"wp-image-8898\" srcset=\"https://larevueia.fr/wp-content/uploads/2025/03/zillow.webp 800w, https://larevueia.fr/wp-content/uploads/2025/03/zillow-300x185.webp 300w, https://larevueia.fr/wp-content/uploads/2025/03/zillow-768x474.webp 768w\" sizes=\"auto, (max-width: 800px) 100vw, 800px\"><figcaption class=\"wp-element-caption\">L’IA dans l’immobilier : la plateforme Zillow</figcaption></figure><p>Les performances de prédictions se sont nettement améliorées sur les dernières années. L’erreur médiane n’est plus que d’environ <strong>2,4 %</strong> pour les biens en vente (et ~7,5 % hors marché)​. L’écart étant dû principalement à la quantité d’accès aux data pour un bien donné.</p><p>En France, des fintechs comme Homiwoo ou des sites d’annonces intègrent également des modèles prédictifs afin d’aider agents et propriétaires à fixer un prix <em>« juste et compétitif »</em> tout en anticipant l’évolution du marché​.</p><p>De plus, l’IA ne se contente pas d’une photo à l’instant <em>t</em>. Elle peut réaliser des <strong>analyses prédictives</strong> pour projeter la valeur d’un bien dans le futur selon divers scénarios économiques​.</p><p>Cette capacité de <em>forecast</em> est précieuse pour les investisseurs qui fondent leurs décisions sur le long terme.</p><p>L’estimation immobilière par IA va continuer de gagner en finesse à mesure que de nouvelles sources de données sont exploitées (images satellite, données socio-économiques en temps réel, etc.). Les professionnels anticipent des évaluations instantanées toujours plus précises et personnalisées, tout en restant vigilants sur la qualité des données pour éviter les biais algorithmiques.</p><h2 class=\"wp-block-heading\" id=\"h-assistance-administrative-pour-les-transactions-immobilieres\">Assistance administrative pour les transactions immobilières</h2><p>Les transactions immobilières impliquent de nombreuses étapes administratives et juridiques où l’IA peut apporter rapidité et fiabilité. Par exemple, des algorithmes de traitement de documents peuvent vérifier automatiquement les contrats, détecter des anomalies ou incohérences et ainsi prévenir les fraudes​.</p><p>De même, un système d’IA saura signaler une clause manquante ou un paiement suspect dans un compromis de vente, évitant des erreurs coûteuses.</p><p>Par ailleurs, certaines solutions analysent les dossiers des acheteurs/locataires (pièces d’identité, bulletins de salaire, etc.) pour repérer d’éventuels faux documents, ce qui sécurise les transactions en amont​.</p><p>L’IA permet aussi la <strong>génération automatique de documents juridiques</strong>. À partir de formulaires, le système peut rédiger un bail ou un contrat conforme aux normes instantanément.</p><p>On peut s’attendre à ce que d’ici quelques années, finaliser une transaction devienne beaucoup plus rapide et transparent. L’IA prenant en charge la vérification et la rédaction, et les <em>smart contracts</em> l’exécution sécurisée.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-l-immobilier-pour-le-marketing-et-la-recherche-de-clients\">L’IA dans l’immobilier pour le marketing et la recherche de clients</h2><p>Attirer des prospects et les convertir en clients est un domaine où l’IA excelle grâce à la personnalisation.</p><p>Les agences et portails immobiliers exploitent l’IA pour <em>générer des leads qualifiés</em>, cibler leur publicité et mieux cerner les préférences des acheteurs :</p><ul class=\"wp-block-list\"><li><strong>Chatbots et assistants virtuels 24/7 :</strong> Sur les sites d’agences, des chatbots conversationnels accueillent les visiteurs en continu. Ils répondent instantanément aux questions fréquentes (disponibilité d’un bien, organiser une visite, etc.) et collectent au passage des informations sur le prospect.<br><br>Ainsi, un visiteur intéressé par un appartement pourra obtenir les premiers renseignements via le bot. Enregistrant au passage ses critères de recherche.<br><br>Si le prospect est qualifié (budget, projet sérieux), le chatbot peut le rediriger automatiquement vers une prise de rendez-vous avec un agent. Ces assistants virtuels font gagner du temps aux professionnels tout en offrant une réactivité appréciée des clients.</li><li><strong>Analyse des comportements en ligne</strong>. Chaque clic, chaque bien consulté sur un site immobilier est une donnée que l’IA analyse pour évaluer un internaute​.<br><br>Si un utilisateur passe beaucoup de temps sur des annonces de studios dans tel quartier, le système peut en conclure ses critères favoris (type de bien, localisation) et adapter en temps réel le contenu affiché pour lui (biens similaires, promotions ciblées)​.<br><br>Cette compréhension fine du parcours client permet d’orienter le prospect vers les offres les plus pertinentes, augmentant les chances de conversion.</li><li><strong>Segmentation et ciblage marketing</strong>. L’IA aide à segmenter automatiquement la base de prospects en groupes homogènes selon leur profil. Par exemple par budget, type de bien recherché, ou localisation souhaitée.<br><br>Chaque segment reçoit alors un message publicitaire adapté (luxe pour les hauts budgets, appartements familiaux pour les jeunes parents, etc.). Cette personnalisation des campagnes maximise leur impact, avec des relances <em>sur-mesure</em> pour chaque catégorie de client​.<br><br>De plus, en croisant ces segments avec des données externes (démographie, intention d’achat détectée sur les réseaux sociaux), l’IA peut aider à <strong>cibler la publicité</strong> vers les personnes ayant le plus fort potentiel (par exemple, identifier dans une zone les locataires ayant 90 % de chances de vouloir acheter sous peu, et leur diffuser une annonce spécifique).</li><li><strong>Recommandations personnalisées de biens</strong>. Les mêmes techniques de machine learning permettent de suggérer automatiquement à chaque prospect des biens susceptibles de lui plaire. C’est un atout marketing pour garder l’attention de l’utilisateur et l’amener à concrétiser. <em>(Nous détaillons ce point plus loin.)</em></li><li><strong>Automatisation des relances commerciales :</strong> L’IA optimise aussi le <em>timing</em> et le contenu des communications marketing. Elle peut déterminer <strong>le meilleur moment d</strong>‘<strong>envoi d’email</strong> à un prospect en se basant sur ses habitudes d’ouverture des messages​.<br><br>Un système intelligent va programmer l’envoi d’une nouvelle annonce le matin si c’est à cette heure que le client consulte ses mails, améliorant ainsi le taux d’engagement​.<br><br>De même, l’IA peut générer automatiquement le texte d’un mail ou d’une annonce en adaptant le ton et les arguments aux intérêts perçus du client (certains outils d’IA générative savent déjà rédiger des annonces immobilières attrayantes ou créer des visuels de <em>home staging</em> virtuel à partir de photos).</li></ul><p>L’IA dans l’immobilier appliquée au marketing porte ses fruits. Elle améliore l’expérience utilisateur et permet aux professionnels d’augmenter à la fois le taux de conversion et la fidélisation de leur clientèle​.</p><p>En pratique, cela se traduit par plus de contacts qualifiés générés. Un suivi plus réactif (grâce aux bots). Des campagnes publicitaires au ROI accru. Une agence qui adopte ces outils peut vendre plus vite<em>,</em> moins cher (moins de coûts marketing gaspillés hors cible).</p><p>À l’avenir, on peut s’attendre à une <strong>hyper-personnalisation</strong> du marketing immobilier. Les plateformes pourront anticiper les besoins des clients avant même qu’ils les expriment (grâce au <em>machine learning</em> prédictif).</p><p>L’IA générative pourrait créer des visites virtuelles sur mesure. Le client pourrait demander à voir le bien avec une décoration différente ou un aménagement optimisé, et obtenir le visuel en temps réel.</p><p>Ces innovations garderont l’humain au centre (le conseiller immobilier reste vital pour conclure et accompagner). Mais elles doteront les professionnels d’<strong>outils efficaces</strong> pour capter et convaincre les acheteurs.</p><h2 class=\"wp-block-heading\" id=\"h-gestion-locative-optimisee-et-maintenance-predictive\">Gestion locative optimisée et maintenance prédictive</h2><p>Administrer des biens en location implique de multiples tâches répétitives et une vigilance sur l’état du patrimoine.</p><p>L’IA dans l’immobilier intervient de plus en plus pour <strong>faciliter la gestion locative</strong> au quotidien et anticiper les problèmes techniques avant qu’ils ne surviennent.</p><ul class=\"wp-block-list\"><li><strong>Sélection des locataires et gestion des dossiers</strong>. Confier l’analyse des candidatures à une IA fait gagner un temps précieux aux gestionnaires. Des outils peuvent vérifier automatiquement les pièces justificatives des candidats (bulletins de salaire, pièces d’identité, avis d’imposition…) et détecter d’éventuelles anomalies ou faux documents.<br><br>Par exemple, la startup toulousaine <a href=\"https://www.eazyrent.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">EazyRent</a> analyse grâce à l’IA l’authenticité et la cohérence des documents fournis par un candidat locataire, signalant en quelques secondes un dossier frauduleux.</li></ul><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"535\" src=\"https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1024x535.png\" alt=\"L'IA dans l'immobilier EazyRent\" class=\"wp-image-8895\" srcset=\"https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1024x535.png 1024w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-300x157.png 300w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-768x402.png 768w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1536x803.png 1536w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1250x653.png 1250w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11.png 1689w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">L’IA dans l’immobilier : la startup EazyRent</figcaption></figure><ul class=\"wp-block-list\"><li><strong>Optimisation des loyers et du taux d’occupation</strong>. Fixer le loyer “juste” est une tâche délicate. L’IA peut aider les propriétaires à déterminer le loyer optimal d’un logement en fonction de la demande en temps réel, de la saison, et des prix pratiqués dans le voisinage.<br><br>Elle peut analyser des milliers d’annonces et de baux, un algorithme pourra recommander d’ajuster légèrement le loyer à la baisse pour remplir plus vite une vacance, ou au contraire de le monter si la demande locale est forte, afin de maximiser le rendement sans perdre en compétitivité.<br><br>Ces <strong>algorithmes de yield management</strong> (inspirés de l’hôtellerie) permettent d’améliorer la rentabilité locative tout en assurant un haut taux d’occupation des biens. À grande échelle (portefeuilles de centaines de logements), ce pilotage dynamique des loyers peut augmenter sensiblement les revenus des bailleurs.</li><li><strong>Maintenance prédictive des équipements :</strong> En équipant les immeubles de capteurs (ascenseurs connectés, chaudières, compteurs intelligents…), l’IA peut surveiller en continu l’état des installations et <strong>anticiper les pannes</strong> avant qu’elles n’arrivent.<br><br>Concrètement, une plateforme IoT peut analyser la température et les vibrations d’une chaudière ; en détectant une dérive anormale par rapport aux schémas habituels, l’algorithme alerte qu’une pièce risque de lâcher sous peu.<br><br>On peut alors intervenir <em>proactivement</em>, planifier la réparation durant un créneau qui gêne le moins les occupants, et éviter la panne subite.<br><br>Des études estiment que la maintenance prédictive peut diminuer <em>jusqu’à 30 %</em> les dépenses d’entretien tout en allongeant la durée de vie des équipements (​<a href=\"https://tw3partners.fr/fr/ia-dans-la-gestion-immobiliere-optimisation-des-operations\" target=\"_blank\" rel=\"noreferrer noopener\">tw3partners.fr</a>).</li><li><strong>Automatisation des échanges courants :</strong> Outre les aspects techniques, l’IA peut seconder les gestionnaires dans la relation avec les locataires.<br><br>Un chatbot dans une résidence peut répondre aux questions basiques des locataires (procédure pour une demande de réparation, solde du compte locataire, etc.) et désengorger le standard.<br><br>De même, la gestion des <em>tickets</em> de maintenance (demandes d’intervention) peut être priorisée par IA en fonction de l’urgence et de la gravité, pour traiter d’abord les problèmes critiques (une fuite d’eau) avant un détail moins urgent (une ampoule grillée).</li></ul><p>L’IA dans l’immobilier tend à rendre la gestion locative <strong>plus réactive, plus économique et plus transparente</strong>. Les propriétaires bénéficient d’une réduction des risques et des coûts, tandis que les locataires profitent d’un meilleur service (moins d’attente et des logements en bon état).</p><p>La prochaine étape pour l’IA en gestion immobilière est l’avènement du <strong>bâtiment intelligent auto-géré</strong>. On voit déjà émerger des systèmes intégrés où l’IA pilote aussi la <strong>consommation d’énergie</strong> d’un immeuble (chauffage, climatisation, éclairage) en fonction de l’occupation réelle des locaux, ce qui peut réduire drastiquement les charges​.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-l-immobilier-pour-la-recherche-et-la-recommandation-de-biens\">L’IA dans l’immobilier pour la recherche et la recommandation de biens</h2><p>Trouver la perle rare parmi des milliers d’annonces est souvent fastidieux pour les acheteurs ou locataires. Les <strong>moteurs de recommandation intelligents</strong> viennent à la rescousse en triant et proposant automatiquement les biens susceptibles de correspondre à chaque client.</p><p>Le fonctionnement s’apparente à celui de Netflix ou Amazon, transposé à l’immobilier : des algorithmes de machine learning analysent vos critères de recherche initiaux, vos filtres appliqués, ainsi que vos interactions passées (biens consultés, sauvegardés, refusés) afin de cerner vos goûts​</p><p>À partir de là, le système <strong>suggère des biens « qui vous vont bien »</strong> : par exemple, si l’IA détecte qu’un utilisateur aime les <em>lofts très lumineux en centre-ville</em>, elle va mettre en avant de nouvelles annonces de lofts spacieux et bien exposés correspondant à ce profil​.</p><p>Ces recommandations personnalisées s’affichent sous forme de <em>« biens qui pourraient vous intéresser »</em> sur le site ou l’appli, ou sont envoyées par email/app notification.</p><p>En France, Seloger, Leboncoin, PAP et consorts développent aussi leurs algorithmes de recommandation, conscients que plus la recherche est facile et pertinente, plus l’utilisateur restera sur leur plateforme.</p><p>D’ailleurs, <strong>91 % des acquéreurs</strong> commencent leurs recherches en ligne, d’où l’importance stratégique d’une bonne recommandation pour capter la demande (chiffre <a href=\"https://www.fnaim.fr/\">FNAIM</a>, 2023).</p><p>Au-delà des portails, les agences immobilières intègrent également ces fonctionnalités dans leurs CRM. Ainsi, un agent peut recevoir des alertes de son logiciel lui indiquant qu’un nouveau bien qu’il vient de rentrer correspond à 5 clients de sa base, avec un <em>scoring</em> indiquant lesquels sont les plus “chauds”. Cela lui permet de faire une <strong>mise en relation proactive</strong> entre vendeurs et acheteurs <em>matchant</em>, accélérant les transactions.</p><p><strong>Bénéfices :</strong> Pour l’utilisateur final, ces moteurs intelligents rendent la recherche beaucoup plus efficace. Pour les professionnels, c’est un moyen d’<strong>augmenter le taux de conversion</strong> : un prospect qui reçoit rapidement des suggestions pertinentes a plus de chances de visiter puis d’acheter un bien via le service.</p><p>On constate également une augmentation du temps passé sur les sites immobiliers qui offrent de bonnes recommandations, car l’interface devient plus <em>« accrocheuse »</em> (on découvre des biens qu’on n’aurait pas cherché soi-même).</p><p>Les systèmes de recommandation continueront de gagner en sophistication. L’<strong>IA conversationnelle</strong> arrive dans la recherche immobilière. Au lieu de cocher des cases, l’utilisateur pourra bientôt dialoguer en langage naturel avec un assistant. Il pourra envoyer des requêtes comme : <em>« Je cherche une maison avec jardin dans un quartier calme, budget 400k »</em>. L’IA comprendra la demande et posera éventuellement des questions de précision, puis proposera directement une sélection.</p><p>Quoi qu’il en soit, l’objectif reste le même. Raccourcir et faciliter la rencontre entre un bien et son futur occupant, grâce à l’intelligence artificielle.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-l-immobilier-conclusion\">L’IA dans l’immobilier : conclusion</h2><p>Qu’il s’agisse d’estimer un appartement, de signer un acte de vente, de trouver un acheteur ou de gérer un parc locatif, l’intelligence artificielle s’impose progressivement à tous les étages de l’immobilier. Les exemples actuels prouvent déjà son efficacité. Précision accrue des estimations, transactions accélérées et sécurisées, marketing mieux ciblé, gestion locative proactive, expérience client enrichie, et même aide à la décision stratégique pour les urbanistes.</p><p>Les <strong>tendances actuelles</strong> montrent une adoption grandissante de ces technologies autrefois futuristes. Les <strong>perspectives futures</strong> laissent entrevoir une transformation encore plus profonde du secteur.</p><p>Bien sûr, l’IA n’est pas une panacée magique : son déploiement doit s’accompagner de <em>garanties éthiques</em> (protection des données personnelles, transparence des algorithmes) et elle ne remplacera pas la valeur ajoutée humaine là où elle est cruciale (conseil personnalisé, expertise terrain, créativité architecturale, etc.).</p><p>Néanmoins, en automatisant les tâches laborieuses et en exploitant de façon pertinente la data, l’IA libère du temps pour se concentrer sur l’essentiel.</p><p>L’avenir de l’immobilier sera sans doute <strong>hybride</strong>, alliant le meilleur de la technologie et de l’humain. Les professionnels qui sauront embrasser cette révolution numérique, tout en gardant le sens du service et de l’éthique, disposeront d’un atout décisif pour répondre aux défis de demain dans un marché immobilier de plus en plus exigeant et connecté.</p><p>L’IA ouvre l’ère de l’<strong>immobilier augmenté</strong>.</p></div>"},
{"url": "https://larevueia.fr/quelles-sont-les-applications-de-lia-dans-le-btp/", "title": "Quelles sont les applications de l’IA dans le BTP ?", "author": "Ilyes Talbi", "date": "\n22 mars 2024\n", "content": "<div class=\"entry-content\"><p>L’intelligence artificielle est en train de révolutionner énormément de métiers et d’industrie, parmi elles, l’industrie du BTP. Dans cet article, je propose une revue complète des applications de l’IA dans le BTP.</p><p>Nous verrons que l’IA peut intervenir dans différentes phases de la vie d’un projet, allant de la réponse aux appels d’offres à la maintenance des machines et bâtiments.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-le-btp-pour-la-conception-et-l-etude-de-faisabilite\">L’IA dans le BTP pour la conception et l’étude de faisabilité</h2><p>Dans l’univers exigeant de la construction, la précision des études de faisabilité est primordiale. Ces évaluations préliminaires déterminent la viabilité d’un projet en analysant des éléments tels que les projections financières, la disponibilité des ressources, l’analyse du site et la conformité réglementaire.</p><p>Un manquement, même mineur, dans ces études peut engendrer des dépassements de coûts, des retards et d’autres complications.</p><p>L’intelligence artificielle offre une solution prometteuse face à ces défis. Grâce à sa capacité à traiter d’énormes volumes de données rapidement et à reconnaître des tendances subtiles, l’IA dans le BTP augmente la précision et accélère les processus décisionnels en construction.</p><h3 class=\"wp-block-heading\" id=\"h-l-importance-de-la-precision-dans-les-etudes-de-faisabilite\">L’importance de la précision dans les études de faisabilité</h3><p>Les études de faisabilité sont le socle des projets de construction réussis, guidant les parties prenantes à travers une multitude de décisions avant le démarrage des travaux. Une étude fiable éclaire tous les aspects du projet, de la planification à l’exécution.</p><h3 class=\"wp-block-heading\" id=\"h-risques-des-etudes-imprecises\">Risques des études imprécises</h3><p>Une évaluation inexacte peut entraîner des dépassements budgétaires ou des retards :</p><ul class=\"wp-block-list\"><li>Ces dépassements surviennent lorsque les coûts réels du projet dépassent les estimations initiales. Cela peut être dû à une mauvaise évaluation des besoins en matériaux, des tarifs sous-estimés des sous-traitants, ou de la non-prévision de certains frais indirects</li><li>Les dépassements budgétaires peuvent contraindre l’équipe projet à solliciter des fonds supplémentaires, ce qui peut s’avérer difficile et parfois même compromettre la viabilité financière du projet</li><li>Les imprécisions dans l’évaluation peuvent conduire à des erreurs de planification, entraînant des retards dans le calendrier de construction. Ces retards peuvent être le résultat d’une mauvaise coordination entre les équipes, d’une insuffisance de ressources, ou de la non-prise en compte de défis spécifiques au site</li><li>Les retards peuvent engendrer des coûts additionnels, comme des pénalités contractuelles, et aussi allonger le délai de réalisation des bénéfices du projet</li></ul><p>De telles imprécisions peuvent aussi occasionner des pertes d’opportunités, des répercussions financières et nuire à la réputation des acteurs impliqués :</p><ul class=\"wp-block-list\"><li>Un projet retardé ou qui dépasse son budget peut faire manquer des opportunités de marché. Par exemple, un complexe résidentiel qui n’est pas prêt à temps pour une période de forte demande peut perdre des clients potentiels</li><li>Les retards peuvent également affecter la capacité d’une entreprise à démarrer de nouveaux projets, entravant ainsi sa croissance futur</li><li>Les retards et les dépassements budgétaires peuvent ternir la réputation des entreprises impliquées. Une mauvaise presse, des critiques négatives, ou un bouche-à-oreille défavorable peuvent décourager de futurs clients ou investisseurs de collaborer avec les acteurs concernés</li><li>À long terme, une réputation endommagée peut réduire la compétitivité de l’entreprise sur le marché</li></ul><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"526\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-1024x526.png\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8707\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-1024x526.png 1024w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-300x154.png 300w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-768x394.png 768w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-1250x642.png 1250w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt.png 1400w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><h3 class=\"wp-block-heading\" id=\"h-comment-l-ia-peut-ameliorer-le-process\">Comment l’IA peut améliorer le process ?</h3><p>L’IA, capable d’analyser rapidement de vastes ensembles de données, réduit les erreurs et améliore la précision des études.</p><p>Elle peut évaluer des données de projets précédents, identifier des tendances et des défis potentiels, offrant ainsi une vue plus complète de la viabilité d’un projet.</p><p>Grâce à l’IA, les études de faisabilité deviennent plus agiles, adaptatives et exactes, posant ainsi les fondations solides nécessaires à tout projet de construction réussi.</p><p>L’intelligence artificielle se caractérise par sa capacité à traiter et analyser de vastes quantités de données à une vitesse vertigineuse. Concrètement, cela se traduit par plusieurs avantages dans le domaine des études de faisabilité en construction :</p><ul class=\"wp-block-list\"><li><strong>Réduction des erreurs</strong> : L’IA, en utilisant des techniques comme le <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, peut détecter et corriger des anomalies dans les données, assurant ainsi que les études soient basées sur des informations fiables. Par exemple, si une donnée de coût semble anormalement élevée ou basse par rapport à des données historiques similaires, l’IA peut la signaler pour une vérification ultérieure.</li><li><strong>Analyse des données historiques</strong> : L’IA peut parcourir des années de données de projets antérieurs en un temps record. En utilisant des techniques comme le <a href=\"https://larevueia.fr/clustering-les-3-methodes-a-connaitre/\" target=\"_blank\" rel=\"noreferrer noopener\">clustering</a>, elle peut regrouper des projets similaires et identifier des tendances, comme les saisons où les coûts de matériaux augmentent ou les régions géographiques présentant des défis spécifiques.</li><li><strong>Identification des défis potentiels</strong> : Par l’analyse prédictive, l’IA peut anticiper les problèmes avant qu’ils ne surviennent. Par exemple, en analysant les données météorologiques, l’IA pourrait prévoir les risques de retards dus à des conditions climatiques défavorables.</li><li><strong>Vue d’ensemble de la viabilité</strong> : L’IA peut intégrer diverses sources de données, allant des informations de site aux réglementations locales, pour fournir une évaluation complète de la faisabilité. Des algorithmes comme l’arbre de décision peuvent être utilisés pour peser divers facteurs et déterminer le meilleur chemin à suivre pour un projet. Plus récemment, les modèles d’IA dits « multi-modaux » peuvent comprendre à la fois des données images, vidéos, audio et texte et donc comprendre la donnée de façon la plus optimale possible.</li><li><strong>Adaptabilité et agilité</strong> : L’IA est intrinsèquement adaptative. Avec des méthodes comme l’apprentissage par renforcement, elle peut s’ajuster en fonction des retours d’information, garantissant que les études de faisabilité sont constamment mises à jour et améliorées.</li></ul><h2 class=\"wp-block-heading\" id=\"h-repondre-aux-appels-d-offres-grace-a-l-ia-dans-le-btp\">Répondre aux appels d’offres grâce à l’IA dans le BTP</h2><p>Dans le secteur du BTP, répondre aux appels d’offres est une étape cruciale pour décrocher de nouveaux projets. Cependant, cette tâche peut s’avérer fastidieuse et complexe, compte tenu de la quantité d’informations à analyser et des détails à fournir.</p><p>L’intégration de l’intelligence artificielle dans ce processus se présente comme une solution innovante pour maximiser l’efficacité et la précision des réponses. Découvrons ensemble les avantages qu’elle procure.</p><h3 class=\"wp-block-heading\" id=\"h-identification-rapide-des-opportunites\"><strong>Identification rapide des opportunités</strong></h3><p>Face à l’abondance d’appels d’offres dans le secteur du BTP, distinguer les opportunités les plus pertinentes devient un véritable défi. La capacité de l’IA à analyser en profondeur et en temps réel les appels d’offres offre une solution novatrice pour résoudre ce problème. Adoptons une méthodologie en cinq étapes pour exploiter au mieux cette technologie :</p><ul class=\"wp-block-list\"><li><strong>Centralisation des sources d’appels d’offres :</strong> La première étape consiste à centraliser toutes les sources d’appels d’offres dans une seule base de données. Cela inclut les plateformes officielles, les sites spécialisés, les publications régionales et toute autre source pertinente. En créant un flux d’informations unifié, l’IA dispose d’un large éventail de données à analyser.</li></ul><ul class=\"wp-block-list\"><li><strong>Profilage de l’entreprise :</strong> Afin que l’IA comprenne et identifie les opportunités les plus appropriées, il est crucial de lui fournir un profil détaillé de l’entreprise. Cela comprend les domaines d’expertise, les projets antérieurs, la capacité de production, le personnel technique disponible, et même les préférences géographiques.</li></ul><ul class=\"wp-block-list\"><li><strong>Analyse et tri en temps réel :</strong> Grâce aux algorithmes avancés, l’IA évalue chaque appel d’offre en fonction du profil de l’entreprise. Elle vérifie la concordance entre les exigences du projet et les compétences de l’entreprise, éliminant ainsi les appels d’offres moins pertinents et mettant en avant les plus adaptés.</li></ul><ul class=\"wp-block-list\"><li><strong>Notification et visualisation :</strong> Lorsqu’un appel d’offre est identifié comme étant d’un intérêt particulier, le système peut envoyer des notifications en temps réel aux décideurs concernés. Ces notifications peuvent être accompagnées d’un tableau de bord interactif, offrant une vue d’ensemble du projet, des exigences clés et des éventuels défis à relever.</li></ul><p>La méthodologie ci-dessus, basée sur l’utilisation de l’IA, offre une approche systématique et efficace pour cibler les appels d’offres les plus pertinents dans le domaine du BTP. En intégrant cette technologie, les entreprises peuvent non seulement gagner du temps, mais aussi améliorer considérablement la qualité de leurs candidatures, augmentant ainsi leurs chances de succès.</p><div class=\"calendly-inline-widget\" data-url=\"https://calendly.com/ilyestalbi75/brainstorm\" style=\"min-width:320px;height:700px;\"></div> <script type=\"text/javascript\" src=\"https://assets.calendly.com/assets/external/widget.js\" async></script> <h3 class=\"wp-block-heading\" id=\"h-analyse-detaillee-des-documents\"><strong>Analyse détaillée des documents</strong></h3><p>Les modèles d’IA ont fait d’énormes progrès ces dernières années, en particulier dans le domaine du traitement du langage naturel (NLP – Natural Language Processing). Ces avancées permettent à l’IA d’analyser des documents complexes comme ceux des appels d’offres.</p><ul class=\"wp-block-list\"><li><strong>Analyse sémantique:</strong> Grâce au NLP, les algorithmes d’IA peuvent comprendre la signification des mots et des phrases dans un contexte donné. Cela signifie qu’ils peuvent identifier les sections d’un document qui parlent d’exigences techniques, de critères de sélection, de délais, etc., même si la terminologie ou la formulation varie d’un document à l’autre.</li></ul><ul class=\"wp-block-list\"><li><strong>Extraction d’éléments clés :</strong> Une fois que les sections pertinentes sont identifiées, l’IA peut extraire les informations essentielles. Par exemple, pour les exigences techniques, elle peut lister les spécifications précises, les normes à respecter ou les certifications requises. Pour les délais, elle peut extraire la date limite de soumission, la date de démarrage et la date d’achèvement.</li></ul><ul class=\"wp-block-list\"><li><strong>Classification et structuration :</strong> Après extraction, les informations sont classées et structurées dans une forme facilement lisible et compréhensible. Cela pourrait prendre la forme d’un tableau, d’une liste ou d’un diagramme, selon ce qui est le plus approprié.</li></ul><ul class=\"wp-block-list\"><li><strong>Comparaison avec les précédents appels d’offres:</strong> L’IA peut également comparer le nouvel appel d’offres avec ceux auxquels l’entreprise a répondu dans le passé. Cela aide à identifier les points communs, les anomalies ou les exigences inhabituelles qui pourraient nécessiter une attention particulière.</li></ul><ul class=\"wp-block-list\"><li><strong>Alertes et recommandations :</strong> En se basant sur l’analyse, l’IA peut générer des alertes pour les éléments qui semblent particulièrement exigeants ou en dehors des compétences normales de l’entreprise. Elle peut également suggérer des réponses basées sur des soumissions précédentes à des appels d’offres similaires.</li></ul><p>L’utilisation des algorithmes d’IA pour l’analyse des appels d’offres ne se limite pas à une simple lecture des documents.</p><p>Elle offre une compréhension en profondeur, permettant aux entreprises de répondre plus efficacement et avec une plus grande précision aux exigences du cahier des charges.</p><p>C’est un outil inestimable pour rester compétitif dans le monde exigeant des appels d’offres du BTP.</p><h3 class=\"wp-block-heading\" id=\"h-estimation-precise\"><strong>Estimation précise</strong></h3><p>L’un des plus grands avantages de l’IA est sa capacité à analyser d’immenses volumes de données et à en extraire des tendances, des motifs et des prédictions.</p><p>Dans le domaine du BTP, cette capacité peut être exploitée pour formuler des estimations plus précises lors de la réponse aux appels d’offres. Examinons comment cela fonctionne étape par étape.</p><ul class=\"wp-block-list\"><li><strong>Collecte et nettoyage des données :</strong> La première étape consiste à rassembler toutes les données pertinentes des projets antérieurs de l’entreprise. Cela peut inclure les coûts réels, la durée des projets, la main-d’œuvre utilisée, les matériaux consommés, etc. Ces données sont ensuite nettoyées pour éliminer les anomalies ou les erreurs.</li></ul><ul class=\"wp-block-list\"><li><strong>Analyse des tendances historiques :</strong> Une fois les données nettoyées, l’IA se plonge dans l’histoire pour identifier des tendances. Par exemple, elle pourrait déceler une augmentation constante du coût des matériaux sur une période de temps donnée ou observer que certains types de projets prennent toujours plus de temps en hiver.</li></ul><ul class=\"wp-block-list\"><li><strong>Modélisation prédictive :</strong> Avec les tendances en main, l’IA utilise des techniques de modélisation prédictive pour estimer les coûts, la durée et les ressources pour de futurs projets. Ces modèles peuvent être affinés en utilisant des techniques d’apprentissage automatique, où l’IA ajuste constamment ses prédictions en fonction des résultats réels des projets.</li></ul><ul class=\"wp-block-list\"><li><strong>Ajustements basés sur des facteurs externes :</strong> L’IA prend également en compte des variables externes qui pourraient influencer un projet. Cela pourrait inclure des choses comme la prévision économique, les variations saisonnières, ou les fluctuations du marché des matériaux de construction. Par exemple, si une pénurie de bois est prévue pour les prochains mois, l’IA ajustera ses estimations de coût en conséquence.</li></ul><ul class=\"wp-block-list\"><li><strong>Estimations personnalisées :</strong> Au-delà des tendances générales, l’IA peut personnaliser ses estimations en fonction du client, du lieu ou de la nature spécifique du projet. Si une entreprise a déjà travaillé pour un client donné, l’IA peut utiliser ces données pour ajuster ses estimations, en prenant en compte les spécificités propres à ce client.</li></ul><ul class=\"wp-block-list\"><li><strong>Proposition d’une offre compétitive :</strong> Fort de ces informations précises, les entreprises du BTP peuvent formuler des offres qui sont non seulement compétitives, mais également réalistes. Cela réduit le risque de sous-estimation, tout en garantissant que l’offre reste attrayante pour le client.</li></ul><p>Grâce à l’IA, les entreprises du BTP peuvent désormais s’appuyer sur des données concrètes et des analyses avancées pour formuler leurs offres.</p><p>Cette approche axée sur les données permet de mieux anticiper les défis et d’optimiser les ressources, donnant ainsi aux entreprises un avantage certain dans le paysage concurrentiel des appels d’offres.</p><h3 class=\"wp-block-heading\" id=\"h-redaction-assistee-des-propositions\"><strong>Rédaction assistée des propositions</strong></h3><p>Des outils d’IA comme <a href=\"https://openai.com/blog/chatgpt\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> peuvent guider la rédaction des propositions en suggérant des formulations optimales, en veillant à ce que toutes les exigences soient abordées et en aidant à structurer le document de manière logique et persuasive.</p><ul class=\"wp-block-list\"><li><strong>Suggestion de formulations optimales :</strong> L’importance de la communication claire et efficace dans une proposition ne peut être sous-estimée. Les systèmes d’IA, en ayant accès à une base de données de propositions réussies et en utilisant l’analyse sémantique, peuvent suggérer des tournures de phrases et des formulations qui ont eu un impact positif dans le passé. Cela peut aider à rendre le contenu plus convaincant.<br><br><em>Exemple</em> : Si une entreprise veut mettre en avant sa durabilité, l’IA pourrait suggérer : « Nous utilisons des méthodes éco-responsables, ayant réduit notre empreinte carbone de 20 % au cours des trois dernières années. »</li></ul><ul class=\"wp-block-list\"><li><strong>Vérification de la couverture des exigences :</strong> L’un des pièges courants lors de la rédaction de propositions est de négliger ou d’omettre certaines exigences mentionnées dans le cahier des charges. L’IA, en scannant le document d’appel d’offres, peut créer une checklist des exigences. Ensuite, lors de la rédaction, elle peut vérifier en temps réel que toutes ces exigences sont correctement abordées dans la proposition.</li></ul><ul class=\"wp-block-list\"><li><strong>Structuration logique du document :</strong> L’organisation et la structure du document sont cruciales pour sa lisibilité et son impact. Les systèmes d’IA peuvent analyser la structure des propositions précédemment réussies et suggérer un agencement optimal des sections. Cela garantit que le lecteur suit un flux d’informations logique, facilitant la compréhension et renforçant l’argumentation.<br><br><em>Exemple</em> : Introduction – Présentation de l’entreprise – Réponse aux exigences techniques – Méthodologie proposée – Estimations de coûts et de délais – Références de projets similaires – Conclusion.</li></ul><ul class=\"wp-block-list\"><li><strong>Persuasion et adaptation au client :</strong> Au-delà de la simple rédaction, il s’agit de persuader le client que votre entreprise est le meilleur choix. En utilisant des algorithmes de traitement du langage naturel, l’IA peut détecter le ton et le style des documents précédents du client pour suggérer une tonalité correspondante. Cette adaptation stylistique permet d’établir une connexion plus profonde avec le client.</li></ul><ul class=\"wp-block-list\"><li><strong>Relecture automatisée :</strong> L’IA peut également jouer un rôle crucial dans la phase de relecture. En plus de la vérification orthographique et grammaticale, elle peut identifier des passages ambigus, des redondances ou des contradictions dans la proposition, garantissant ainsi un document final de haute qualité.</li></ul><p>En intégrant l’IA dans le processus de rédaction de propositions, les entreprises peuvent améliorer la précision, l’efficacité et la persuasion de leurs documents.</p><p>Cela maximise leurs chances de succès dans les appels d’offres, tout en économisant du temps et des efforts.</p><p>Le futur de la rédaction de propositions dans le BTP pourrait bien être guidé par des outils d’IA sophistiqués, apportant une valeur ajoutée à chaque étape du processus.</p><h2 class=\"wp-block-heading\" id=\"h-comment-utiliser-l-ia-pour-le-suivi-d-un-chantier\">Comment utiliser l’IA pour le suivi d’un chantier ?</h2><p>Le suivi d’un chantier est une tâche complexe qui nécessite une attention constante aux détails, une mise à jour régulière des progrès et une capacité à anticiper et résoudre les problèmes rapidement.</p><p>Avec l’évolution de la technologie, l’IA se présente comme un allié inestimable pour améliorer l’efficacité du suivi de chantier.</p><p>Voici comment l’IA peut être utilisée à cet effet.</p><h3 class=\"wp-block-heading\" id=\"h-surveillance-en-temps-reel-grace-a-la-vision-par-ordinateur\"><strong>Surveillance en temps réel grâce à la vision par ordinateur</strong></h3><p>Les caméras équipées de systèmes d’IA peuvent surveiller en continu un chantier. Grâce à la <a href=\"https://larevueia.fr/tout-ce-que-vous-pouvez-faire-avec-la-computer-vision/\" target=\"_blank\" rel=\"noreferrer noopener\">vision par ordinateur</a>, elles peuvent détecter automatiquement des anomalies, comme un matériel défectueux, des problèmes de sécurité ou des retards dans certaines zones du chantier. Les responsables peuvent alors être alertés en temps réel, permettant une intervention rapide.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"683\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/btp1-1024x683.png\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8704\" style=\"width:683px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/btp1-1024x683.png 1024w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-300x200.png 300w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-768x512.png 768w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-1536x1024.png 1536w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-1250x834.png 1250w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-900x600.png 900w, https://larevueia.fr/wp-content/uploads/2023/10/btp1.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Les caméras qui intègrent des systèmes d’intelligence artificielle jouent un rôle croissant dans la surveillance moderne des chantiers de construction.</p><p>Contrairement aux caméras traditionnelles qui se contentent de capturer des images, ces dispositifs avancés vont bien au-delà.</p><p>Elles tirent parti de la vision par ordinateur, une branche de l’IA spécialisée dans l’interprétation et la compréhension du contenu visuel.</p><p>Dans le contexte d’un chantier, cette capacité d’analyse visuelle s’avère précieuse.</p><p>Par exemple, la caméra peut identifier un équipement qui ne fonctionne pas correctement simplement en analysant les images qu’elle capture.</p><p>Elle peut aussi repérer des situations potentiellement dangereuses pour les ouvriers, comme des équipements mal placés ou des zones qui ne respectent pas les normes de sécurité. De plus, si certaines zones du chantier ne progressent pas comme prévu, ces anomalies sont également détectables.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"640\" height=\"356\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/btp2.webp\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8706\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/btp2.webp 640w, https://larevueia.fr/wp-content/uploads/2023/10/btp2-300x167.webp 300w\" sizes=\"auto, (max-width: 640px) 100vw, 640px\"><figcaption class=\"wp-element-caption\">Détection d’un travailleur sous une charge lourde</figcaption></figure></div><p>L’un des avantages majeurs de ces systèmes est leur capacité à agir de manière proactive. Au lieu d’attendre qu’un humain observe et identifie un problème, le système d’IA envoie des alertes automatiques aux responsables dès qu’une anomalie est détectée.</p><p>Cette réactivité permet d’éviter de nombreux problèmes potentiels. Par exemple, si un équipement est identifié comme défectueux, une intervention rapide peut empêcher des retards supplémentaires dans le projet ou, dans le pire des cas, un accident sur le chantier.</p><p>De cette façon, l’IA se révèle être un outil essentiel pour assurer le bon déroulement des travaux, la sécurité des employés et le respect des délais.</p><h3 class=\"wp-block-heading\" id=\"h-prevision-et-gestion-des-retards\"><strong>Prévision et gestion des retards</strong></h3><p>En analysant les données des chantiers précédents et en combinant ces informations avec le suivi en temps réel, l’IA peut prédire les éventuels retards et leurs causes. Cela permet aux gestionnaires de prendre des mesures préventives ou d’ajuster les ressources en conséquence.</p><p>Dans le secteur du BTP, le suivi des projets est d’une importance cruciale, et l’intégration de l’IA dans ce processus ouvre la porte à une gestion de chantier nettement plus efficace et prédictive. En tirant parti de l’analyse des données issues des chantiers précédents, l’IA peut jouer un rôle proactif, plutôt que réactif, dans la gestion des projets.</p><p>Les données historiques d’un chantier sont une mine d’informations.</p><p>Elles peuvent renfermer des détails sur les délais d’achèvement de certaines tâches, les conditions météorologiques ayant affecté le travail, les problèmes de main-d’œuvre ou de matériel, et bien d’autres facteurs qui ont pu influencer la progression du projet.</p><p>En digérant et en analysant ces données, l’IA peut identifier des tendances et des motifs récurrents qui ont conduit à des retards dans le passé.</p><p>En parallèle, la surveillance en temps réel du chantier actuel fournit à l’IA des informations sur l’état actuel des travaux.</p><p>En combinant ces données en direct avec les enseignements tirés des chantiers précédents, l’IA est en mesure de prédire avec précision où et quand des retards pourraient se produire à l’avenir.</p><p>Par exemple, si l’IA reconnaît que des conditions météorologiques similaires ont précédemment causé des retards dans la livraison de matériaux, elle peut alerter les gestionnaires avant que le problème ne survienne.</p><p>De même, si elle détecte un ralentissement dans une zone spécifique du chantier qui, dans le passé, a conduit à des retards plus conséquents, les responsables peuvent être alertés pour qu’ils puissent intervenir rapidement.</p><p>Cette approche proactive, soutenue par l’IA, permet aux gestionnaires de chantier d’être toujours un pas en avance sur les défis potentiels.</p><p>Au lieu d’attendre qu’un problème survienne et de réagir à la hâte, ils peuvent anticiper les obstacles et déployer des ressources, ajuster les équipes ou réorganiser le planning pour assurer un déroulement fluide du projet.</p><p>En fin de compte, cela conduit à des projets plus efficaces, des coûts réduits et une meilleure satisfaction des parties prenantes.</p><h3 class=\"wp-block-heading\" id=\"h-autres-cas-d-usage-de-l-ia-pour-le-suivi-de-chantier\"><strong>Autres cas d’usage de l’IA pour le suivi de chantier</strong></h3><ul class=\"wp-block-list\"><li><strong>Optimisation de la logistique :</strong> l’IA peut analyser les schémas de circulation des matériaux et des ouvriers sur le chantier, proposant des itinéraires optimisés pour réduire les temps d’attente, les mouvements inutiles et accélérer le processus de construction.</li></ul><ul class=\"wp-block-list\"><li><strong>Gestion des ressources humaines</strong> : en analysant les données sur la productivité des travailleurs, les systèmes d’IA peuvent identifier les besoins en formation ou suggérer des réaffectations d’équipe pour maximiser l’efficacité.</li></ul><ul class=\"wp-block-list\"><li><strong>Contrôle qualité automatisé</strong> : les drones équipés de caméras et de systèmes d’IA peuvent survoler le chantier pour inspecter la qualité des travaux. Ils peuvent détecter des défauts, des malfaçons ou des écarts par rapport aux plans initiaux, offrant ainsi un contrôle qualité supplémentaire.</li></ul><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/btp3-1024x576.jpeg\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8705\" style=\"width:770px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/btp3-1024x576.jpeg 1024w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-300x169.jpeg 300w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-768x432.jpeg 768w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-1536x864.jpeg 1536w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-1250x703.jpeg 1250w, https://larevueia.fr/wp-content/uploads/2023/10/btp3.jpeg 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><ul class=\"wp-block-list\"><li><strong>Suivi environnemental</strong> : l’IA peut aider à surveiller l’impact environnemental du chantier en temps réel, en détectant par exemple les émissions de substances polluantes ou les perturbations de la faune locale. Cela aide les entreprises à respecter les réglementations environnementales et à adopter des pratiques plus durables.</li><li><strong>Communication automatisée avec les parties prenantes</strong> : les systèmes d’IA peuvent générer des rapports automatisés sur l’avancement du chantier, les problèmes rencontrés et les solutions apportées, assurant ainsi une communication transparente avec les clients, les fournisseurs et les autres parties prenantes.</li></ul><p>L’IA offre une multitude de possibilités pour améliorer le suivi d’un chantier, rendant le processus plus efficace, plus sûr et plus conforme aux attentes. En adoptant ces technologies, les entreprises du BTP peuvent non seulement gagner en compétitivité, mais aussi contribuer à l’édification de structures de meilleure qualité, dans le respect des délais et des budgets.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>La révolution de l’intelligence artificielle (IA) redessine de nombreux secteurs, et le BTP n’y fait pas exception. À travers l’ensemble des étapes d’un projet, de la réponse aux appels d’offres jusqu’au suivi minutieux des chantiers, l’IA se révèle être un allié puissant. Elle offre une précision, une efficacité et une proactivité inégalées, transformant ainsi la manière dont les projets sont gérés et exécutés.</p><p>L’intégration de l’IA dans le BTP ne se limite pas à une simple automatisation des tâches. Elle implique une réinterprétation des méthodes traditionnelles, une anticipation des défis et une optimisation constante des ressources. Les entreprises qui adoptent ces technologies innovantes se positionnent non seulement en leaders sur le marché actuel, mais se préparent aussi à modeler l’avenir du secteur.</p><p>L’IA dans le BTP n’est pas simplement une tendance éphémère ; c’est la prochaine étape logique de l’évolution du secteur. Les entreprises qui reconnaissent son potentiel aujourd’hui se préparent à un avenir plus compétitif, efficient et, surtout, à la pointe de l’innovation. Embrasser l’IA, c’est embrasser l’avenir du BTP.</p></div>"},
{"url": "https://larevueia.fr/rag-et-documentation-interne-en-entreprise/", "title": "L’IA et les RAG au service de la documentation interne d’entreprise", "author": "Ilyes Talbi", "date": "\n25 octobre 2024\n", "content": "<div class=\"entry-content\"><p>Au delà du buzz autour de l’intelligence artificielle et des RAG, certaines entreprises peinent à trouver des cas d’usages concrets qui peuvent réellement « révolutionner » leur secteur.</p><p>Un des points communs entre toutes les entreprises c’est le besoin de structuration de la documentation interne.</p><p>La quantité de données générée et traitée par une entreprise est énorme et énormément d’informations se perdent dans la nature.</p><p>McKinsey estime le temps perdu lié à la recherche d’informations à plus de 20% du temps travaillé d’un employé. Ils estiment à plus de 10k€ par an et par employé le manque à gagner liées à des pertes de connaissances.</p><p>Cela inclus plusieurs choses, comme dans la tech le fait que des développeurs doivent refaire plusieurs fois un même code à cause d’une mauvaise documentation ou une mauvaise structuration des informations.</p><p>Par ailleurs, une mauvaise documentation interne peut entraîner des risques liés à la sécurité de la donnée d’entreprise. Des informations privées peuvent être échangées via Whatsapp, par téléphone, sur Slack, via des messageries électroniques non-sécurisées, etc.</p><p>D’où l’importance pour l’entreprise d’optimiser l’accès à la données interne au sein de l’entreprise.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-peut-aider-la-notion-de-rag\">L’IA peut aider : la notion de RAG</h2><p>Les RAG : Retrieval Augmented Generation, sont des techniques qui permettent au LLM de baser leurs réponses sur des bases de connaissances externes, au delà de la simple base d’entraînement du modèle.</p><p>Le principe est le suivant :</p><ul class=\"wp-block-list\"><li>On commence par créer notre base de connaissance qui contient toute la données de l’entreprise. Cette donnée sera stockée sous la forme de vecteurs mathématiques, les vecteurs d’embedding, et rangées par contexte. Les vecteurs doivent être construits intelligemment en faisant en sorte que les documents avec un contexte proche soit proches au sens mathématique. Par ailleurs, on doit aussi faire en sorte que la base soit optimisée pour la recherche afin de permettre une récupération de données rapides. Une des entreprises de référence sur ce sujet est <a href=\"https://pathway.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Pathway</a>.</li><li>Une fois que la base vectorielle est construite, son utilisation est simple. On va récupérer la recherche de l’utilisateur, la transformer en vecteur d’embedding et récupérer dans la base vectorielle les morceaux de documents qui sont proches de la question sémantiquement. On va ensuite faire en sorte de compresser les documents récupérées pour créer un contexte synthétique. Enfin, on va redonner au LLM la question initiale de l’utilisateur et lui demander de baser sa réponse sur le contexte que l’on vient de construire.</li></ul><p>Le framework de référence qui permet de mettre en place ce genre de pipeline de RAG est <a href=\"https://larevueia.fr/langchain-le-guide-essentiel/\" target=\"_blank\" rel=\"noreferrer noopener\">Langchain</a>. Il permet de gérer tous le processus de la création de la base de connaissance à la restitution des réponses, en passant par la compression du contexte.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"665\" src=\"https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1024x665.png\" alt=\"Pipeline de RAG avec Langchain pour la documentation interne en entreprise\" class=\"wp-image-8829\" style=\"width:580px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1024x665.png 1024w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-300x195.png 300w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-768x499.png 768w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1536x998.png 1536w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1250x812.png 1250w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18.png 1644w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Pipeline de RAG avec Langchain</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"h-comment-securiser-son-pipeline-de-rag\">Comment sécuriser son pipeline de RAG</h2><p>Cette approche basée sur Langchain n’est pas sans risque, l’aspect sécuritaire doit être pris en considération.</p><h3 class=\"wp-block-heading\" id=\"h-le-phenomene-d-hallucination\">Le phénomène d’hallucination</h3><p>D’abord, il faut avoir en tête que les LLM sont initialement conçus comme des modèles mathématiques dont le rôle est de prédire le mot suivant. Ils doivent proposer une séquence de mots qui parait juste et qui se rapproche de ce qu’un humain aurait pu dire.</p><p>A aucun moment du processus on ne prend en compte la véracité de l’information transmise à l’utilisateur. Il est donc assez courant qu’un modèle de LLM donne une réponse fausse avec assurance, ce phénomène est ce que l’on appelle « l’hallucination ».</p><p>Malgré les améliorations récentes liées à l’hallucination dans les dernières versions de LLM comme GPT-4, ce phénomène est encore présent. Et il peut affecter votre pipeline dans le cas où le contexte extrait de votre base de connaissance serait trop vague. Le LLM peut être tenté de compléter la réponse en inventant des informations.</p><p>La première étape pour la résolution de ce problème consiste à mettre en place des métriques de performances basées sur du feedback humain, via des notes par exemple. N’hésitez pas à essayer plusieurs LLM et les mettre en compétition sur ce point là.</p><h3 class=\"wp-block-heading\" id=\"h-acces-et-infiltration-de-donnees-dans-le-pipeline-de-rag\">Accès et infiltration de données dans le pipeline de RAG</h3><p>L’autre grand risque lié aux pipelines de RAG réside dans la compartimentalisation des données de l’entreprise. On ne veut pas que le LLM donne toutes les informations de l’entreprise à tous les employés.</p><p>On doit pouvoir définir des périmètres d’accès à la données comme on le ferait dans un drive classique.</p><p>Sur ce sujet la solution n’a rien à voir avec l’IA en elle-même, elle repose entièrement sur l’infrastructure proposée et la qualité de la données en entrée. Tous les documents doivent être labéllisés et contenir dans leurs metadata les informations liées aux autorisations d’accès.</p><p>Par ailleurs, les risques cyber classique comme une injection de données par un acteur malveillant, peuvent être plus difficiles à déceler. Le LLM répondra avec le contexte présent dans la base de connaissance, sans savoir qu’elle a été inflitrée.</p><h3 class=\"wp-block-heading\" id=\"h-le-risque-de-mal-controler-les-couts-du-pipeline\">Le risque de mal contrôler les coûts du pipeline</h3><p>Contrairement à une recherche classique dans une base de connaissance, la recherche par RAG fait intervenir plusieurs modèles de LLM qui sont potentiellement appelés plusieurs fois par requête. Ils sont appelés une première fois pour la compréhension de la requête de l’utilisateur, ils sont ensuite appelés plusieurs fois pour la compression du contexte en fonction de la quantité d’informations, et enfin une dernière fois pour résumer la réponse.</p><p>Si on utilise une API externe, avec une facturation par token (c’est l’unité mathématique qui est utilisée pour l’encodage du langage) les coûts peuvent très vite s’envoler. D’où l’importance de faire des tests et d’avoir un contrôle rigoureux des dépenses.</p><h3 class=\"wp-block-heading\" id=\"h-souverainete-des-donnees\">Souveraineté des données</h3><p>La souveraineté des données constitue un dernier risque à ne pas négliger. En utilisant des API de LLM d’entreprises externes vous exposez à l’extérieur les données de votre entreprise et les recherches de vos employés dans votre base interne.</p><p>En fonction de la politique de l’entreprise vous pouvez passer par des clouds providers de confiance ou alors décider de construire une architecture local en utilisant des modèles open-source comme LLAMA par exemple.</p></div>"},
{"url": "https://larevueia.fr/fine-tuner-chatgpt-depuis-le-dashboard-openai/", "title": "Fine-tuner ChatGPT depuis le dashboard OpenAI", "author": "Ilyes Talbi", "date": "\n19 juin 2024\n", "content": "<div class=\"entry-content\"><p>OpenAI a révolutionné le domaine de l’intelligence artificielle en démocratisant des techniques autrefois réservées aux experts. Aujourd’hui, le fine-tuning de modèles de langage (LLM), tels que ChatGPT (3.5 ou 4o), est à la portée de tous. Pour mieux comprendre comment Fine-tuner ChatGPT, continuez à lire.</p><p>Que vous soyez un développeur cherchant à affiner les réponses de votre assistant virtuel ou une entreprise souhaitant adapter un modèle à des besoins spécifiques, OpenAI offre les outils nécessaires pour personnaliser ces assitants.</p><p>Dans cet article je vous explique comment préparer votre jeu de données, configurer votre compte OpenAI et lancer le processus de fine-tuning pour créer votre version personnalisée de ChatGPT.</p><h2 class=\"wp-block-heading\" id=\"h-preparation-du-dataset-pour-le-fine-tuning-de-chatgpt\">Préparation du dataset pour le fine-tuning de ChatGPT</h2><p>Le succès du fine-tuning d’un modèle de langage comme ChatGPT dépend largement de la qualité et de la pertinence de votre jeu de données. Voici comment vous pouvez préparer efficacement votre dataset pour obtenir les meilleurs résultats possibles.</p><p>Le dataset que vous utilisez pour le fine-tuning doit être soigneusement sélectionné et structuré. Il doit contenir des paires d’entrée/sortie qui représentent fidèlement les interactions que vous attendez entre l’utilisateur et le modèle. Plus vos données seront représentatives des scénarios réels d’utilisation, meilleur sera le comportement de votre modèle personnalisé.</p><p>Commencez par rassembler au moins 20 paires d’interactions input/output. L’input doit refléter ce que vous prévoyez de demander au modèle, et l’output doit illustrer la réponse que vous souhaitez obtenir. Par exemple, si vous préparez un assistant pour aider avec des requêtes client spécifiques, chaque input pourrait être une question fréquente d’un client, et l’output serait la réponse idéale que l’assistant devrait fournir.</p><p>Une fois votre collection d’exemples prête, vous devrez organiser ces données dans un fichier au format <em>.jsonl</em>, où chaque ligne correspond à un échange spécifique entre l’utilisateur et l’assistant. Voici le format à suivre pour chaque interaction :</p><pre class=\"wp-block-code\"><code>{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"Prompt du système ici\"},\n    {\"role\": \"user\", \"content\": \"Entrée de l'utilisateur ici\"},\n    {\"role\": \"assistant\", \"content\": \"Réponse de l'assistant ici\"}\n  ]\n}</code></pre><p>Chaque ligne doit représenter une interaction complète, et il est crucial que le format soit respecté pour garantir le bon traitement des données par la plateforme OpenAI. Cela permettra une meilleure compréhension du contexte par le modèle et une personnalisation plus précise de ses réponses.</p><p>Maintenant que notre dataset est prêt on passe à la prochaine étape. Dans la prochaine section nous allons gérer la configuration de votre compte OpenAI pour commencer le processus de fine-tuning.</p><h2 class=\"wp-block-heading\" id=\"h-configuration-du-compte-openai\">Configuration du compte OpenAI</h2><p>Pour commencer, vous devez avoir un compte OpenAI. Si ce n’est pas déjà fait, rendez-vous sur le site officiel <a href=\"https://platform.openai.com/login\">d’OpenAI</a> et suivez les instructions pour créer un compte. Une fois votre compte créé, vous pourrez accéder à votre dashboard personnel.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"657\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1024x657.png\" alt=\"Fine-tuner ChatGPT depuis le dashboard OpenAI\" class=\"wp-image-8767\" style=\"width:710px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1024x657.png 1024w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-300x192.png 300w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-768x492.png 768w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1536x985.png 1536w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1250x802.png 1250w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">UI connexion au dashboard OpenAI</figcaption></figure></div><p>Après vous être connecté, naviguez dans le tableau de bord OpenAI jusqu’à la section « Fine-tuning ». Vous y trouverez toutes les options et les outils nécessaires pour démarrer le processus de personnalisation de votre modèle.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"446\" height=\"736\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.14.48.png\" alt=\"Fine-tuner ChatGPT depuis le dashboard OpenAI\" class=\"wp-image-8768\" style=\"width:270px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.14.48.png 446w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.14.48-182x300.png 182w\" sizes=\"auto, (max-width: 446px) 100vw, 446px\"><figcaption class=\"wp-element-caption\">Panneau latéral à gauche sur le dashboard OpenAI</figcaption></figure></div><ul class=\"wp-block-list\"><li><strong>Sélection du modèle</strong> : Choisissez le modèle de base que vous souhaitez fine-tuner, comme GPT-3.5 ou GPT-4o. Chaque modèle a des caractéristiques et des capacités différentes, donc sélectionnez celui qui correspond le mieux à vos besoins</li><li><strong>Téléchargement du dataset</strong> : Chargez votre fichier .jsonl préparé dans l’étape précédente. Assurez-vous que le fichier soit correctement formaté comme décrit pour éviter des erreurs pendant le processus de fine-tuning.</li><li><strong>Configuration des paramètres de fine-tuning</strong> : Bien que les paramètres par défaut fonctionnent généralement bien pour de nombreux cas d’usage, vous avez la possibilité de personnaliser des aspects tels que la taille du lot (batch size), le nombre d’époques (epochs), et le seed initial. Si vous êtes familier avec ces paramètres, ajustez-les selon les spécificités de votre projet.</li></ul><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"869\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-1024x869.png\" alt=\"Fine-tuner ChatGPT depuis le dashboard OpenAI\" class=\"wp-image-8770\" style=\"width:654px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-1024x869.png 1024w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-300x255.png 300w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-768x652.png 768w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-1250x1061.png 1250w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10.png 1374w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Paramètrage du fine-tuning de ChatGPT</figcaption></figure></div><p>Une fois que tout est en place, vous pouvez lancer le processus de fine-tuning en cliquant sur le bouton « Create ». OpenAI prendra en charge l’entraînement de votre modèle avec les données fournies. Vous recevrez une notification par email une fois que le modèle sera prêt à l’emploi.</p><h2 class=\"wp-block-heading\" id=\"h-entrainement-et-utilisation-apres-le-fine-tuning-de-chatgpt\">Entraînement et utilisation après le fine-tuning de ChatGPT</h2><p>Après avoir configuré votre compte et lancé le processus de fine-tuning, vous pourrez bientôt tester votre modèle personnalisé.</p><p>Une fois le fine-tuning initié, vous pouvez suivre l’avancement via le tableau de bord OpenAI. Cela vous permet de voir le progrès du modèle et de vous assurer que tout se déroule comme prévu. Lorsque l’entraînement est terminé, vous recevrez une notification indiquant que votre modèle est prêt à être utilisé.</p><p>Une fois le fine-tuning de ChatGPT terminé, votre modèle personnalisé est maintenant accessible via l’API d’OpenAI ou directement dans le Playground OpenAI. Vous pouvez commencer à l’intégrer dans vos applications ou à l’utiliser pour des tâches spécifiques. Testez le modèle pour évaluer ses performances et assurez-vous qu’il répond bien à vos attentes. N’hésitez pas à faire des ajustements supplémentaires si nécessaire.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>Le fine-tuning de ChatGPT offre une opportunité incroyable d’adapter les capacités de pointe de l’IA aux besoins spécifiques de votre projet ou de votre entreprise. En suivant les étapes de préparation du dataset, de configuration du compte, et de lancement du processus de fine-tuning, vous pouvez maximiser l’efficacité de votre assistant virtuel.</p><p>Cette approche personnalisée non seulement améliore l’interaction utilisateur mais ouvre également de nouvelles possibilités pour l’innovation et l’efficacité dans divers domaines.</p></div>"},
{"url": "https://larevueia.fr/lintelligence-artificielle-au-service-du-sport/", "title": "L’intelligence artificielle au service du sport", "author": "Ilyes Talbi", "date": "\n10 avril 2023\n", "content": "<div class=\"entry-content\"><p>L’intelligence artificielle a transformé profondément le monde du sport. Des terrains de football aux pistes d’athlétisme, cette technologie révolutionne la façon dont les athlètes s’entraînent, se préparent, et atteignent leurs objectifs de performance.</p><p><strong>Pourquoi une telle révolution ?</strong> L’IA offre des capacités inédites pour analyser des données complexes, personnaliser les entraînements, et anticiper les risques de blessures. Sa présence est désormais incontournable, que ce soit pour optimiser les programmes sportifs, affiner les tactiques de jeu ou encore améliorer la compréhension de la biomécanique.</p><p>En plus de l’amélioration des techniques d’intelligence artificielle, on a observé une augmentation considérable de la quantité de données extraites dans le sport. Les moindres gestes des athlètes, en entraînement ou en compétition, sont mesurer et analyser avec un grand degré de précision.</p><p>Par exemple, la <a href=\"https://larevueia.fr/tout-ce-que-vous-pouvez-faire-avec-la-computer-vision/\" target=\"_blank\" rel=\"noreferrer noopener\">computer vision</a> est utilisée pour décortiquer les vidéos de matchs ou d’entraînements, fournissant aux entraîneurs et athlètes des insights détaillés sur les mouvements, stratégies, et tactiques. En parallèle, les algorithmes de machine learning identifient les schémas de performance, proposent des améliorations personnalisées, et même prédisent les risques de blessures pour les prévenir.</p><p>De plus, l’IA s’invite dans les études de biomécanique pour aider à comprendre les mouvements complexes et les contraintes physiques auxquels sont soumis les athlètes, permettant ainsi d’adapter les préparations physiques à chaque sport.</p><p>Dans cet article, nous explorerons comment l’IA redéfinit le monde du sport, les bénéfices concrets qu’elle apporte aux athlètes et aux équipes, ainsi que les défis éthiques qu’elle soulève.</p><h2 class=\"wp-block-heading\" id=\"h-ameliorer-les-performances-grace-a-l-intelligence-artificielle-dans-le-sport\">Améliorer les performances grâce à l’intelligence artificielle dans le sport</h2><p>L’IA permet d’améliorer les performances sportives en collectant et en analysant une grande quantité de données qui peuvent être utilisées pour personnaliser l’entraînement et visualiser la progression de l’athlète.</p><p>Par exemple, dans le domaine de la course à pied, des capteurs intégrés aux chaussures peuvent enregistrer des données sur la foulée, la cadence, la force de poussée ou l’équilibre.</p><p>Ces données sont ensuite analysées par un algorithme d’IA qui identifie les points d’amélioration, comme une répartition de poids inégale pouvant causer des blessures. Sur cette base, des recommandations précises sont fournies à l’athlète pour corriger sa posture et améliorer son efficacité.</p><p>Dans le cadre des sports collectifs, comme le football, des caméras à haute résolution couplées à des systèmes d’IA peuvent suivre chaque joueur sur le terrain et analyser leurs déplacements.</p><p>Par exemple, les données peuvent révéler qu’un joueur se fatigue trop vite lorsqu’il effectue des sprints. Les entraîneurs peuvent alors adapter son programme d’entraînement pour améliorer son endurance, et mieux organiser les tactiques de jeu en fonction de sa condition physique.</p><p>Pour les athlètes de haut niveau, l’IA peut également analyser les données physiologiques recueillies par des outils comme les montres connectées : la variabilité de la fréquence cardiaque, le sommeil, etc. pour ajuster les sessions d’entraînement et optimiser la récupération.</p><p>Un athlète de triathlon pourrait recevoir des recommandations pour réduire l’intensité de l’entraînement un jour donné afin de favoriser la récupération, suite à une analyse démontrant un niveau de fatigue élevé.</p><p>Les programmes d’entraînement personnalisés basés sur l’IA fournissent ainsi des exercices spécifiques à chaque athlète. L’analyse des données collectées permet de comprendre les points faibles, les opportunités d’amélioration, et d’adapter l’entraînement en conséquence.</p><p>De plus, l’utilisation de l’IA dans l’analyse de la performance peut aider les athlètes à mieux comprendre leur corps et à optimiser leurs mouvements. Par exemple, en natation, des caméras associées à l’IA peuvent détecter des irrégularités dans le mouvement des bras et des jambes, permettant au nageur de rectifier sa technique pour gagner en efficacité.</p><h2 class=\"wp-block-heading\" id=\"h-prevenir-les-blessures-avec-l-ia\">Prévenir les blessures avec l’IA</h2><p>La prévention des blessures est essentielle pour les athlètes, car une blessure peut s’avérer coûteuse en termes de temps et de ressources financières.</p><p>L’IA est en train de révolutionner la manière dont les athlètes sont protégés en aidant à identifier les facteurs de risque de blessure.</p><p>L’IA peut aider à prédire les futurs <a href=\"https://sport.cnrs.fr/sport-et-ia-modelisation-du-risque-de-blessure-chez-les-sportifs-professionnels/\" target=\"_blank\" rel=\"noreferrer noopener\">risques de blessures</a> en analysant les données collectées sur l’athlète, tels que l’historique des blessures, des informations biomécaniques et physiologiques du corps.</p><p>Ces données peuvent être utilisées pour recommander des actions préventives, telles que des exercices d’étirements ou des programmes de prévention d’insuffisance musculaire.</p><p>En outre, l’utilisation de l’IA pour la surveillance des mouvements peut aider les athlètes à éviter les blessures en les informant de tout mouvement anormal.</p><p>Par exemple, l’analyse de la biomécanique et des mouvements lors de la course à moteur aide les athlètes à s’ajuster pour éviter d’endommager les tissus corporels.</p><h2 class=\"wp-block-heading\" id=\"h-utilisation-de-l-ia-en-matiere-d-analyse-video\">Utilisation de l’IA en matière d’analyse vidéo</h2><p>L’utilisation de l’Intelligence Artificielle a permis d’obtenir des résultats très intéressants dans l’analyse vidéo. Cela est possible grâce à l’augmentation des capacités de traitement de données de l’IA, ainsi que des algorithmes d’apprentissage automatique qui permettent à l’IA d’apprendre à partir de données et de prendre des décisions.</p><p>L’analyse vidéo assistée par IA peut être utilisée pour diverses applications telles que la surveillance de la sécurité, l’analyse de comportement, la reconnaissance faciale et la comptabilisation du trafic.</p><p>Grâce à l’IA, l’analyse vidéo atteint un niveau de précision et de rapidité rarement atteint par les méthodes traditionnelles.</p><p>Cependant, la mise en place de telles solutions nécessite des compétences spécialisées et une compréhension des complexités techniques reliées à l’IA.</p><p>Il est donc essentiel pour les entreprises intéressées par l’analyse vidéo IA de travailler avec des experts pour réussir la mise en place de tels projets.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-et-la-personnalisation-de-l-experience-sportive\">L’IA et la personnalisation de l’expérience sportive</h2><p>L’intelligence artificielle a révolutionné l’expérience des fans dans l’industrie du sport. L’IA est utilisée pour personnaliser l’expérience du fan, en fournissant des recommandations et des offres qui correspondent à leurs préférences individuelles. Les entreprises de sport peuvent utiliser l’IA pour suivre les habitudes d’achat de chaque fan, leurs préférences d’équipe et d’autres données pour créer des expériences personnalisées.</p><p>L’IA peut également être utilisée pour fournir aux fans des points de vue uniques sur les événements sportifs en utilisant des données de capteurs et des images de caméras. Avec l’IA, les entreprises peuvent offrir des perspectives nouvelles et intéressantes aux fans, tout en augmentant leur engagement.</p><p>De plus, l’IA peut également aider les entraîneurs et les joueurs à prendre des décisions optimales. Les algorithmes d’apprentissage automatique peuvent être utilisés pour analyser des données telles que les performances passées, la météo, le terrain et les statistiques des adversaires afin d’optimiser les décisions en matière de formation, de stratégie et de jeu.</p><p>L’utilisation de l’IA dans l’expérience sportive offre de nombreuses opportunités passionnantes pour les fans, les entraîneurs et les joueurs.</p><p>C’est une tendance intéressante et en constante évolution à surveiller pour les fans de sport et les entreprises de l’industrie du sport.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>En conclusion, l’utilisation de l’intelligence artificielle est une tendance à la hausse dans de nombreuses industries, y compris l’industrie du sport.</p><p>Les entreprises utilisent l’IA pour améliorer l’expérience des fans, augmenter l’engagement et améliorer les performances des joueurs et des entraîneurs.</p><p>Avec l’augmentation de la puissance de traitement de l’IA, les entreprises peuvent mieux comprendre leurs clients et leur offrir des expériences plus personnalisées.</p><p>Les algorithmes d’apprentissage automatique permettent également une analyse plus précise des données et des performances, ce qui peut conduire à des améliorations significatives dans les performances des joueurs et l’efficacité des entreprises.</p><p>Cependant, il est important de noter que l’utilisation de l’IA doit être accompagnée d’une solide stratégie d’entreprise et de responsabilité.</p><p>Les entreprises doivent travailler avec des experts pour développer des technologies AI robustes et éthiques, et s’assurer que l’utilisation de l’IA ne compromet pas ou ne viole pas la confidentialité ou la sécurité des données des clients.</p><p>Dans l’ensemble, l’IA représente une opportunité passionnante pour l’industrie du sport d’améliorer l’expérience des fans et d’optimiser les performances des joueurs et des équipes, tout en restant éthiques et responsables.</p></div>"},
{"url": "https://larevueia.fr/introduction-a-lintelligence-artificielle-generative/", "title": "Qu’est-ce que l’intelligence artificielle générative ?", "author": "Ilyes Talbi", "date": "\n30 janvier 2023\n", "content": "<div class=\"entry-content\"><p>L’intelligence artificielle générative est un domaine du deep learning qui donne aux machines la capacité de générer du contenu (image, vidéo, texte, etc.), à partir de données crées manuellement.</p><p>Après les deep fake, la génération de visages ou de voitures, les derniers modèles conçus sont capables de générer du texte ou des images très réalistes.</p><p>Dans cet article, on explique ce qu’est l’intelligence artificielle générative, on présente le fonctionnement de ces modèles, leurs applications, et on parle de l’aspect éthique.</p><h2 class=\"wp-block-heading\">Quelles sont les applications de l’Intelligence artificielle générative ?</h2><p>L’IA générative a un nombre infini d’applications. Dans cette section je vous présente celles qui sont le plus impressionnantes et qui commencent à se démocratiser.</p><h3 class=\"wp-block-heading\">Générer des images avec l’IA générative</h3><p>L’application qui a le plus fait réagir dernièrement c’est cette capacité des modèles à générer des images à partir de textes simples. J’ai beaucoup écrit sur le sujet, j’ai même proposé un tutoriel pour générer vos images rapidement.</p><p>Les images obtenues en sortie sont vraiment impressionnantes, et il faut se rappeler que nous ne sommes qu’au début de cette technologie.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/image-generees.jpeg\" alt=\"exemple d'image générées grâce à l'intelligence artificielle générative\" class=\"wp-image-8004\" width=\"325\" height=\"488\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/image-generees.jpeg 512w, https://larevueia.fr/wp-content/uploads/2023/01/image-generees-200x300.jpeg 200w\" sizes=\"auto, (max-width: 325px) 100vw, 325px\"></figure></div><h3 class=\"wp-block-heading\">Créer du texte</h3><p>En plus de la création d’images, les IA génératives sont de plus en plus performantes pour l’écriture de texte. En plus d’être capables de mener une discussion d’un niveau humain sur la plupart des sujets, les meilleurs modèles d’aujourd’hui peuvent générer des paragraphes, des articles, voir des livres entiers.</p><p>J’ai généré <a href=\"https://www.amazon.fr/dp/B0BRZ1J55N\" target=\"_blank\" rel=\"noreferrer noopener\">cet ebook</a> grâce à GPT-3 par exemple.</p><h3 class=\"wp-block-heading\">Ecrire du code</h3><p>Ce n’est pas tout!</p><p>Des projets comme GitHub copilot, ont fait passer la génération de code par intelligence artificielle dans des sphères nouvelles. Exemple :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/codechatgpt.png\" alt=\"Qu'est-ce que l'intelligence artificielle générative ?\" class=\"wp-image-8006\" width=\"501\" height=\"588\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/codechatgpt.png 729w, https://larevueia.fr/wp-content/uploads/2023/01/codechatgpt-255x300.png 255w\" sizes=\"auto, (max-width: 501px) 100vw, 501px\"></figure></div><h2 class=\"wp-block-heading\">Comment fonctionne les modèles d’intelligence artificielle générative ?</h2><p>Les méthodes les plus utilisées aujourd’hui sont les GAN, les VAE et les <a href=\"https://larevueia.fr/introduction-aux-reseaux-de-neurones-transformers/\" target=\"_blank\" rel=\"noreferrer noopener\">transformers</a>.</p><h3 class=\"wp-block-heading\">GAN, ou Generative Adversarial Networks</h3><p>Les GANs sont des réseaux de neurones génératifs introduits pour produire du contenu réaliste à partir de données d’entrées. Leur fonctionnement ingénieux a été considéré par Yann LeCun comme l’idée la plus importante en machine learning de ces 10 dernières années.</p><p>Les GANs comprennent un générateur et un discriminant qui s’entraînent en compétition. Le générateur génère le contenu, et le discriminant doit determiner si le contenu généré est réel ou non. Grâce à cette concurrence, les deux modèles s’améliorent simultanément au fil de l’entraînement.</p><h3 class=\"wp-block-heading\">VAE, ou Variational Auto-Encoders</h3><p>Les VAE sont une variantes des auto-encodeurs.</p><p>Ils ont une architecture de réseaux de neurones en entonnoir. La première partie de l’entonnoir, appelée encodeur, a pour but d’encoder la donnée d’entrée dans un vecteur de petite taille.</p><p>La seconde partie, appelée décodeur, permet de reconstruire la donnée d’entrée à partir de son encodage.</p><p>L’intérêt de cette approche, est de construire un espace latent dans lequel les encodages de toutes les données d’entrées sont rangées de telle sorte que des opérations simples soient possibles.</p><p>On peut, avec cette méthode, générer de nouvelles données qui ressembleront à l’espace latent.</p><p>Récemment, les modèles d’intelligence artificielle générative sont entraînés en utilisant des approches comme les Transformers qui utilisent les mécanismes d’attention, des approches d’apprentissage par renforcement, ou encore des modèles plus traditionnels et moins gourmands comme les chaînes de Markov cachées.</p><h2 class=\"wp-block-heading\">Quelques exemples d’utilisation de l’intelligence artificielle générative</h2><p>Concrètement, voici 3 exemples de modèles qui utilisent les techniques vues dans la section précédente pour faire de la génération de contenu automatisée.</p><h3 class=\"wp-block-heading\">Stable diffusion</h3><p>Stable diffusion est un modèle open-source, financé par <a href=\"https://stability.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Stability AI</a>. Il permet de générer des images à partir de textes. C’est une version open-source, plus fiable et plus rapide de DALL-E 2, le modèle proposé par OpenAI en 2022.</p><h3 class=\"wp-block-heading\">ChatGPT, l’apogée de l’intelligence artificielle générative</h3><p><a href=\"https://larevueia.fr/chatgpt/\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> est un modèle de traitement du langage développé par OpenAI. Il utilise le transfert de connaissances pour produire des réponses à des questions en utilisant une grande quantité de données textuelles précédemment vues.</p><figure class=\"wp-block-image size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/chatgpt.jpeg\" alt=\"chatgpt, l'apogée de l'intelligence artificielle générative\" class=\"wp-image-8002\" width=\"375\" height=\"210\"></figure><p>ChatGPT est capable de comprendre et de générer du texte dans divers domaines, allant des conversations informelles à des sujets plus complexes tels que la science et la technologie.</p><h3 class=\"wp-block-heading\">Make-A-Video</h3><p>En plus du texte et des images, les dernières avancées nous permettent d’envisager des progrès dans le domaine du text2video. C’est à dire la génération de vidéos à partir de texte.</p><p>Meta a proposé un papier en 2022, appelé <a href=\"https://larevueia.fr/make-a-video-generer-des-videos-avec-un-texte/\" target=\"_blank\" rel=\"noreferrer noopener\">Make-A-Video</a>, qui permet de générer de courtes vidéos à partir de texte.</p><h2 class=\"wp-block-heading\">Quid de l’aspect éthique ?</h2><p>Les modèles d’intelligence artificielle générative progressent énormément sur l’aspect technique. Dans pas mal de cas, le contenu généré est quasiment aussi bons qu’un contenu humain.</p><p>Néanmoins, sur la sécurisation de ces modèles, il reste beaucoup à faire, et plusieurs questions d’ordre éthiques restent en suspens.</p><h3 class=\"wp-block-heading\">L’impact environnemental de l’entraînement de modèles d’intelligence artificielle générative</h3><p>La plupart du temps, les modèles récents proposés ne présentent pas de grandes avancées d’un point de vue algorithmique.</p><p>Elles consistent simplement à réutiliser les modèles déjà disponibles, mais avec des centaines de milliards de paramètres, et des quantités astronomiques de données.</p><p>J’ai parlé de problème de monopole dans de précédents articles. J’expliquais que seules les très grandes entreprises pouvaient entraîner ce type de modèles d’intelligence artificielle générative, et je proposais la décentralisation comme une des approches viables.</p><p>L’autre problème de cette course à la données et à un nombre de paramètres qui n’a plus trop de sens, c’est même le problème principal, c’est l’impact sur l’environnement.</p><p>Des datacenters de plus en plus grands, qui nécessitent de plus en plus d’énergie pour fonctionner, et un désastre de moins en moins contrôlable sur le plan écologique.</p><h3 class=\"wp-block-heading\">La labellisation des données, à la limite de l’esclavage</h3><p>Pour créer des modèles d’IA générative vraiment performants, le fait d’avoir une grosse quantité de données ne suffit pas. Il faut aussi être capables d’associer ces données à des labels.</p><p>Ce travail, qui est fait manuellement, est souvent chronophage et laborieux.</p><p>Et que font les grandes entreprises de la tech dans ces cas là ? Ils recrutent des petites mains, sous-payées, à la limite de l’esclavage, dans des pays en Afrique ou en Asie pour faire le travail.</p><p>Pire encore.</p><p>Lorsque les données à annoter sont simplement des images d’animaux, des textes littéraires ou des pages Wikipédia, la tâche est acceptable.</p><p>Mais dans le cas de modèles comme ChatGPT ou DALL-E, parmi le contenu qui devait être annoté on trouve du contenu très sensible voir vraiment hardcore.</p><p>Des images d’esclavages, du contenu pédo-pornographique, des textes insultants et qui décrivent des scènes immondes.</p><p>Cette tâche permet de sécuriser le modèle, et éviter qu’il soit utiliser pour générer ce type de contenus. Mais il est inacceptable que des gens soient payés moins de 2 euros la journée pour regarder ce type de contenu pendant des jours et des jours.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Quoi de mieux pour conclure cet article, que de laisser un modèle d’IA générative générer la conclusion ?</p><p>L’IA générative est un domaine du deep learning permettant aux machines de générer du contenu à partir de données manuelles. Les derniers modèles peuvent générer des images et du texte très réalistes.</p><p>Il existe un nombre infini d’applications pour l’IA générative, telles que la génération d’images, d’écriture de texte et même de code.</p><p>Les méthodes les plus couramment utilisées sont les GAN, les VAE et les transformers. Les GAN utilisent un générateur et un discriminant pour produire du contenu réaliste, tandis que les VAE utilisent un encodage pour construire un espace latent pour générer de nouvelles données.</p><p>Les applications de l’IA générative sont prometteuses, mais elles soulèvent également des questions éthiques importantes quant à la fiabilité et la responsabilité de ces technologies.</p></div>"},
{"url": "https://larevueia.fr/farmbot/", "title": "FarmBot : l’IA qui gère votre potager", "author": "Ilyes Talbi", "date": "\n14 janvier 2023\n", "content": "<div class=\"entry-content\"><p><a href=\"https://farm.bot/\" target=\"_blank\" rel=\"noreferrer noopener\">FarmBot</a> est un projet open-source innovant qui vise à révolutionner l’agriculture en utilisant des technologies de pointe telles que la robotique et l’intelligence artificielle.</p><p>L’objectif de FarmBot est de permettre de planter, cultiver et récolter des fruits et légumes de manière plus efficace et précise, tout en réduisant les coûts et en optimisant le rendement.</p><p>Ce projet est soutenu par une communauté de développeurs qui travaillent en continu pour améliorer les fonctionnalités de la plateforme. Dans cet article, nous allons vous montrer comment FarmBot fonctionne, ses impacts sur l’agriculture et les perspectives de développement futur.</p><h2 class=\"wp-block-heading\">Principe et fonctionnement de Farmbot</h2><p>Concrètement, le FarmBot est un potager entièrement autonome. Il se compose d’un robot mobile équipé d’un ensemble d’outils de plantation et de récolte, ainsi que d’un système de guidage autonome pour une localisation précise au sein du potager.</p><figure class=\"wp-block-video\"><video controls src=\"https://larevueia.fr/wp-content/uploads/2023/01/Farm_Designer_Loop_ultra_short.mp4\"></video></figure><p>La planification des cultures est l’une des caractéristiques les plus importantes du robot. Il utilise des données en temps réel, telles que les prévisions météorologiques, les informations sur le sol et les données de croissance des plantes pour optimiser les rendements. </p><p>Les utilisateurs peuvent planifier les cultures de leurs fruits et légumes via une interface en ligne ou une application mobile. Le robot est capable de planter et récolter des graines de manière précise et en autonomie complète, et il sait détecter les fruits et légumes mûrs et de les récolter de manière précise, évitant ainsi les pertes de récolte.</p><p>Par ailleurs, grâce à des méthodes de <a href=\"https://larevueia.fr/tout-ce-que-vous-pouvez-faire-avec-la-computer-vision/\" target=\"_blank\" rel=\"noreferrer noopener\">vision par ordinateur</a>, le Farmbot peut détecter les mauvaises herbes et les nettoyer régulièrement.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x.webp\" alt=\"FarmBot : l'IA qui gère votre potager\" class=\"wp-image-7986\" width=\"365\" height=\"465\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x.webp 800w, https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x-236x300.webp 236w, https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x-768x977.webp 768w\" sizes=\"auto, (max-width: 365px) 100vw, 365px\"></figure></div><h2 class=\"wp-block-heading\">Qu’est-ce que Farmbot change pour les utilisateurs ?</h2><p>Un potager autonome tel que celui offert par le projet FarmBot peut apporter de nombreux avantages en termes d’indépendance alimentaire et de durabilité. Il permet aux gens de produire leur propre nourriture de qualité, de manière efficace, sans avoir à dépendre de sources d’approvisionnement extérieures. Cela peut être particulièrement bénéfique pour les personnes vivant dans des zones plus isolées, où l’accès aux aliments frais peut être limité.</p><p>En termes de durabilité, un potager autonome peut nous aider à réduire notre impact environnemental en utilisant des méthodes de culture plus respectueuses de l’environnement, telles que la réduction des pesticides et des engrais, la réutilisation de l’eau, tout en améliorant les rendements.</p><p>D’un point de vue moins pragmatique, plus en lien avec l’aspect émotionnel, le fait de produire ses propres fruits et légumes permet de se connecter à la nature et de revenir à l’essentiel. Même si ça se fait avec du matériel technologique de pointe.</p><p>L’objectif de farmbot était aussi à vocation éducative, il peut permettre aux enfants et aux étudiants d’apprendre sur l’agriculture, l’intelligence artificielle, la biologie et l’environnement de manière interactive.</p><h2 class=\"wp-block-heading\">Le passage à l’échelle pour gérer de champs plus grands</h2><p>Je conçois ce projet de potager autonome de Farmbot comme une simple étape vers une automatisation de masse de l’agriculture.</p><p>Passer d’un potager autonome à une agriculture autonome sur des champs parfois immenses, nécessite des investissements en matière de technologie et de ressources.</p><p>Des expérimentations sont déjà en cours, et on commence à bien maîtriser les sujets comme <a href=\"https://www.poolse.io/arrosage/\" target=\"_blank\" rel=\"noreferrer noopener\">l’irrigation automatisée</a> et adaptée au besoin des plantes en temps réel.</p><p>On peut aussi détecter lorsque des fruits et légumes sont mûrs, ou détecter les insectes et les mauvaises herbes en utilisant des drones de surveillance.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, le projet FarmBot offre une solution innovante pour l’agriculture de demain en utilisant l’automatisation, la robotique et l’intelligence artificielle pour planter, cultiver et récolter des aliments de manière plus efficace et précise. Il permet de maximiser les rendements alimentaires tout en réduisant les coûts et les déchets, et en augmentant la durabilité de l’agriculture.</p><p>Mais FarmBot ne se limite pas qu’à un système de robotisation agricole, c’est aussi un projet qui réunit une communauté de développeurs passionnés pour continuer à améliorer les fonctionnalités de la plateforme. Il permet également aux gens de produire leur propre nourriture de manière efficace, sans avoir à dépendre de sources d’approvisionnement extérieures, et de se connecter à la nature en cultivant leurs propres aliments frais.</p></div>"},
{"url": "https://larevueia.fr/6-projets-pour-apprendre-la-data-science/", "title": "6 projets pour apprendre la data science", "author": "Ilyes Talbi", "date": "\n21 septembre 2022\n", "content": "<div class=\"entry-content\"><p>L’apprentissage par la pratique est de loin le meilleur moyen pour monter en compétences. C’est vrai dans n’importe quel domaine, mais encore plus dans les domaines en liens avec la programmation.</p><p>Dans cet article j’ai compilé 10 projets, de simple à difficile, qui permettent de monter rapidement en compétences sur le machine learning.</p><h2 class=\"wp-block-heading\">Titanic : machine learning from disaster</h2><p>Beaucoup de data scientist ont commencé par là. C’est un des premiers projets que je propose à ceux qui débutent en machine learning.</p><p>Le principe du projet est simple. On a un dataset qui réunit des données sur les passagers du Titanic pendant son naufrage : nom, prénom, classe, age, sexe, numéro de cabine, etc. Et pour chaque passager on a une variable qui nous dit s’il a survécu au naufrage ou non.</p><p>L’idée est d’utiliser ces données pour entraîner un modèle capable de prédire la survie ou le naufrage d’un passager.</p><p>Ce projet permet de se familiariser avec des librairies comme Pandas et Scikitlearn, et d’utiliser des algorithmes comme Random forest ou XGBoost.</p><p>Je vous laisse commencer à vous amuser sur <a href=\"https://www.kaggle.com/competitions/titanic/data\" target=\"_blank\" rel=\"noreferrer noopener\">Kaggle</a> 🙂</p><h2 class=\"wp-block-heading\">Prédire la gravité d’un accident</h2><p>Pour trouver des projets intéressants à réaliser je me rend souvent sur <a href=\"https://www.data.gouv.fr/fr/reuses/machine-learning-pour-predire-la-gravite-des-accidents/\" target=\"_blank\" rel=\"noreferrer noopener\">datagouv</a>. Une base de données libre proposée par l’état.</p><p>Parmi les dataset avec lesquels vous pouvez jouer, il y a une base de données qui recense les accidents par gravité. On a des informations comme le nombre de véhicules impliqués, le lieu, le moment, et pour chaque accident on a un indice de gravité compris entre 1 et 5.</p><p>L’objectif est de construire un modèle qui puisse prédire ce degré de gravité.</p><p>En plus d’apprendre à manipuler des données plus complexes avec Pandas, vous verrez comment gérer les problèmes liés aux données manquantes ou au déséquilibre des classes.</p><h2 class=\"wp-block-heading\">Prédire le loyer d’un appartement à Paris</h2><p>Pour ce projet là aussi vous trouverez les données sur datagouv.</p><p>Contrairement aux 2 premiers projets, dans celui ci on ne fait pas de classification mais une régression. Ce qui est légèrement différent, même si les étapes de traitement des données et les algorithmes utilisés sont très similaires.</p><p>L’objectif sera de pouvoir prédire les loyers d’appartements parisiens à partir de localisation, de leur surface et d’autres données.</p><p>Je vous propose de suivre mon tutoriel <a href=\"https://larevueia.fr/regression-avec-random-forest-predire-le-loyer-dun-logement-a-paris/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>.</p><h2 class=\"wp-block-heading\">MNIST : le premier réseau de neurones</h2><p>Ce projet là est le hello world du deep learning.</p><p>Il s’agit de classifier des images de chiffres manuscrits en utilisant des techniques simples de deep learning.</p><p>Ce projet permet de se familiariser avec la manipulation de données sous forme d’images. Il permet aussi de travailler avec une librairie plus haut niveau comme Tensorflow ou PyTorch, et d’entraîner un premier réseau de neurones simples.</p><p>L’intérêt de travailler sur ce projet est que les tutoriels et vidéos sur ce dataset ne manquent pas, vous serez soutenu du début à la fin du projet.</p><p>Vous trouverez le dataset et des propositions de solutions sur <a href=\"https://www.kaggle.com/competitions/digit-recognizer\" target=\"_blank\" rel=\"noreferrer noopener\">Kaggle</a>.</p><h2 class=\"wp-block-heading\">Fashion MNIST</h2><p>Pour rester sur le même type de projets, vous pouvez enchaîner avec <a href=\"https://www.youtube.com/watch?v=uITtXg2zoHg\" target=\"_blank\" rel=\"noreferrer noopener\">Fashion MNIST</a>. Le principe est exactement le même, et les outils utilisés sont les mêmes.</p><p>Sauf que cette fois les données sont moins uniformes (on dit que la variance intra-classe est plus élevée. Le modèle de classification devra donc être un peu plus fin.</p><p>Cette fois l’objectif est de construire un modèle de classification d’images d’articles de modes. Le dataset avait été proposé par Zalando. Et comme pour la base MNIST classique vous trouverez beaucoup d’articles et de tutoriels sur ce projet.</p><h2 class=\"wp-block-heading\">Classification des musiques</h2><p>Pour le dernier projet, encore un peu plus difficile, je vous propose de travailler avec des données sonores. Le travail sur les données sonores est similaire au traitement de séries temporelles.</p><p>L’idée de ce projet est d’entraîner un modèle pour classifier des sons en fonction de leur types (jazz, rock, hip-hop, etc.).</p><p>Pour ce projet je vous conseille de tester plusieurs modèles sur les mêmes données et de comparer les résultats. J’ai fait ce travail pour vous dans le <a href=\"https://larevueia.fr/machine-learning-pour-la-classification-automatique-de-musiques-avec-python/\" target=\"_blank\" rel=\"noreferrer noopener\">tutoriel suivant</a> 🙂</p></div>"},
{"url": "https://larevueia.fr/algorithmes-de-gradient-boosting-et-introduction-a-xgboost/", "title": "Algorithmes de gradient boosting et introduction à XGBoost", "author": "Adib Habbou", "date": "\n26 février 2023\n", "content": "<div class=\"entry-content\"><p>Si vous avez déjà participé à des compétitions <strong><a href=\"https://www.kaggle.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Kaggle</a></strong>, vous avez sûrement déjà entendu parler de <strong>XGBoost </strong>(eXtreme Gradient Boosting) qui est parmi les algorithmes de <strong>Gradient Boosting </strong>les plus connus et les plus utilisés dans le monde. Mais est-ce que vous vous êtes déjà demandé qu’est-ce qu’il se cache derrière ses algorithmes qu’on utilise souvent comme des boîtes noires ? Dans la suite, je vais essayer de lever le capot et de vous expliquer comment tout cela fonctionne !</p><h2 class=\"wp-block-heading\">L’intuition derrière le gradient boosting</h2><p>Les algorithmes de<strong> Gradient Boosting</strong> s’appuient sur une idée fondamentale : tenir compte des erreurs du modèle pour améliorer les performances en formant un nouveau modèle qui réussisse à prédire les erreurs faites par le modèle original.</p><p>Grâce à cette idée, pour tout modèle prédictif, nous pouvons améliorer sa précision en formant un nouveau prédicteur pour prédire ses erreurs actuelles. Ensuite, on forme un nouveau modèle « amélioré » qui va en quelque sorte être une agrégation des deux modèles initiaux.</p><p>Pour un algorithme de <strong>Gradient Boosting</strong> comme <strong>XGBoost</strong>, ce processus est répété un nombre arbitraire de fois pour améliorer continuellement la précision du modèle. Ce processus répété constitue l’essence même du <strong>Gradient Boosting</strong> puisqu’on se base sur le principe que l’erreur va continuellement converger vers 0 au fur et à mesure qu’on répète le processus.</p><h2 class=\"wp-block-heading\">Quel est l’intérêt des Weak Learners du coup ?</h2><p>Lors de la formation d’un nouveau modèle prédicteur d’erreurs pour prédire les erreurs actuelles d’un modèle, nous régularisons sa complexité pour éviter de tomber dans de <a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">l’overfitting</a>. Ce modèle régularisé aura des « erreurs » lorsqu’il prédit les « erreurs » du modèle original. Nous réduisons notre confiance envers un seul prédicteur d’erreur en appliquant un petit poids <strong>η</strong> à sa sortie.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/720/1*7EhjRtzxSj5whkHf-MxjLA.png\" alt=\"Algorithmes de gradient boosting et introduction à XGBoost\"></figure></div><h2 class=\"wp-block-heading\">Pourquoi on parle de Gradient alors ?</h2><p>Il s’avère que l’erreur qu’on essaye de corriger avec les <strong>Weak Learners</strong> est le gradient de la fonction de coût par rapport à la prédiction du modèle.</p><p>Mathématiquement, la dérivée de la fonction de coût nous donne la direction dans laquelle les prédictions peuvent être ajustées pour maximiser la perte. Dans le <strong>Gradient Boosting</strong>, nous ajustons nos prédictions dans la direction opposée c’est-à-dire vers le gradient négatif afin de pouvoir minimiser le coût et donc améliorer la performance.</p><p>Intuitivement, l’idée derrière le <strong>Gradient Boosting</strong> est que nous déplaçons les prédictions de notre modèle par petits pas vers des directions qui améliorent la performance globale de notre modèle.</p><h2 class=\"wp-block-heading\">Mais du coup c’est quoi au juste XGBoost ?</h2><p><strong>XGBoost </strong>est une variante des méthodes de <strong>Gradient Boosting</strong> qui utilise des arbres de décisions dit <strong>Gradient Boosting Tree </strong>comme prédicteur d’erreur. Il commence avec un prédicteur simple qui prédit un nombre arbitraire en générale 0.5 quelque soit l’entrée. Inutile de vous dire que ce prédicteur commet beaucoup d’erreurs. Le <strong>Gradient Boosting</strong> est ensuite appliquée jusqu’à ce que l’erreur soit ramenée à un minimum.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/1400/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg\" alt=\"Algorithmes de gradient boosting et introduction à XGBoost\"></figure></div><p>La dénomination <strong>eXtreme </strong>vient du fait que le <strong>XGBoost </strong>est une combinaison parfaite de techniques d’optimisation logicielle et matérielle permettant d’obtenir des résultats supérieurs en utilisant moins de ressources informatiques et en un minimum de temps.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/1400/1*FLshv-wVDfu-i54OqvZdHg.png\" alt=\"Algorithmes de gradient boosting et introduction à XGBoost\"></figure></div><p>Depuis d’autres algorithmes de <strong>Gradient Boosting</strong> ont vu le jour comme <strong>LightGBM </strong>développé par <strong>Microsoft </strong>ou encore <strong>CatBoost </strong>développé par <strong>Yandex </strong>mais qui sait quel sera le prochain roi du Gradient Boosting…</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*i0CA9ho0WArOj-0UdpuKGQ.png\" alt=\"Algorithmes de gradient boosting et introduction à XGBoost\"></figure></div><h2 class=\"wp-block-heading\">Comment implémenter XGBoost avec Python</h2><p>En <strong>Python </strong>il existe toujours une super libraire pour faire ce que vous rechercher, dans notre cas c’est <strong>xgboost</strong> ! Mais comme pour tout bon modèle il faut chercher les bons hyperparamètres pour obtenir le meilleur résultat possible. Dans le code qui suit on va utiliser la fonction <strong>GridSearchCV </strong>de <strong>scikit-learn</strong> pour trouver les bons hyperparamètres.</p><p><strong>Grid Search Cross Valildation</strong> étant un algorithme de recherche d’hyperparamètres qui effectue une recherche exhaustive sur une grille d’hyperparamètres spécifiée. Il teste toutes les combinaisons possibles des hyperparamètres spécifiés pour déterminer les meilleures valeurs pour ce faire il utilise une validation croisée pour évaluer les performances de chaque combinaison d’hyperparamètres.</p><pre class=\"wp-block-code\"><code>from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Paramètres à tester pour le réglage des hyperparamètres\nparam_grid = {\n    'learning_rate': [0.01, 0.1, 1],\n    'max_depth': [100, 200, 300],\n    'min_child_weight': [1, 3, 5],\n    'gamma': [1, 3, 5],\n    'n_estimators': [300, 500, 700],\n    'alpha': [0.01, 0.1, 1],\n    'colsample_bytree': [0.8, 0.9, 1]\n}\n\n# Initialisation du modèle XGBoost\nxgb = XGBClassifier(random_state=42)\n\n# Initialiser GridSearchCV pour ajuster les hyperparamètres du modèle\ngrid_search = GridSearchCV(xgb, param_grid, cv=5)\n\n# Fit du modèle en utilisant les données d'entraînement\ngrid_search.fit(X_train, y_train)\n\n# Affichage des meilleurs hyperparamètres trouvés\nprint(\"Meilleurs hyperparamètres : \", grid_search.best_params_)\n\n# Sauvegarde des meilleurs hyperparamètres trouvés\nxgb_best_param = grid_search.best_params_\n\n# Instanciation du modèle avec les meilleurs hyperparamètres\nxgb_optimized = XGBClassifier(**grid_search.best_params_)\n\n# Entraînement du modèle sur les données d'entraînement\nxgb_optimized.fit(X_train, y_train)\n\n# Utilisation des hyperparamètres pour faire des prédictions sur les données de test\ny_pred = xgb_optimized.predict(X_test)\n\n# Calcul de l'accuracy du modèle\naccuracy = accuracy_score(y_test, y_pred)\n\n# Affichage de l'accuracy du modèle\nprint(\"Accuracy XGBoost :\", accuracy)</code></pre><h2 class=\"wp-block-heading\">Pour aller plus loin</h2><p><strong>Vidéos sur le Gradient Boost de StatQuest :</strong></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Gradient Boost Part 1 (of 4): Regression Main Ideas\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/3CC4N4z3GJc?list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div></figure><p><strong>Vidéos sur le XGBoost de StatQuest :</strong></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"XGBoost Part 1 (of 4): Regression\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/OtD8wVaFm6E?list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div></figure><h2 class=\"wp-block-heading\">Conclusion</h2><p>Maintenant que vous êtes un peu plus familiers avec le <strong>Gradient Boosting</strong><em> </em>vous pouvez explorer toutes les possibilités offertes par ces modèles et monter tout en haut du classement de votre compétition <strong>Kaggle </strong>préférée !</p><p>N’hésitez pas à me demander en commentaire si vous avez besoin d’aide 🙂</p></div>"},
{"url": "https://larevueia.fr/larchitecture-seq2seq-en-deep-learning-fonctionnement-et-limites/", "title": "L’architecture Seq2Seq en deep learning : fonctionnement et limites", "author": "Ilyes Talbi", "date": "\n28 novembre 2024\n", "content": "<div class=\"entry-content\"><p>Les réseaux Seq2Seq sont des modèles d’apprentissage automatique puissants qui transforment une séquence d’entrée en une séquence de sortie, même lorsque les longueurs de ces séquences sont différentes. Ils permettent de résoudre les problèmes liées aux tailles figées des sorties des réseaux de neurones classiques.</p><p>L’architecture Seq2Seq est utilisée principalement en NLP (traitement du langage naturel), pour la réalisation de tâches comme la traduction.</p><p>Dans cet article je vous explique tout ce qu’il y a à savoir sur les Seq2Seq. On parlera de leurs applications concrètes, de leur fonctionnement technique et des limites de cette architecture.</p><h2 class=\"wp-block-heading\" id=\"h-les-applications-des-seq2seq\">Les applications des Seq2Seq</h2><p>Les applications des Seq2Seq sont nombreuses et variées, notamment dans le domaine du traitement du langage naturel (NLP).</p><p>Les réseaux Seq2Seq sont à la base des systèmes de traduction tels que <a href=\"https://research.google/blog/a-neural-network-for-machine-translation-at-production-scale/\">Google Translate</a>. Ils transforment une séquence de mots dans une langue source en une séquence équivalente dans une langue cible, même si les structures grammaticales diffèrent. Et permettent une compréhension linguistique du contexte plus précise que beaucoup d’autres architectures.</p><p>De manière générale, les Seq2Seq permettent d’obtenir des performances intéressantes dans toutes les tâches de génération ou transformation de texte :</p><ul class=\"wp-block-list\"><li>Générer un résumé d’un document est une autre application populaire des Seq2Seq. Ils lisent le texte source et produisent une version plus courte tout en conservant les points essentiels.</li><li>Dans les chatbots et assistants virtuels, les Seq2Seq sont souvent utilisés pour modéliser les dialogues. En fonction d’une requête ou d’un message, le modèle génère une réponse appropriée.</li><li>Ces réseaux sont aussi utilisés pour des systèmes de questions-réponses, en prenant une question en entrée et générant une réponse en fonction du contexte fourni.</li></ul><p>Les Seq2Seq ont été proposés initialement pour régler les problèmes liés aux données séquentielles. Le texte n’est qu’un exemple de tous les types de données séquentielles que l’on génère.</p><p>Ainsi, on pourrait reprendre les approches Seq2Seq, les combiner à des réseaux de convolutions pour la compréhension d’une image, pour pouvoir entraîner des modèles à comprendre les scènes d’une vidéo.</p><p>Les Seq2Seq ne se limitent pas uniquement à la manipulation du texte, mais sont très polyvalents lorsqu’il s’agit de transformer des séquences d’informations complexes en d’autres séquences compréhensibles.</p><h2 class=\"wp-block-heading\" id=\"h-le-fonctionnement-des-seq2seq\">Le fonctionnement des Seq2Seq</h2><p>L’architecture des Seq2Seq consiste en 2 parties : une partie d’encodage et une partie de décodage.</p><p>Le rôle de la partie encodeur sera de résumer l’information disponible dans la séquence d’entrée sous forme d’un vecteur de contexte.</p><p>Le rôle du décodeur est de construire la séquence de sortie élément par élément.</p><h3 class=\"wp-block-heading\" id=\"h-comment-fonctionne-la-partie-encodeur\">Comment fonctionne la partie encodeur ?</h3><p>La partie encodeur d’un modèle Seq2Seq est responsable de traiter la séquence d’entrée et de la convertir en une représentation interne compacte, souvent appelée vecteur de contexte.</p><p>Cette représentation contient les caractéristiques essentielles de la séquence d’entrée qui seront ensuite utilisées par le décodeur pour générer la séquence de sortie. L’encodeur est typiquement constitué de plusieurs couches de réseaux récurrents RNN, qui permettent d’assimiler l’information dans un format adapté pour le traitement ultérieur par le décodeur.</p><p>Mathématiquement, le vecteur de contexte qui résulte de l’encodeur est une somme des états cachés des différentes cellules de RNN qui le composent.</p><p>Dans certaines variantes des modèles Seq2Seq, comme les modèles utilisant le mécanisme d’attention, le vecteur de contexte est enrichi en mettant en évidence les parties les plus pertinentes de la séquence d’entrée pour chaque étape de la génération de la sortie.</p><p>Cela permet au modèle de mieux se concentrer sur les informations cruciales à chaque instant, en faisant une somme pondérée par l’importance des différents éléments d’une séquence donnée.</p><p>Par exemple, dans une phrase comme « Le chat dort sur le canapé », un mécanisme d’attention pourrait permettre au modèle de se concentrer successivement sur « chat », puis sur « dort », et enfin sur « canapé », afin de générer un vecteur mathématiques qui permet d’extraire le contexte linguistique de manière précise.</p><h3 class=\"wp-block-heading\" id=\"h-comment-fonctionne-la-partie-decodeur\">Comment fonctionne la partie décodeur ?</h3><p>La partie décodeur d’un modèle Seq2Seq reçoit la représentation interne générée par l’encodeur, souvent appelée vecteur de contexte, et utilise cette information pour produire la séquence de sortie, un élément à la fois. Le décodeur est également constitué de réseaux récurrents RNN (<a href=\"https://larevueia.fr/quest-ce-quun-reseau-lstm/\">LSTM</a> ou GRU), qui génèrent chaque mot de la séquence de sortie en fonction de l’état précédent et du vecteur de contexte.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"473\" height=\"149\" src=\"https://larevueia.fr/wp-content/uploads/2024/11/seq2seq.png\" alt=\"Le fonctionnement de l'architecture Seq2Seq en deep learning\" class=\"wp-image-8874\" style=\"width:695px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/11/seq2seq.png 473w, https://larevueia.fr/wp-content/uploads/2024/11/seq2seq-300x95.png 300w\" sizes=\"auto, (max-width: 473px) 100vw, 473px\"><figcaption class=\"wp-element-caption\">Seq2Seq (Source : <a href=\"https://d2l.ai/chapter_recurrent-modern/seq2seq.html\" target=\"_blank\" rel=\"noreferrer noopener\">Dive into deep learning</a>)</figcaption></figure></div><p>En d’autres termes, à chaque fois qu’un nouvel élément est généré dans la séquence de sortie, le vecteur de contexte est mis à jour. Par exemple, si je traduis la phrase « Le chat dort sur le canapé » voici ce qui se passe :</p><ul class=\"wp-block-list\"><li>l’encodeur me donne un vecteur de contexte pour cette phrase</li><li>je vais utiliser le décodeur une première fois pour générer le premier élément de ma sortie « The »</li><li>en conséquence, le vecteur de contexte sera mis à jour pour contenir aussi bien la phrase d’entrée que le « The », ce qui permettra de généra le deuxième élément de ma séquence « cat »</li><li>on réitère ce processus, jusqu’a ce que le décodeur prédise le mot de fin de séquence , souvent la chaine de caractère &lt;EOS&gt; (pour End Of Sequence)</li></ul><p>Lorsque le mécanisme d’attention est utilisé, le décodeur peut accéder directement aux parties spécifiques de la séquence d’entrée via l’attention, lui permettant ainsi de se concentrer sur les informations pertinentes à chaque étape de la génération.</p><p>Cela améliore la qualité de la sortie, notamment pour des séquences longues ou complexes, où il est important de se référer à différents éléments de la séquence d’entrée.</p><p>Par exemple, pour traduire la phrase « Le chat dort sur le canapé », le décodeur génèrera chaque mot de la phrase cible en se basant sur le vecteur de contexte et les mots déjà générés, tout en utilisant l’attention pour se concentrer sur les parties pertinentes de la séquence source.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"407\" src=\"https://larevueia.fr/wp-content/uploads/2024/11/Seq2seq_with_RNN_and_attention_mechanism.gif\" alt=\"Le mécanisme d'attention dans les Seq2Seq\" class=\"wp-image-8875\" style=\"width:635px;height:auto\"><figcaption class=\"wp-element-caption\">Seq2Seq avec le mécanisme d’attention (<a href=\"https://en.wikipedia.org/wiki/Seq2seq\" target=\"_blank\" rel=\"noreferrer noopener\">Wikipédia</a>)</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"h-quelles-sont-les-limites-de-ces-architectures\">Quelles sont les limites de ces architectures ?</h2><p>Les modèles Seq2Seq, bien qu’efficaces pour de nombreuses tâches, présentent plusieurs limites importantes.</p><p>D’abord, les architectures Seq2Seq classiques, en particulier celles qui n’utilisent pas de mécanisme d’attention, ont du mal à gérer de très longues séquences. Le vecteur de contexte doit résumer toute la séquence d’entrée en une seule représentation fixe, ce qui peut entraîner une perte d’information pour les longues phrases ou documents.</p><p>Pour cette même raison, les modèles Seq2Seq ont tendance à être biaisés vers les mots les plus récents dans la séquence d’entrée, ce qui peut affecter la qualité de la sortie, notamment pour les traductions ou résumés où l’ensemble de la phrase est important.</p><p>Par ailleurs, les réseaux Seq2Seq, en particulier lorsqu’ils sont combinés avec des mécanismes d’attention, peuvent être coûteux en termes de calcul, surtout pour des séquences longues et des modèles de grande taille. Même si cela est aussi le cas pour d’autres architectures comme les Transformers, le problème dans les Seq2Seq est que toutes les opérations ne sont pas parallélisables, ce qui rend l’entraînement d’un Seq2Seq difficile aussi bien sur GPU que sur CPU.</p><p>C’est pour pallier certaines de ces limites, des améliorations comme les mécanismes d’attention ou l’utilisation de <a href=\"https://larevueia.fr/introduction-aux-reseaux-de-neurones-transformers/\">Transformers</a> ont été introduites, rendant les modèles plus performants pour traiter des séquences longues et complexes.</p><p>Les Transformers introduisent des mécanismes comme la self-attention ou des méthodes qui rendent possible les calculs en parallèle.</p></div>"},
{"url": "https://larevueia.fr/deconfinement-le-role-de-lintelligence-artificielle-dans-le-maintien-de-la-distanciation-sociale/", "title": "Déconfinement : le rôle de l’intelligence artificielle dans le maintien de la distanciation sociale", "author": "Dr. Rajae Ghanimi", "date": "\n21 mai 2020\n", "content": "<div class=\"entry-content custom-excerpt\"><p>Le confinement est une solution qui a démontré son efficacité dans la lutte contre la propagation des épidémies, mais, elle reste toujours une solution psychologiquement lourde et économiquement très dommageable.</p></div>"},
{"url": "https://larevueia.fr/langchain-le-guide-essentiel/", "title": "LangChain: Le guide essentiel", "author": "Alexandre Lavallée", "date": "\n26 avril 2023\n", "content": "<div class=\"entry-content\"><p><em>Article co-écrit avec Ilyes Talbi</em></p><p>Nous allons voir dans cet article les fondamentaux de LangChain, pour une prise en main rapide de cette bibliothèque si particulière et si puissante pour quiconque s’intéressant aux modèles de languages, ou autres agents augmentés/chatbots et de leurs déploiements dans la sphère du développement grand public et du monde du business.</p><p>Bien que la bibliothèque n’en soit qu’à ses débuts, elle est déjà remplie de fonctionnalités incroyables permettant de construire des outils, des applications ou encore des plugin extraordinaires autour du cœur des modèles de language dernière génération comme GPT-4.</p><p>Note: une fois cet article lu, nous vous recommandons d’utiliser ce <a href=\"https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">notebook pour débutant sur langchain</a> pour reprendre tout les concepts mis en avant un à un par vous même — mis en place par le génial <a href=\"https://github.com/gkamradt\" target=\"_blank\" rel=\"noreferrer noopener\">Greg Kamradt</a>.</p><h2 class=\"wp-block-heading\">Aperçu des use-cases possibles avec LangChain</h2><ul class=\"wp-block-list\"><li>création et déploiement d’assistants personnels (agents)</li><li>création d’Agents autonomes (rendu à la mode avec Auto-GPT, BabyAGI etc)</li><li>mise en place de Q&amp;A sur vos documents propres (en local, vos pdf, drive, notion etc) avec récupération des sources exactes</li><li>création de résumés, d’analyses et de synthèses de tous vos documents et ce peu important la taille</li><li>création et personnalisation de Chatbots “vraiment” crédibles avec lesquels vous interagissez en language naturel</li><li>interrogation de vos données tabulaires</li><li>création de plugin personnalisés pour faire de la compréhension de votre code</li><li>interaction multiples et variés avec d’autres API (comme google search) pour combiner les LLM avec vos apps préférées</li><li>etc etc etc</li></ul><p>La liste est beaucoup plus longue, et en évolution permanente grâce à la flexibilité de LangChain d’interagir et de suivre les dernières évolutions du GenerativeAI.</p><h2 class=\"wp-block-heading\">Historique: L’émergence de LangChain</h2><p>Les grands modèles de langage (LLM) sont apparus sur la scène mondiale avec la publication du GPT-3 d’OpenAI en 2020. Depuis lors, leur popularité n’a cessé de croître avec le couronnement de <a href=\"https://larevueia.fr/chatgpt/\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> en Décembre 2022 propulsant les LLM sous les feux des projecteurs.</p><p>L’intérêt pour les LLM et la discipline plus large de l’IA générative est monté en flèche. Ce progrès est très rapide que l’on peut résumer comme suit :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*NjyH5uyad15dJBqMlsMswQ@2x.png\" alt=\"LangChain: Le guide essentiel\"></figure><p><a href=\"https://python.langchain.com/en/latest/\" rel=\"noreferrer noopener\" target=\"_blank\">LangChain</a> vient s’insérer à ce moment crucial de l’histoire ou la commodité des modèles de languages et leur efficacité les rend tout à fait matures pour être utilisées dans le monde applicatif. En d’autres termes, OpenAI a lancé le mouvement des modèles de language comme GPT-4 consumables via API, LangChain créée le pont entre le monde des applications et les modèles de language— qu’ils soient d’OpenAI ou votre propre version Open-Source <em>fine-tuné</em> d’un LLM comme celui de Stability.ai (<a href=\"https://github.com/Stability-AI/StableLM\" rel=\"noreferrer noopener\" target=\"_blank\">StableLM</a>).</p><h2 class=\"wp-block-heading\">La philosophie de LangChain</h2><p>La philosophie de LangChain est résumé par son fondateur <a href=\"https://twitter.com/hwchase17?lang=en\" rel=\"noreferrer noopener\" target=\"_blank\">Harrison Chase</a> comme suit:</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*XzYeDKpNWqU81Sw1sNtIeg@2x.png\" alt=\"LangChain: Le guide essentiel\"><figcaption class=\"wp-element-caption\">source: LangChain Python official doc</figcaption></figure><p>Ce qui est intéressant de prime abord, c’est ce parti pris très affirmé, les applications les plus radicales de demain utiliseront des modèles de language via API, et ces modèles de language pourront se renforcer:</p><ol class=\"wp-block-list\"><li>en “apprenant” de nouvelles sources de données non-vues lors de leur entraînement, mais aussi se connecter à d’autres flux de données via API</li><li>en “augmentant” leurs capacités en étant capable d’utiliser de nouveaux outils et d’interagir avec son propre environnement de données – le concept d’agents si cher à LangChain, que nous verrons en détail lors de cet article</li></ol><p>Si on fait un schéma, LangChain vient donc pouvoir s’interfacer avec de nouvelles données et vous permet de construire vos applications en unifiant le tout sous la bannière d’un modèle de language.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*ea1-4Tm0TCYGu0-rvXBiVg.png\" alt=\"LangChain: Le guide essentiel\"></figure><h2 class=\"wp-block-heading\">Les 3 concepts fondamentaux de LangChain</h2><p>Nous avons vu en introduction un petit aperçu des use-cases possibles avec LangChain comme pour les chatbots, les questions-réponses génératives (GQA), les résumés etc</p><p>L’idée centrale de la bibliothèque est que nous pouvons “enchaîner” différents composants pour créer des cas d’utilisation plus avancés autour des LLM. Les <strong>chaînes</strong> peuvent être constituées de plusieurs composants provenant de plusieurs modules :</p><h3 class=\"wp-block-heading\"><strong>Concept fondamental #1 Prompt Template :</strong></h3><p>ce sont des modèles ré-utilisables, des moules déjà faits permettant de réutiliser simplement et d’adapter ses prompts via un schéma pré-défini.</p><h3 class=\"wp-block-heading\"><strong>Concept fondamental #2 Agents :</strong></h3><p>les agents utilisent les LLM pour décider des actions à entreprendre. Des outils tels que la recherche sur le web ou les calculatrices peuvent être utilisés, et tous sont intégrés dans une boucle logique d’opérations.</p><h3 class=\"wp-block-heading\"><strong>Concept fondamental #3 Mémoire</strong> :</h3><p>Mémoire à court terme, mémoire à long terme pour les bots et agents que vous mettez en place, afin qu’ils se souviennent de leurs interactions passés avec vous.</p><h2 class=\"wp-block-heading\"><strong>Le principe des « Prompt Template »dans LangChain</strong></h2><p>Commençons par un exemple simple, afin de mettre en place un template de prompt pour effectuer de simple question-réponse avec le modèle GPT 3.5 d’OpenAI. Nous devons d’abord installer la bibliothèque LangChain</p><pre class=\"wp-block-code\"><code>!pip install langchain</code></pre><pre class=\"wp-block-code\"><code>from langchain import PromptTemplate\n\ntemplate = \"\"\"Voila la question d'un utilisateur: {question}\n\nDonnez votre Réponse: \"\"\"\nprompt = PromptTemplate(\n        template=template,\n    input_variables=['question']\n)\n\n# user question\nquestion = \"Qui a gagné la coupe du monde 2022 au Qatar ?\"</code></pre><p>Dans l’exemple ci-dessus, on ne fait simplement qu’injecter de manière dynamique le champ ‘question” dans le prompt.</p><pre class=\"wp-block-preformatted\">Voila la question d'un utilisateur: {\"Qui a gagné la coupe du monde 2022 au Qatar ?\"}<br>Donnez votre réponse</pre><p>ça n’a l’air de rien, mais c’est un des features clefs majeurs de LangChain, car c’est ce qui vous permet de construire votre propre use-case en utilisant la <em>composabilité</em> de l’outils et des prompts entre elles.</p><p>Les endpoints OpenAI dans LangChain se connectent à OpenAI directement. Vous aurez besoin d’un compte OpenAI et de <a href=\"https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\" rel=\"noreferrer noopener\" target=\"_blank\">votre clef secrète API</a> pour aller plus loin si vous souhaitez utiliser le modèle de language</p><p>Une fois que vous avez une clé API, nous l’ajoutons à la variable d’environnement OPENAI_API_TOKEN. Nous pouvons le faire avec Python comme suit :https://larevueia.fr/langchain-le-guide-essentiel/</p><pre class=\"wp-block-code\"><code>import os<br><br>os.environ['OPENAI_API_TOKEN'] = 'OPENAI_API_KEY'</code></pre><p>Ensuite, nous devons installer la bibliothèque OpenAI via Pip.</p><pre class=\"wp-block-code\"><code>!pip install openai</code></pre><p>Nous pouvons maintenant générer du texte en utilisant le template de prompt que nous avons créé dans la précédente partie. On va utiliser la capacité de génération (ou de complétion) de GPT-3 d’OpenAI. Nous utiliserons text-davinci-003, pas de panique c’est juste le nom de code de GPT-3.</p><pre class=\"wp-block-code\"><code>from langchain.llms import OpenAI<br><br>davinci = OpenAI(model_name='text-davinci-003')</code></pre><pre class=\"wp-block-code\"><code>llm_chain = LLMChain(<br>    prompt=prompt,<br>    llm=davinci<br>)<br><br>print(llm_chain.run(question))</code></pre><p>Et voila donc votre première chaîne, vous venez d’exécuter votre requête en utilisant la classe “template de prompt” (PromptTemplate) et en faisant appel à l’API d’OpenAI pour activer le modèle GPT 3.</p><p>Les classes de “template de prompt” de LangChain sont donc conçues pour faciliter la construction de prompts avec des entrées dynamiques.</p><p>Voyons un exemple un prompt un peu plus compliqué en l’apparence mais reposant sur le même méchanisme.</p><pre class=\"wp-block-code\"><code>from langchain import PromptTemplate<br><br>template = \"\"\"Répondez à la question en vous basant sur le contexte ci-dessous. <br>Si les informations fournies ne permettent pas de répondre à la question,<br>répondez par \"Je ne sais pas\".<br><br><br>Contexte additionnelle : Les grands modèles de langage (LLM) sont les modèles les plus récents utilisés dans le domaine du NLP.<br>Leurs performances supérieures à celles des modèles plus petits les ont rendus incroyablement utiles pour les développeurs d'applications NLP.<br>pour les développeurs d'applications NLP. Ces modèles<br>Ces modèles sont accessibles via la bibliothèque `transformers` de Hugging Face, via OpenAI<br>en utilisant la bibliothèque `openai`, et via Cohere en utilisant la bibliothèque `cohere`.<br><br>Question : {requête}<br><br>Réponse :\"\"\"<br><br>prompt_template = PromptTemplate(<br>    input_variables=[\"query\"],<br>    template=template<br>)</code></pre><p>Naturellement, nous pouvons passer la sortie de votre prompt_template directement dans un objet LLM comme ceci.</p><h2 class=\"wp-block-heading\">Le concept de <em>“few shot Prompt Template”</em>: LangChain et l’art de l’ingiénérie de prompt</h2><p>Le succès des LLM provient de leur grande taille et de leur capacité à stocker la “connaissance” dans les paramètres du modèle, le stock des connaissances est faite pendant la phase d’entraînement du modèle. Les deux méthodes principales pour transmettre des connaissances à un modèle de language sont les suivantes :</p><ul class=\"wp-block-list\"><li><strong>Connaissance paramétrique </strong>— la connaissance mentionnée ci-dessus est tout ce qui a été appris par le modèle pendant le temps de formation et est stocké dans les poids (ou paramètres) du modèle.</li><li><strong>Connaissance extérieure</strong>— toute connaissances complémentaires fournies au modèle au moment de l’inférence par l’intermédiaire des prompts</li></ul><p>Le modèle<em> F</em><a href=\"https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/few_shot_examples.html\" rel=\"noreferrer noopener\" target=\"_blank\"><em>ewShotPromptTemplate</em></a> de Langchain permet de spécialiser votre Bot, votre agent via des sources de connaissances extérieures, ou des indications d’exemples que vous donnez au modèle via vos prompts.</p><p>L’idée est d’”entraîner” le modèle sur quelques exemples que vous allez lui fournir — nous appelons cela l’apprentissage à la volée (Few Shot Learning) — et ces exemples sont donnés au modèle dans le prompt directement.</p><p>Cette capacité est très pratique et idéale lorsque notre modèle a besoin d’aide pour comprendre ce que nous lui demandons de faire. C’est ce que montre l’exemple suivant :</p><pre class=\"wp-block-code\"><code>prompt = \"\"\"Voici des extraits de conversations avec un assistant d'IA<br>assistant. L'assistant est généralement sarcastique et plein d'esprit, <br>produisant des réponses créatives et amusantes aux questions des utilisateurs. <br><br>Voici quelques exemples : <br><br>Utilisateur : Comment allez-vous ?<br>AI : Je n'ai pas à me plaindre, mais il m'arrive de le faire.<br><br>Utilisateur : Quelle heure est-il ?<br>IA : Il est temps d'acheter une montre.<br><br>Utilisateur : Quel est le sens de la vie ?<br>IA :\"\"\"<br><br>print(openai(prompt))</code></pre><p>Si nos exemples renforcent les instructions que nous avons données dans le prompt, nous avons beaucoup plus de chances d’obtenir une réponse plus amusante et comme nous le souhaitons. Nous pouvons ensuite formaliser ce processus avec le FewShotPromptTemplate de Langchain :</p><pre class=\"wp-block-code\"><code>from langchain import FewShotPromptTemplate<br><br># création de nos exemples perso pour base d'entrainement<br>examples = [<br>    {<br>        \"requête\": \"How are you?\",<br>        \"réponse\": \"I can't complain but sometimes I still do.\"<br>    }, {<br>        \"requête\": \"What time is it?\",<br>        \"réponse\": \"It's time to get a watch.\"<br>    }<br>]<br><br># création du template de nos exemples<br>example_template = \"\"\"<br>Utilisateur: {requête}<br>AI: {réponse}<br>\"\"\"<br><br># création d'un prompt d'example basé sur notre template ci-dessus<br>example_prompt = PromptTemplate(<br>    input_variables=[\"requête\", \"réponse\"],<br>    template=example_template<br>)<br><br># décomposons notre précédent prompt en deux parties<br># le prefix qui sont nos instructions<br>prefix = \"\"\"The following are exerpts from conversations with an AI<br>assistant. The assistant is typically sarcastic and witty, producing<br>creative  and funny responses to the users questions. Here are some<br>examples: <br>\"\"\"<br># et le suffix qui sont la requête en input de notre utilisateur et l'indicateur de sorties<br>suffix = \"\"\"<br>Utilisateur: {requête}<br>AI: \"\"\"<br><br># now create the few shot prompt template<br>few_shot_prompt_template = FewShotPromptTemplate(<br>    examples=examples,<br>    example_prompt=example_prompt,<br>    prefix=prefix,<br>    suffix=suffix,<br>    input_variables=[\"requête\"],<br>    example_separator=\"\\n\\n\"<br>)</code></pre><p>Naturellement, le prompt est l’élement incontournable et essentiel du monde merveilleux des LLM. Il vaut la peine d’explorer les <a href=\"https://python.langchain.com/en/latest/modules/chains/how_to_guides.html\" target=\"_blank\" rel=\"noreferrer noopener\">outils</a> disponibles dans LangChain et de se familiariser avec les différentes techniques d’ingénierie de prompts.</p><p>Ici, nous n’avons couvert que quelques exemples d’outils disponible dans Langchain pour manipuler et créer vos prompts pour répondre à votre use-case précis. Dans la prochaine section, nous explorerons une autre partie essentielle de Langchain — appelée “Agents”.</p><h2 class=\"wp-block-heading\"><strong>Le concept fondamental #2 </strong>de LangChain : les Agents</h2><p>Bien que très performants dans pas mal de cas, les LLM ont des limitations majeures, et une en particulier qui les rend inutilisable dans certains cas.</p><p>Ils ne sont pas capables de donner des réponses toujours justes, sont limités aux informations vues pendant leur training, ont tendance à extrapoler sur plusieurs sujets et sont moins bons sur des choses simples comme le calcul.</p><p>Une solution à ces problèmes est proposée par Langchain avec le concept d’agents.</p><h3 class=\"wp-block-heading\"><strong>Qu’est-ce qu’un agent concrètement ?</strong></h3><p>Les agents peuvent être considérés comme des “outils” permettant aux LLMs de fonctionner. Tout comme un humain utiliserait une calculatrice pour les mathématiques ou effectuerait une recherche Google pour obtenir des informations, les agents permettent à un LLM d’étendre ses capacités en faisant la même chose.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*hT2cpiCY6EmnoLmE.png\" alt=\"LangChain: Le guide essentiel\"><figcaption class=\"wp-element-caption\"><a href=\"https://www.pinecone.io/learn/langchain-agents/\" rel=\"noreferrer noopener\" target=\"_blank\">source: LangChain AI handbook de Pinecone</a></figcaption></figure><p>En utilisant des agents, un LLM peut écrire et exécuter du code Python, utiliser une calculatrice. Il peut également rechercher des informations et interroger une base de données SQL.</p><p>Imaginez toutes les applications qui peuvent en découler !</p><h3 class=\"wp-block-heading\"><strong>Comment fonctionnent les agents en pratique ?</strong></h3><p>On va faire un exemple très concret en utilisant Python.</p><p>Pour utiliser les agents on doit avoir un modèle de langage de base, on va utiliser davinci d’OpenAI ici, un “outil” au sens de LangChain et un agent qui va contrôler l’interaction entre les 2.</p><p>Commençons par initialiser notre LLM :</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><pre class=\"wp-block-code\"><code>from langchain import OpenAI</code></pre><pre class=\"wp-block-code\"><code>llm = OpenAI(<br>    openai_api_key=\"OPENAI_API_KEY\",<br>    temperature=0,<br>    model_name=\"text-davinci-003\"<br>)</code></pre></blockquote><p>On va maintenant initialiser l’outil, qui peut être un outil déjà développé par LangChain ou un outil custom que vous pouvez créer.</p><p>Ici, on va utiliser l’outil llm_math, qui va permettre de faire des opérations mathématiques :</p><pre class=\"wp-block-code\"><code>from langchain.agents import load_tools</code></pre><pre class=\"wp-block-code\"><code>tools = load_tools(<br>    ['llm-math'],<br>    llm=llm<br>)</code></pre><p>Le 3ème ingrédient, c’est l’agent, qui va gérer la connexion entre le llm et l’outil.</p><p>On initialise l’agent de cette manière :</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><pre class=\"wp-block-preformatted\">from langchain.agents import initialize_agent</pre><pre class=\"wp-block-preformatted\">zero_shot_agent = initialize_agent(<br>    agent=\"zero-shot-react-description\",<br>    tools=tools,<br>    llm=llm,<br>    verbose=True,<br>    max_iterations=3<br>)</pre></blockquote><p>L’agent utilisé <em>zero-shot-react-description</em> repose sur le framework ReAct (Reasoning + Acting), proposé en 2022, dans <a href=\"https://arxiv.org/abs/2210.03629https://arxiv.org/abs/2210.03629\" rel=\"noreferrer noopener\" target=\"_blank\">ce papier</a> de recherche.</p><p>C’est le framework qui va permettre au LLM de determiner quelle action il doit effectuer en fonction du prompt de l’utilisateur et des descriptions des outils auxquels il accès.</p><p>On peut tester notre agent :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Combient fait (4.5*2.1)^2.2 ?\")</code></pre><p>Et voici le résultat obtenu :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*6qbB9-QPOo31F8HI8Ltlig.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>En laissant verbose à <em>True</em>, on peut voir comment l’agent “raisonne” étape par étape.</p><p>On peut faire un nouvel exemple dans lequel on va aller un peu plus loin niveau raisonnement :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Si Marie a 4 pommes et Georges en apporte 2\"<br>                \"et une moitié de boîte\"<br>                \"(une boîte contient 8 pommes), combien a-t-on de pommes ?\")</code></pre><p>L’agent réussi parfaitement bien le test, voici sa réponse :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*opLj05T4rJmJgCgLaVePCQ.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Si vous avez bien suivi notre raisonnement, vous comprendrez qu’il manque quelque chose.</p><p>Notre agent, pour le moment, n’a accès qu’à un seul outil, qui est l’outil de calcul, à chaque requête il va tenter de l’utiliser ce qui peut renvoyer des erreurs lorsqu’il n’y a pas de calculs à effectuer.</p><p>Par exemple :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Quelle est la capitale de la Norvége ?\")</code></pre><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*zoH3lP6sU69hAXultDNZBg.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Pour résoudre ce problème, on peut ajouter l’outil de modèle de langage à notre agent.</p><p>On commence par initialiser l’outil :</p><pre class=\"wp-block-code\"><code>from langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.agents import Tool\n\nprompt = PromptTemplate(\n    input_variables=[\"query\"],\n    template=\"{query}\"\n)\n\nllm_chain = LLMChain(llm=llm, prompt=prompt)\n\n# initialize the LLM tool\nllm_tool = Tool(\n    name='Language Model',\n    func=llm_chain.run,\n    description='use this tool for general purpose queries and logic'\n)</code></pre><p>On l’ajoute ensuite à la “boîte à outils” de notre agent et on le réinitialise :</p><pre class=\"wp-block-preformatted\">tools.append(llm_tool)</pre><pre class=\"wp-block-code\"><code># reinitialize the agent<br>zero_shot_agent = initialize_agent(<br>    agent=\"zero-shot-react-description\",<br>    tools=tools,<br>    llm=llm,<br>    verbose=True,<br>    max_iterations=3<br>)</code></pre><p>Si on repose la question :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Quelle est la capitale de la Norvége ?\")</code></pre><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*pY5i_qWO934rr6DY0pmALA.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>A présent nous avons la bonne réponse, l’agent décide de prendre comme action par lui même d’utiliser le modèle de language qui contient la réponse à cette question dans les poids du modèle.</p><h3 class=\"wp-block-heading\"><strong>Quels sont les différents agents ?</strong></h3><p>Comme nous l’avons vu dans les 2 premières parties, les agents utilisent un LLM pour déterminer quelles actions entreprendre et dans quel ordre.</p><p>Une action peut consister à utiliser un outil et observer sa sortie, ou retourner une réponse à l’utilisateur.</p><p>Voici les agents qui sont disponibles dans LangChain de façon native :</p><ul class=\"wp-block-list\"><li><em>zero-shot-react-description</em></li></ul><p>Cet agent utilise le framework ReAct, que j’ai mentionné plus haut, pour déterminer l’outil à utiliser en se basant sur la description de l’outil. On peut utiliser plusieurs outils avec cet agent et il n’y a pas de limites de nombre, il faut par contre qu’une description soit fournie pour chacun des outils sélectionnés.</p><ul class=\"wp-block-list\"><li><em>react-docstore</em></li></ul><p>Cet agent utilise le framework ReAct pour interagir avec un docstore (un ensemble de documents). Deux outils doivent être fournis : un outil de recherche (Search tool) et un outil de consultation (Lookup tool) (ils doivent être nommés exactement comme cela). L’outil de recherche doit rechercher un document, tandis que l’outil de consultation doit rechercher un terme dans le document le plus récemment trouvé. Cet agent est équivalent à l’article ReAct original, spécifiquement l’exemple de Wikipédia.</p><ul class=\"wp-block-list\"><li><em>self-ask-with-search</em></li></ul><p>Cet agent utilise un seul outil qui doit être nommé Intermediate Answer. Cet outil doit être capable de rechercher des réponses factuelles aux questions. Cet agent est équivalent à l’article original self ask with search, où une API de recherche Google était fournie en tant qu’outil.</p><ul class=\"wp-block-list\"><li><em>conversational-react-description</em></li></ul><p>Cet agent est conçu pour être utilisé dans des contextes conversationnels. L’invite est conçue pour rendre l’agent utile et conversationnel. Il utilise le framework ReAct pour décider quel outil utiliser et se sert de la mémoire pour se souvenir des interactions de conversation précédentes.</p><h2 class=\"wp-block-heading\">Le concept fondamental #3 « Memory » décortiqué</h2><p>Une des grandes forces de ChatGPT, et des Transformers en général, réside dans leur capacité à garder les informations en mémoire.</p><p>On avait ce comportement avec les LSTM mais c’était une mémoire court-terme qui fonctionnait le temps d’une phrase ou d’un court paragraphe.</p><p>C’est un comportement que l’on peut reproduire avec LangChain.</p><p>Par défaut les chains et les agents LangChain n’ont pas de mémoires, mais il y a des composantes proposer pour gérer les messages précédents.</p><p>Néanmoins, les interactions entre l’utilisateur et le modèle de langage peuvent être gardées en mémoire grâce au ChatMessages et construite avec les ConversationChains.</p><p>La mémoire peut renvoyer plusieurs éléments d’information (par exemple, les N messages les plus récents et un résumé de tous les messages précédents). Les informations renvoyées peuvent être une chaîne de caractères ou une liste de messages.</p><p>Nous allons décortiquer quelques types de mémoires ensemble, n’hésitez pas à creuser d’avantage le sujet avec ces <a href=\"https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\" rel=\"noreferrer noopener\" target=\"_blank\">tutoriels</a> mis en ligne par LangChain.</p><h3 class=\"wp-block-heading\"><strong>Le concept de ConversationChain</strong> dans LangChain</h3><p>On va commencer par initialiser notre modèle de langage, on utilise GPT-3.5 pour cet exemple.</p><pre class=\"wp-block-code\"><code>from langchain import OpenAI\nfrom langchain.chains import ConversationChain\n\n# first initialize the large language model\n\nllm = OpenAI(\n\ttemperature=0,\n\topenai_api_key=\"OPENAI_API_KEY\",\n\tmodel_name=\"gpt-3.5-turbo\"\n)</code></pre><p>On initialise ensuite la ConversationChain :</p><pre class=\"wp-block-code\"><code># now initialize the conversation chain<br>conversation = ConversationChain(llm=llm)</code></pre><p>Si on affiche l’objet conversation, voici ce qu’on a :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*LG3PiK8CGWxTvuz-8Chwxw.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>L’utilisateur est défini par “Human” et l’agent par “AI”. Après le prompt initial, nous voyons deux paramètres ; <strong>{history}</strong> et <strong>{input}</strong>.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*_FJu_49tOczk0KwTvTd2DQ.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Le paramètre<strong> {input}</strong> est l’endroit où nous placerions la dernière requête humaine ; il s’agit de l’entrée saisie dans une zone de texte du chatbot. Ici {history} fait donc référence à la conversation initiée avec GPT comme montré ci-dessus.</p><p>Les différentes types de mémoires</p><p>Comme l’humain a différentes mémoires (sensorielle, visuelle, sonore etc), nous pouvons utiliser plusieurs types de mémoire conversationnelle avec la <em>ConversationChain</em>. En fonction du type de mémoire choisie, le texte passé au paramètre {history} changera. On peut lister</p><h3 class=\"wp-block-heading\">Type de mémoire #1: ConversationBufferMemory</h3><p>La mémoire tampon de conversation (ConversationBufferMemory en anglais) fait exactement ce que son nom suggère : elle conserve une mémoire tampon des extraits de conversation précédents dans le cadre du contexte du prompt.</p><p><strong>Caractéristique Principale : </strong>la mémoire tampon de conversation conserve les éléments de conversation précédents sans aucune modification, dans leur forme brute.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*ErLc3N4e7L91gJ4C3EZ_Fg.png\" alt=\"LangChain: Le guide essentiel\"></figure><h3 class=\"wp-block-heading\">Type de mémoire #2: ConversationSummaryMemory</h3><p>Le problème avec la mémoire tampon de la conversation est qu’au fur et à mesure que la conversation progresse, le nombre de jetons (tokens) de l’historique du contexte augmente. C’est un problème parce que nous pourrions épuiser notre LLM avec une prompt qui est trop grande pour être traitée. Pour rappel les longs historiques de conversations ne peuvent pas être mémorisées car nous avons une limite de jetons lorsqu’on utilise un LLM comme ChatGPT (4096 jetons pour text-davinci-003 et gpt-3.5-turbo).</p><p>Pas de panique, il y a une solution avec<em> ConversationSummaryMemory.</em></p><p>Encore une fois, nous pouvons déduire du nom ce qui se passe… nous allons conserver un résumé de nos bribes de conversation précédentes comme historique. Comment allons-nous les résumer ? LLM à la rescousse.</p><p><strong>Caractéristique Principale:</strong> la mémoire de résumé de conversation conserve les bribes de conversation précédentes sous une forme résumée, le résumé étant effectué par votre LLM.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*MrKDQ5XRH3ppl3F9_Q4iKA.png\" alt=\"LangChain: Le guide essentiel\"></figure><h3 class=\"wp-block-heading\">Type de mémoire #3: ConversationBufferWindowMemory</h3><p>Une autre option intéressante pour ces cas est le <em>ConversationBufferWindowMemory</em> où nous conserverons quelques-unes des dernières interactions dans notre mémoire, mais où nous laisserons intentionnellement tomber les plus anciennes — une mémoire à court terme si vous voulez. Ici, le nombre de jetons agrégés et le nombre de jetons par appel diminueront sensiblement.</p><p>Si nous n’avons besoin que de la mémoire des interactions récentes, c’est une excellente option.</p><p><strong>Caractéristique Principale </strong>: la mémoire tampon de la conversation conserve les derniers éléments de la conversation sous forme brute.</p><p>Vous pouvez voir une analyse comparative détaillée sur ce <a href=\"https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/03a-token-counter.ipynb\" rel=\"noreferrer noopener\" target=\"_blank\">notebook</a> proposé par Pinecone.</p><p>Il existe bien d’autres types de mémoires, nous voulions simplement vous en proposer quelques unes, pour aller plus loin c’est <a href=\"https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\" rel=\"noreferrer noopener\" target=\"_blank\">ici</a>.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>LangChain fournit un ensemble complet d’outils, de fonctionnalités et de capacités qui simplifient le processus de combinaison des LLM avec des sources de données externes et des outils via API, ce qui rend plus facile que jamais l’exploitation de la pleine puissance des LLM et la mise en œuvre de solutions et d’apps révolutionnaires. Grâce à la prise en charge intégrée de divers fournisseurs de LLM, d’outils de gestion de prompts, de chaînes, d’agents et d’évaluation, LangChain ouvre la voie aux développeurs pour créer des applications sophistiquées, spécifiques à un domaine, qui maximisent le potentiel des LLM.</p><p>Une des voies les plus prometteuses semblent la création d’agents autonomes, des projets comme Auto-GPT ou BabyAGI (qui sont d’ailleurs supportés par Langchain)</p><p>Concrètement, vous avez plus de use-cases ?</p><p>Yes ser — <a href=\"https://www.twitter.com/mattprd?utm_source=www.mattprd.com&amp;utm_medium=referral&amp;utm_campaign=the-complete-beginners-guide-to-autonomous-agents\" rel=\"noreferrer noopener\" target=\"_blank\">Matt Schlicht</a>, CEO d’Octane AI, que nous vous recommandons de suivre et de lire, propose la petite analyse suivante des cas possibles ou LangChain devient hyper pertinent:</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*Ss07UdgIep5zuQf4.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Voilà on espère que ça vous a plu, et on vous dit à bientôt pour des tutoriels hands-on dédiés à LangChain maintenant que nous avons vu la théorie et les grands concepts fondamentaux ensemble.</p><h3 class=\"wp-block-heading\">Nos recos de YouTube Playlists</h3><ol class=\"wp-block-list\"><li><a href=\"https://www.youtube.com/watch?v=_v_fgW2SkkQ&amp;list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5&amp;index=1\" rel=\"noreferrer noopener\" target=\"_blank\">Aperçu complète de LangChain par la chaîne “Data Independant”</a></li><li><a href=\"https://www.youtube.com/watch?v=nE2skSRWTTs&amp;list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F\" rel=\"noreferrer noopener\" target=\"_blank\">Les tutos de James Briggs — évangéliste pour LangChain et Pinecone</a></li><li><a href=\"https://youtube.com/playlist?list=PLqQrRCH56DH82KNwvlWpgh3YJXu461q69\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI — Streamlit Web Apps</a></li><li><a href=\"https://youtube.com/playlist?list=PLqQrRCH56DH8JSoGC3hsciV-dQhgFGS1K\" rel=\"noreferrer noopener\" target=\"_blank\">Streamlit-Python-Tutorials</a></li></ol><h3 class=\"wp-block-heading\">Liens et crédits:</h3><ol class=\"wp-block-list\"><li>LangChain Docs : <a href=\"https://langchain.readthedocs.io/en/latest/index.html\" rel=\"noreferrer noopener\" target=\"_blank\">https://langchain.readthedocs.io/en/latest/index.html</a></li><li><a href=\"https://www.pinecone.io/learn/langchain/\" rel=\"noreferrer noopener\" target=\"_blank\">Pinecone AI handbook</a> (massive respect to James Brigg and the pinecone team for this)</li><li>LangChain GitHub Repo : <a href=\"https://github.com/hwchase17/langchain\" rel=\"noreferrer noopener\" target=\"_blank\">https://github.com/hwchase17/langchain</a></li><li><a href=\"https://platform.openai.com/docs/api-reference/completions/create#completions/create-stream\" rel=\"noreferrer noopener\" target=\"_blank\">Open AI document</a></li><li><a href=\"https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents\" rel=\"noreferrer noopener\" target=\"_blank\">Matt schlicht blog sur les agents autonomes</a></li></ol></div>"},
{"url": "https://larevueia.fr/la-revue-ia-est-partenaire-du-salon-ai-big-data-paris/", "title": "La revue IA est partenaire du salon AI & Big Data Paris", "author": "Ilyes Talbi", "date": "\n2 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Plus de 15 000 porteurs de projets, startups et leaders de la tech participent à l’évènement n°1 en France dédié à l’intégration du big data et de l’intelligence artificielle en entreprise !</p><p>Pour cette 11ème édition du congrès Big Data &amp; AI Paris, reconnu par l’ensemble des acteurs de la scène tech’ française comme le rendez-vous le plus important de cette rentrée 2022, plus de 700 speakers, 250 entreprises exposantes et 100 partenaires ont déjà répondu présents.</p><p>Offrant une programmation de choix aux directions et métiers en quête d’impact tangibles et singuliers sur leurs Big Data &amp; AI journey.</p><p>Avec son positionnement unique de « facilitateur d’adoption » résolument orienté sur le partage de bonnes pratiques utiles, sans langues de bois et créatrices de valeurs entre pairs, Big Data &amp; AI Paris ne cesse de prendre de l’ampleur auprès des métiers qui portent le big data et l’intelligence artificielle au quotidien. </p><p>Cette concentration jamais vue en France de personnalités, startups, talents, fournisseurs de solutions ou encore poids lourds de la tech’, fait aujourd’hui de Big Data &amp; AI Paris la 1<sup>ère</sup> place de marché hexagonale où il faut être. </p></div>"},
{"url": "https://larevueia.fr/compte-rendu-de-lai-et-big-data-paris-corp/", "title": "Compte rendu de l’AI et Big Data Paris Corp", "author": "Ilyes Talbi", "date": "\n17 septembre 2020\n", "content": "<div class=\"entry-content\"><figure class=\"wp-block-image alignfull size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"631\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-1024x631.jpg\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-2139\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-1024x631.jpg 1024w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-300x185.jpg 300w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-768x473.jpg 768w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-1536x946.jpg 1536w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-2048x1262.jpg 2048w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-404x250.jpg 404w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-scaled.jpg 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Les participants sont unanimes, la data c’est l’argent et le pouvoir ! Et vous qu’en pensez-vous ?</figcaption></figure><p>Les 14 et 15 septembre se tenait l’<a href=\"https://aiparis.fr/2020/\" target=\"_blank\" rel=\"noreferrer noopener\">AI Paris Corp</a> au parc des expositions de la porte de Versailles. C’était l’occasion pour les acteurs de l’IA en France de se réunir de nouveau après un long moment. Ça m’avait manqué !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Malgré la situation sanitaire, les organisateurs ont tenus à garder le format classique de l’événement. Les participants qui le souhaitaient pouvaient assister à l’événement en ligne.</p><p>C’était ma première expérience d’un événement hybride. Et je pense que c’est un format très intéressant. Mis à part un bug des serveurs lundi après-midi, la plateforme semble avoir fonctionné correctement. Bonne nouvelle, car je pense que ce genre de format va se démocratiser !</p><p>Le salon était divisé en deux parties : <em>big data</em> et <em>intelligence artificielle</em>. Ne pouvant pas être sur tous les fronts, je me suis naturellement concentré sur la partie IA.</p><p>Comme d’habitude dans les événements Corp, les speakers étaient de grandes qualités et de nombreuses entreprises étaient représentées comme Airbus, Microsoft ou encore IBM.</p><h2 class=\"wp-block-heading\">Le NLP et l’explicabilité à l’honneur</h2><p>L’événement couvrait un large champ de domaines de l’intelligence artificielle. Mais l’accent a été mis sur le NLP et l’explicabilité des modèles de machine learning.</p><h3 class=\"wp-block-heading\">En 2021 on mise tout sur l’explicabilité !</h3><p>ENFIN ! <br>Les dirigeants de grandes entreprises ont enfin compris ! <a href=\"https://larevueia.fr/explicabilite-des-modeles-ne-croyez-pas-aveuglement-ce-que-lia-vous-dit/\" target=\"_blank\" rel=\"noreferrer noopener\">L’explicabilité</a> des modèles est devenue une priorité pour certains.</p><p>Que ce fut dur !</p><p>L’explicabilité n’est plus un simple <em>buzz word</em>, des actions concrètes sont misent en oeuvre pour rendre les IA explicables. Même si les solutions proposées sont encore à améliorer, je suis content de voir qu’il y a une réelle prise de conscience. Beaucoup sont prêts à investir dans ce sens et plusieurs conférenciers abordaient le sujet.</p><h3 class=\"wp-block-heading\">Le NLP vole la vedette aux systèmes de computer vision</h3><p>Depuis que j’assiste à des conférences sur le machine learning, la star incontestée était la computer vision. Les exposants ressortaient à chaque fois leurs systèmes de reconnaissances faciales, leurs outils de reconnaissances d’objets et tous ces gadgets. C’est vrai que ces sujets sont très importants, mais ça fait 2-3 ans qu’on a pas vraiment progressé dans ce domaine.</p><p>Cette fois c’était différent. Le <a href=\"https://larevueia.fr/nlp/\" target=\"_blank\" rel=\"noreferrer noopener\">NLP</a> avait une plus grande place, et comme j’aime ça (pas plus que la computer vision non plus haha), je n’ai pas été déçu 🙂 . Il semblerait que l’impact de <a href=\"https://larevueia.fr/introduction-a-gpt-3-lun-des-modeles-de-nlp-les-plus-avances/\" target=\"_blank\" rel=\"noreferrer noopener\">GPT-3</a> se fait ressentir dans les grands événements !</p><h2 class=\"wp-block-heading\">Les entreprises cool 😎</h2><p>L’événement était une bonne occasion de rencontrer certaines entreprises de l’intelligence artificielle. Voici celles que j’ai retenus !</p><h3 class=\"wp-block-heading\">Malinblack : la solution française pour sécuriser les communications internes</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"1024\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-1024x1024.png\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-2162\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-1024x1024.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-300x300.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-150x150.png 150w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-768x768.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-1536x1536.png 1536w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-2048x2048.png 2048w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-500x500.png 500w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>J’ai eu la chance de rencontrer Thomas Kerjean. Il est le CEO de <a href=\"https://www.mailinblack.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Mailinblack</a>. Passé par ReciTal et Accenture, il a été responsable de la branche Cloud et IA chez Microsoft pendant prés de 3 ans. Autant dire que sur l’intelligence artificielle, cet homme avait des choses à m’apprendre ! Il a pris les commandes de l’entreprise marseillaise en 2019, au même moment l’entreprise faisait une levée de fonds de 14M€.</p><p>Mailinblack propose des solutions pour sécuriser les communications par mail en entreprise. Une entreprise de cybersécurité classique me direz-vous. Sauf que Mailinblack mise tout sur le deep learning pour développer son produit. Au moins 30% de son effectif travaille sur des problématiques de machine learning, ils font surtout de la R&amp;D.</p><p>J’attendais la conférence de Thomas Kerjean ‘<em>Protéger ses données personnelles grâce au machine learning et au deep learning</em>‘ avec impatience. Mais la plateforme a planté au même moment et j’attends toujours de recevoir les rediffusions… Vous serez tenus au courant.</p><h3 class=\"wp-block-heading\">TIBCO : l’IA de Lewis Hamilton, rien que ça !</h3><p>Mon cœur palpite à chaque fois que je découvre de nouvelles applications du machine learning. Non je n’exagère pas 🙂 . Et c’est d’autant plus vrai lorsque ça touche au domaine du sport.</p><p>J’ai rencontré <a href=\"https://www.tibco.com/formula-one-competitive-advantage\" target=\"_blank\" rel=\"noreferrer noopener\">TIBCO</a> pendant le salon. Ils proposent des solutions de traitements de données aux entreprises. Et à travers l’outil Sportfire, un de leurs clients est Mercedes-AMG Petronas. C’est la meilleure écurie de Formule 1, celle de Lewis Hamilton.</p><p>Ils récupèrent en direct des données pendant la course pour assister la prise de décisions. Quand faut-il changer les roues ? Quelle stratégie de conduite adopter ? Et plein d’autres questions auquel le machine learning sait répondre.</p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Mercedes AMG Petronas Motorsport Handles Constant Change\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/bKdpWF95cFo?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div><figcaption>Présentation du partenariat TIBCO-Mercedes</figcaption></figure><blockquote class=\"wp-block-quote is-style-default is-layout-flow wp-block-quote-is-layout-flow\"><p>Pour gagner vous devez comprendre ce qui est important et ce qui ne l’est pas. Nous devons nous assurer de prendre la bonne décision au bon moment.</p><cite>James Vowles, Directeur de la Stratégie chez Mercedes-AMG Petronas</cite></blockquote><h3 class=\"wp-block-heading\">Talend calcule le Trust score : un score de confiance pour vos données</h3><p>Pour entraîner des modèles fiables et robustes, il faut des données propres, non biaisés et qui respectent certaines règles. Malheureusement pour la majorité des projets on a très peu d’indicateurs de fiabilité pour nos données.</p><p>Pour résoudre ce problème, <a href=\"https://www.talend.com/fr/\" target=\"_blank\" rel=\"noreferrer noopener\">Talend</a> a crée une mesure de fiabilité des données, le Trust Score. Ce score permet de donner un indicateur de la confiance qu’une entreprise peut avoir vis à vis de ses données. Ils permettent au passage de résoudre un paradoxe réel lorsque l’on traite des données en entreprise. Les données permettent de créer des mesures et des KPI pour tout ce qui est mesurable, mais nous ne disposons d’aucun KPI qui nous permette d’évaluer nos données.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"693\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-1024x693.png\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-2164\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-1024x693.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-300x203.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-768x520.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data.png 1200w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Trust Score pour mesurer la qualité des données</figcaption></figure></div><p><br><br>Pour conclure, cette expérience m’a permis de voir que de réels progrès sont faits. L’intelligence artificielle qui n’était autre fois qu’un argument marketing dont les journalistes raffolaient, est en train de devenir un vrai moteur de croissance pour beaucoup. Les solutions sont de mieux en mieux et les stratégies de traitements de données sont de plus en plus robustes.</p><p>A l’échelle du pays aussi l’IA progresse. Plusieurs initiatives ont permis de créer une stratégie globale de développement de l’IA en France. Finalement l’Europe pourra peut-être un jour rattraper son retard sur les Etats-Unis et la Chine…</p></div>"},
{"url": "https://larevueia.fr/la-revue-ia-est-partenaire-du-salon-ai-big-data-paris-2/", "title": "La revue IA est partenaire du salon AI & Big Data Paris", "author": "Ilyes Talbi", "date": "\n18 septembre 2023\n", "content": "<div class=\"entry-content\"><p>La 12ème édition du congrès Big Data &amp; AI Paris ouvrira ses portes les 25 &amp; 26 septembre 2023 au Palais des Congrès de Paris autour d’une promesse ambitieuse : <em>offrir aux décideurs et acteurs de l’écosystème 2 jours immersifs dans l’univers du Big Data et de l’intelligence artificielle en France.</em></p><p>Avec plus de 350 conférences et ateliers, 250 entreprises exposantes et 16 000 participants, Big Data &amp; AI Paris offrira une occasion unique de découvrir en avant-première les dernières tendances du marché et d’échanger avec l’ensemble des professionnels de la data et de l’intelligence artificielle en France.</p><p>Il s’agit du plus grand événement dédié à l’intelligence artificielle et aux data en Europe.</p><p>J’y serais les 2 jours, et je monte sur scène Mardi 26 pour parler de documentation interne d’entreprise à l’heure de ChatGPT et des LLM.</p><p><a href=\"https://www.bigdataparis.com/fr\" target=\"_blank\" rel=\"noreferrer noopener\">Rejoindre l’évènement.</a></p></div>"},
{"url": "https://larevueia.fr/compte-rendu-de-big-data-ai-paris-2023/", "title": "Compte rendu de Big Data & AI Paris 2023", "author": "Ilyes Talbi", "date": "\n4 octobre 2023\n", "content": "<div class=\"entry-content\"><p>Cette année le salon BigData &amp; AI Paris, partenaire de La revue IA pour la 2ème année, a connu un record en termes de fréquentation. D’après les organisateurs, 16 500 visiteurs (dont 1000 en ligne) ont participé à cette 12ème édition qui a eu lieu les 25 et 26 septembre 2023, au Palais des Congrès de Paris.</p><p>Cet événement qui réunit des experts du Big Data et de l’IA est organisé autour de conférences, ateliers techniques, et expositions de professionnels.</p><h2 class=\"wp-block-heading\"><em>Organisation du salon</em></h2><p>Les conférences sont organisées selon 3 parcours : les conférences stratégiques, les retours d’expériences business, et l’expertise. </p><p>La particularité de cet événement est de mettre en avant le travail d’experts et ainsi saisir les applications réelles des outils d’IA et du Big Data dans la vie quotidienne des entreprises, notamment à travers les conférences “retour d’expériences business”.</p><p>Les ateliers quant à eux portent sur des sujets techniques et sont plutôt orientés “pratique”. A l’exception de tout de même de certains ateliers qui questionnent sur l’éthique à l’instar de celui de  l’association Latitudes “la bataille de l’IA” (sous forme de jeux permettant un débat entre les participants, très intéressant au passage) ou celui de “Women in Big Data” qui se demandent comment l’IA peut-être plus responsable et contribuer à un monde plus “désirable”.</p><p>Quant aux 250 exposants, ils venaient de plusieurs domaines et de tous horizons : à la fois de grosses entreprises et des start-ups, en passant par des écoles (ESCP …)</p><h2 class=\"wp-block-heading\"><em>Tour d’horizon des principaux thèmes  abordés cette année</em></h2><p>Une balade entre les différentes conférences, ateliers et exposants nous permet de nous imprégner de la tendance actuelle en termes de Big Data et d’IA.</p><p>Contrairement à ce à quoi nous aurions pu nous attendre, les IA génératives n’étaient pas le principal sujet du salon. En effet, étant donné tout le vacarme médiatique autour de ChatGPT, que ce soit dans les médias mainstream ou bien chez les créateurs de contenus, nous aurions imaginé un salon axé sur la thématique des IA génératives et notamment la partie LLM (large language models).</p><p>Même si le sujet a été abordé, il a laissé, cette année encore, la place à des solutions pour les entreprises basées sur des technologies déjà existantes et en production depuis quelques années comme les systèmes de détection de faille sur les chaines de production ou les solutions de structuration et stockage de données.</p><p>Ce qui ressort principalement de ces conférences, ce sont les questions de l’impact du Big Data et plus précisément cette année de l’IA avec ChatGPT, sur notre société. Ainsi, la régulation de l’IA, la sécurisation de nos données, l’impact écologique et enfin la transformation des métiers par l’IA ont été les thèmes centraux du parcours “conférences stratégiques”.</p><p>L’intervention de Luc Julia a permis notamment d’aborder le thème des “Promesses et réalités des IA génératives”.</p><p>Lors de ce salon, que ce soit au niveau des exposants ou des conférences type “retours d’expériences business Big Data &amp; IA” il a plutôt été question de solutions très orientées business avec des résolutions de problèmes rencontrés au quotidien par les entreprises.</p><p>On peut citer à titre d’exemple l’intervention de Technip en collaboration avec Google. Ces deux entreprises ont collaboré ensemble pour s’aider de l’IA afin de gérer la documentation de Technip, et cela a pris plus de 2 ans de travail d’équipe.</p><h2 class=\"wp-block-heading\"><em>“Les data, le Big Data, l’IA…mais l’humain avant tout”</em></h2><p>On constate que même si les outils sont considérés comme puissants, il n’empêche que des équipes importantes qui travaillent des années sont nécessaires pour trouver et déployer des solutions dans un contexte d’entreprise.</p><p>A l’heure actuelle les entreprises concentrent leurs efforts afin de remettre l’humain au centre, en redonnant notamment aux métiers l’accès aux outils. </p><p>La notion de self-service est remise à l’ordre du jour, alors que la tendance était plutôt de laisser les experts des données gérer et exploiter les données des entreprises. </p><p>Les outils sont devenus tellement <em>user-friendly</em> que de plus en plus d’entreprises, même traditionnelles comme Pierre Fabre, ont décidé de mettre en place des stratégies et des solutions afin que leurs employés puissent eux-mêmes les utiliser. </p><p>Désormais, les entreprises préfèrent éliminer au maximum les biais liés au traitement des données par des personnes qui ne sont pas du métier. Plusieurs entreprises ont aussi décidé, afin d’éviter l’effet shadow IT, comme celui lié à ChatGPT et aux outils qui en découlent, de mettre l’accent sur la formation et l’accompagnement du personnel. </p><p>Luc Julia a brillamment rappelé lors de son intervention à quel point jamais une IA ne pourra remplacer un humain. Un point qu’il relève sans cesse dans ses interventions et qui nécessiterait tout un article à part entière, est le nom même d’IA qui prête à confusion. Il n’a de cesse de rappeler depuis des années déjà, que ce  ne sont que des outils et non pas une “intelligence” au sens humain du terme.</p><h2 class=\"wp-block-heading\"><em>Quelques moments forts du salon</em></h2><p>L’entreprise que j’ai trouvée épatante est IKTOS. Elle en a d’ailleurs épaté plus d’un(e), puisqu’elle a reçu un prix BIG DATA &amp; AI for GOOD lors de la remise des trophées de l’innovation BIG DATA &amp; AI PARIS 2023.</p><p>Sa spécialité est d’utiliser l’IA afin d’aider à la découverte et la création de nouveaux médicaments. IKTOS a réalisé un travail impressionnant : à la fois d’un point de vue technique mais aussi d’un point de vue de son développement commercial à la fois rapide et solide (partenariat avec des industriels pharmaceutiques comme Servier).</p><p>L’utilisation de l’IA afin de trouver de nouveaux candidats médicaments est un domaine extrêmement complexe, à la fois scientifiquement et techniquement. Arriver à de tels résultats et réussir à travailler avec de grands laboratoires pharmaceutiques (qui possèdent des équipes R&amp;D performantes ainsi que des moyens colossaux) est un exploit qui mérite d’être souligné.</p><p>Un article à propos de l’IA pour la découverte de nouveaux médicaments arrive bientôt sur la revue.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Même si l’IA generative est une révolution, il y a encore un décalage entre le changement de paradigme annoncé par les influenceurs, la LinkedIn mania, et la frilosité des grandes entreprises.</p><p>Les grands acteurs de l’industrie française observent de prés ce qui passe mais ne passent pas encore à l’action. Enjeux de sécurité, gouvernance, enjeux éthiques, sociaux, beaucoup de barrières restent à casser pour faire passer l’IA generative d’une technologie prometteuse, cool, intéressante et ç une technologie REVOLUTIONNAIRE.</p></div>"},
{"url": "https://larevueia.fr/compte-rendu-de-ai-big-data-paris-2022/", "title": "Compte rendu de AI & Big data Paris 2022", "author": "Ilyes Talbi", "date": "\n29 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Les 26 et 27 septembre derniers j’étais à AI &amp; Big Data Paris. C’était l’évènement data de la rentrée à ne pas manquer. J’ai rencontré pas mal d’entreprises et assisté à quelques-unes des conférences proposées.</p><p>J’ai même rencontré Luc Julia pendant une séance de dédicace 🙂</p><p>J’ai beaucoup aimé la partie exposition, un peu moins la partie conférence, que j’ai trouvé trop marketing et pas assez technique.</p><p>Ca ne m’intéresse pas trop d’écouter les <em>data strategy</em> mise en place par les grandes entreprises pour gérer leurs <em>data transition</em> dans leurs <em>data warehouse</em> connectées à leur <em>data platform</em> construites <em>data by design</em> (j’ai peut-être juste pas eu de chance sur les conférences choisies ahah).</p><p>Globalement le bilan est positif, j’ai rencontré pas mal de gens, appris beaucoup de choses, et j’ai trouvé quelques partenaires potentiels pour La revue IA !</p><h2 class=\"wp-block-heading\">L’intelligence artificielle pour le métavers</h2><p>J’ai rencontré pas mal d’entreprise qui travaillaient sur le sujet à Vivatech. L’avantage cette fois c’est qu’il y avait moins de folklore et plus de choses concretes.</p><p>On commence à bien maitriser les techniques de jumeaux numérique, la génération de scènes commencent à se développer, et la France devient forte sur les sujets de vision par ordinateur, notamment grâce à des startups comme Picsellia ou <a href=\"https://www.xxii.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">XXII</a>.</p><p>J’ai même discuté avec une entreprise qui faisait des jumeaux numériques d’usines !</p><figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\"><blockquote class=\"twitter-tweet\" data-width=\"550\" data-dnt=\"true\"><p lang=\"fr\" dir=\"ltr\">[<a href=\"https://twitter.com/hashtag/BDAIP22?src=hash&amp;ref_src=twsrc%5Etfw\">#BDAIP22</a> : It's over 🤩]<br><br>Vous avez été + de 16 000 participants ! Big Data &amp; AI Paris ne serait rien sans vous, alors merci d'être venus aussi nombreux !<br><br>À l’année prochaine pour la 12ème édition 🎬 <br>TO BE CONTINUED … <a href=\"https://t.co/vrgIIgjL7V\">pic.twitter.com/vrgIIgjL7V</a></p>— BIG DATA &amp; AI PARIS (@bigdataparis) <a href=\"https://twitter.com/bigdataparis/status/1574818788842913794?ref_src=twsrc%5Etfw\">September 27, 2022</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> </div></figure><h2 class=\"wp-block-heading\">Le maillage de données ou Data mesh est sur toutes les langues</h2><p>La tendance à la mode en ce moment dans le monde du big data est clairement cette histoire de data mesh. Beaucoup des entreprises que j’ai rencontré travaillent sur le sujet.</p><p>Le data mesh, plus qu’un outil, est un nouveau paradigme prôné par les grands groupes qui ont des données en grande quantité et très diverses. Il s’agit de proposer une méthode de gestion des données en entreprise plus intelligente et moins centralisée.</p><p>Chaque corp de métier d’une entreprise a accès à ses données et est responsable de leur qualité et leur sécurité. En même temps, des passerelles sont construites pour permettre aux autres équipes au sein de l’entreprise de pouvoir accéder de façon sécurisée et contrôlée aux données, pour éviter de copier trop souvent les mêmes données et faciliter l’accès pour tout le monde.</p><p>L’objectif du data mesh est de proposer un fonctionnement plus efficace, plus sécurisé et plus flexible que les modèles traditionnels.</p><h2 class=\"wp-block-heading\">Les startups à suivre</h2><p>J’ai rencontré énormément de gens pendant le salon, et bien profité de l’exposition. Le village startup était très intéressant, j’ai fais TOUS les stands de cette zone, et je regrette vraiment pas.</p><p>Contrairement aux stands des grandes entreprises, les startups ne sont pas là que pour vendre et chaque stand est différent.</p><p>Le choix a été difficile j’avoue, mais je tenais à ne garder que 3 projets dans ce compte rendu.</p><h3 class=\"wp-block-heading\">Buster.ai : détecter les fausses informations grâce au NLP</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/09/buster_ai.png\" alt=\"Compte rendu de AI &amp; Big data Paris 2022\" class=\"wp-image-6572\" width=\"464\" height=\"380\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/09/buster_ai.png 692w, https://larevueia.fr/wp-content/uploads/2022/09/buster_ai-300x246.png 300w\" sizes=\"auto, (max-width: 464px) 100vw, 464px\"></figure></div><p><a href=\"https://buster.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Buster.ai</a> est une startup française spécialisée dans la détection de fake news automatique.</p><p>Ils proposent une plateforme SAS, boostée au NLP, qui permet de donner des indications sur la fiabilité d’une information en analysant son contenu et en proposant des sources qui confirment ou qui infirment l’information.</p><p>Maintenant que les régulateurs européens ont imposés aux grandes entreprises comme Meta de combattre plus sérieusement les fake news, cette solution française pourrait s’imposer rapidement.</p><h3 class=\"wp-block-heading\">Vocads : la solution de e-commerce par la voix</h3><p>Les interactions humains machines se font plus naturellement par la voix. Maintenant que les modèles de reconnaissances vocale et de NLP sont plus performants, il est temps de repenser toutes nos expériences sur internet.</p><p>Vocads, propose un assistant vocal intelligent qui permet d’accompagner les utilisateurs pendant leur expérience d’achat. L’assistant les aide à trouver le bon produit, leur suggère des produits complémentaires et les accompagne jusqu’à la finalisation de l’achat. J’imagine même à terme la capacité d’identifier l’acheteur avec sa voix et ainsi assurer plus de sécurité.</p><p>Par ailleurs, ce type d’assistants pourra être utilisé pour rendre les sites internet plus accessibles. Qui sait, bientôt on aura un assistant Vocads qui vous aidera dans votre expérience d’apprentissage sur La revue IA 🙂</p><h3 class=\"wp-block-heading\">Selas studio : le (j’espère) futur leader européen de la génération d’images par intelligence artificielle</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-1024x614.jpeg\" alt=\"Compte rendu de AI &amp; Big data Paris 2022\" class=\"wp-image-6574\" width=\"512\" height=\"306\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-1024x614.jpeg 1024w, https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-300x180.jpeg 300w, https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-768x461.jpeg 768w, https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080.jpeg 1080w\" sizes=\"auto, (max-width: 512px) 100vw, 512px\"></figure></div><p>On vient à peine d’entrer dans l’ère de l’art génératif, beaucoup d’applications doivent encore être développée et les modèles seront encore améliorés.</p><p>Sur ce sujet, j’ai rencontré Selas studio, une startup française qui compte l’un des contributeurs de <a href=\"https://larevueia.fr/comment-generer-des-images-avec-stable-diffusion/\" target=\"_blank\" rel=\"noreferrer noopener\">stable diffusion</a> parmi les co-fondateurs. Stylé !</p><p>J’ai bien aimé l’équipe et je pense qu’on pourra faire des choses intéressantes avec eux 🙂</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Voilà pour ce compte rendu. Le salon Big data &amp; AI Paris a encore une fois tenu toutes ses promesses, j’ai été ravi d’être partenaire de cette initiative et j’attend l’édition 2023 avec impatience !</p></div>"},
{"url": "https://larevueia.fr/mes-dernieres-lectures-en-data-science/", "title": "Mes dernières lectures en data science", "author": "Ilyes Talbi", "date": "\n8 novembre 2020\n", "content": "<div class=\"entry-content\"><p>Les <a href=\"https://www.editions-eyrolles.com/\" target=\"_blank\" rel=\"noreferrer noopener\">éditions Eyrolles</a> m’ont gentiment envoyés plusieurs livres. J’ai profité du confinement et du fait que j’ai un peu plus de temps libre pour me plonger dedans et vous en parler.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Mes dernières lectures en data science\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-décran-2022-06-14-à-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Avant de commencer sachez que j’ai mis des liens affiliés qui me permettent de récupérer une petite commission sans que ça ne vous coûte plus cher. Si vous comptez acheter un livre et que vous souhaitez me soutenir faites le depuis ces liens 🙂</p><h2 class=\"wp-block-heading\"><a href=\"https://www.amazon.fr/gp/product/2212142439/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212142439&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=5941cec3d1634efb7b993c1c50f2e789\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Data Science : fondamentaux et études de cas</a></h2><p>Le premier livre de cette sélection a été écrit par Eric Biernat et Michel Lutz. Cet ouvrage vous permettra de comprendre certains des algorithmes fondamentaux de la data science de façon poussée (Régressions, <a href=\"https://larevueia.fr/support-vector-machines-svm/\" target=\"_blank\" rel=\"noreferrer noopener\">SVM</a>, Naive Bayes, <a href=\"https://larevueia.fr/random-forest/\" target=\"_blank\" rel=\"noreferrer noopener\">Random Forest</a>, etc.).</p><p>Contrairement à la majorité des autres ouvrages, qui vous donneront une présentation rapide de tout ce qui se fait, ce livre rentre dans les détails mais en traitant uniquement les modèles les plus utilisés.</p><p><a href=\"https://www.amazon.fr/gp/product/2212142439/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212142439&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=5941cec3d1634efb7b993c1c50f2e789\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Acheter</a></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://www.amazon.fr/gp/product/2212142439/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212142439&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=5941cec3d1634efb7b993c1c50f2e789\"><img loading=\"lazy\" decoding=\"async\" width=\"411\" height=\"500\" src=\"https://larevueia.fr/wp-content/uploads/2020/11/41e5vygI6jL._SX409_BO1204203200_.jpg\" alt=\"Mes dernières lectures en data science\" class=\"wp-image-2700\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/11/41e5vygI6jL._SX409_BO1204203200_.jpg 411w, https://larevueia.fr/wp-content/uploads/2020/11/41e5vygI6jL._SX409_BO1204203200_-247x300.jpg 247w\" sizes=\"auto, (max-width: 411px) 100vw, 411px\"></a><figcaption>Data science : fondamentaux et études de cas</figcaption></figure></div><h2 class=\"wp-block-heading\"><a href=\"https://www.amazon.fr/gp/product/B08LMSGMN9/ref=as_li_tl?ie=UTF8&amp;tag=ilyeslarevuei-21&amp;camp=1642&amp;creative=6746&amp;linkCode=as2&amp;creativeASIN=B08LMSGMN9&amp;linkId=b7ad1b48a9dbf190488b763cd7d12a2a\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Data Science par la pratique</a></h2><p>Le second livre de cette liste a été écrit par Joel Grus. La 2ème édition été publié le 22 Octobre, c’est tout frais ! Joel Grus est ingénieur à Seattle chez Google et il est déjà auteur de plusieurs ouvrages de data science.</p><p>L’auteur part d’un principe, auquel j’adhère complètement, l’apprentissage de la data science se fait par la pratique. Il faut travailler sur des projets concrets pour progresser réellement et c’est l’approche qui est adoptée dans ce livre.</p><p>Les premiers chapitres consistent en une présentation exhaustive des fondamentaux théoriques et un cours sur la programmation en Python. L’auteur présente ensuite les différents outils de la data science avec plusieurs exemples concrets implémentés sur Python.</p><p><a href=\"https://www.amazon.fr/gp/product/B08LMSGMN9/ref=as_li_tl?ie=UTF8&amp;tag=ilyeslarevuei-21&amp;camp=1642&amp;creative=6746&amp;linkCode=as2&amp;creativeASIN=B08LMSGMN9&amp;linkId=b7ad1b48a9dbf190488b763cd7d12a2a\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Acheter</a></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://www.amazon.fr/gp/product/B08LMSGMN9/ref=as_li_tl?ie=UTF8&amp;tag=ilyeslarevuei-21&amp;camp=1642&amp;creative=6746&amp;linkCode=as2&amp;creativeASIN=B08LMSGMN9&amp;linkId=b7ad1b48a9dbf190488b763cd7d12a2a\"><img loading=\"lazy\" decoding=\"async\" width=\"408\" height=\"500\" src=\"https://larevueia.fr/wp-content/uploads/2020/11/41TpytEeAZL.jpg\" alt=\"Mes dernières lectures en data science\" class=\"wp-image-2703\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/11/41TpytEeAZL.jpg 408w, https://larevueia.fr/wp-content/uploads/2020/11/41TpytEeAZL-245x300.jpg 245w\" sizes=\"auto, (max-width: 408px) 100vw, 408px\"></a><figcaption>Data science par la pratique</figcaption></figure></div><h2 class=\"wp-block-heading\"><a href=\"https://www.amazon.fr/gp/product/2212679513/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212679513&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=804e8a937eb95c873272ec44b32159e3\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Les Data Sciences en 100 questions/réponses</a></h2><p><em>Last but not least !</em></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://www.amazon.fr/gp/product/2212679513/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212679513&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=804e8a937eb95c873272ec44b32159e3\"><img loading=\"lazy\" decoding=\"async\" width=\"405\" height=\"500\" src=\"https://larevueia.fr/wp-content/uploads/2020/11/41gu4Jei6TL._SX403_BO1204203200_.jpg\" alt=\"Mes dernières lectures en data science\" class=\"wp-image-2701\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/11/41gu4Jei6TL._SX403_BO1204203200_.jpg 405w, https://larevueia.fr/wp-content/uploads/2020/11/41gu4Jei6TL._SX403_BO1204203200_-243x300.jpg 243w\" sizes=\"auto, (max-width: 405px) 100vw, 405px\"></a><figcaption>Les data science en 100 questions/réponses</figcaption></figure></div><p>Le dernier livre dont je voulais parler est celui de Younes Benzaki, l’auteur de <a href=\"https://mrmint.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">Mr Mint</a>, l’un des premiers blogs de machine learning en France. Contrairement aux deux premiers, ce livre vise plutôt un public déjà familiariser avec les notions de bases du machine learning.</p><p>J’ai beaucoup aimé l’originalité de l’ouvrage. Même si le contenu est finalement assez classique, le fait d’avoir structuré la première partie du livre sous forme de questions/réponses facilite beaucoup la lecture. La seconde partie est plus orientée pratique. En plus de donner des éléments de méthodologies, l’auteur explique pas à pas la construction de modèles prédictifs.</p><p>Explications théoriques du fonctionnement des algorithmes classiques; métriques d’évaluations des performances des modèles; notions mathématiques fondamentales du machine learning, ce livre permet de couvrir de façon très large le domaine de la data science.</p><p>Cet ouvrage est très complémentaire des deux autres. Il vous permettra d’avoir une compréhension un peu plus subtil de certains concepts du machine learning. Il est idéal quelqu’un qui souhaite préparer un entretien par exemple.</p><p><a href=\"https://www.amazon.fr/gp/product/2212679513/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212679513&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=804e8a937eb95c873272ec44b32159e3\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Acheter</a></p></div>"}
]