[
{"url": "https://larevueia.fr/introduction-au-nlp-avec-python-les-ia-prennent-la-parole/", "title": "Introduction au NLP avec Python", "author": "Ilyes Talbi", "date": "\n13 mai 2020\n", "content": "<div class=\"entry-content\"><p>Dans cet article on explique les bases du NLP avec Python en travaillant sur un exemple de classification de textes.</p><p>Chatbots, moteurs de recherches, assistants vocaux, les IA ont Ã©normÃ©ment de choses Ã  nous dire. NÃ©anmoins, la comprÃ©hension du langage, qui est une formalitÃ© pour les Ãªtres humains, est un challenge quasiment insurmontable pour les machines. Câ€™est dâ€™ailleurs un domaine entier du machine learning, on le nomme NLP.</p><p>Ces derniÃ¨res annÃ©es ont Ã©tÃ© trÃ¨s riches en progrÃ¨s pour le Natural Language Processing (NLP) et les rÃ©sultats observÃ©s sont de plus en plus impressionnants. Câ€™est vrai que dans mon article <em><a data-type=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" href=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" target=\"_blank\" rel=\"noreferrer noopener\">Personne nâ€™aime parler Ã  une IA</a></em>, jâ€™ai Ã©tÃ© assez sÃ©vÃ¨re dans ma prÃ©sentation des IA conversationnelles. MalgrÃ© que les systÃ¨mes qui existent sont loin dâ€™Ãªtre parfaits (et risquent de ne jamais le devenir), ils permettent dÃ©jÃ  de faire des choses trÃ¨s intÃ©ressantes.</p><h2 class=\"wp-block-heading\" id=\"du-mot-au-vecteur\" style=\"font-size:21px\"><strong>Du mot au vecteur</strong></h2><p>Pour comprendre le langage le systÃ¨me doit Ãªtre en mesure de saisir les diffÃ©rences entre les mots. Pour cela, lâ€™idÃ©al est de pouvoir les reprÃ©senter mathÃ©matiquement, on parle dâ€™encodage. De la mÃªme maniÃ¨re quâ€™une image est reprÃ©sentÃ©e par une matrice de valeurs reprÃ©sentant les nuances de couleurs, un mot sera reprÃ©sentÃ© par un vecteur de grande dimension, câ€™est ce que lâ€™on appelle le <em>word embedding</em>.</p><p>Ces vecteurs sont construits pour chaque langue en traitant des bases de donnÃ©es de textes Ã©normes (on parle de plusieurs centaines de Gb). En comptant les occurrences des mots dans les textes, lâ€™algorithme peut Ã©tablir des correspondance entre les mots.</p><p>Les modÃ¨les de ce type sont nombreux, les plus connus sont Word2vec, BERT ou encore ELMO. Leurs utilisations est rendue simple grÃ¢ce Ã  des modÃ¨les prÃ©-entrainÃ©s que vous pouvez trouver facilement.</p><p>Rien ne nous empÃªche de dessiner les vecteurs (aprÃ¨s les avoir projeter en dimension 2), je trouve Ã§a assez joli !<br></p><figure class=\"wp-block-image size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"512\" height=\"297\" src=\"https://larevueia.fr/wp-content/uploads/2020/05/word2vec.png\" alt=\"word2vec, tutoriel NLP avec Python\" class=\"wp-image-446\" style=\"width:712px;height:413px\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/05/word2vec.png 512w, https://larevueia.fr/wp-content/uploads/2020/05/word2vec-300x174.png 300w\" sizes=\"auto, (max-width: 512px) 100vw, 512px\"><figcaption class=\"wp-element-caption\">ReprÃ©sentation graphique de mots avec Word2vec</figcaption></figure><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Cette reprÃ©sentation est trÃ¨s astucieuse puisquâ€™elle permet maintenant de dÃ©finir une distance entre 2 mots. Vous pouvez mÃªme Ã©crire des Ã©quations de mots comme : <em>Roi â€“ Homme = Reine â€“ Femme</em></p></blockquote><h2 class=\"wp-block-heading\" id=\"application-du-nlp-classification-de-phrases-sur-python\" style=\"font-size:21px\"><br><strong>Application du NLP avec Python : classification de phrases</strong></h2><p>PrÃ©-requis : <a href=\"https://www.emil.school/articles/comment-installer-python\" target=\"_blank\" rel=\"noreferrer noopener\">Installation de Python</a></p><p>Maintenant que lâ€™on a compris les concepts de bases du NLP, nous pouvons travailler sur un premier petit exemple. Prenons une liste de phrases incluant des fruits et lÃ©gumes. Nous allons construire en quelques lignes un systÃ¨me qui va permettre de les classer suivant 2 catÃ©gories.</p><p>Nous verrons que faire du NLP avec Python peut Ãªtre trÃ¨s efficace, mais il sera intÃ©ressant de voir que certaines subtilitÃ©s de langages peuvent Ã©chapper au systÃ¨me !</p><p>Je vous conseille dâ€™utiliser Google Collab, câ€™est lâ€™environnement de codage que je prÃ©fÃ¨re.</p><p><em>Voici nos donnÃ©es de dÃ©partÂ :</em></p><pre class=\"wp-block-code\"><code>phrases = [\"J'ai achetÃ© des tomates\",\n          \"La saison des oignons arrive\",\n          'Cette mangue est trÃ¨s bonne',\n          'Ca sent les haricots',\n          'Je crois que je vais tomber dans les pommes',\n          'Penses Ã  acheter des carottes',\n          \"Un petit jus orange?\",\n          \"Ces fraises sont belles\",\n          \"Prend des aubergines aussi\"]</code></pre><p><br>Avant de commencer nous devons importer les bibliothÃ¨ques qui vont nous servir :<br></p><pre class=\"wp-block-code\"><code># import des bibliothÃ¨ques utiles\n\nfrom gensim.models import Word2Vec\nimport nltk\nfrom gensim.models import KeyedVectors\n\nfrom nltk.cluster import KMeansClusterer\nimport numpy as np \n\nfrom sklearn import cluster\nfrom sklearn import metrics</code></pre><p>Si elles ne sont pas installÃ©es vous nâ€™avez quâ€™Ã  faire <em>pip install gensim</em>, pip <em>install sklearn</em>, â€¦<br></p><h3 class=\"wp-block-heading\" id=\"nettoyage-des-donnees\" style=\"font-size:18px\"><em><strong>Â Â Â Â Â Â Â Â Â Â Â Â Â  Nettoyage des donnÃ©es</strong></em></h3><p><br>La premiÃ¨re Ã©tape Ã  chaque fois que lâ€™on fait du NLP avec Python, est de construire une pipeline de nettoyage de nos donnÃ©es. Lâ€™exemple que je vous prÃ©sente ici est assez basique mais vous pouvez Ãªtre amenÃ©s Ã  traiter des donnÃ©es beaucoup moins structurÃ©es que celles-ci.</p><p>Et dâ€™ailleurs le plus gros travail du data scientist ne rÃ©side malheureusement pas dans la crÃ©ation de modÃ¨le. Le nettoyage du dataset reprÃ©sente une part Ã©norme du processus.</p><p>Pour nettoyage des donnÃ©es textuelles on retire les chiffres ou les nombres, on enlÃ¨ve la ponctuation, les caractÃ¨res spÃ©ciaux comme les @, /, -, :, â€¦ et on met tous les mots en minuscules.</p><p>Pour cela on utiliser ce que lâ€™on appelle les expressions rÃ©guliÃ¨res ou regex. Sur Python leur utilisation est assez simple, vous devez importer la bibliothÃ¨que â€˜reâ€™. Puis construire vos regex. Attention Ã  lâ€™ordre dans lequel vous Ã©crivez les instructions.</p><p>Il nâ€™y a malheureusement aucune pipeline NLP qui fonctionne Ã  tous les coups, elles doivent Ãªtre construites au cas par cas. Dans le cas qui nous importe cette fonction fera lâ€™affaire :</p><pre class=\"wp-block-code\"><code>import re\n\ndef nlp_pipeline(text):\n\n    text = text.lower() # mettre les mots en minuscule\n\n# Retirons les caractÃ¨res spÃ©ciaux :\n\n    text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)\n    text = re.sub(r\"\\&amp;\\S*\\s\", \"\", text)\n    text = re.sub(r\"\\-\", \"\", text)\n    \n    return text</code></pre><h3 class=\"wp-block-heading\" id=\"installation-d-un-modele-word2vec-pre-entraine\" style=\"font-size:18px\"><strong>Â </strong><br><strong><em>Installation dâ€™un modÃ¨le Word2vec prÃ©-entrainÃ©Â :</em></strong></h3><p>Pour gagner du temps et pouvoir crÃ©er un systÃ¨me efficace facilement il est prÃ©fÃ©rable dâ€™utiliser des modÃ¨les dÃ©jÃ  entraÃ®nÃ©s.</p><p>Pour cet exemple jâ€™ai choisi un modÃ¨le Word2vec que vous pouvez importer rapidement via la bibliothÃ¨que <em>Gensim</em>. Voici le code Ã  Ã©crire sur Google Collab. Rien ne vous empÃªche de tÃ©lÃ©charger la base et de travailler en local.</p><pre class=\"wp-block-code\"><code># Import d'une base word2vec en francais deja entrainee\n\nw2v = KeyedVectors.load_word2vec_format(\nhttps://s3.us-east 2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin,\n    binary=True)</code></pre><h3 class=\"wp-block-heading\" id=\"encodage-la-transformation-des-mots-en-vecteurs-est-la-base-du-nlp\" style=\"font-size:18px\"><em><strong>Â Â Â Â Â Â Â Â Â Â Â Â Â  </strong></em><br><em><strong>EncodageÂ : la transformation des mots en vecteurs</strong></em> <em>est la base du NLP</em> avec Python</h3><p>Câ€™est lâ€™Ã©tape cruciale du processus. Nous devons transformer nos phrases en vecteurs.</p><p>Pour cela, word2vec nous permet de transformer des mots et vecteurs. Je vais ensuite faire simplement la moyenne de chaque phrase. Sachez que pour des phrases longues cette approche ne fonctionnera pas, la moyenne nâ€™est pas  assez robuste. Si vous avez des phrases plus longues ou des textes il vaut mieux choisir une approche qui utilise TF-IDF.<br></p><pre class=\"wp-block-code\"><code># On commence par utiliser notre pipeline dÃ©finie plus haut\n\nphrases_propres = []\n\nfor phrase in phrases:\n    phrases_propres.append(nlp_pipeline(phrase))\n\n# Nous devons sÃ©parer les phrases en liste de mots\n\nphrases_split = []\n\nfor phrase in phrases_propres:\n    phrases_split.append(phrase.split(\" \"))\n\n# C'est lÃ  que Word2vec intervient\nX = []\n\nfor phrase in phrases_split:\n    vec_phrase = []\n    for mot in phrase:\n        vec_phrase.append(w2v.wv[mot])\n    X.append(np.mean(vec_phrase,0))</code></pre><hr class=\"wp-block-separator has-css-opacity\"><h3 class=\"wp-block-heading\" id=\"classification-par-la-methode-des-k-means\" style=\"font-size:18px\"><em><strong>Â Â Â Â Â Â Â Â Â Â Â Â Â  </strong></em><br><em><strong>Classification par la mÃ©thode des k-meansÂ :</strong></em></h3><p>Maintenant que nous avons nos vecteurs, nous pouvons commencer la classification.</p><p>En classification il nâ€™y a pas de consensus concernant la mÃ©thode a utiliser. Vous pouvez lire lâ€™article <a href=\"https://larevueia.fr/clustering-les-3-methodes-a-connaitre/\" target=\"_blank\" rel=\"noreferrer noopener\">3 mÃ©thodes de clustering Ã  connaitre</a>.</p><p>Ici nous aller utiliser la mÃ©thode des k moyennes, ou k-means. Elle est dâ€™autant plus intÃ©ressante dans notre situation puisque lâ€™on sait dÃ©jÃ  que nos donnÃ©es sont rÃ©parties suivant deux catÃ©gories.</p><p>Le code pour le k-means avec Scikit learn est assez simple :</p><pre class=\"wp-block-code\"><code>kclusterer = KMeansClusterer(2, distance=nltk.cluster.util.cosine_distance, repeats=25)\nclusters = kclusterer.cluster(X, assign_clusters=True)\nprint (clusters)\n\nfor index, phrase in enumerate(phrases):    \n    print (str(clusters[index]) + \":\" + str(phrase))\n\nkmeans = cluster.KMeans(n_clusters=2)\nkmeans.fit(X)\n  \nlabels = kmeans.labels_\ncentroids = kmeans.cluster_centers_</code></pre><p>Voici les rÃ©sultats que lâ€™on obtient :</p><pre class=\"wp-block-code\"><code>1 : J'ai achetÃ© des tomates\n1 : La saison des oignons arrive\n0 : Cette mangue est trÃ¨s bonne\n1 : Ca sent les haricots\n1 : Je crois que je vais tomber dans les pommes\n1 : Penses Ã  acheter des carottes\n0 : Un petit jus orange?\n0 : Ces fraises sont belles\n1 : Prend des aubergines aussi</code></pre><p>A part pour les pommes chaque phrase est rangÃ©e dans la bonne catÃ©gorie. Pour les pommes on a peut-Ãªtre un problÃ¨me dans la taille de la phrase. Comme je lâ€™ai expliquÃ© plus la taille de la phrase sera grande moins la moyenne sera pertinente.</p><p>Il peut Ãªtre intÃ©ressant de projeter les vecteurs en dimension 2 et visualiser Ã  quoi nos catÃ©gories ressemblent sur un nuage de points.</p><pre class=\"wp-block-code\"><code>import matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\nmodel = TSNE(n_components=2, random_state=0)\nnp.set_printoptions(suppress=True)\n\nY = model.fit_transform(X)\nplt.scatter(Y[:, 0], Y[:, 1], c=clusters, s=290,alpha=.5)\n\nplt.show()</code></pre><p>VoilÃ  ce que lâ€™on obtient :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"383\" height=\"248\" src=\"https://larevueia.fr/wp-content/uploads/2020/05/clusters_fruits.png\" alt=\"Nuages de points\" class=\"wp-image-462\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/05/clusters_fruits.png 383w, https://larevueia.fr/wp-content/uploads/2020/05/clusters_fruits-300x194.png 300w\" sizes=\"auto, (max-width: 383px) 100vw, 383px\"><figcaption class=\"wp-element-caption\">Nuage de points reprÃ©sentant les phrases de notre corpus</figcaption></figure></div><p>Je suis fan de beaux graphiques sur Python, câ€™est pour cela que jâ€™aimerais aussi construire une matrice de similaritÃ©. Elle nous permettra de voir rapidement quelles sont les phrases les plus similaires.</p><pre class=\"wp-block-code\"><code>size = 10\n\n# Construction de la matrice des distances\n\nS = np.zeros((size,size))\n\nfor i in range(len(X)):\n    for j in range(len(X)):\n        S[i][j] = np.dot(X[i],X[j])/(np.linalg.norm(X[i])*np.linalg.norm(X[j]))\n\nfig, ax = plt.subplots()\nimg = ax.imshow(S)\n\n# Pour afficher les phrases\n\nx_label_list = phrases\ny_label_list = phrases\n\n# Imposons qu'ils soient tous afficher, sinon par dÃ©faut vous n'en verrez #que la moitiÃ©\n\nax.set_xticks(np.arange(10))\nax.set_yticks(np.arange(10))\n\n# Afficher les labels et le titre principal\n\nax.set_xticklabels(x_label_list,rotation='vertical',verticalalignment='top')\nax.set_yticklabels(y_label_list)\nax.set_title(\"Matrice de similaritÃ©\")\n\n# Ecrire la valeur de la similaritÃ© dans chaque case de la matrice\n\nfor i in range(len(x_label_list)):\n    for j in range(len(y_label_list)):\n        text = ax.text(j, i, round(S[j,i],3),fontsize=5,\n                       ha=\"center\", va=\"center\", color=\"w\")\n\n# Imposer un angle de rotation pour faciliter la lecture des #labels en abscisses\n\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\nplt.show()</code></pre><p>VoilÃ  le rÃ©sultat !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"461\" height=\"419\" src=\"https://larevueia.fr/wp-content/uploads/2020/05/sim_fruits.png\" alt=\"Introduction au NLP avec Python\" class=\"wp-image-465\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/05/sim_fruits.png 461w, https://larevueia.fr/wp-content/uploads/2020/05/sim_fruits-300x273.png 300w\" sizes=\"auto, (max-width: 461px) 100vw, 461px\"></figure></div><p><br>A lâ€™Ã©chelle dâ€™un mot ou de phrases courtes la comprÃ©hension pour une machine est aujourdâ€™hui assez facile (mÃªme si certaines subtilitÃ©s de langages restent difficiles Ã  saisir). NÃ©anmoins, pour des phrases plus longues ou pour un paragraphe, les choses sont beaucoup moins Ã©videntes. Et on utilise souvent des modÃ¨les de <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" data-type=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">rÃ©seaux de neurones</a> comme les LSTM.</p><p>Lâ€™algorithme doit Ãªtre capable de prendre en compte les liens entre les diffÃ©rents mots. Il se trouve que le passage de la sÃ©mantique des mots obtenue grÃ¢ce aux modÃ¨les comme Word2vec, Ã  une comprÃ©hension syntaxique est difficile Ã  surmonter pour un algorithme simple. Les chatbots qui nous entourent sont trÃ¨s souvent rien dâ€™autre quâ€™une succession dâ€™instructions empilÃ©es de faÃ§on astucieuse.</p><p>NÃ©anmoins, le fait que le NLP soit lâ€™un des domaines de recherches les plus actifs en machine learning, laisse penser que les modÃ¨les ne cesseront de sâ€™amÃ©liorer. Peut-Ãªtre que nous aurons un jour un chatbot capable de comprendre rÃ©ellement le langage.</p></div>"},
{"url": "https://larevueia.fr/quels-liens-entre-blockchain-et-intelligence-artificielle/", "title": "Quels liens entre blockchain et intelligence artificielle ?", "author": "Ilyes Talbi", "date": "\n24 mars 2022\n", "content": "<div class=\"entry-content\"><p>Il y a 3 ans, aprÃ¨s la <a href=\"https://larevueia.fr/compte-rendu-de-la-tech-expo-2019-a-la-silicon-valley/\" target=\"_blank\" rel=\"noreferrer noopener\">tech expo</a> de San Francisco, je dÃ©crivais la blockchain comme une technologie prometteuse mais qui trouverait difficilement des applications en dehors du monde de la finance.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Quels liens entre blockchain et intelligence artificielle ?\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Heureusement, jâ€™ai grandi depuis !</p><p>Le monde de la blockchain aussi dâ€™ailleurs.</p><p>Il a tellement grandi quâ€™il peut maintenant nous aider Ã  rÃ©volutionner lâ€™intelligence artificielle; et câ€™est le sujet de notre article!</p><h2 class=\"wp-block-heading\">Lexique</h2><p>Comme pour toutes les technologies de pointes, il est parfois difficile de bien comprendre le lexique.  Pour clarifier cet aspect, la premiÃ¨re section me permettra de dÃ©finir les diffÃ©rents termes utilisÃ©s.</p><p>Vous pouvez passer si vous connaissez dÃ©jÃ .</p><h3 class=\"wp-block-heading\">Quâ€™est-ce que le web3 ?</h3><p>Plus quâ€™une nouvelle technologie, le web3 constitue une veritable rÃ©volution, un changement de paradigme dans le monde du web.</p><h4 class=\"wp-block-heading\">Web1, web2</h4><p>Pour mieux comprendre le web3.0, il convient de revenir dans le temps et de reprendre les diffÃ©rentes phases du web.</p><p>Initialement, internet Ã©tait une encyclopÃ©die en ligne qui permettait de consulter lâ€™information mais sans contenu interactif. Le contenu se limitait aux textes ou aux images lÃ©gÃ¨res. La connexion Ã©tait incroyablement lente, tÃ©lÃ©charger une musique vous aurez pris une journÃ©e complÃ¨te.</p><p>Je suis trop jeune pour avoir connu le web1, par contre, je connais trÃ¨s bien le web2, ses avantages, ses limites et ses dangers.</p><p>Le web2 est le web des cookies. En plus de lire et consommer le contenu, on peut interagir avec. Les sites peuvent collecter nos donnÃ©es dâ€™utilisation pour nous envoyer des publicitÃ©s ciblÃ©es, on peut payer en ligne et interagir avec les autres utilisateurs.</p><p>Lâ€™amÃ©lioration des infrastructures de connexion Ã  internet, notamment grÃ¢ce Ã  la fibre optique, la 3G et la 4G, a permis de proposer un contenu plus diversifiÃ©, avec les vidÃ©os, les sons, des images de meilleurs qualitÃ© et mÃªme du contenu 3D.</p><p>Le web2 est lâ€™Ã¢ge des rÃ©seaux sociaux, on ne consulte plus seulement internet, on y participe.</p><p>Lâ€™augmentation considÃ©rable du nombre dâ€™utilisateurs a entraÃ®nÃ© une explosion de la quantitÃ© de donnÃ©es gÃ©nÃ©rÃ©es par le web2.0, Ã  tel point que les donnÃ©es des internautes sont devenus la base du business model de beaucoup de gÃ©ants de la tech.</p><p>Le web2.0 est le symbole de la centralisation, une poignÃ©e dâ€™entreprises contrÃ´lent la data, et le monde digital. Les donnÃ©es de plus de 80% de la population sont stockÃ©es dans les data centers de Google, dâ€™Amazon, de Twitter, â€¦</p><p></p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Internet is broken</em></p>\n<cite>Gavin Wood, Co-founder dâ€™Eth</cite></blockquote><p></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Silicon Valley - Richard Hendricks speech to Congress\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/lXyeZA54bko?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div><figcaption>Lâ€™internet dÃ©centralisÃ© selon Richard Hendricks</figcaption></figure><p>Toutes ces raisons nous poussent Ã  nous rÃ©volter. Comme dans lâ€™AmÃ©rique de 1776, lâ€™heure de faire tomber les rois est arrivÃ©eâ€¦</p><p>â€¦ non jrigoleâ€¦</p><p>â€¦ mais bon, on va quand mÃªme proposer une alternative au cas oÃ¹ ğŸ‘€</p><h4 class=\"wp-block-heading\">Le web 3.0</h4><p>Le web3.0 reprend le principe du peer to peer, ou <em>dÃ©centralisation</em>, sur lequel la blockchain repose.</p><p>PlutÃ´t que les donnÃ©es soient centralisÃ©es dans les data center de grosses entreprises, elles sont stockÃ©es de faÃ§on dÃ©centralisÃ©e et en plusieurs morceaux, et rÃ©parties entre tous les participants du rÃ©seaux.</p><h3 class=\"wp-block-heading\">Quâ€™est-ce quâ€™un NFT ?</h3><p>Un NFT, ou Non Fungible Token, est un actif digital qui prend la forme dâ€™une image, un son, une vidÃ©o, etc.</p><p>Il est rattachÃ© Ã  au moins un propriÃ©taire via une identitÃ© numÃ©rique (wallet). Ã€Â chaque NFT est associÃ© des mÃ©ta donnÃ©es qui contiennent ses informations de bases, comme les identitÃ©s du propriÃ©taire et du crÃ©ateur.</p><p>Ces mÃ©ta donnÃ©es sont inscrites dans une blockchain, qui permet de sÃ©curiser et rendre plus transparentes les transactions de NFT.</p><p>MÃªme si lâ€™utilisation de base des NFT est purement artistique, ils ont Ã©normÃ©ment dâ€™applications dans diffÃ©rentes industries. LVMH par exemple, associe chaque sac Ã  main de luxe Ã  un NFT que le propriÃ©taire du sac transfÃ¨re Ã  lâ€™acheteur sâ€™il le lui revend. Cela permet de luter contre les contrefaÃ§ons.</p><p></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.therealtatooine.io/\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/03/Capture-de%CC%81cran-2022-03-17-a%CC%80-16.07.23-1024x478.png\" alt=\"Quels liens entre blockchain et intelligence artificielle ?\" class=\"wp-image-4762\" width=\"483\" height=\"226\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/03/Capture-deÌcran-2022-03-17-aÌ€-16.07.23-1024x478.png 1024w, https://larevueia.fr/wp-content/uploads/2022/03/Capture-deÌcran-2022-03-17-aÌ€-16.07.23-300x140.png 300w, https://larevueia.fr/wp-content/uploads/2022/03/Capture-deÌcran-2022-03-17-aÌ€-16.07.23-768x358.png 768w, https://larevueia.fr/wp-content/uploads/2022/03/Capture-deÌcran-2022-03-17-aÌ€-16.07.23.png 1312w\" sizes=\"auto, (max-width: 483px) 100vw, 483px\"></a></figure></div><p></p><h3 class=\"wp-block-heading\">Quâ€™est-ce que le metavers ?</h3><p>Le web3 et les NFT vont tous les deux contribuÃ©s Ã  la conception de <em>mÃ©tavers</em>.</p><p>Les mÃ©tavers, mis sous le feu des projecteurs par Zuckerberg le CEO de Meta (ex Facebook), sont des espaces virtuels qui vont crÃ©er de nouvelles formes dâ€™interactions entre les utilisateurs.</p><p>Câ€™est une nouvelle forme dâ€™internet qui se rapproche plus de la rÃ©alitÃ©. On peut assister Ã  des Ã©vÃ¨nements virtuels complÃ¨tement recrÃ©Ã©s en 3D (comme des concerts ou des mariages), on peut regarder des Ã©vÃ¨nements sportifs de faÃ§on plus immersive, travailler entre collÃ¨gues, Ã©tudier depuis chez soi avec un casque VR, etc.</p><p>Câ€™est vrai que Ã§a peut faire peur dit comme Ã§a, mais bon, si on crÃ©Ã© pas notre metavers on se baladera dans le metavers de quelquâ€™un dâ€™autre (comme Baidu par exemple ğŸ‘€).</p><h2 class=\"wp-block-heading\">Lâ€™IA au service de la blockchain</h2><p>Les applications de lâ€™intelligence artificielle pour toutes les technologies qui reposent sur la blockchain sont nombreuses.</p><p>Lâ€™IA intervient dans le trading de cryptomonnaies, dans la gÃ©nÃ©ration de NFT ou encore pour la construction du metavers.</p><h3 class=\"wp-block-heading\">Trading de cryptomonnaies</h3><p>Jâ€™ai hÃ©sitÃ© Ã  commencer par cette application, de peur dâ€™alimenter encore plus le raccourci blockchain=cryptomonnaies, mais bon comme mes lecteurs sont intelligents je la met quand mÃªme ğŸ™‚</p><p>Les cryptomonnaies sont rÃ©putÃ©es pour leur forte volatilitÃ© qui rend trÃ¨s difficile les prÃ©dictions. NÃ©anmoins, certaines techniques dâ€™analyse de sÃ©ries temporelles comme les LSTM permettent de prÃ©dire les tendances du marchÃ©, mÃªme si les modÃ¨les sont beaucoup moins performants que pour la bourse.</p><p>Tapez Â«Â bitcoin LSTMÂ Â» sur Google.</p><h3 class=\"wp-block-heading\">GÃ©nÃ©ration automatique de NFT</h3><p>Une des applications de lâ€™intelligence artificielle utilise la gÃ©nÃ©ration automatique dâ€™objets dâ€™art digitaux. MÃªme si la technique existe depuis longtemps, elle a pris de lâ€™ampleur avec lâ€™explosion des NFT, qui rendent beaucoup plus simple la revente de ses crÃ©ations digitales.</p><p>En pratique on utilise souvent des <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones-gan/\" target=\"_blank\" rel=\"noreferrer noopener\">rÃ©seaux GAN</a>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"664\" height=\"452\" src=\"https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted.png\" alt=\"Quels liens entre blockchain et intelligence artificielle ?\" class=\"wp-image-4813\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted.png 664w, https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted-300x204.png 300w, https://larevueia.fr/wp-content/uploads/2022/03/ai-generated-nfts-now-popping-up-only-1000-minted-535x364.png 535w\" sizes=\"auto, (max-width: 664px) 100vw, 664px\"></figure></div><h3 class=\"wp-block-heading\">Reconstruction 3D dâ€™objets pour le metaverse</h3><p>En plus de permettre de gÃ©nÃ©rer des NFT, la vision par ordinateur permet de modÃ©liser des objets du monde rÃ©elles en 3D beaucoup plus facilement.</p><p>Les metavers vont recrÃ©er un environnement qui soit le plus rÃ©aliste possible. Pour permettre cela, on doit Ãªtre capable de reproduire des objets et des formes complexes de faÃ§on systÃ©matique et rapide, sans Ãªtre obligÃ© de remodÃ©liser Ã  chaque fois.</p><p>Aujourdâ€™hui, les meilleurs modÃ¨les de reconstruction 3D sont capable de modÃ©liser un objet de faÃ§on plutÃ´t rÃ©aliste Ã  partir de 2 ou 3 photos.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/03/acai2020-25-fig1.jpeg\" alt=\"3D reconstruction metavers\" class=\"wp-image-4816\" width=\"591\" height=\"314\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/03/acai2020-25-fig1.jpeg 493w, https://larevueia.fr/wp-content/uploads/2022/03/acai2020-25-fig1-300x159.jpeg 300w\" sizes=\"auto, (max-width: 591px) 100vw, 591px\"><figcaption class=\"wp-element-caption\">Exemple de reconstruction 3D Ã  partir dâ€™une seule image</figcaption></figure></div><p>Jâ€™ai parlÃ© de la reconstruction 3D dans un <a href=\"https://larevueia.fr/focus-sur-6-sous-domaines-de-la-computer-vision-et-leurs-applications/\" target=\"_blank\" rel=\"noreferrer noopener\">prÃ©cÃ©dent article</a>.</p><h2 class=\"wp-block-heading\">La blockchain au service de lâ€™IA</h2><p>Les utilisations de lâ€™intelligence artificielle pour la blockchain Ã©taient faciles Ã  trouver, lâ€™IA Ã©tant dÃ©jÃ  assez mÃ¢ture et la recherche sur ce sujet est dÃ©jÃ  en place.</p><p>NÃ©anmoins, les applications de la blockchain au service de lâ€™IA sont moins Ã©videntes, bien quâ€™un domaine entier de lâ€™intelligence artificielle, quâ€™on appelle <em><a href=\"https://larevueia.fr/quest-ce-que-lintelligence-artificielle-decentralisee/\" target=\"_blank\" rel=\"noreferrer noopener\">IA dÃ©centralisÃ©e</a></em> est en train de se crÃ©er.</p><p>Lâ€™IA dÃ©centralisÃ©e est issue du besoin de sÃ©curiser les donnÃ©es utilisÃ©es pour entraÃ®ner un modÃ¨le. Le stockage dÃ©centralisÃ©e et cryptÃ© permet dâ€™assurer la sÃ©curitÃ© des donnÃ©es et dâ€™Ã©viter les falsifications ou les pertes.</p><h3 class=\"wp-block-heading\">TraÃ§abilitÃ© des donnÃ©es</h3><p>La blockchain peut amÃ©liorer la traÃ§abilitÃ© des donnÃ©es.</p><p>La force de la blockchain aujourdâ€™hui rÃ©side dans sa sÃ©curitÃ©. Câ€™est ce qui la rend utilisable pour de grosses transactions financiÃ¨res.</p><p>Lorsque lâ€™on entraÃ®ne un modÃ¨le dâ€™intelligence artificielle, on a besoin de valider la provenance du dataset. Dâ€™une part pour mieux Ã©valuer la qualitÃ© des donnÃ©es et Ã©viter dâ€™entraÃ®ner une IA biaisÃ©e, dâ€™autre part pour nous assurer que les donnÃ©es ont Ã©tÃ© rassemblÃ©es en conformitÃ© avec les rÃ©glementations en vigueurs.</p><p>Je ne pense pas que la solution existe dÃ©jÃ , mais jâ€™imagine bien une plateforme dÃ©centralisÃ©e dâ€™Ã©change de dataset qui fonctionnerait avec des NFT. Lorsque lâ€™on transfÃ¨re un dataset, on transfÃ¨re un NFT associÃ©.</p><p>Ce fonctionnement permettrait Ã  tout moment de vÃ©rifier la provenance du dataset et de remonter jusquâ€™a sa crÃ©ation. Chaque action rÃ©alisÃ©e sur le dataset pourra Ãªtre enregistrÃ©e et visible.</p><h3 class=\"wp-block-heading\">Sharing Updatable Models sur la blockchain</h3><p>Toujours dans lâ€™optique de rendre lâ€™utilisation et lâ€™entraÃ®nement des modÃ¨les plus Ã©thiques, la blockchain peut offrir plus de transparence quant aux modÃ¨les qui sont proposÃ©s sur les diffÃ©rentes plateformes et faciliter la collaboration.</p><p>Ainsi, Microsoft Ã  crÃ©Ã©e un framework, Sharing Updatable Models, pour la maintenance collaborative de modÃ¨les de machine learning.</p><p>Le modÃ¨le de machine learning est initialement construit via un smart contract sur la blockchain Etherum et il est en accÃ¨s libre, vous pouvez lâ€™utiliser en payant les gas fee du rÃ©seau.</p><p>Lâ€™utilisateur peut ensuite modifier le modÃ¨le, ou ajouter des donnÃ©es dâ€™entraÃ®nement pour le rendre plus robuste. Les modifications sont ensuite testÃ©es de faÃ§on automatisÃ©e, Ã  partir dâ€™un dataset de test initial qui reste lui inchangÃ©. Si elles ont contribuÃ©es positivement aux performances du modÃ¨le lâ€™utilisateur est rÃ©compensÃ©, sinon il est pÃ©nalisÃ©.</p><p>Les rÃ©compenses sont donnÃ©s soit sous formes de points sur la plateforme, soit sous forme de compensation financiÃ¨re. Le principe de points ressemble beaucoup Ã  celui de Stackoverflow, et reposent sur les choix des autres utilisateurs de valider ou non les modifications proposÃ©es. Les compensations financiÃ¨res sont calculÃ©es via un autre smart contract public, et repose sur plusieurs critÃ¨res comme le gain de performance ou la taille du dataset apportÃ©.</p><p>Comme souvent dans le monde de la blockchain et du web3, le succÃ¨s de ce type de projets repose sur la capacitÃ© Ã  crÃ©er une communautÃ© dÃ©vouÃ©e et de confiance.</p><p>Pour plus dâ€™info je vous invite Ã  lire <a href=\"https://www.microsoft.com/en-us/research/blog/leveraging-blockchain-to-make-machine-learning-models-more-accessible/\" target=\"_blank\" rel=\"noreferrer noopener\">lâ€™article</a> de blog sur le site de Microsoft. Les plus courageux peuvent regarder le papier de recherche directement, <a href=\"https://arxiv.org/pdf/1907.07247.pdf\" target=\"_blank\" rel=\"noreferrer noopener\">Decentralized &amp; collaborative AI on blockchain</a>.</p><p></p><p>Les enjeux liÃ©s Ã  lâ€™intelligence artificielle et la blockchain dÃ©passent le cadre purement technologique et vont remettre en cause toute lâ€™Ã©conomie du web. La fin des cookies implique la fin des publicitÃ©s ciblÃ©es et donc la remise en cause des business model de plusieurs gÃ©ants de la tech.</p><p>Lâ€™IA, comme dans tous les domaines, sera un outil important dans le nouveau monde. Aussi bien pour sa construction que pour sa maintenance.</p><p>Inversement, la blockchain va rendre lâ€™IA plus sÃ©curisÃ©e, plus Ã©thique et plus collaborative, on parlera dâ€™<em>IA dÃ©centralisÃ©e</em>. Des problÃ¨mes importants, comme lâ€™anonymisation des donnÃ©es de certaines industries, qui restent jusquâ€™aujourdâ€™hui difficile Ã  traiter, pourraient Ãªtre rÃ©solus via la blockchain.</p></div>"},
{"url": "https://larevueia.fr/classification-de-tweets-en-direct-avec-apache-kafka-et-tweepy/", "title": "Tutoriel Apache Kafka : classification de tweets en direct", "author": "Walid Chrimni", "date": "\n18 mai 2022\n", "content": "<div class=\"entry-content\"><p><em>Dans cet article, on vous explique comment utiliser apache Kafka pour faire de la classification de tweets en direct.</em></p><p>Depuis 3 ans, une grande quantitÃ© de tweets sur la Covid-19 a Ã©tÃ© postÃ© sur Twitter. On y retrouve des news, des rÃ©flexions, lâ€™expression de sentiments ou dâ€™opinion et tant dâ€™autres choses. Et depuis, cela ne sâ€™arrÃªte pas.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Le but de cet article est de tirer parti de cette quantitÃ© dâ€™information immense et accessible afin de faire de la classification de tweets en direct, câ€™est-Ã -dire que nous allons rÃ©cupÃ©rer les tweets qui ont Ã©tÃ© postÃ©s dans les derniÃ¨res secondes, et les classifier selon leur topic.</p><p>Pour cela, nous allons utiliser Apache Kafka ainsi quâ€™une libraire python qui se nomme Tweepy. Kafka est dÃ©fini par ses crÃ©ateurs comme <em>une plateforme open-source de streaming dâ€™Ã©vÃ©nements distribuÃ©s utilisÃ©e par des milliers dâ€™entreprises pour des pipelines de donnÃ©es haute performance, des analyses en continu, lâ€™intÃ©gration de donnÃ©es et des applications critiques</em>.</p><p>En dâ€™autres termes, cela permet de mettre en contact des <em>Producers</em> (ici ceux qui tweetent) avec des <em>Consumers</em> (ici ceux qui lisent les tweets ou bien dans notre cas prÃ©cis, notre algorithme qui va rÃ©cupÃ©rer les tweets) via des <em>Topics</em> en temps rÃ©el. Câ€™est un systÃ¨me de messagerie distribuÃ© Ã  haut dÃ©bit. Câ€™est une technologie utilisÃ©e notamment par Twitter, Linkedin, Uber, AirBnB et Netflix.</p><p>CommenÃ§ons sans plus tarder !</p><h2 class=\"wp-block-heading\">Installer Apache Kafka</h2><p>Pour installer Kafka, je vous recommande de passer par Docker. Si vous nâ€™avez pas Docker, il suffit de tÃ©lÃ©charger et installer Docker Desktop <a href=\"https://www.docker.com/get-started/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. Une fois que lâ€™installation est terminÃ©e, vous pouvez utiliser Docker via votre terminal de commande. Dâ€™abord, il faut copier la cellule suivante dans un fichier texte que vous nommez <code>docker-compose.yml</code></p><pre class=\"wp-block-code\"><code>version: '3'\nservices:\n  zookeeper:\n    image: confluentinc/cp-zookeeper:6.2.0\n    container_name: zookeeper\n    environment:\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n\n  broker:\n    image: confluentinc/cp-kafka:6.2.0\n    container_name: broker\n    ports:\n    # To learn about configuring Kafka for access across networks see\n    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/\n      - \"9092:9092\"\n    depends_on:\n      - zookeeper\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1</code></pre><p>Une fois que câ€™est fait, ouvrez votre terminal de commande, naviguez jusquâ€™au dossier oÃ¹ vous avez sauvegardÃ© <code>docker-compose.yml</code> et lancez la commande suivante :</p><pre class=\"wp-block-code\"><code>docker-compose -f docker-compose.yml up -d\n</code></pre><p>Un tÃ©lÃ©chargement devrait se lancer. Une fois quâ€™il est terminÃ©, lancez la commander <code>docker ps</code> pour vÃ©rifier que tout sâ€™est bien lancÃ© :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"211\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-1024x211.png\" alt=\"installation d'apache kafka\" class=\"wp-image-5162\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-1024x211.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-300x62.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-768x158.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3-1536x317.png 1536w, https://larevueia.fr/wp-content/uploads/2022/05/Capture-3.png 1538w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption> Sortie obtenue avec docker ps</figcaption></figure><p>Vous pouvez Ã©galement lancer Kafka via Docker en vous rendant dans lâ€™onglet <code>Containers/Apps</code> de Docker :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"233\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/docker-1-1024x233.png\" alt=\"apache kafka est lancÃ©\" class=\"wp-image-5163\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/docker-1-1024x233.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-300x68.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-768x175.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-1536x349.png 1536w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1-2048x466.png 2048w, https://larevueia.fr/wp-content/uploads/2022/05/docker-1.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Onglet Containers/Apps dans docker</figcaption></figure><p>Il faut Ã  prÃ©sent crÃ©er un Topic, câ€™est-Ã -dire une catÃ©gorie oÃ¹ lâ€™on va stocker les messages (ici les tweets) envoyÃ©s par le Producer. Comme nous allons rÃ©cupÃ©rer des tweets sur la Covid-19, nous allons nommer notre topic <code>covid</code>. Pour ce faire, il suffit de lancer la commande suivante dans le terminal en ayant Docker lancÃ© (vous pouvez vÃ©rifier que câ€™est le cas dans lâ€™onglet Containers/Apps de Docker) :</p><pre class=\"wp-block-code\"><code>docker exec broker kafka-topics --bootstrap-server localhost:9092 --create --topic covid</code></pre><p>Un message indiquant <code>Created topic covid.</code> devrait alors sâ€™afficher. Si vous Ãªtes arrivÃ© jusque lÃ , vous avez fait le plus dur !</p><p>Afin dâ€™interagir avec Kafka via Python, il faut tÃ©lÃ©charger une libraire qui se nomme kafka-python. Pour lâ€™installer : <code>pip install kafka-python </code>dans le terminal de commande.</p><h2 class=\"wp-block-heading\">Tweepy et lâ€™API Twitter</h2><p>Pour pouvoir rÃ©cupÃ©rer des tweets avec Kafka et Python, il nous faut passer par lâ€™API Twitter. Pour cela, vous devez au prÃ©alable disposer dâ€™un compte Twitter. Il vous faudra ensuite vous rendre <a href=\"https://developer.twitter.com/en\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a> et vous connecter pour activer votre compte dÃ©veloppeur.</p><p>Il se peut que vous ayez Ã  remplir quelques questions rapides (prÃ©nom, pays de rÃ©sidence,â€¦) ainsi quâ€™Ã  valider votre compte dÃ©veloppeur par mail. Une fois que câ€™est fait, il vous est demandÃ© de choisir le nom de votre application :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"587\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/get_keys-1024x587.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5127\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/get_keys-1024x587.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-300x172.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-768x440.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-1536x880.png 1536w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys-2048x1174.png 2048w, https://larevueia.fr/wp-content/uploads/2022/05/get_keys.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Twitter Developer Platform</figcaption></figure><p>DÃ¨s que vous validez, vous avez accÃ¨s Ã  vos tokens de connexion Ã  lâ€™API. Gardez les en lieu sÃ»r, on les utilisera juste aprÃ¨s.</p><h2 class=\"wp-block-heading\">RÃ©cupÃ©rer les tweets en direct avec Apache Kafka</h2><p>Ã€ prÃ©sent, nous allons Ã©crire le script python qui va nous permettre de rÃ©cupÃ©rer les tweets en direct. Dâ€™abord, on importe les librairies dont on aura besoin :</p><pre class=\"wp-block-code\"><code>from kafka import KafkaProducer\nimport tweepy\nimport datetime\nimport time\nimport json\n</code></pre><p>KafkaProducer va nous permettre dâ€™envoyer les tweets Ã  Kafka (et on les rÃ©cupÃ©rera plus tard avec KafkaConsumer). Tweepy permet de se connecter Ã  lâ€™API Twitter. Les autres modules nous seront utiles pour certaines manipulations.</p><p>Nous allons nous connecter Ã  lâ€™API Twitter avec la classe <code>Client </code>de <a href=\"https://larevueia.fr/nlp-avec-python-analyse-de-sentiments-sur-twitter/\" target=\"_blank\" rel=\"noreferrer noopener\">Tweepy</a>. On aura pour cela besoin du BearerToken que vous avez mis de cÃ´tÃ© prÃ©cÃ©demment. Nous allons Ã©galement initialiser un objet de la classe KafkaProducer :</p><pre class=\"wp-block-code\"><code>client = tweepy.Client(bearer_token=\"PLACER_VOTRE_BEARER_TOKEN_ICI\")\nproducer = KafkaProducer()\nquery = \"covid\"</code></pre><p>On dÃ©finit Ã©galement la query, câ€™est-Ã -dire le mot que lâ€™on veut chercher dans tous les tweets. Pour nous, ce sera Â«Â covidÂ Â», mais vous pouvez essayer dâ€™autres mots ou sÃ©ries de mots si vous le voulez ! Nous allons rÃ©cupÃ©rer les tweets anglais puisquâ€™ils sont plus nombreux et que nous allons utiliser un modÃ¨le entrainÃ© sur des tweets anglais.</p><p>Avec tweepy, on ne peut rÃ©colter que les tweets qui datent dâ€™au moins 10 secondes. Pour Ãªtre sÃ»r de respecter ce dÃ©lai (et comme jâ€™ai rencontrÃ© des problÃ¨mes mÃªme en prenant 15 secondes), nous allons prendre 30 secondes. Nous allons donc rÃ©gler le temps de dÃ©but de rÃ©colte des tweets Ã  40 secondes du temps actuel, et la fin Ã  30 secondes.</p><p>On utilise la mÃ©thode <code>search_recent_tweets</code> pour rÃ©colter les tweets les plus rÃ©cents. Nous sommes limitÃ©s Ã  100 par appel de la mÃ©thode, nous allons donc nous limiter Ã  100 tweets. Enfin, on spÃ©cifie les champs que lâ€™on veut rÃ©colter via le paramÃ¨tre <code>tweet_fields</code> : le corps du tweet, sa date de crÃ©ation ainsi que sa langue :</p><pre class=\"wp-block-code\"><code>start_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=40)\nend_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=10)\n\ntweets = client.search_recent_tweets(query=query,\n                                        tweet_fields=['context_annotations', 'created_at', 'lang'], \n                                        max_results=100, \n                                        start_time=start_time,\n                                        end_time=end_time)\nstart_time = end_time\nend_time = start_time + datetime.timedelta(seconds=10)\n</code></pre><p>Puis on rÃ©cupÃ¨re le contenu des tweets en sÃ©lectionnant uniquement les tweets anglais, on envoie les tweets sur Kafka et on affiche un message pour indiquer que tout sâ€™est bien passÃ©.</p><pre class=\"wp-block-code\"><code>for i,tweet in enumerate(tweets.data):\n  if tweet.lang == 'en':\n    tweet = json.dumps(tweet.text).encode('utf-8')\n    producer.send('covid', tweet)\n    print(f'Le {i}Ã¨me tweet a Ã©tÃ© envoyÃ© Ã  Kafka avec succÃ¨s!')\n\n    </code></pre><p>On ajoute une boucle <code>while</code> pour rÃ©pÃ©ter le processus sans arrÃªt. On fait une pause de 10 secondes pour ne pas avoir une redondance dans les tweets rÃ©cupÃ©rÃ©s : Le script complet :</p><pre class=\"wp-block-code\"><code>from kafka import KafkaProducer\nimport tweepy\nimport datetime\nimport time\nimport json\n\nclient = tweepy.Client(bearer_token='PLACER_VOTRE_BEARER_TOKEN_ICI')\nproducer = KafkaProducer()\n# producer.flush()\nquery = 'covid'\nstart_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=40)\nend_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=30)\n\nwhile True:\n\n    tweets = client.search_recent_tweets(query=query,\n                                        tweet_fields=['context_annotations', 'created_at', 'lang'], \n                                        max_results=100, \n                                        start_time=start_time,\n                                        end_time=end_time)\n    start_time = end_time\n    end_time = start_time + datetime.timedelta(seconds=10)\n\n    for i,tweet in enumerate(tweets.data):\n        if tweet.lang == 'en':\n            tweet = json.dumps(tweet.text).encode('utf-8')\n            producer.send('covid', tweet)\n        print(f'Le {i}Ã¨me tweet a Ã©tÃ© envoyÃ© Ã  Kafka avec succÃ¨s!')\n    print('Pause de 10 secondes!')\n    time.sleep(10)</code></pre><p>En lanÃ§ant le script, on obtient le message que les tweets ont bien Ã©tÃ© envoyÃ©s Ã  Kafka. Toutes les 10 secondes, une centaine de tweet sont envoyÃ©s Ã  Kafka au topic Â«Â covidÂ Â». Il faut maintenant les rÃ©cupÃ©rer pour pouvoir les utiliser ultÃ©rieurement. <strong>Il est indispensable que ce script soit lancÃ© lorsque vous rÃ©aliserez les parties suivantes !</strong> Je vous conseille de le lancer via le terminal de votre PC en ouvrant un terminal au niveau de votre script et en lancant <code>python nom_de_votre_script.py</code></p><h2 class=\"wp-block-heading\">Nuage de mots</h2><p>Faisons tout dâ€™abord un nuage de mots des tweets que nous avons rÃ©cupÃ©rÃ©. Cela nous permettra de voir quels sont les mots les plus rÃ©currents. Dâ€™abord nous allons dÃ©finir une fonction pour nettoyer et prÃ©parer nos tweets. Comme dâ€™habitude, si vous nâ€™avez pas la librairie nltk, faites <code>pip install nltk</code>.</p><pre class=\"wp-block-code\"><code>from nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nimport string\n\ndef pre_process_tweet(tweet):\n    tokenizer = RegexpTokenizer(r'\\w+')\n    lemmatizer = WordNetLemmatizer()\n    # tokenize and remove stop words and number\n    tweet_tokens = tokenizer.tokenize(tweet)[1:]\n    tweet_tokens = [word for word in tweet_tokens if word.isalpha()]\n    tweet_tokens = [word for word in tweet_tokens if word.lower() != 'rt']\n    tweet = \" \".join([word for word in tweet_tokens if word not in stopwords.words('french')])\n\n    # remove \\n from the end after every sentence\n    tweet = tweet.strip('\\n')\n\n    # Remove any word that starts with the symbol @\n    tweet = \" \".join(filter(lambda x: x[0] != '@', tweet.split()))\n\n    # remove non utf-8 characters\n    tweet = bytes(tweet, 'utf-8').decode('utf-8','ignore')\n\n    # Remove any URL\n    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n    tweet = re.sub(r\"www\\S+\", \"\", tweet)\n\n    # remove colons from the end of the sentences (if any) after removing url\n    tweet = tweet.strip()\n    tweet_len = len(tweet)\n    if tweet_len &gt; 0:\n        if tweet[len(tweet) - 1] == ':':\n            tweet = tweet[:len(tweet) - 1]\n\n    # Remove any hash-tags symbols\n    tweet = tweet.replace('#', '')\n\n    # Convert every word to lowercase\n    tweet = tweet.lower()\n\n    # remove punctuations\n    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n\n    # trim extra spaces\n    tweet = \" \".join(tweet.split())\n\n    # lematize words\n    tweet = lemmatizer.lemmatize(tweet)\n\n    return(tweet)</code></pre><p>Parmi les opÃ©rations effectuÃ©es : tokenization, lemmatization (prendre la racine dâ€™un mot), suppression des url, de la ponctuation, des symboles, â€¦</p><p>Pour crÃ©er notre nuage de mots, nous allons utiliser la librairie <code>wordcloud</code>. Si elle nâ€™est pas installÃ©e sur votre machine, faites simplement <code>pip install wordcloud.</code> Pour rÃ©cupÃ©rer les tweets qui ont Ã©tÃ© envoyÃ© sur le <em>topic </em>Â«Â covidÂ Â», nous allons initialiser un <em>Consumer </em>avec le paramÃ¨tre Â«Â covidÂ Â» (le nom du topic) :</p><pre class=\"wp-block-code\"><code>from wordcloud import WordCloud\nfrom kafka import KafkaConsumer\nconsumer = KafkaConsumer(\"covid\")</code></pre><p>Nous allons dâ€™abord rÃ©cupÃ©rer les 50 premiers tweets et construire le wordcloud avec les mots quâ€™ils contiennent. Pour cela, nous allons concatÃ©ner tous les tweets dans la chaine de caractÃ¨re nommÃ©e <code>total_sentences</code>. Nous allons ajouter un <em>mask</em> afin de donner Ã  notre nuage de point la forme du logo Twitter.  Pour ce faire, tÃ©lÃ©charger lâ€™image <a href=\"https://i.goopics.net/6jle2q.jpg\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>, nommez la Â«Â twitter_logo.jpgÂ Â» et placer-lÃ  dans le mÃªme dossier que votre script/notebook. Vous pouvez vous amuser en modifiant les paramÃ¨tres du nuage de mots pour obtenir des rÃ©sultats differents.</p><pre class=\"wp-block-code\"><code>import numpy as np\nfrom PIL import Image\nimport json\nimport numpy as np\nfrom PIL import Image\nimport json\nimport matplotlib.pyplot as plt\n\ntotal_sentences = \"\"\ntwitter_mask = np.array(Image.open(\"twitter_logo.jpg\"))\nfor i in range(50):\n        tweet = json.loads(next(iter(consumer)).value)\n        clean_tweet = pre_process_tweet(tweet=tweet)\n        total_sentences += clean_tweet\n        total_sentences += \" \"\nwordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100, mask=twitter_mask, \ncontour_color=\"steelblue\", contour_width=0, background_color=\"white\").generate(total_sentences)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()</code></pre><p>Le code peut prendre un peu de temps Ã  se lancer. Kafka peut parfois Ãªtre capricieux, si vous utilisez une notebook, nâ€™hÃ©sitez pas Ã  rÃ©instancier votre Consumer avant de lancer une cellule. Jâ€™ai effectuÃ© le nuage de mots en franÃ§ais pour que cela soit plus parlant (et car on nâ€™a pas besoin dâ€™utiliser le modÃ¨le entrainÃ© sur les tweets anglais), mais je passerai Ã  lâ€™anglais Ã  partir de maintenant. Vous devriez obtenir quelque chose semblable Ã  ceci :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/wordcloud.png\" alt=\"Nuage de mots obtenu avec des tweets franÃ§ais, tweepy\" class=\"wp-image-5128\" width=\"669\" height=\"513\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/wordcloud.png 585w, https://larevueia.fr/wp-content/uploads/2022/05/wordcloud-300x230.png 300w\" sizes=\"auto, (max-width: 669px) 100vw, 669px\"><figcaption>Nuage de mots obtenu avec des tweets franÃ§ais</figcaption></figure></div><p>On obtient des mots qui sont bien liÃ©s au covid et quâ€™on a beaucoup entendus ces derniÃ¨res annÃ©es : morts, vaccin, olivier veran, Ã©pidÃ©mie, â€¦</p><p>Vous nâ€™obtiendrez pas exactement la mÃªme chose que moi car les tweets que vous allez rÃ©cupÃ©rer sont diffÃ©rents des miens. On peut modifier le code pour actualiser le nuage de mots avec les nouveaux tweets toutes les 5 secondes :</p><pre class=\"wp-block-code\"><code>import numpy as np\nfrom PIL import Image\nimport json\nimport numpy as np\nfrom PIL import Image\nimport json\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15,8))\ntwitter_mask = np.array(Image.open(\"img_notebook/twitter_logo.jpg\"))\ntotal_sentences = \"\"\nwhile True:\n    for i in range(10):\n        tweet = json.loads(next(iter(consumer)).value)\n        clean_tweet = pre_process_tweet(tweet=tweet)\n        total_sentences += clean_tweet\n        total_sentences += \" \"\n    wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100, mask=twitter_mask, \n    contour_color=\"steelblue\", contour_width=0, background_color=\"white\").generate(total_sentences)\n\n    # plot the graph\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    plt.pause(5)\n    clear_output(wait=True)\n    plt.figure(figsize=(15,8))</code></pre><p>Il est important de noter que nous aurions pu effectuer ces manipulations et obtenir ce nuage de mots sans passer par Apache Kafka, uniquement avec lâ€™API Twitter. Nous nâ€™avons pas utilisÃ© tout le potentiel de Kafka. Nous pourrions par exemple rÃ©cupÃ©rer les tweets avec diffÃ©rents scripts donc chacun serait indÃ©pendant et aurait un but diffÃ©rent : crÃ©er un wordcloud dynamique, classifier les tweets, prÃ©venir lâ€™utilisateur dÃ¨s lors quâ€™un certains type de tweet est dÃ©tectÃ©, ou quâ€™un utilisateur en particulier poste un tweet, â€¦Il est Ã©galement possible dâ€™envoyer les tweets vers diffÃ©rents topics en mÃªme temps et les rÃ©cupÃ©rer sur diffÃ©rents scripts pour diffÃ©rentes utilisations.</p><p>Ici, la force de Kafka que lâ€™on utilise est que les tweets sont rÃ©cupÃ©rÃ©s et envoyÃ©s dans un topic Kafka de maniÃ¨re indÃ©pendante de tous les autres scripts. Ainsi, en initialisant un <em>Consumer</em> avec le topic Â«Â covidÂ Â», nous pouvons rÃ©cupÃ©rez tous les tweets qui ont Ã©tÃ© envoyÃ© sur Kafka peu import oÃ¹ lâ€™on se trouve sur la machine.</p><h2 class=\"wp-block-heading\">CrÃ©ation des topics</h2><p>Nous passons maintenant Ã  la partie Machine Learning de lâ€™article ! Afin de dÃ©terminer les topics dans lesquels nous allons classer nos tweets, nous allons rÃ©cupÃ©rer 20 000 tweets, puis, aprÃ¨s les avoir nettoyÃ©s, nous allons dÃ©terminer les 10 sujets les plus rÃ©currents.  Pour transformer nos tweets (qui sont des chaines de caractÃ¨res), en inputs comprÃ©hensibles pour lâ€™ordinateur (des chiffres), nous allons utiliser word2vec. Je vous en ai dÃ©jÃ  parlÃ© dans un article prÃ©cÃ©dent <a href=\"https://larevueia.fr/quest-ce-que-le-nlp-natural-language-processing/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. Nous allons utiliser un modÃ¨le qui a Ã©tÃ© prÃ©-entrainÃ© sur plus de 400M de tweets anglais. Vous pouvez le tÃ©lÃ©charger <a href=\"https://mega.nz/file/h0VCxDQJ#RD11bJvp6NbEfFLGKe0H7ZGDgppz7-95LDNpep5vP2s\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a> (attention, il est assez volumineux). Pour le charger, nous utilisons gensim :</p><pre class=\"wp-block-code\"><code>model = gensim.models.KeyedVectors.load_word2vec_format('word2vec_twitter_model.bin', binary=True, unicode_errors='ignore')\n</code></pre><p>Ce modÃ¨le transforme chaque tweet en un vecteur de taille 400. Le script suivant permet de rÃ©cupÃ©rer 20000 tweets. <code>tweet_embeddings</code> est un tableau qui contient lâ€™embedding de chaque tweet, et <code>text_data</code> contient les tweets bruts.</p><pre class=\"wp-block-code\"><code># n_sample = 20000\n# tweets_embeddings = np.zeros((n_sample, 400))\n# text_data = []\n# row = 0\n\n# for tweet in consumer:\n#     if row == n_sample:\n#         break\n#     tweet = json.loads(tweet.value)\n#     clean_tweet = pre_process_tweet(tweet)\n#     embeddings = get_word2vec_embeddings(model=model, tokenizer=tokenizer, sentence=clean_tweet, k=400)\n#     if np.isnan(embeddings).sum() == 0:\n#         tweets_embeddings[row,:] = embeddings\n#         text_data.append(clean_tweet)\n#         row += 1</code></pre><p>Cette Ã©tape est relativement longue (environ 1h30). Pour la faire durer moins longtemps, vous pouvez rÃ©duire le nombre de tweets Ã  rÃ©cupÃ©rer. Vous pouvez Ã©galement utiliser les tweets que jâ€™ai moi-mÃªme rÃ©cupÃ©rÃ©s. Vous pouvez tÃ©lÃ©charger <code>text_data</code> <a href=\"https://drive.google.com/file/d/1xmzMG6Xt8Rqdxgqk0HJ7kvWxw9SBPHWR/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a> et <code>tweets_embeddings</code> <a href=\"https://drive.google.com/file/d/1Lkqa-2L5-X3lukU5am17D05God28rFPt/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. Il faut ensuite les charger avec la librairie <code>pickle</code> (si vous avez Python 3.9 ou plus, pickle devrait Ãªtre nativement prÃ©sent, sinon <code>pip install pickle4</code> ou <code>pip install pickle-mixin</code>.</p><h2 class=\"wp-block-heading\">TF-IDF</h2><p>Afin de dÃ©terminer quels sont les topics prÃ©ponderants dans nos tweets, nous allons utiliser la mÃ©thode TF-IDF. Si vous ne savez pas ce que câ€™est, nous en avons dÃ©jÃ  parlÃ© <a href=\"https://larevueia.fr/quest-ce-que-le-nlp-natural-language-processing/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>. En quelques mots, TF-IDF compte de maniÃ¨re intelligente le nombre de fois que chaque mot apparaÃ®t dans une classe de documents. Si le mot apparaÃ®t Ã©galement dans toutes les autres classes, il nâ€™est probablement pas important (comme Â«Â leÂ Â» ou Â«Â unÂ Â») et, pour cette raison, il nâ€™est pas considÃ©rÃ© comme Â«Â frÃ©quentÂ Â». Cela nous permet de rÃ©cupÃ©rer les topics les plus pertinents. Pour ce faire, nous allons dÃ©finir trois fonctions :</p><pre class=\"wp-block-code\"><code>from sklearn.feature_extraction.text import CountVectorizer\n\ndef c_tf_idf(documents, m, ngram_range=(1, 1)):\n    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n    t = count.transform(documents).toarray()\n    w = t.sum(axis=1)\n    tf = np.divide(t.T, w)\n    sum_t = t.sum(axis=0)\n    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n    tf_idf = np.multiply(tf, idf)\n\n    return tf_idf, count\n\ndef extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n    words = count.get_feature_names()\n    labels = list(docs_per_topic.Topic)\n    tf_idf_transposed = tf_idf.T\n    indices = tf_idf_transposed.argsort()[:, -n:]\n    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n    return top_n_words\n\ndef extract_topic_sizes(df):\n    topic_sizes = (df.groupby(['Topic'])\n                     .Doc\n                     .count()\n                     .reset_index()\n                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n                     .sort_values(\"Size\", ascending=False))\n    return topic_sizes</code></pre><p>La fonction <code>c_tf_idf</code> permet dâ€™obtenir le score TF-IDF ainsi que le nombre de mots totaux; <code>extract_top_n_words_per_topic</code> et <code>extract_topic_sizes</code> donnent respectivement les n mots avec le score TF-IDF le plus Ã©lÃ©vÃ© et la taille de chaque topic. Pour dÃ©terminer les topics, nous utilisons un modÃ¨le K-Means de scikit-learn que nous entrainons avec nos 20000 tweets. Nous choisissons 15 clusters pour avoir 15 topics. Vous pouvez choisir plus ou moins, en fonction du nombre de topics que vous dÃ©sirez.</p><pre class=\"wp-block-code\"><code>from sklearn.cluster import MiniBatchKMeans\n\nn_clusters=15\ncluster = MiniBatchKMeans(n_clusters=n_clusters, random_state=0).fit(tweets_embeddings)\n</code></pre><p>Pour chaque cluster, nous regroupons tous les tweets en un seul gros tweet afin de pouvoir effectuer le comptage TF-IDF. Ensuite, pour chaque classe, nous rÃ©cupÃ©rons les n premiers mots ayant le score TF-IDF le plus Ã©levÃ©, puis, pour chaque classe, nous choisissons le mot ayant le score le plus bas. Cette mÃ©thode nous permet de rÃ©cupÃ©rer les mots qui apparaissent souvent dans un document mais qui sont en mÃªme temps discriminants.</p><pre class=\"wp-block-code\"><code>docs_df = pd.DataFrame(text_data, columns=[\"Doc\"])\ndocs_df['Topic'] = cluster.labels_\ndocs_df['Doc_ID'] = range(len(docs_df))\ndocs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})\n\n  \ntf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(text_data))\ntop_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=10)\ntopic_sizes = extract_topic_sizes(docs_df).set_index('Topic')\ntopic_sizes.head(15)</code></pre><p>Nous pouvons voir nos 15 topics avec la taille de chaque topic (sans le label des topics pour le moment) :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/output1-1.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5143\" width=\"164\" height=\"495\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/output1-1.png 163w, https://larevueia.fr/wp-content/uploads/2022/05/output1-1-99x300.png 99w\" sizes=\"auto, (max-width: 164px) 100vw, 164px\"><figcaption>NumÃ©rotation et taille des topics</figcaption></figure></div><p>Pour obtenir le label de chaque topic, nous allons prendre lâ€™Ã©lÃ©ment avec le plus petit score TF-IDF dans <code>top_n_words</code> pour chaque topic :</p><pre class=\"wp-block-code\"><code>data = pd.DataFrame(top_n_words[0][:n_clusters])\ndata['Class'] = [0]*len(data)\nfor i in range(1,len(top_n_words)):\n  data_i = data_0 = pd.DataFrame(top_n_words[i][:1000])\n  data_i['Class'] = [i]*len(data_i)\n  data = data.append(data_i)\ndata = data.sort_values(by=1,ascending=False)\n\nfinal_data = data.drop_duplicates(subset=0).sort_values(by='Class').drop_duplicates(subset='Class',keep='last').rename(columns={0:'label', 1:'TF-IDF score'})\nfinal_data</code></pre><p>Ce qui donne les labels suivants :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"466\" height=\"682\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/output2-1.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5144\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/output2-1.png 466w, https://larevueia.fr/wp-content/uploads/2022/05/output2-1-205x300.png 205w\" sizes=\"auto, (max-width: 466px) 100vw, 466px\"><figcaption>Label et score de chaque topic</figcaption></figure></div><p>On trouve des topics assez parlant comme Â«Â vaxÂ Â», Â«Â lawsÂ Â» ou Â«Â variantÂ Â», et dâ€™autres un peu moins comme Â«Â spouseÂ Â» ou Â«Â likeÂ Â». Câ€™est nÃ©anmoins assez reprÃ©sentatif du covid. Vous pouvez vous amusez Ã  jouer avec le nombre de topics ainsi que le nombre de mots que vous choisissez dans la fonction <code>top_n_words</code> pour obtenir des rÃ©sultats diffÃ©rents.</p><h2 class=\"wp-block-heading\">Visualisation des topics via PCA</h2><p>Nous pouvons faire une PCA (Analyse par Composantes Principales) pour voir comment se rÃ©partissent les diffÃ©rents topics. Dâ€™abord, effectuons une PCA en 2D avec scickit-learn. Nous allons faire la PCA sur les embeddings des 20 000 tweets que nous avons rÃ©cupÃ©rÃ©s, puis nous allons associer Ã  chaque embedding son topic. Pour cela, nous utilisons seaborn et scikit-learn.</p><pre class=\"wp-block-code\"><code>from sklearn.decomposition import PCA\nimport seaborn as sns\n\npca_2d = PCA(n_components=2)\npca_2d.fit(tweets_embeddings)\npca_2d_data = pd.DataFrame(pca_2d.transform(tweets_embeddings),columns=['FirstComponent','SecondComponent'])\nsns.scatterplot(x=pca_2d_data.FirstComponent,y=pca_2d_data.SecondComponent, \n                hue=[labels_to_class[cluster_label] for cluster_label in cluster.labels_])\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)</code></pre><p>On obtient un rÃ©sultat assez Ã©lÃ©gant, les diffÃ©rents topics sont bien sÃ©parÃ©s !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA2D.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5145\" width=\"652\" height=\"321\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA2D.png 532w, https://larevueia.fr/wp-content/uploads/2022/05/PCA2D-300x148.png 300w\" sizes=\"auto, (max-width: 652px) 100vw, 652px\"><figcaption>Visualisation de la PCA en 2D</figcaption></figure></div><p>Nous pouvons Ã©galement le faire en 3D pour encore mieux visualiser les embeddings. Câ€™est un peu plus complexe que pour la 2D mais rien de trÃ¨s difficile Ã  comprendre. Nous utilisons plotly :</p><pre class=\"wp-block-code\"><code>import plotly.express as px\n\npca_3d = PCA(n_components=3)\npca_3d.fit(tweets_embeddings)\npca_3d_data = pd.DataFrame(pca_3d.transform(tweets_embeddings),columns=['FirstComponent','SecondComponent','ThirdComponent'])\nx = pca_3d_data.FirstComponent\ny = pca_3d_data.SecondComponent\nz = pca_3d_data.ThirdComponent\n\ndf_3D = pd.DataFrame(columns=['x', 'y', 'z', 'label'])\ndf_3D['x'] = x\ndf_3D['y'] = y\ndf_3D['z'] = z\ndf_3D['label'] = [labels_to_class[cluster_label] for cluster_label in cluster.labels_]\n\nfig = px.scatter_3d(df_3D, x='x', y='y', z='z',\n              color='label')\n\nfig.show()</code></pre><p>Le rÃ©sultat est encore meilleur ! Lorsque vous le lancez chez vous, pouvez faire bouger le plot avec la souris pour visualiser comme bon vous semble !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-1024x406.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5147\" width=\"794\" height=\"315\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-1024x406.png 1024w, https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-300x119.png 300w, https://larevueia.fr/wp-content/uploads/2022/05/PCA3D-768x305.png 768w, https://larevueia.fr/wp-content/uploads/2022/05/PCA3D.png 1134w\" sizes=\"auto, (max-width: 794px) 100vw, 794px\"><figcaption>Visualisation de la PCA en 3D</figcaption></figure></div><p>Vous pourriez avoir lâ€™idÃ©e dâ€™utiliser les tweets obtenu via la PCA pour faire la classification (que nous ferons Ã  la prochaine partie), mais cela ne fait que trop rÃ©duire lâ€™information, et cela mÃ¨ne Ã  de moins bon rÃ©sultats. Vous verrez que le modÃ¨le se dÃ©brouille plutÃ´t bien mÃªme avec 400 composantes dans lâ€™embeddings !</p><h2 class=\"wp-block-heading\">Classification en direct des tweets</h2><p>Nous passons dorÃ©navant Ã  la partie Machine Learning avec laquelle vous Ãªtes, je pense, un peu plus Ã  lâ€™aise ! Nous allons utiliser les clusters que nous avons dÃ©terminÃ©s dans la partie prÃ©cÃ©dente, ainsi que le mÃªme MiniBatchKMeans. Chaque fois quâ€™un tweet est classÃ©, nous le mettons dans un DataFrame qui contient les tweets et leur prÃ©diction. Tous les 100 tweets, nous sauvegarderons ce DataFrame ainsi que notre modÃ¨le sous le nom Â«Â clusterÂ Â». Nous devons dâ€™abord initialiser un Consumer avec le topic Â«Â covidÂ Â». Nâ€™oubliez pas de lancer docker et Kafka avant cette Ã©tape si ce nâ€™est pas dÃ©jÃ  fait (toujours dans lâ€™onglet Containers/Apps).</p><pre class=\"wp-block-code\"><code>consumer = KafkaConsumer('covid')\n</code></pre><p>Toutes les 100 prÃ©dictions, nous affichons un message qui indique que cents tweets supplÃ©mentaires ont Ã©tÃ© classifiÃ©s. <strong>Notez bien quâ€™il faut lancer le script qui rÃ©cupÃ¨re les tweets et les envoie sur Kafka avant de lancer la cellule suivante !</strong></p><pre class=\"wp-block-code\"><code>df_predictions = pd.DataFrame(columns=['tweet', 'prediction'])\n\nfor tweet in consumer:\n    row = df_predictions.shape[0]\n    tweet = json.loads(tweet.value)\n    clean_tweet = pre_process_tweet(tweet)\n    embeddings = get_word2vec_embeddings(model=model, tokenizer=tokenizer, sentence=clean_tweet, k=400).reshape(1,-1).astype(np.double)\n    cluster.partial_fit(embeddings)\n    prediction = cluster.predict(embeddings)[0]\n    df_predictions.loc[row, 'tweet'], df_predictions.loc[row, 'prediction'] = tweet, labels_to_class[prediction]\n    sample_score_embeddings[row % 1000, :] = embeddings\n    sample_score_labels[row % 1000, :] = prediction\n    if row % 100 == 0:\n        print(f'{row} tweets ont Ã©tÃ© classifiÃ©s')\n        print(100*'-')\n        with open('cluster', 'wb') as f:\n            pickle.dump(cluster, f)\n        try:\n            df_predictions.to_excel('df_predictions.xls')\n        except:\n            pass</code></pre><p>Le script est conÃ§u pour tourner en continu et ne pas sâ€™arrÃªter, vous pouvez interrompre son exÃ©cution quand vous le voulez, ou le modifier pour quâ€™il sâ€™arrÃªte lorsque vous le dÃ©sirez. VoilÃ  un extrait de ce que jâ€™ai obtenu :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"711\" height=\"534\" src=\"https://larevueia.fr/wp-content/uploads/2022/05/final_output.png\" alt=\"Tutoriel Apache Kafka : classification de tweets en direct\" class=\"wp-image-5155\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/05/final_output.png 711w, https://larevueia.fr/wp-content/uploads/2022/05/final_output-300x225.png 300w\" sizes=\"auto, (max-width: 711px) 100vw, 711px\"><figcaption>Extrait du dataframe de prÃ©diction final</figcaption></figure></div><p>On retrouve le numÃ©ro du tweet classifiÃ© (dans lâ€™ordre croissant dâ€™arrivÃ©), le tweet en question et le topic dans lequel il a Ã©tÃ© classifiÃ©.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Ceci conclu notre tutoriel de classification non supervisÃ© de tweet en utilisant Apache Kafka. Il est important de noter que nous nâ€™avons pas exploitÃ© Kafka Ã  son plein potentiel dans cet article.</p><p>Nous avons seulement voulu vous introduire cette technologie. Il est possible de faire beaucoup plus, notamment en utilisant diffÃ©rents topics, diffÃ©rents consumers, diffÃ©rents producers, differentes applications, â€¦</p><p>Vous pouvez vous entrainer et dÃ©velopper le potentiel de Kafka sur des donnÃ©es de vÃ©los partagÃ©s : <a href=\"https://developer.jcdecaux.com/#/login\" target=\"_blank\" rel=\"noreferrer noopener\">https://developer.jcdecaux.com/#/login</a>. Vous obtiendrez les donnÃ©es de <em>Bike Sharing Systems</em> (comme VÃ©lib Ã  Paris) disponible partout dans le monde. On a, entre autre, le nom de la station, la ville, le nombre de vÃ©los disponibles, le nombre de vÃ©los maximum,â€¦ Vous pouvez vous entrainer et vous amusez avec ce jeu de donnÃ©es en direct!</p></div>"},
{"url": "https://larevueia.fr/lintelligence-artificielle-au-service-du-recrutement/", "title": "Lâ€™intelligence artificielle au service du recrutement", "author": "Ryan Nursoo", "date": "\n19 juillet 2022\n", "content": "<div class=\"entry-content\"><p>Depuis quâ€™Alan Turing a introduit la question de la capacitÃ© de rÃ©flexion des machines en 1950, le paysage technologique de lâ€™intelligence artificielle (IA) a changÃ©.</p><p>Lâ€™intelligence artificielle sâ€™est dÃ©veloppÃ©e depuis des dÃ©cennies : lâ€™IA symbolique, marquÃ©e par la conception de systÃ¨mes basÃ©s sur la logique, a connu un temps dâ€™arrÃªt avant sa renaissance dans les annÃ©es 1970 (<em>AI Winter</em>).</p><p>Depuis 2011, des progrÃ¨s dÃ©cisifs ont Ã©tÃ© rÃ©alisÃ©s dans le domaine du <a href=\"https://larevueia.fr/le-machine-learning-en-20-questions/\" target=\"_blank\" rel=\"noreferrer noopener\">machine learning</a> et les branches de lâ€™IA qui sâ€™appuient sur des mÃ©thodes statistiques, permettant dâ€™amÃ©liorer la capacitÃ© des machines Ã  faire des prÃ©dictions basÃ©es sur des donnÃ©es historiques.</p><p>Depuis quelques annÃ©es, les RH des entreprises sâ€™intÃ©ressent Ã  ces nouvelles techniques. Les ressources humaines notamment, se sont armÃ©es de logiciels toujours plus performants. Mais comme toute rÃ©volution, celle-ci vient avec des aspects positifs et des aspects qui le sont moins.</p><h2 class=\"wp-block-heading\">Un milieu qui Ã©volue</h2><p>Les ressources humaines bÃ©nÃ©ficient des nombreuses opportunitÃ©s offertes par lâ€™intelligence artificielle, que ce soit dans le recrutement, la gestion des effectifs ou la communication interne.</p><p>Ces solutions offrent par exemple la possibilitÃ© de sâ€™affranchir de certaines tÃ¢ches rÃ©pÃ©titives, dâ€™anticiper les besoins en compÃ©tences des collaborateurs, de traiter les candidatures de maniÃ¨re plus pertinente ou encore dâ€™optimiser la communication interne via des systÃ¨mes intelligents de recherche et de partage de lâ€™information.</p><p>Beaucoup dâ€™acteurs sont dâ€™accord pour dire que lâ€™IA entraÃ®ne une Ã©volution plus que positive dans les ressources humaines. En effet : 66 % des PDG pensent que ces technologies peuvent apporter de la valeur aux RH ; 50 % des DRH reconnaissent leur capacitÃ© Ã  modifier des aspects majeurs de leur activitÃ© ; 54 % pensent que lâ€™IA aura un impact sur les rÃ´les clÃ©s des organisations RH.</p><h2 class=\"wp-block-heading\">Les risques et avantages de lâ€™utilisation de lâ€™IA pour le recrutement</h2><p>Toute transformation numÃ©rique comporte des risques et des avantages.</p><p>Le principal risque, qui est le plus citÃ©, est que lâ€™IA pourrait entraÃ®ner la suppression de certains emplois. MÃªme si le mÃ©tier de RH reste humain aujourdâ€™hui, les recruteurs interviennent de moins en moins et sont de plus en plus spÃ©cialisÃ©s.</p><p>Par ailleurs, lâ€™utilisation de lâ€™intelligence artificielle de faÃ§on plus Ã©thique. Dans un prÃ©cÃ©dent article nous vous avions parlÃ© de lâ€™entreprise japonaise <strong><em>Iâ€™m beside you</em></strong>. Ils utilisent lâ€™intelligence artificielle pour prÃ©dire le caractÃ¨re dâ€™une personne ou pour dÃ©tecter des formes dâ€™autismes durant les entretiens qui se font en visio.</p><p>ParallÃ¨lement, lâ€™utilisation des nouveaux outils numÃ©riques permet aux salariÃ©s dâ€™acquÃ©rir de nouvelles compÃ©tences et de sâ€™adapter Ã  de nouvelles formes de travail.</p><p>En pratique, cela aide les RH Ã  se recentrer sur les tÃ¢ches les plus pertinentes, Ã  les dÃ©charger et Ã  se concentrer sur le capital humain. Lâ€™intelligence artificielle facilite lâ€™adaptation dâ€™un employÃ© dans une organisation Ã  diffÃ©rentes Ã©tapes : recrutement, Ã©volution au sein de lâ€™entreprise, formation.</p><p>Lâ€™IA peut Ãªtre un vÃ©ritable alliÃ© qui permet Ã  lâ€™organisation de se diffÃ©rencier de ses concurrents, dâ€™attirer les talents Ã  fort potentiel et de fidÃ©liser les collaborateurs existants. Lâ€™intelligence artificielle est un partenaire idÃ©al pour les employÃ©s comme pour les managers car elle les soulage de bon nombre de leurs tÃ¢ches quotidiennes chronophage.</p><p>Lâ€™autonomie des collaborateurs et de lâ€™ensemble de la fonction RH prÃ©sente des avantages considÃ©rables. Investir dans lâ€™IA est unÂ  moyen de dÃ©velopper sa performance, dâ€™affronter un environnement concurrentiel et dâ€™apporter une touche plus humaine Ã  la gestion des ressources humaines.</p><p>Cependant, les responsables RH doivent Ãªtre conscients que lâ€™inclusion de lâ€™intelligence artificielle dans le processus de recrutement, doit se faire en prenant en compte le fait que câ€™est un processus humain.</p><p>En fait, du point de vue dâ€™un candidat, de nombreuses prÃ©occupations liÃ©es Ã  lâ€™intelligence artificielle se font ressentir, et le fait de laisser Ã  une IA le soin de dÃ©cider du sort du candidat est effrayant.</p><p>Enfin, les <a href=\"https://larevueia.fr/les-5-plus-gros-fails-de-lintelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">biais</a> de la sociÃ©tÃ© ont tendance Ã  Ãªtre amplifiÃ©s par lâ€™intelligence artificielle, comme lâ€™exemple de lâ€™IA dâ€™Amazon qui avait Ã©tÃ© entraÃ®nÃ©e avec des donnÃ©es biaisÃ©es et qui a considÃ©rÃ© quâ€™il ne fallait recruter que des hommesâ€¦</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Bien que lâ€™IA peut aider les recruteurs Ã  diffÃ©rentes Ã©tapes de leur processus de recrutement, lâ€™humain doit garder le contrÃ´le de la dÃ©cision finale.</p><p>MÃªme si cela semble paradoxale, lâ€™IA peut aider Ã  rendre le recrutement plus centrÃ© sur lâ€™humain.</p></div>"},
{"url": "https://larevueia.fr/quest-ce-quun-reseau-lstm/", "title": "Quâ€™est ce quâ€™un rÃ©seau LSTM ?", "author": "Adib Habbou", "date": "\n11 aoÃ»t 2022\n", "content": "<div class=\"entry-content\"><p>Un des avantages des <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">rÃ©seaux de neurones</a> rÃ©side dans la diversitÃ© des architectures existantes. Dans cet article, on parle des LSTM, une architecture de rÃ©seaux de neurones trÃ¨s utilisÃ©e pour le traitement du langage.</p><h2 class=\"wp-block-heading\">RÃ©seaux Neuronaux RÃ©currents</h2><p>Les <strong>rÃ©seaux neuronaux rÃ©currents</strong> sont les plus efficaces pour gÃ©rer des entrÃ©es de diffÃ©rentes tailles Ã©tant donnÃ© quâ€™ils possÃ¨dent une <strong>mÃ©moire court terme</strong>. Ils permettent aussi une meilleure comprÃ©hension du contexte puisquâ€™ils peuvent traiter des paquets de donnÃ©es quasi simultanÃ©ment.</p><p>Malheureusement, cette mÃ©moire Ã  court terme nâ€™a pas une durÃ©e de vie suffisante pour certaines tÃ¢ches Ã  cause dâ€™un problÃ¨me cÃ©lÃ¨bre appelÃ© le <strong><em>Vanishing Gradient Problem</em></strong>.</p><figure class=\"wp-block-image size-large\"><img decoding=\"async\" src=\"https://www.researchgate.net/profile/Vidushi-Mishra/publication/324883736/figure/fig2/AS:621644821307392@1525223083712/Recurrent-neural-networkRNN-or-Long-Short-Term-MemoryLSTM-5616.png\" alt=\"illustration d'un rÃ©seau de neurones rÃ©current (RNN)\"><figcaption class=\"wp-element-caption\"><strong>SchÃ©ma dâ€™une rÃ©seau neuronal rÃ©current</strong></figcaption></figure><h2 class=\"wp-block-heading\">Quâ€™est ce que le vanishing Gradient Problem ?</h2><p>En utilisant la rÃ©tropropagation, un rÃ©seau rÃ©current peut retracer les dÃ©pendances arbitraires quâ€™il trouve dans les donnÃ©es dâ€™entrÃ©e. Cependant les <strong>gradients Ã  long terme</strong> qui sont <strong>rÃ©tropropagÃ©s </strong>peuvent tendre vers <strong><em>zÃ©ro </em></strong>(<em>on dit quâ€™ils disparaissent</em>) ou peuvent tendre vers lâ€™<strong><em>infini</em></strong> (<em>on dit quâ€™ils explosent</em>). Dans les deux cas on perd lâ€™information quâ€™on voulait garder <em>en mÃ©moire</em>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/1400/1*A4-H1K_bXM_SYbBc2ux-Dg.png\" alt=\"vanishing et exploding gradient\"><figcaption class=\"wp-element-caption\"><strong>SchÃ©mas de la disparition et de lâ€™explosion du gradient</strong></figcaption></figure></div><h2 class=\"wp-block-heading\">Long Short-Term Memory</h2><h3 class=\"wp-block-heading\">Comment les LSTM permettent dâ€™Ã©viter le vanishing gradient ?</h3><p>Un nouveau sous-type de rÃ©seau est donc apparu pour essayer de contourner cette problÃ©matique : ce sont les rÃ©seaux <em><strong>LSTM</strong> </em>qui contiennent une mÃ©moire Ã  court terme capable de durer assez longtemps pour quâ€™on la qualifie de <strong>mÃ©moire longue Ã  court terme</strong>. De ce fait, on Ã©vite le problÃ¨me de fuite du gradient mÃªme sâ€™il peut arriver encore que notre gradient explose.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://www.researchgate.net/publication/341131167/figure/fig1/AS:887489082445828@1588605294853/RNN-v-s-LSTM-a-RNNs-use-their-internal-state-memory-to-process-sequences-of-inputs.jpg\" alt=\"comment les lstm rÃ©solvent le problÃ¨me du vanishing gradient\"><figcaption class=\"wp-element-caption\"><strong>Comparaison entre RNN et LSTM</strong></figcaption></figure></div><h3 class=\"wp-block-heading\">Architecture des LSTM</h3><p>Une cellule dâ€™un rÃ©seau LSTM est principalement composÃ©e dâ€™un <strong>input gate</strong>, un <strong>output gate</strong> et un <strong>forget gate</strong>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-16-13-41-03.png\" alt=\"schÃ¨ma d'un neurone lstm\"><figcaption class=\"wp-element-caption\"><strong>SchÃ©ma simplifiÃ© dâ€™une cellule dâ€™un rÃ©seau LSTM</strong></figcaption></figure></div><p>La principale idÃ©e derriÃ¨re un LSTM est de diviser le signal qui traverse notre rÃ©seau en deux parties bien distinctes :</p><ul class=\"wp-block-list\"><li><em>Court Terme</em> Ã  travers le <strong>hidden state</strong></li><li><em>Long Terme</em> Ã  travers le <strong>cell state</strong></li></ul><h3 class=\"wp-block-heading\">Etapes LSTM</h3><p>Un rÃ©seau LSTM effectue durant chaque passage les 5 Ã©tapes suivantes :</p><ul class=\"wp-block-list\"><li>DÃ©tection des informations passÃ©es dans le <strong>cell state</strong> via le <strong>forget gate</strong></li><li>Choix des informations pertinentes Ã  <em>long terme</em> Ã  travers lâ€™<strong>input gate</strong></li><li>Ajout des informations choisies au <strong>cell state</strong></li><li>DÃ©tection des informations importantes Ã  <em>court terme</em> dans le <strong>cell state</strong></li><li>GÃ©nÃ©ration du nouveau <strong>hidden state</strong> Ã  travers lâ€™<strong>output gate</strong></li></ul><p>La <strong>relation de rÃ©currence </strong>dâ€™un <strong><em>LSTM </em></strong>comprend donc une variable <strong>h</strong> pour le <em>hidden state</em> et une variable <strong>c </strong>pour le <em>cell state</em> :</p><p class=\"has-text-align-center\"><strong>h<sub>t</sub> , c<sub>t</sub>Â = f(x<sub>t </sub>, h<sub>t-1 </sub>, c<sub>t-1</sub>)</strong></p><figure class=\"wp-block-image size-large\"><img decoding=\"async\" src=\"https://i.postimg.cc/yNjdf6gF/1-7c-Mfenu76-BZCzd-KWCf-BABA.png\" alt=\"lstm, untÃ© rÃ©currente\"><figcaption class=\"wp-element-caption\"><strong>Cellule dâ€™un rÃ©seau LSTM</strong></figcaption></figure><h3 class=\"wp-block-heading\">Limites du rÃ©seau</h3><p>MalgrÃ© le fait que les <strong><em>LSTM </em></strong>rÃ¨glent en partie le <em><strong>Vanishing Gradient Problem</strong></em>, le modÃ¨le nâ€™est pas pour autant parfait. En effet, il comprend de nombreux dÃ©fauts parfois assez compliquÃ©s Ã  surpasser. Parmi eux, on peut citer les problÃ¨mes dâ€™<strong><a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">overfitting</a></strong> (<em>quand le modÃ¨le colle trop aux donnÃ©es dâ€™entraÃ®nement</em>) ou encore le fait que le modÃ¨le est fortement <strong>affectÃ©</strong> par les <strong>initialisations</strong> de poids alÃ©atoires.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://www.educative.io/api/edpresso/shot/6668977167138816/image/5033807687188480\" alt=\"Qu'est ce qu'un rÃ©seau LSTM ?\"><figcaption class=\"wp-element-caption\"><strong>SchÃ©mas de lâ€™overfitting et underfitting</strong></figcaption></figure></div><h2 class=\"wp-block-heading\">Applications : les LSTM pour gÃ©nÃ©rer de paroles de rap</h2><p>Maintenant quâ€™on a vu le cÃ´tÃ© thÃ©orique derriÃ¨re les rÃ©seaux <strong><em>LSTM</em></strong>, il est temps de voir le cÃ´tÃ© pratique et comment ils peuvent Ãªtre utilisÃ©s pour faire des choses assez originales et drÃ´les.</p><p>AprÃ¨s avoir rÃ©coltÃ© les paroles de plus de 100 rappeurs franÃ§ais sur <strong>Genius </strong>en utilisant Ã  la fois lâ€™API et des techniques de Web Scraping avec <em><strong><a href=\"https://larevueia.fr/introduction-a-beautifulsoup-web-scraping-avec-python/\" target=\"_blank\" rel=\"noreferrer noopener\">BeautifulSoup</a></strong></em>, jâ€™ai entraÃ®nÃ© un petit rÃ©seau <em><strong>LSTM </strong></em>Ã  gÃ©nÃ©rer des paroles de rap franÃ§ais Ã  partir dâ€™une petite phrase en input. Vous pouvez retrouver tout le code et le dataset utilisÃ© sur le repo git suivant : <a href=\"https://github.com/Adib-Habbou/french-rap-lyrics-generator\" target=\"_blank\" rel=\"noreferrer noopener\">https://github.com/Adib-Habbou/french-rap-lyrics-generator</a></p><p>Le modÃ¨le sâ€™avÃ¨re Ãªtre assez vulgaire et grossier, ce qui nous rappelle encore une fois quâ€™un modÃ¨le câ€™est avant tout les donnÃ©es sur lesquelles on lâ€™entraÃ®ne et que si lâ€™on ne fait pas attention aux donnÃ©es quâ€™on lui donne, on peut malheureusement se retrouver avec des rÃ©sultats inattendues voire dangereux.</p><p>Comme cela sâ€™est avÃ©rÃ© Ãªtre le cas pour lâ€™IA de <strong><em>Microsoft </em>Tay </strong>qui est trÃ¨s vite devenue raciste Ã  cause des tweets sur lesquelles le modÃ¨le a Ã©tÃ© entraÃ®nÃ©, ou encore <strong>DALL-E</strong> dâ€™<em><strong>OpenAI</strong></em> qui comporte un bon nombre de biais racistes et misogynes.</p><h2 class=\"wp-block-heading\">Pour aller plus loin</h2><ul class=\"wp-block-list\"><li>Un des premiers papiers scientifiques : <a href=\"https://cutt.ly/UZnNet4\" target=\"_blank\" rel=\"noreferrer noopener\">https://cutt.ly/UZnNet4</a></li><li>Librairie <em>Python </em>pour crÃ©er des <em><strong>LSTM </strong></em>: <a href=\"https://cutt.ly/NZnNg7r\" target=\"_blank\" rel=\"noreferrer noopener\">https://cutt.ly/NZnNg7r</a></li><li>Article sur lâ€™IA raciste de Microsoft : <a href=\"https://cutt.ly/YZLQ79W\" target=\"_blank\" rel=\"noreferrer noopener\">https://cutt.ly/YZLQ79W</a></li></ul></div>"},
{"url": "https://larevueia.fr/quest-ce-que-lintelligence-artificielle-decentralisee/", "title": "Quâ€™est-ce que lâ€™intelligence artificielle dÃ©centralisÃ©e ?", "author": "Ilyes Talbi", "date": "\n30 octobre 2022\n", "content": "<div class=\"entry-content\"><p>Le web2 est cassÃ©. Et comme lui, lâ€™IA est cassÃ©e. Monopole, biais, manque de transparence; la liste des infractions est longue.</p><p>De maniÃ¨re gÃ©nÃ©rale, le monde digital que nous avons construit, si on le juge avec dÃ©tachement et objectivitÃ©, est finalement assez absurde.</p><p>On offre nos donnÃ©es gratuitement, les algorithmes du web savent ce que lâ€™on aime, ce que lâ€™on mange, comment on va sâ€™habiller demain, les informations que lâ€™on publie ne nous appartiennent plus, et la censure est centralisÃ©e, et contrÃ´lÃ©e par des organisations toutes puissantes.</p><h2 class=\"wp-block-heading\">OpenAI vous veut du bien</h2><p>Ces derniÃ¨res semaines, nous avons clairement vu les limites des modÃ¨les comme celui dâ€™OpenAI ou Deepmind, qui se sont Ã©loignÃ©s de leur mission initiale : proposer des modÃ¨les qui bÃ©nÃ©ficient Ã  tout le monde.</p><p>Pire encore, ils utilisent les donnÃ©es de tout le monde, pour crÃ©er des modÃ¨les qui ne bÃ©nÃ©ficient quâ€™Ã  leurs crÃ©ateurs, bloquent lâ€™accÃ¨s aux outils, sous prÃ©texte quâ€™ils savent mieux que nous ce qui est bien pour nous, et utilisent lâ€™argument Ã©thique pour le justifierâ€¦</p><p>Le cas DALL-E 2 montre le manque de transparence devenu symptomatique pour les IA dâ€™aujourdâ€™hui. Des modÃ¨les entraÃ®nÃ©s avec les donnÃ©es du peuple, pour le bien du peuple, finalement accaparÃ©s par une poignÃ©e de privilÃ©giÃ©s.</p><p>Les artistes et photographes qui publient leurs travaux sur Instagram sont-ils au courant de ce qui se passe ?</p><p>MÃªme si OpenAI a apportÃ© beaucoup au monde de lâ€™IA, beaucoup de choses ont changÃ© ces derniÃ¨res annÃ©es.</p><h2 class=\"wp-block-heading\">Un monopole dÃ©mesurÃ©</h2><p>En plus de ce manque de transparence, ce sont les mÃªmes acteurs qui contrÃ´lent toutes les donnÃ©es gÃ©nÃ©rÃ©es par les internautes.</p><p>Sur des sujets aussi critiques que la comprÃ©hension du langage, seuls quelques mastodontes sont capables de rÃ©ellement innover : Amazon, Google, Meta et quelques autres entreprises. La course aux donnÃ©es et aux modÃ¨les de plus en plus larges est perdue dâ€™avance pour la majoritÃ© des acteurs.</p><p>Les architectures des derniers modÃ¨les ne sont pas si novatrices que Ã§a, elles consistent simplement en un empilement de couches de plus en plus grand, et lâ€™ajout dâ€™une quantitÃ© quasi-infinie de donnÃ©es. Et pour les gÃ©ants citÃ©s juste avant, ni la capacitÃ© de calcul ni la quantitÃ© de donnÃ©es ne sont des problÃ¨mes.</p><p>MÃªme si certaines de ces entreprises ont Ã©tÃ© rattrapÃ©es par les autoritÃ©s europÃ©ennes pour leur monopole sur certains sujets, elles nâ€™ont jamais Ã©tÃ© inquiÃ©tÃ©es sur la question de la quantitÃ© de donnÃ©es stockÃ©es.</p><h2 class=\"wp-block-heading\">Le modÃ¨le open-source : une alternative qui a ses limites</h2><p>Le modÃ¨le open-source semble rÃ©soudre les problÃ¨mes Ã©noncÃ©s prÃ©cÃ©demment. Pour la transparence la question ne se pose pas, les donnÃ©es et le travail rÃ©sultant sont visibles publiquement. Concernant le monopole, il permet un accÃ¨s Ã©quitable pour tous les acteurs.</p><p>Câ€™est dâ€™ailleurs cette approche lÃ  quâ€™a choisi Stability.ai, lâ€™entreprise Ã  lâ€™origine du modÃ¨le stable diffusion. En plus dâ€™Ãªtre plus robuste et plus rapide, stable diffusion est complÃ¨tement open-source.</p><p><a href=\"https://stability.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Stability.ai</a> a dâ€™ailleurs annoncÃ© une levÃ©e de fonds de 101 millions de dollars, pour mettre en place une nouvelle approche dâ€™entreprise Ã  impact dans le domaine de lâ€™IA.</p><p>Mais lâ€™open-source ne rÃ©sout pas tous les problÃ¨mes.</p><p>Jusquâ€™ici câ€™Ã©tait un monde Ã  part, rÃ©gi par des rÃ¨gles tacites et qui reposait sur la confiance et la collaboration. Sauf que des rÃ©cents Ã©vÃ©nements ont montrÃ© sa vulnÃ©rabilitÃ©, comme Marak Squirres qui a sabotÃ© son propre projet et causÃ© pas mal de dÃ©gÃ¢ts (on parle de dizaines de milliers de projets concernÃ©s), ou encore les dÃ©bats causÃ©s par le lancement de GitHub copilot.</p><p>Concernant lâ€™affaire Marak Squirres, les mÃ©dias mainstream ont abordÃ© le sujet en se demandant Â«Â comment sÃ©curiser les projets open source ?Â Â», comme pour remettre en cause la fiabilitÃ© du modÃ¨le.</p><p>Nous sommes dâ€™accord, la question se pose et elle est importante, mais lâ€™urgence est plutÃ´t de savoir comment rendre le monde du open source plus juste et rÃ©compenser les contributeurs les plus assidus.</p><h2 class=\"wp-block-heading\">Lâ€™intelligence artificielle dÃ©centralisÃ©e comme solution ?</h2><p>Je ne fais pas partie de ceux qui clament la dÃ©centralisation Ã  chaque revers du modÃ¨le classique. Jâ€™analyse les Ã©vÃ¨nements de faÃ§on pragmatique et rationnelle, et je suis conscient que la <a href=\"https://larevueia.fr/quels-liens-entre-blockchain-et-intelligence-artificielle\" target=\"_blank\" rel=\"noreferrer noopener\">blockchain</a> nâ€™est pas une baguette magique solution Ã  tous nos maux. Mais je pense que si lâ€™on veut faire passer lâ€™intelligence artificielle dans une nouvelle dimension, il faut du changement.</p><p>Lâ€™intelligence artificielle dÃ©centralisÃ©e est un nouveau paradigme dans lequel les donnÃ©es et les modÃ¨les qui en rÃ©sultent appartiennent Ã  tous les membres dâ€™un rÃ©seau. Les donnÃ©es sont collectÃ©es et labellisÃ©es collectivement, et chaque membre apporte une partie de la puissance de calcul nÃ©cessaire Ã  lâ€™entraÃ®nement du modÃ¨le, on parle de <em>federated learning</em> ou <em>apprentissage fÃ©dÃ©rÃ©</em>.</p><p>Le premier avantage du rÃ©seau dÃ©centralisÃ©, est quâ€™il permet Ã  chaque membre dâ€™avoir un intÃ©rÃªt Ã  ce que le rÃ©seau fonctionne bien. Si le rÃ©seau fonctionne le membre gagne, si le rÃ©seau ne fonctionne plus il perd.</p><p>Par ailleurs, les gains finaux sont partagÃ©s Ã©quitablement, chacun Ã©tant rÃ©compensÃ© Ã  la hauteur de son apport : lâ€™artiste qui publie ses travaux sera gratifiÃ© pour leur utilisation, lâ€™internaute sera payÃ© pour ses donnÃ©es, le data scientist qui propose une architecture ou des solutions techniques aussi, et tout le monde peut bÃ©nÃ©ficier au rÃ©seau en apportant un espace de stockage ou de la capacitÃ© de calcul.</p><p>Enfin, dâ€™un point de vue traÃ§abilitÃ© aussi la blockchain a des arguments. Elle permettra de tracker avec plus de transparence les Ã©changes de donnÃ©es, et donc permettra de remonter plus facilement Ã  la source.</p><p>Contrairement Ã  ce que certains suggÃ¨rent, ce modÃ¨le nâ€™est pas un spin-off du communisme au service de lâ€™intelligence artificielle, câ€™est simplement une alternative et un contrÃ´le dâ€™un capitalisme destructeur.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Pour conclure, mÃªme si cet article pose plus de questions quâ€™il ne donne de rÃ©ponses, lâ€™objectif est de constater les limites de lâ€™intelligence artificielle dâ€™aujourdâ€™hui, et prendre conscience quâ€™un changement sâ€™impose.</p><p>MÃªme si les solutions les plus robustes sur le long terme seront celles apportÃ©es par la recherche : Comment crÃ©er des architectures de rÃ©seaux plus fiables et qui consomment moins de donnÃ©es ? Comment mieux assurer lâ€™explicabilitÃ© des modÃ¨les ? Des sujets comme le self-supervised learning, largement promu par Yann Le Cun, sont la clÃ© des problÃ©matiques actuelles.</p><p>De faÃ§on plus globale, on tend vers une convergence entre toutes les technologies disponibles aujourdâ€™hui : lâ€™IoT pour la rÃ©colte des donnÃ©es, la blockchain et la cybersecuritÃ© pour la confiance et la traÃ§abilitÃ©, lâ€™intelligence artificielle pour le traitement, et des technologies comme la robotique ou la rÃ©alitÃ© virtuelle pour lâ€™interfaÃ§age. Et il est clair que le tout sera bien plus grand que la somme de ses parties.</p></div>"},
{"url": "https://larevueia.fr/tutorial-creez-un-ai-avatar-parlant-avec-des-outils-gratuits-no-code/", "title": "Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code", "author": "Alexandre LavallÃ©e", "date": "\n4 avril 2023\n", "content": "<div class=\"entry-content\"><hr class=\"wp-block-separator has-alpha-channel-opacity\"><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*HooQcNGGuvYRv2sTdDKBtw.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>A lâ€™occasion du 1er avril, je me suis permis de prÃ©tendre que je devenais le <em>â€˜Head of AI contentâ€™</em> de la fameuse marque Balenciaga, et dâ€™annoncer en grande pompe un partenariat entre la marque de luxe et le monde dâ€™Harry Potter avec une <a href=\"https://www.youtube.com/watch?v=iE39q-IKOzA\" rel=\"noreferrer noopener\" target=\"_blank\">vidÃ©o</a> soignÃ©eâ€Šâ€”â€Šsur une idÃ©e originale du crÃ©ateur <a href=\"https://www.instagram.com/demonflyingfox/\" rel=\"noreferrer noopener\" target=\"_blank\">demonflyingfox</a>.</p><p>Pensant que ma supercherie Ã©tait vraiment beaucoup trop grosse pour Ãªtre vraie, jâ€™ai pourtant reÃ§u nombre de fÃ©licitationsâ€¦ Pourtant, tout Ã©tait absolument gÃ©nÃ©rÃ© par une IA, le script, la vidÃ©o, les images, lâ€™animation des avatars, les voix des personnages.</p><p>Au delÃ  du cÃ´tÃ© ludique et, avouons-le, un tantinet provocateur de ce poisson dâ€™avril, câ€™Ã©tait avant tout la parfaite occasion pÃ©dagogique pour nous de montrer en conditions rÃ©elles comment utiliser la panoplie des <strong>outils</strong> gÃ©nÃ©ratifs, et les enjeux Ã©thiques associÃ©s</p><p>Je dÃ©couperais donc lâ€™article en deux axes:</p><p>1/ <strong>Tuto</strong>: montrer toute la panoplie des outils disponibles en matiÃ¨re de Generative AI qui peuvent vous permettre de crÃ©er une vidÃ©o dâ€™un avatar animÃ© qui sâ€™exprime, et ce de A Ã  Z par vous-mÃªmes</p><p>2/ <strong>Analyse</strong>: partager quelques rÃ©flexions en fin de ce tuto sur les questions et implications Ã©thique de ces outils trÃ¨s sophistiquÃ©s qui auraient faire pÃ¢lir dâ€™envie <a href=\"https://www.cairn.info/revue-du-mauss-2007-2-page-452.htm\" target=\"_blank\" rel=\"noreferrer noopener\">Edward Bernays</a></p><p>Etre informÃ© sur le monde technologique qui nous entoure, câ€™est aussi mieux Ãªtre mieux armÃ© pour tenter dâ€™apporter un Ã©clairage lucide et critique du fonctionnement de ces IA multi-modales.</p><p></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Harry Potter by Balenciaga\" width=\"1250\" height=\"938\" src=\"https://www.youtube.com/embed/iE39q-IKOzA?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div></figure><p><a href=\"\"></a></p><p>Nous allons vous guider Ã  travers les Ã©tapes simples pour dÃ©composer le processus de crÃ©ation de cette vidÃ©o ci-dessus, qui est entiÃ¨rement fake.Â </p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Rendons Ã  CÃ©sar ce qui est Ã  CÃ©sar, lâ€™idÃ©e de mixer lâ€™univers de Balenciaga avec celui du monde de J.K Rowling, vient de cette brillante idÃ©e de lâ€™AI-artist (<a href=\"https://www.instagram.com/demonflyingfox/\" target=\"_blank\" rel=\"noreferrer noopener\">demonflyingfox</a>) â€“ que je trouve trÃ¨s mordant et efficace.</p></blockquote><p>Ce dont vous avez besoin avant dâ€™aller plus loin:</p><ul class=\"wp-block-list\"><li>un gÃ©nÃ©rateur dâ€™image AI-art (<a href=\"https://docs.midjourney.com/docs/quick-start\" rel=\"noreferrer noopener\" target=\"_blank\">Midjourney</a>, <a href=\"https://beta.dreamstudio.ai/generate\" rel=\"noreferrer noopener\" target=\"_blank\">DreamStudio</a>, <a href=\"https://www.scenario.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Scenario</a>â€Šâ€”â€Š<a href=\"https://sourceforge.net/software/product/DreamStudio/alternatives\" rel=\"noreferrer noopener\" target=\"_blank\">voir plus de dÃ©tails</a>)</li><li>un compte gratuit chez <a href=\"https://play.ht/\" rel=\"noreferrer noopener\" target=\"_blank\">play.ht</a></li><li>un compte gratuit chez <a href=\"https://www.d-id.com/\" rel=\"noreferrer noopener\" target=\"_blank\">D-ID</a></li><li>un outil gratuit super pratique comme <a href=\"https://cloud.lambdalabs.com/demos/ml/CLIP-Interrogator\" rel=\"noreferrer noopener\" target=\"_blank\">Clip Interrogator</a></li></ul><h3 class=\"wp-block-heading\">Etape 1: Image-To-PromptÂ </h3><h4 class=\"wp-block-heading\">objectif: Trouvez le bon prompt qui permettra de crÃ©er notre personnageÂ </h4><p>Outils utilisÃ©s lors de cet Ã©tape:</p><ul class=\"wp-block-list\"><li><a href=\"https://cloud.lambdalabs.com/demos/ml/CLIP-Interrogator\" rel=\"noreferrer noopener\" target=\"_blank\">clip interrogator</a></li></ul><p>Je vais tout bonnement commencer par faire une capture dâ€™Ã©cran dâ€™un des personnages stylÃ©s dans la vidÃ©o, prenons par exemple ce Dumbledore total new-look dans le pur jus de Balenciaga.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*GiYRX2PIWVOMxAQWfAVU3g.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>On va passer cette image dans clip interrogatorâ€Šâ€”â€Š<a href=\"https://cloud.lambdalabs.com/demos/ml/CLIP-Interrogator\" rel=\"noreferrer noopener\" target=\"_blank\">ICI</a></p><p>Grosso modo, CLIP nous permet de traduire via une IA le contenu dâ€™une image en mots. Vous lui donnez une image, il vous dit quel serait le â€œpromptâ€ correspondant Ã  utiliser dans un gÃ©nÃ©rateur dâ€™AI-art comme Dall-E ou Stable diffusion etc si vous souhaitiez recrÃ©er lâ€™image.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Pour plus de dÃ©tails sur <a href=\"https://openai.com/research/clip\" rel=\"noreferrer noopener\" target=\"_blank\">CLIP</a>, je fais une apartÃ© en fin de cet article. honnÃªtement câ€™est sans doute lâ€™outil le plus sous-cÃ´tÃ©/mÃ©connu du grand public, alors quâ€™il est absolument fondamental dans les progrÃ¨s des algos Text-To-Image</p></blockquote><p>Donc dans notre exemple</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*Vrz44P_00FDaDjZaYOilBA.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>Voila un prompt que nous propose un CLIP, que nous allons nous empresser de copier/coller dans un bloc-note</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><strong>a man with a long white beard wearing a hat and sunglasses, still from the matrix (1999), flash gordon, dressed as a wizard, fantastic details full faces, elfpunk, sephiroth, willem dafoe, necro, am a naranbaatar ganbold, overlord billie eilish, jerma985, old movieÂ </strong></p></blockquote><h3 class=\"wp-block-heading\">Etape 2: Text-To-Image</h3><h4 class=\"wp-block-heading\">Objectif: GÃ©nÃ©rez lâ€™image de notre personnage fictif, qui servira de base pour une animation vidÃ©oÂ future.</h4><p>Outils utilisÃ©s lors de cette Ã©tape:</p><ul class=\"wp-block-list\"><li><a href=\"https://docs.midjourney.com/docs/quick-start\" rel=\"noreferrer noopener\" target=\"_blank\">Midjourney</a></li></ul><p>Ouvrons notre gÃ©nÃ©rateur dâ€™AI-art, dans le cas Ã©chÃ©ant Midjourney. Si câ€™est la premiÃ¨re fois pour vous que vous utilisez cette plateforme, lisez dâ€™abord ce <a href=\"https://docs.midjourney.com/docs/quick-start\" rel=\"noreferrer noopener\" target=\"_blank\">quick start guide</a> de Midjourney pour pasgalÃ©rer sur votre set-up.</p><p>On se rend sur discord, on tape <strong>/imagine</strong> et on copie colle notre prompt donnÃ© par CLIP lors de lâ€™Ã©tape 1</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*0cc8xIumwDS-izBwHwTJ2w.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>notez que je rajoute quelques paramÃ¨tres Ã  la fin du promptâ€Š<strong>â€”â€Šar 2:1â€Šâ€”â€Šq 2â€Šâ€”â€Šs 750â€Šâ€”â€Šv 5. </strong>Ce sont des paramÃ¨tres qui me permettent de mieux gÃ©rer lâ€™aspect visuel de mon image qui sera gÃ©nÃ©rÃ©e, pour aller plus loin câ€™est <a href=\"https://docs.midjourney.com/docs/parameter-list\" rel=\"noreferrer noopener\" target=\"_blank\">ici</a>.</p><p>Ok voyons le rÃ©sultat.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*1s0bNRF0AkixTnmq_xsdRQ.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>OK on a notre dumbledore new-look.Â </p><p>Vous pouvez aussi essayer la prompt alternative suivante, si vous souhaitez donner un grain un peu plus dark et vintage Ã  votre Dumbledore.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*fpsMU4-LSnKKlbniw1PGXg.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>Bon ici vous pouvez prendre nâ€™importe quelle image hein, pas forcÃ©ment obligÃ© dâ€™utiliser Midjourney, vous pourriez tout Ã  faire un screenshot dâ€™une image dâ€™un personnage dans une vidÃ©o youtube.</p><h3 class=\"wp-block-heading\">Etape 3: Text-To-Speech</h3><h4 class=\"wp-block-heading\">objectif: CrÃ©er le script + la voix de notre personnage fictif</h4><p>Outils utilisÃ©s lors de cette Ã©tape:</p><ul class=\"wp-block-list\"><li><a href=\"https://play.ht/\" rel=\"noreferrer noopener\" target=\"_blank\">play.ht</a></li></ul><p>A prÃ©sent on va utiliser les fonctionnalitÃ©s de play.ht pour crÃ©er le fichier audio.Â </p><p>En express, Play.ht est un service en ligne qui convertit du texte en audio grÃ¢ce Ã  la synthÃ¨se vocale. Il utilise des voix artificielles avancÃ©es pour lire des articles, des histoires ou dâ€™autres types de contenu Ã©crit, afin que tu puisses les Ã©couter plutÃ´t que de les lire.</p><p>On va sÃ©lectionner une voix synthÃ©tique dâ€™IA, et lui faire dire notre texte/script.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*_nvXIs_CV-NV6nruCiLViA.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>A prÃ©sent familiarisez vous un peu avec lâ€™interface suivante. Dans notre cas, on va copier-coller une des citations de Dumbledore (<a href=\"https://bookroo.com/quotes/dumbledore\" rel=\"noreferrer noopener\" target=\"_blank\">source</a>)</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*O0MNMg9Cgy7OgXr6opEWuw.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>Avec lâ€™outil de prÃ©-Ã©coute, on peut apprÃ©cier la diction de notre voix-off et lâ€™affiner au besoin. Mais vu que câ€™est un compte gratuit, soyez parcimonieux avant de tÃ©lÃ©charger le rÃ©sultat final de votre audio.</p><p>Nous nâ€™avons plus quâ€™Ã  tÃ©lÃ©charger notre fichierÂ .mp3.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*B7ibbMb-TMSt-DwVxhAf0w.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*LuJtoUc26fxNdRSbijSquQ@2x.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><h3 class=\"wp-block-heading\">Etape 4: (Image+Speech)-To-Video</h3><h4 class=\"wp-block-heading\">objectif: Mixer lâ€™image et la voix de notre personnage fictif pour crÃ©er un rendu vidÃ©o animÃ© avec un avatar quiÂ parle</h4><p>Outils utilisÃ©s lors de cet Ã©tape:</p><ul class=\"wp-block-list\"><li><a href=\"https://www.d-id.com/\" rel=\"noreferrer noopener\" target=\"_blank\">D-ID</a></li></ul><p>A prÃ©sent, rendons nous sur notre compte D-ID (je suis personnellement en essai gratuit). D-ID est une application web qui utilise lâ€™animation faciale en temps rÃ©el et la synthÃ¨se vocale avancÃ©e pour crÃ©er une expÃ©rience dâ€™IA conversationnelle immersive et rÃ©aliste. En somme, câ€™est un outil dâ€™IA gÃ©nÃ©rative pour crÃ©er des avatars parlants en quelques clicks.</p><p>On va faire une nouvelle vidÃ©o, et commencez par importer notre image crÃ©Ã©e lors de lâ€™Ã©tape 2.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*7ysJ0qypQUDA0cb4oxPhdQ.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>A prÃ©sent, on va uploader notre voix crÃ©Ã©e lors de lâ€™Ã©tape 3.Â </p><p>Notez que vous pouvez aussi tout Ã  fait utiliser les pre-sets existants de voix dans D-ID, câ€™est juste que je trouve Ã§a un peu cher et pas forcÃ©ment trÃ¨s flexible.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*wrd2Ybp7xdflEEXwXjV1zQ.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><p>on upload notre fichier audio, pour moi câ€™est le fichier <strong>Dumbledore Balenciaga Audio Script.mp3</strong></p><p>Et plus quâ€™Ã  cliquer sur generate Video, et exportez votre rÃ©sultat final, une vidÃ©oÂ .mp4 avec votre avatar parlant.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*3dPvRc3keAy87SWszBWKDg.png\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"></figure><h3 class=\"wp-block-heading\">RÃ©cap</h3><p>On aura donc successivement en moins de 5min:</p><ul class=\"wp-block-list\"><li>gÃ©nÃ©rÃ© une prompt Ã  partir dâ€™une image cible</li><li>reproduit cette image cible dans midjourney</li><li>gÃ©nÃ©rÃ© une voice-over avec un texte personnalisÃ©</li><li>synchronisÃ© la voice-over avec notre image pour crÃ©er une vidÃ©o (ou notre Dumbledore nous troll superbement dâ€™ailleurs)</li></ul><hr class=\"wp-block-separator has-alpha-channel-opacity\"><h3 class=\"wp-block-heading\">Pour aller plusÂ loin</h3><h4 class=\"wp-block-heading\">RÃ©flexions Ã©thiques: le Generative AI, Edward Bernays et la fabrique du consentement</h4><p>Ce qui est intÃ©ressant Ã  observer dans cette expÃ©rimentation, câ€™est quâ€™il est aisÃ© de crÃ©er un contenu rÃ©aliste et faire dire ce quâ€™on veut Ã  Ã  peu prÃ¨s nâ€™importe qui. Jâ€™aurais pu tout Ã  fait Ã©galement cloner la voix de nâ€™importe qui Ã  partir de 60 secondes dâ€™audio, pour utiliser la voix de christopher lee ou celle de Steve Jobsâ€Šâ€”â€Šles Ã©tudes de <a href=\"https://valle-demo.github.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Vall-E</a> montrent que nous sommes Ã©galement en train de passer un cap dans ce domaine.Â </p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*PxJDwxZ2KJ-eNUoJ.jpg\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"><figcaption class=\"wp-element-caption\">Vall-E: voiceÂ cloning</figcaption></figure><p>De tels outils posent nÃ©cessairement la question de la limite de leurs utilisations face Ã  leur capacitÃ©s Ã  modeler le consentement du public.Â </p><p>Et câ€™est bien la ou je souhaite en venir.Â </p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*9YmfDjyrW4bP6JbZ.jpg\" alt=\"Tutorial: CrÃ©ez un AI-avatar parlant avec des outils gratuitsÂ no-code\"><figcaption class=\"wp-element-caption\">edward bernays a notamment rÃ©alisÃ© la campagne de pub Lucky Strike visant Ã  inciter les femmes Ã  fumer, ouvrant un nouveau public Ã  la firme deÂ tabac</figcaption></figure><p>Dans son livre â€œ<a href=\"https://www.cairn.info/revue-du-mauss-2007-2-page-452.htm\" rel=\"noreferrer noopener\" target=\"_blank\">Propaganda</a>â€ (1928), Bernays, considÃ©rÃ© comme le pÃ¨re des relations publiques modernes mais aussi au passage neveu dâ€™un certain Sigmund Freud, soutient que le consentement du public peut Ãªtre â€œfabriquÃ©â€ ou â€œmanipulÃ©â€ par des experts en communication et en relations publiques des masses.</p><p>La thÃ¨se de Bernays est que des personnes â€œinvisiblesâ€ qui crÃ©ent le savoir et la propagande rÃ¨gnent sur les masses, avec le monopole du pouvoir de faÃ§onner les pensÃ©es, les valeurs et les rÃ©actions des citoyens. Selon lui, il serait alors nÃ©cessaire dâ€™avoir un â€œconsentement techniqueâ€â€Šâ€”â€Šou â€œengineering consentâ€ qui signifie influencer lâ€™opinion publique en utilisant des techniques de communication et de persuasion pour faÃ§onner les perceptions, les attitudes et les comportements des individus. Bernays voyait cette approche comme un outil nÃ©cessaire pour maintenir lâ€™ordre social et la stabilitÃ©, Ã©tant donnÃ© que les gens sont souvent influencÃ©s par des forces irrationnelles et Ã©motionnelles. Tout un programme donc pour ce cher Edward Bernays.</p><p>Je pense quâ€™il est intÃ©ressant en tout cas de percevoir Ã  quel point ces <strong>outils</strong> dâ€™IA gÃ©nÃ©ratives, qui ne sont que des <strong>artefacts</strong>, peuvent rapidement Ãªtre prise Ã  leur compte par des visÃ©es de propagande, et bien entendu pose la lÃ©gitime question du copyright que ce soit pour les images ou la voix.Â </p><p>Si lâ€™on fait un parallÃ¨le entre la thÃ¨se de Bernays Ã  lâ€™aune du <em>Generative AI</em> on peut donc au moins dÃ©noter deux facteurs amplificateurs de chaos dans la manipulation du consentement du public:</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>ğŸ’¥<em> Premier facteur de ChaosÂ : lâ€™IA permet de diminuer les coÃ»ts des 3 types dâ€™opÃ©rations indispensables Ã  une propagande efficaceÂ : il est possible de simuler des auteurs instantanÃ©ment et mÃªme dâ€™usurper leur identitÃ©, de simuler leur succÃ¨s (en gÃ©nÃ©rant de faux commentaires crÃ©dibles ou des reprises dâ€™informations par de faux utilisateurs) et, bien entendu, de produire du contenu automatiquement.</em></p></blockquote><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>ğŸ’¥ <em>DeuxiÃ¨me facteur de ChaosÂ : affaiblir la confiance dans le systÃ¨me en instaurant un doute constant. PlutÃ´t que de provoquer lâ€™adhÃ©sion Ã  des fausses convictions, semer lâ€™incertitude est souvent le premier but des propagandistes. Avec lâ€™Ã©volution de lâ€™IA, tout le monde se demandera si un message particulier pourrait Ãªtre inauthentique ou trompeur.</em></p></blockquote><p>Je vous invite Ã  aller plus loin en consultant cette <a href=\"https://arxiv.org/abs/2301.04246\" rel=\"noreferrer noopener\" target=\"_blank\">Ã©tude captivante</a>, pÃ©dagogique et mesurÃ©e, rÃ©alisÃ©e des chercheurs dâ€™OpenAI (dÃ©veloppeurs de ChatGPT), en collaboration avec le â€œGeorgetownâ€™s Center for Security and Emerging Technologyâ€ et le â€œStanford Internet Observatoryâ€, ont rÃ©alisÃ© des Ã©tudes pour identifier les dangers et Ã©tablir les fondements dâ€™un dÃ©bat sur les rÃ©gulations envisageables.</p><p>En tout cas, jâ€™espÃ¨re que cela vous apporte un peu dâ€™esprit critique et de mises en perspective de plus en plus nÃ©cessaire sur lâ€™utilisation de ces outils.</p><p>Pur aller plus loin:</p><ul class=\"wp-block-list\"><li><a href=\"https://davidrozado.substack.com/p/political-bias-chatgpt\" rel=\"noreferrer noopener\" target=\"_blank\">https://davidrozado.substack.com/p/political-bias-chatgpt</a></li><li><a href=\"https://arxiv.org/abs/2301.04246\" rel=\"noreferrer noopener\" target=\"_blank\">https://arxiv.org/abs/2301.04246</a></li><li><a href=\"https://youtu.be/8OpW5qboDDs\" rel=\"noreferrer noopener\" target=\"_blank\">https://youtu.be/8OpW5qboDDs</a></li></ul><hr class=\"wp-block-separator has-alpha-channel-opacity\"><p>ApartÃ©:</p><p>Quel est le point commun entre les rÃ©centes percÃ©es de lâ€™IA, DALL-E et de stable diffusionÂ ?<br>Elles utilisent toutes deux des Ã©lÃ©ments de lâ€™architecture CLIP. Par consÃ©quent, pour comprendre le fonctionnement de ces modÃ¨les, il est indispensable de comprendre CLIP.<br>Dâ€™ailleurs, CLIP a Ã©tÃ© utilisÃ© pour indexer des photos sur Unsplash.<br>Mais que fait CLIP et pourquoi est-ce une Ã©tape importante pour la communautÃ© de lâ€™IAÂ ?</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><strong><em>CLIP est lâ€™acronyme de Constastive Language-Image PretrainingÂ :</em></strong><br>CLIP est un modÃ¨le open source, multimodal et sans prise de vue. Ã‰tant donnÃ© une image et des descriptions textuelles, le modÃ¨le peut prÃ©dire la description textuelle la plus pertinente pour cette image, sans optimiser pour une tÃ¢che particuliÃ¨re.</p></blockquote><p>DÃ©cortiquons cette descriptionÂ :</p><ul class=\"wp-block-list\"><li>Open Source: Le modÃ¨le est crÃ©Ã© et mis Ã  disposition par OpenAI.Â </li><li>Multi-modalitÃ©Â : les architectures multimodales exploitent plus dâ€™un domaine pour apprendre une tÃ¢che spÃ©cifique. CLIP combine le traitement du langage naturel et la vision par ordinateur.</li><li>Zero-shotÂ : Lâ€™apprentissage Ã  partir de zÃ©ro est un moyen de gÃ©nÃ©raliser sur des Ã©tiquettes inÃ©dites, sans avoir Ã©tÃ© spÃ©cifiquement entraÃ®nÃ© Ã  les classer. Par exemple, tous les modÃ¨les ImageNet sont formÃ©s pour reconnaÃ®tre 1000 classes spÃ©cifiques. CLIP nâ€™est pas soumis Ã  cette limitation.</li><li>Langage contraignantÂ : Avec cette technique, CLIP est entraÃ®nÃ© Ã  comprendre que les reprÃ©sentations similaires doivent Ãªtre proches de lâ€™espace latent, tandis que les reprÃ©sentations dissemblables doivent en Ãªtre Ã©loignÃ©es.</li></ul></div>"},
{"url": "https://larevueia.fr/nlp-avec-python-analyse-de-sentiments-sur-twitter/", "title": "NLP avec Python : analyse de sentiments sur Twitter", "author": "Ilyes Talbi", "date": "\n14 septembre 2020\n", "content": "<div class=\"entry-content\"><p>Dans le prÃ©cÃ©dent <a data-type=\"https://larevueia.fr/introduction-au-nlp-avec-python-les-ia-prennent-la-parole/\" href=\"https://larevueia.fr/introduction-au-nlp-avec-python-les-ia-prennent-la-parole/\" target=\"_blank\" rel=\"noreferrer noopener\">tutoriel NLP</a> nous avons introduit la notion dâ€™encodage de texte, expliquÃ© ce quâ€™Ã©tait un pipeline NLP pour le nettoyage de notre dataset et avons construits un outil pour classifier des phrases non labÃ©lisÃ©es. Dâ€™ailleurs je vous conseille vivement de commencer par le lire avant dâ€™aborder celui-lÃ , beaucoup de notions sont complÃ©mentaires. Dans cette article il est question dâ€™analyse de sentiments.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"NLP avec Python : analyse de sentiments sur Twitter\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Avant de commencer, sachez que tous les codes et les donnÃ©es utilisÃ©es ici sont disponibles sur ma page <a href=\"https://github.com/IlyesTal/covid-19_sentiment_analysis\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub</a>.</p></blockquote><p>Le NLP est la discipline du machine learning liÃ©e Ã  la comprÃ©hension du langage par les machines. Les derniÃ¨res avancÃ©es dans ce domaine ont permis lâ€™Ã©mergence dâ€™applications intÃ©ressantes (effrayantes aussi).</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://larevueia.fr/contact/\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-1024x576.jpg\" alt=\"NLP avec Python : analyse de sentiments sur Twitter\" class=\"wp-image-4429\" width=\"465\" height=\"261\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-1024x576.jpg 1024w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-300x169.jpg 300w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-768x432.jpg 768w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1-1536x864.jpg 1536w, https://larevueia.fr/wp-content/uploads/2021/12/Copie-de-soutenance_29_11-1-1.jpg 1600w\" sizes=\"auto, (max-width: 465px) 100vw, 465px\"></a></figure></div><p>Lâ€™analyse de sentiments des textes en est une. Le principe est simple, en Ã©tudiant des millions de textes labellisÃ©s avec un certain sentiment, le systÃ¨me est capable dâ€™associer un champ lexical prÃ©cis pour chaque sentiment. En lui donnant un nouveau texte, il sera alors capable de prÃ©dire avec une bonne prÃ©cision, lâ€™Ã©tat Ã©motionnel de lâ€™auteur au moment de lâ€™Ã©criture de ce texte.</p><p>Certaines organisations utilisent lâ€™analyse de sentiments afin de pouvoir suivre en temps rÃ©el la satisfaction de leurs utilisateurs. Si un client vous envoi un mail et que votre systÃ¨me dÃ©tecte que la personne est Ã©nervÃ©e, vous savez que vous risquez de perdre un client. Vous avez intÃ©rÃªt Ã  offrir quelque chose !</p><p>Lâ€™analyse de sentiments des tweets est une des applications classiques du NLP, câ€™est le â€˜<em>Hello World</em>â€˜ du NLP. Dans cet article, qui sera un peu plus ambitieux que le prÃ©cÃ©dent, lâ€™idÃ©e sera de pouvoir faire de lâ€™analyse de sentiments dâ€™un tweets Ã  partir des mots utilisÃ©s en utilisant <em>TextBlob</em>. Ce qui constituera une mÃ©trique de lâ€™angoisse globale liÃ©e au Covid-19 qui rÃ¨gne sur Twitter, en fonction de ce qui y est publiÃ©.</p><p>Avant dâ€™avoir les rÃ©sultats on sâ€™attend Ã  voir une courbe qui commence Ã  croitre dÃ©but fÃ©vrier et qui ne dÃ©croit quâ€™aux alentours de fin avril.</p><p>Comme je vous lâ€™ai expliquÃ© dans le prÃ©cÃ©dent tutoriel, en data science on traite essentiellement des vecteurs et des donnÃ©es numÃ©riques. Les machines ne savent pas ce quâ€™est un mot ou une phrase, dâ€™oÃ¹ la nÃ©cessitÃ© dâ€™encoder nos donnÃ©es. Pour des phrases standard lâ€™encodage est assez facile en utilisant Word2vec ou BERT. Pour lâ€™encodage de tweets câ€™est plus dÃ©licat.</p><p>La structure dâ€™un tweet est moins organisÃ©e. Certains utilisent des emojis, lâ€™utilisation de ponctuations est beaucoup plus prÃ©sente, les fautes dâ€™orthographes sont trÃ¨s courantes. Tout ceci complique le travail de nettoyage prÃ©alable, surtout lorsquâ€™il est question dâ€™analyse de sentiments.</p><p>Pour contourner cela plutÃ´t que dâ€™encoder nous mÃªme les tweets, nous allons passer par TextBlob. Ce module a une option qui permet de mesurer le sentiment dâ€™un texte donnÃ©. En sortie la fonction nous donne un coefficient de polaritÃ© et un coefficient de sensibilitÃ©.</p><p>Câ€™est la polaritÃ© qui nous intÃ©resse ici. Câ€™est un coefficient compris entre -1 et 1. Plus la polaritÃ© est proche de -1 plus le tweet est nÃ©gatif, Ã  lâ€™inverse une polaritÃ© proche de 1 signifie que le tweet est plutÃ´t positif.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://opensea.io/assets/0x495f947276749ce646f68ac8c248420045cb7b5e/72801339140492550428127495057349254902305173249976114551882572743813200084993/\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/12/Capture-de%CC%81cran-2021-12-16-a%CC%80-18.19.33-1024x652.png\" alt=\"NLP avec Python : analyse de sentiments sur Twitter\" class=\"wp-image-4369\" width=\"545\" height=\"346\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/12/Capture-deÌcran-2021-12-16-aÌ€-18.19.33-1024x652.png 1024w, https://larevueia.fr/wp-content/uploads/2021/12/Capture-deÌcran-2021-12-16-aÌ€-18.19.33-300x191.png 300w, https://larevueia.fr/wp-content/uploads/2021/12/Capture-deÌcran-2021-12-16-aÌ€-18.19.33-768x489.png 768w, https://larevueia.fr/wp-content/uploads/2021/12/Capture-deÌcran-2021-12-16-aÌ€-18.19.33.png 1058w\" sizes=\"auto, (max-width: 545px) 100vw, 545px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"extraction-de-tweets\"><strong>Extraction de tweets</strong></h2><p><br>Pour faire du machine learning sur des tweets il faut des tweetsÂ ğŸ˜Š Pour cela deux options se prÃ©sentent. La premiÃ¨re est dâ€™utiliser lâ€™API que Twitter lui-mÃªme propose. Elle permet de rÃ©cupÃ©rer des tweets en ajoutant certaines conditions sur le type de tweets que vous souhaitez.</p><p>La seconde option est lâ€™utilisation du module Python <em>Twitterscrapper.</em> Vous pouvez extraire un grand nombre de tweets en spÃ©cifiant des critÃ¨res de date, de langues et en vous limitant aux tweets qui contiennent certains mots-clÃ©s. Cette option est plus simple Ã  utiliser mais ne fonctionne pas toujours, si Ã§a marche pour vous tant mieux !<br></p><p>Jâ€™ai choisi de rÃ©cupÃ©rer les tweets entre le 1<sup>er</sup> Janvier et le 1<sup>er</sup> Juin, qui contiennent les termes â€˜<em>Covid-19â€™</em>, â€˜<em>Covidâ€™</em>, â€˜<em>Coronavirusâ€™</em>,<em> â€˜PandÃ©mieâ€™</em>,<em> â€™Ã©pidÃ©mieâ€™</em>, <em>â€™coronaâ€™</em> ou â€˜<em>virusâ€™.</em> Les tweets doivent Ãªtre en franÃ§ais. Pour cela le code est trÃ¨s simple.<br></p><p>Vous devez dâ€™abord installer le module twitterscraper. Si vous codez sur Google Colab, Kaggle ou sur un notebook Jupyter nâ€™oubliez pas le â€˜!â€™ :</p><pre class=\"wp-block-code\"><code>!pip install twitterscraper</code></pre><p>On importe ensuite les modules que nous allons utiliser :</p><pre class=\"wp-block-code\"><code>from twitterscraper import query_tweets\nimport datetime as dt\nimport pandas as pd</code></pre><p>Le module <em>datetime</em> va permettre de gÃ©rer les dates et les horaires de publications des tweets. Pandas (que nous avons dÃ©jÃ  utilisÃ© dans de prÃ©cÃ©dents tutoriels) est le module Python le plus adaptÃ© pour la gestion de grandes base de donnÃ©es.</p><pre class=\"wp-block-code\"><code>debut = dt.date(2020,1,1)\nfin = dt.date(2020,6,1)\nmots=\"Covid-19 OR Covid OR Corona OR PandÃ©mie OR Ã©pidÃ©mie OR Coronavirus OR virus\"\n\ntweets = query_tweets(query=mots, begindate = debut, \nenddate = fin, lang = \"fr\")\n\ntweets = pd.DataFrame(t.__dict__ for t in tweets)\n\ntweets.to_csv('tweet_covid.csv')</code></pre><p>On fixe la date de dÃ©but pour lâ€™extraction de tweets avec <em>dt.date(2020,1,1)</em> le format est <em>YYYY/MM/DD</em>. De mÃªme la ligne <em>dt.date(2020,6,1)</em> permet de fixer la date de fin dâ€™extraction au 1er Juin.</p><p>On sÃ©lectionne les mots-clÃ©s qui doivent apparaÃ®tre dans les tweets puis on commence lâ€™extraction avec <em>query_tweets</em>. Nâ€™oubliez pas de prÃ©ciser que lâ€™on veut seulement les tweets en franÃ§ais.</p><p>La commande DataFrame permet dâ€™organiser toutes nos donnÃ©es sur les tweets dans un tableau pandas. On exporte ensuite le dataframe au format csv. Si vous le souhaitez il est possible de lâ€™enregistrer autre part que dans votre environnement de travail, vous nâ€™avez quâ€™Ã  spÃ©cifier le chemin.</p><p>Lâ€™extraction peut prendre du temps tout dÃ©pend de votre connexion internet. Pour vous faciliter la tache jâ€™ai mis <a href=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" data-type=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">en ligne</a> un fichier csv avec tous les tweets qui ont Ã©tÃ© extraits. Il y en a 13000 en tout. Il devrait yâ€™en avoir beaucoup plus, mais il semblerait que Twitter limite lâ€™extraction pour certains mots-clÃ©s. NÃ©anmoins pour notre Ã©tude nous pouvons nous contenter de cette base.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Pour des raisons que jâ€™ignore lâ€™extraction avec <em>Twitterscrapper</em> a cessÃ© de fonctionner pour moi. Jâ€™ai donc Ã©tÃ© contraint dâ€™utiliser lâ€™API. Elle est un peu moins Ã©vidente Ã  comprendre, mais le code est plutÃ´t simple. La grosse diffÃ©rence câ€™est quâ€™avec <em>Tweepy</em> vous avez besoin dâ€™un accÃ¨s Ã  un compte Twitter.</p></blockquote><p>Si vous voulez seulement utiliser les tweets dÃ©jÃ  disponible vous nâ€™avez quâ€™Ã  tÃ©lÃ©charger le fichier CSV et sauter cette partie. Sinon, voici comment rÃ©cupÃ©rer des tweets avec <em>Tweepy.</em> Cette mÃ©thode est laborieuse est beaucoup moins pratique que la prÃ©cÃ©dente, mais je nâ€™ai pas dâ€™autres alternativesÂ :</p><ul class=\"wp-block-list\" type=\"1\"><li>Dâ€™abord vous aurez besoin dâ€™un compte Twitter dÃ©veloppeur. La demande est un peu laborieuse et lente (Ã§a fait plus dâ€™une semaine que jâ€™attends mes accÃ¨s ğŸ™‚ ). Pour cela rendez-vous sur <a href=\"https://developer.twitter.com/\" data-type=\"https://developer.twitter.com/\" target=\"_blank\" rel=\"noreferrer noopener\">cette page</a>, renseignez les informations demandÃ©es et attendez que Twitter confirme votre demande.<br></li><li>Une fois votre compte dÃ©veloppeur crÃ©e, il vous faudra quelques informationsÂ : <em>lâ€™API key, lâ€™API secret key, lâ€™Access token, lâ€™Access token secret. </em>Ils sont faciles Ã  trouver depuis votre compte.<br></li><li>Enfin, voici le code qui permet dâ€™extraire les tweetsÂ :</li></ul><pre class=\"wp-block-code\"><code>!pip install tweepy\n\nimport os\nimport tweepy as tw\n\nconsumer_key = \"CF COMPTE TWITTER\" \nconsumer_secret = \"CF COMPTE TWITTER\"\naccess_key = \"CF COMPTE TWITTER\"\naccess_secret = \"CF COMPTE TWITTER\"\n\n# Authentification :\n\nauth = tw.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\napi = tw.API(auth, wait_on_rate_limit=True)\n\nrequete = \"Covid-19 OR Covid OR Corona OR PandÃ©mie OR Ã©pidÃ©mie OR Coronavirus OR virus\"\n\ntweets = tw.Cursor(api.search,\n                   q = requete,\n                   lang = \"fr\",\n                   since='2018-01-15').items(1000)\n\nall_tweets = [tweet.text for tweet in tweets]</code></pre><p>Pour information une des caractÃ©ristiques de Twitter que je ne comprends pas bien, est que les commentaires sont aussi considÃ©rÃ©s comme des tweets. Donc notre base comportera les tweets et leurs rÃ©ponses.</p><p>Maintenant que nous avons notre base de tweets, nous pouvons commencer lâ€™analyse Ã  proprement parler.</p><p><em>Update !</em></p><p>Entre temps jâ€™ai trouvÃ© sur Medium une mÃ©thode encore plus facile !</p><p>Le module <em>Twint </em>permet de se passer de lâ€™API de Twitter, le code est trÃ¨s simple. La plupart des exemples que vous trouverez sur internet sont Ã©crits en lignes de commandes. Pour rendre lâ€™extraction plus simple, je vous ai Ã©crit le code Python.</p><p>Vous devez dâ€™abord installer Twint :</p><pre class=\"wp-block-code\"><code>!pip install twint</code></pre><p>Encore une fois, nâ€™oubliez pas â€˜!â€™ si vous Ãªtes sur Google Colab ou sur un Notebook Jupyter.</p><p>Ensuite vous pouvez commencer lâ€™extraction des tweets :</p><pre class=\"wp-block-code\"><code>import twint\n\ntw = twint.Config()\n\ntw.Search = \"Covid-19 OR Corona OR Covid OR Virus OR pandÃ©mie OR Ã©pidÃ©mie OR Coronavirus\"\ntw.Since = \"2020-02-01 12:00:00\"\ntw.Custom[\"tweet\"] = [\"id\"]\ntw.Pandas = True\ntw.Lang = \"fr\"\n\ntwint.run.Search(tw)\ntweet = twint.storage.panda.Tweets_df</code></pre><p>On commence par importer twint. La syntaxe utilisÃ©e par ce module est un peu diffÃ©rente mais reste trÃ¨s simple Ã  comprendre.</p><p>Dans <em>search </em>on dÃ©finit la requÃªte que lâ€™on recherche, Ã  savoir les mots clÃ©s qui nous intÃ©ressent.</p><p><em>Since </em>permet de dÃ©finir une date de dÃ©but dâ€™extraction. Jâ€™ai choisi le 1er FÃ©vrier Ã  midi, rien ne vous empÃªche de commencer encore plus tÃ´t.</p><p>On spÃ©cifie le franÃ§ais comme langue. Nous aurions aussi pu considÃ©rer tous les tweets et les traduire.</p><p>Enfin on dÃ©finit un nom pour lâ€™enregistrement de notre dataframe pandas.</p><p>En pratique, Twint est trÃ¨s lent pour extraire les tweets. Jâ€™ai donc fixÃ© Ã  1000 le nombres maximale de tweets Ã  extraire et jâ€™ai fait lâ€™extraction sur 13 pÃ©riodes de 10 jours de FÃ©vrier Ã  Juin 2020.</p><p>On se retrouve avec un fichier constituÃ© de 13 000 tweets en tout. Vous pouvez le <a data-type=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" href=\"https://drive.google.com/file/d/1ByoJlO9LyJ-o0x0GYGj7s7eJRwi0g3bz/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">tÃ©lÃ©charger ici</a>.</p><p>Si vous utilisez <em>twint</em> sur Jupyter ou Colab vous pourriez avoir cette erreur au moment de lâ€™exÃ©cution :<em> â€˜this event loopis already runing</em>â€˜.</p><p>Pour rÃ©soudre ce problÃ¨me, vous nâ€™avez quâ€™Ã  installer ce module :</p><pre class=\"wp-block-code\"><code>pip install nest_asyncio</code></pre><p>Puis exÃ©cuter ce code :</p><pre class=\"wp-block-code\"><code>import nest_asyncio\nnest_asyncio.apply()</code></pre><h2 class=\"wp-block-heading\" id=\"nettoyage-et-construction-du-pipeline-nlp\"><strong>Nettoyage et construction du pipeline NLP</strong></h2><p><br>Une rapide inspection de la base nous permet de voir que la comprÃ©hension de certains tweets est difficile mÃªme pour des Ãªtres-humains haha. Le nettoyage sera dâ€™autant plus important.<br></p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>Je ne vous le rÃ©pÃ©terai jamais assez, la prÃ©paration de votre dataset est lâ€™aspect le plus important du processus, toute la construction du modÃ¨le en dÃ©pend. Une prÃ©paration faite de maniÃ¨re hÃ¢tive peut conduire Ã  des rÃ©sultats faux et biaisÃ©s, ce qui nâ€™est pas souhaitable. Surtout dans le cadre dâ€™un <a href=\"https://larevueia.fr/voici-comment-lia-peut-vous-aider-dans-votre-business/\" data-type=\"https://larevueia.fr/voici-comment-lia-peut-vous-aider-dans-votre-business/\" target=\"_blank\" rel=\"noreferrer noopener\">business</a> ou pour le traitement de problÃ©matiques de sociÃ©tÃ© importantes, sans parler des catastrophes que cela peut engendrer dans des domaines comme le <a href=\"https://larevueia.fr/le-droit-doit-sadapter-aux-avancees-en-intelligence-artificielle/\" data-type=\"https://larevueia.fr/le-droit-doit-sadapter-aux-avancees-en-intelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">juridique</a> ou la <a href=\"https://larevueia.fr/lintelligence-artificielle-au-service-de-la-sante/\" data-type=\"https://larevueia.fr/lintelligence-artificielle-au-service-de-la-sante/\" target=\"_blank\" rel=\"noreferrer noopener\">santÃ©</a>â€¦</p></blockquote><p><br>En NLP, on commence toujours par construire un pipeline de nettoyage des donnÃ©es. Personnellement jâ€™utilise les Reg-ex avec le module Python <em>re </em>qui permettent de faire cela facilement.<br></p><p style=\"font-size:18px\"><em>Le nettoyage des tweets comprendra plusieurs chosesÂ :</em><br></p><ul class=\"wp-block-list\" type=\"1\"><li>Enlever les emojisÂ : pour cela il faut un module Python spÃ©cial (si vous connaissez des approches plus simples mettez-les en commentaire Ã§a mâ€™intÃ©resse)<br></li><li>Retirer la ponctuationÂ : trÃ¨s facile avec les reg-ex<br></li><li>Retirer les caractÃ¨res spÃ©ciauxÂ : trÃ¨s facile avec les reg-ex mais tous les caractÃ¨res ne seront pas retirÃ©s dans un premier temps. Les tweets sont des objets trÃ¨s salesÂ !<br></li><li>Retirer les chiffresÂ : avec une Reg-ex aussi<br></li><li>Changer les lettres majuscules en minuscules</li></ul><p>Comme dâ€™habitude pour ne pas se tromper il vaut mieux aller du plus restrictif au moins restrictif.</p><p>VoilÃ  Ã  quoi ressemble notre pipelineÂ :</p><pre class=\"wp-block-code\"><code>import re\n\ndef nlp_pipeline(text):\n\n    text = text.lower()\n    text = text.replace('\\n', ' ').replace('\\r', '')\n    text = ' '.join(text.split())\n    text = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%Â°\\.]*\", \"\", text)\n    text = re.sub(r\"(\\s\\-\\s|-$)\", \"\", text)\n    text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)\n    text = re.sub(r\"\\&amp;\\S*\\s\", \"\", text)\n    text = re.sub(r\"\\&amp;\", \"\", text)\n    text = re.sub(r\"\\+\", \"\", text)\n    text = re.sub(r\"\\#\", \"\", text)\n    text = re.sub(r\"\\$\", \"\", text)\n    text = re.sub(r\"\\Â£\", \"\", text)\n    text = re.sub(r\"\\%\", \"\", text)\n    text = re.sub(r\"\\:\", \"\", text)\n    text = re.sub(r\"\\@\", \"\", text)\n    text = re.sub(r\"\\-\", \"\", text)\n\n    return text</code></pre><p>Ce pipeline nous permet dâ€™avoir des tweets Ã  peu prÃ©s propres. Cela permet a TextBlob dâ€™analyser le sentiment du tweet plus efficacement.<br></p><h2 class=\"wp-block-heading\" id=\"le-module-nlp-textblob-pour-l-analyse-de-sentiments\">Le module NLP <strong><em>TextBlob</em> pour lâ€™analyse de sentiments</strong></h2><p><br>TextBlob est un module NLP sur Python utilisÃ© pour lâ€™analyse de sentiment. La fonction de TextBlob qui nous intÃ©resse permet pour un texte donnÃ© de dÃ©terminer le ton du texte et le sentiment de la personne qui lâ€™a Ã©crit.</p><p>Pour chaque tweet nous aurons une mÃ©trique qui donne la polaritÃ© de ce tweet. Nous allons regrouper les tweets par jours et faire une moyenne de la polaritÃ© sur chaque jour. Nous tracerons ensuite la courbe dâ€™Ã©volution de la polaritÃ© ambiante.</p><p>Dâ€™abord ouvrons le fichier csv que nous avons enregistrer plus haut. Si vous avez utilisÃ© <em>twitterscraper</em> ou twint vous nâ€™avez pas Ã  le faire vos tweets sont dÃ©jÃ  stockÃ©s dans la variable <em>df</em>.</p><pre class=\"wp-block-code\"><code>tweet = pd.read_csv(\"tweet_covid.csv\")\n\ncorpus = df['tweet']\ncorpus_clean = corpus.apply(nlp_pipeline)</code></pre><p>Lâ€™instruction co<em>rpus.apply(nlp_pipeline)</em> permet dâ€™appliquer les rÃ¨gles de nettoyage Ã  chaque tweet du corpus.</p><p>Il faut maintenant installer le module TextBlob :</p><pre class=\"wp-block-code\"><code>!pip install textblob\n!pip install textblob-fr</code></pre><p>Vous devez installer les deux modules car textblob dans sa version de base nâ€™est pas disponible pour la langue franÃ§aise. Si vous travaillez avec un corpus en anglais ce ne sera pas nÃ©cessaire.</p><p>On peut maintenant calculer facilement la polaritÃ© dâ€™un tweet. Avant de le faire sur nos donnÃ©es, voici deux exemples :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1235\" height=\"381\" src=\"https://i2.wp.com/larevueia.fr/wp-content/uploads/2020/06/ex_tweet.png?fit=1024%2C316&amp;ssl=1\" alt=\"NLP pour l'analyse de sentiment de tweet avec Python\" class=\"wp-image-991\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet.png 1235w, https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet-300x93.png 300w, https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet-1024x316.png 1024w, https://larevueia.fr/wp-content/uploads/2020/06/ex_tweet-768x237.png 768w\" sizes=\"auto, (max-width: 1235px) 100vw, 1235px\"><figcaption>Exemple dâ€™analyse de sentiment de tweets, avec TextBlob</figcaption></figure><pre class=\"wp-block-code\"><code>from textblob import TextBlob\nfrom textblob_fr import PatternTagger, PatternAnalyzer\n\npolarity = []\nfor tweet in corpus_clean:\n  polarity.append(TextBlob(tweet,pos_tagger=PatternTagger(),analyzer=PatternAnalyzer()).sentiment[0])</code></pre><h2 class=\"wp-block-heading\" id=\"visualisation-des-resultats\"><strong>Visualisation des rÃ©sultats</strong></h2><p><br>La partie que je prÃ©fÃ¨re dans tous les projets data science câ€™est la visualisation des rÃ©sultats. Il est bon de pouvoir construire des modÃ¨les complexes, mais ils ne servent Ã  rien si on ne peut pas les rÃ©sumÃ© de maniÃ¨re simple et Ã©lÃ©gante.</p><p>Maintenant que nous avons une liste avec toutes les polaritÃ©s des tweets du corpus, nous pouvons tracer une premiÃ¨re courbe pour voir Ã  quoi lâ€™Ã©volution ressemble.</p><p>Pour cela on utilise matplotlib.pyplot, câ€™est la librairie de rÃ©fÃ©rence pour le tracÃ© de courbes sur Python :</p><pre class=\"wp-block-code\"><code>import matplotlib.pyplot as plt\n\nplt.plot(polarity)</code></pre><p><br>Avec cette commande, on obtient le tracÃ© de lâ€™Ã©volution de la polaritÃ© des tweets. Comme on a 13000 tweets, cette mÃ©thode ne permet pas de voir grand chose :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"386\" height=\"248\" src=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid.png\" alt=\"Evolution des sentiments sur Twitter liÃ©s au Covid-19\" class=\"wp-image-948\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid.png 386w, https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid-300x193.png 300w\" sizes=\"auto, (max-width: 386px) 100vw, 386px\"><figcaption>Evolution de la polaritÃ© des tweets liÃ©s au Covid-19 depuis FÃ©vrier</figcaption></figure></div><p>Comme vous le voyez on ne peut rien tirer de ce graphe, on a plusieurs milliers de valeurs. Il faudra Ãªtre moins bourrin.</p><p>La premiÃ¨re chose que lâ€™on peut faire est de regrouper les tweets en paquets suivant lâ€™ordre chronologique. On conservera ensuite pour chaque groupe uniquement sa moyenne. Je dÃ©cide de les regrouper par paquet de 100 tweets.</p><pre class=\"wp-block-code\"><code>group = lambda liste, size : [liste[i:i+size] for i in range(0, len(liste), size)]\n\npolarity_par_paquet = group(polarity,100)\n\nliste_moyennes = []\nfor l in polarity_par_paquet :\n  liste_moyennes.append(np.mean(l))\n\nplt.plot(liste_moyennes)</code></pre><p>On obtient la courbe suivante :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"378\" height=\"248\" src=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid_grouped.png\" alt=\"Courbe de l'Ã©volution des sentiments des tweets sur le covid-19 depuis FÃ©vrier. Approche par paquet\" class=\"wp-image-961\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid_grouped.png 378w, https://larevueia.fr/wp-content/uploads/2020/06/evolution_covid_grouped-300x197.png 300w\" sizes=\"auto, (max-width: 378px) 100vw, 378px\"><figcaption>Evolution de sentiments des tweets sur le Covid-19 (mÃ©thode 2)</figcaption></figure></div><p>Une fois de plus les rÃ©sultats ne sont pas ceux attendus. Je suis un peu dÃ©Ã§u. Je mâ€™attendais Ã  voir une tendance dâ€™Ã©volution se dÃ©gageait sur nos rÃ©sultats. Il peut y avoir plusieurs raisons Ã  cela.</p><p>Dâ€™abord, tout au long de lâ€™Ã©pidÃ©mie, les gens Ã©taient assez partagÃ©s sur le danger du virus. De plus, les rÃ©actions des gens face au danger ne sont pas toutes identiques. Certains prÃ©fÃ¨rent plutÃ´t prendre les choses Ã  la rigolade. Ces rÃ©actions contribuent Ã  augmenter la polaritÃ©.</p><p>Des problÃ¨mes dans le modÃ¨le peuvent aussi exister. Textblob est un module trÃ¨s gÃ©nÃ©raliste entraÃ®nÃ© sur des tweets couvrants de nombreux sujets, il est difficilement applicable Ã  un sujet prÃ©cis.</p><p>Ces rÃ©sultats peuvent Ãªtre considÃ©rablement amÃ©liorÃ©s. Il suffit pour cela de construire une base de donnÃ©es labellisÃ©e propre Ã  notre contexte. Si voulez savoir comment faire contactez-moi. Le travail de labellisation est assez long mais permet dâ€™avoir de bien meilleurs performances.</p><p>Comme souvent dans les problÃ¨mes de NLP le plus difficile est de constituer une base de donnÃ©es propres et utilisables. Câ€™est la plus grande partie du travail dâ€™un ingÃ©nieur NLP. Pour cela les reg-ex sont de trÃ¨s bons outils quâ€™il est important de maÃ®triser (des alternatives intÃ©ressantes existent Ã©videmment).</p><p>MÃªme si nous nâ€™avons pas obtenu les rÃ©sultats espÃ©rÃ©s, ce tutoriel permet dâ€™avoir une mÃ©thodologie claire pour la rÃ©alisation de ce type de projet. Le schÃ©ma sera souvent similaire :<br><br><br>           1. Constitution de la base<br>           2. Nettoyage<br>           3. Conception du modÃ¨le<br>           4. InterprÃ©tation des rÃ©sultats<br></p><p>La communautÃ© Python est trÃ¨s active concernant les problÃ©matiques de NLP. Câ€™est pour cela quâ€™avec des connaissances simples vous pouvez faire de trÃ¨s belles choses. A lâ€™image de TextBlob, qui nous a Ã©tÃ© utile dans ce tutoriel (nous auront lâ€™occasion de lâ€™utiliser encore), de nombreux packages Python vous permette de rÃ©aliser vos projets : NLTK, Gensim, SpaCy et dâ€™autres.</p><p>MalgrÃ© tous ces outils dont on dispose et malgrÃ© tous les efforts de milliers de chercheurs, les dÃ©fis liÃ©s au NLP sont encore difficile Ã  rÃ©soudre. La construction de sÃ©mantiques fiables et flexibles nâ€™est pas encore parfaitement maÃ®trisÃ©e. Et nous sommes encore trÃ¨s loin dâ€™une vraie comprÃ©hension du langage par les IA, câ€™est dâ€™ailleurs pour cela que <em><a href=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" data-type=\"https://larevueia.fr/personne-naime-parler-a-une-machine/\" target=\"_blank\" rel=\"noreferrer noopener\">â€˜Personne nâ€™aime parler Ã  une IAâ€™</a></em>.</p></div>"},
{"url": "https://larevueia.fr/le-machine-learning-en-20-questions/", "title": "Le machine learning en 20 questions", "author": "Ilyes Talbi", "date": "\n30 aoÃ»t 2020\n", "content": "<div class=\"entry-content\"><figure class=\"wp-block-audio\"><audio controls src=\"https://larevueia.fr/wp-content/uploads/2021/08/Le-machine-learning-en-20-questions_mixed.mp3\"></audio></figure><p>Beaucoup de choses sont dites au sujet du <strong>machine learning</strong>. Certains le voit comme un monstre qui mÃ¨ne lâ€™humanitÃ© Ã  sa perte. Dâ€™autres comme un magicien solution Ã  tous leurs maux. En rÃ©alitÃ© câ€™est beaucoup plus simple que Ã§a (et un peu moins effrayant).</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Le machine learning en 20 questions\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"qu-est-ce-que-le-machine-learning\">Quâ€™est-ce que le machine learning ?</h2><p>Le machine learning est une technique qui permet aux systÃ¨mes automatiques de sâ€™amÃ©liorer grÃ¢ce aux donnÃ©es. LittÃ©ralement on parle <em>dâ€™apprentissage automatique</em>.</p><p>Lâ€™explosion du volume de donnÃ©es et le progrÃ¨s des techniques de traitement et de stockage, on permit au machine learning de sâ€™imposer dans de nombreux domaines.</p><h2 class=\"wp-block-heading\" id=\"comment-fonctionne-le-machine-learning\">Comment fonctionne le machine learning ?</h2><p>DerriÃ¨re ce nom mystÃ©rieux, se cache un fonctionnement en principe trÃ¨s simple. Le systÃ¨me sâ€™inspire dâ€™exemples dÃ©jÃ  existants, regroupÃ©s dans des bases de donnÃ©es, pour comprendre la tÃ¢che qui lui est demandÃ©e.</p><p>Que les choses soient claires. Ce nâ€™est pas parce que lâ€™on parle de machines quâ€™il faut imaginer des robots qui suivent des cours dans une salle de classe. Le vocabulaire utilisÃ© nâ€™est quâ€™une maniÃ¨re imagÃ©e de dÃ©crire le processus.</p><h2 class=\"wp-block-heading\" id=\"quel-est-le-lien-entre-machine-learning-deep-learning-et-intelligence-artificielle\">Quel est le lien entre machine learning, deep learning et intelligence artificielle ?</h2><p>Comme tous les domaines polÃ©miques, lâ€™intelligence artificielle fait couler beaucoup dâ€™encre. La consÃ©quence directe de cela est lâ€™apparition de <em>buzzwords</em> et on finit un peu par se perdre.</p><p>En rÃ©alitÃ©, le <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a> nâ€™est quâ€™un sous ensemble du machine learning, lui mÃªme sous ensemble de lâ€™intelligence artificielle. Dans un diagramme voici ce que Ã§a donne.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-1024x576.png\" alt=\"Le machine learning en 20 questions\" class=\"wp-image-1734\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-1024x576.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-768x432.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning-1536x864.png 1536w, https://larevueia.fr/wp-content/uploads/2020/09/machine-learning-vs-deep-learning.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Intelligence artificielle, machine learning, deep learning, quelle est la diffÃ©rence</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-applications-du-machine-learning\">Quelles sont les applications du machine learning ?</h2><p>Le machine learning sâ€™est imposÃ© dans un trÃ¨s grand nombre de domaines. Il nâ€™y a pas rÃ©ellement de limites Ã  ce que les modÃ¨les de machine learning peuvent rÃ©aliser. DÃ¨s quâ€™il y a des donnÃ©es on peut faire du machine learning.</p><p>En finance par exemple, la volatilitÃ© des marchÃ©s boursiers semble ne pas laisser de place Ã  la prÃ©diction. NÃ©anmoins, le machine learning fournit une solution. Il permet de donner des prÃ©visions plus ou moins prÃ©cises concernant lâ€™Ã©volution dâ€™une action boursiÃ¨re.</p><p>Dans leÂ <a href=\"https://larevueia.fr/lintelligence-artificielle-au-service-de-la-sante/\" target=\"_blank\" rel=\"noreferrer noopener\">domaine de la santÃ©</a>Â aussi, lâ€™intelligence artificielle commence Ã  sâ€™imposer comme un outil majeur. Lâ€™IA est rÃ©guliÃ¨rement utilisÃ©e par les mÃ©decins aujourdâ€™hui. La mÃ©decine du futur est souvent associÃ©e aux 3 P : PrÃ©vention, PrÃ©diction, Personnalisation</p><p>Câ€™est surtout pour lâ€™imagerie mÃ©dicale que les IA dâ€™aujourdâ€™hui se dÃ©marquent vraiment. Les progrÃ¨s en terme de computer vision ont Ã©tÃ© impressionnants ces derniÃ¨res annÃ©es. Et les IA dâ€™aujourdâ€™hui sont au moins aussi fortes que les mÃ©decins sur des tÃ¢ches comme la dÃ©tection de tumeurs cancÃ©reuses ou le calcul de lâ€™Ã¢ge osseux.</p><p>De maniÃ¨re plus gÃ©nÃ©rale, lâ€™IA constitue une opportunitÃ© de dÃ©veloppement sans prÃ©cÃ©dent pour les entreprises. Elle permet dâ€™Ã©tablir des stratÃ©gies Ã  plus ou moins long terme Ã  travers des outils dâ€™aide Ã  la prise de dÃ©cision.</p><p>Le machine learning permet de rÃ©pondre Ã  des questions comme : Dois-je me lancer dans ce projet de <a href=\"https://larevueia.fr/les-cas-dusages-de-lia-dans-limmobilier/\" target=\"_blank\" rel=\"noreferrer noopener\">construction immobiliÃ¨re</a> ? Est-ce que le profil de ce candidat correspond Ã  ce poste ? Comment va Ã©voluer le marchÃ© de la voiture Ã©lectrique dâ€™ici 2025 ? Et des millions dâ€™autres questions propres Ã  chaque activitÃ©.</p><h2 class=\"wp-block-heading\" id=\"quelle-est-la-difference-entre-apprentissage-supervise-et-apprentissage-non-supervise\">Quelle est la diffÃ©rence entre apprentissage supervisÃ© et apprentissage non supervisÃ© ?</h2><p>Le machine learning se divise essentiellement en deux modes dâ€™apprentissage. Lâ€™apprentissage supervisÃ© et lâ€™<a href=\"https://larevueia.fr/panorama-de-l-apprentissage-non-supervise/\" target=\"_blank\" rel=\"noreferrer noopener\">apprentissage non supervisÃ©</a>.</p><p>En apprentissage supervisÃ©, les donnÃ©es dont on dispose sont labellisÃ©es. Câ€™est Ã  dire, les sorties du modÃ¨le sont dÃ©jÃ  connues. Câ€™est le cas pour les rÃ©seaux de neurones par exemple.</p><p>A lâ€™inverse, lorsque lâ€™on fait de lâ€™apprentissage non supervisÃ©, on laisse le modÃ¨le sâ€™entraÃ®ner tout seul, sans labelliser les donnÃ©es. Un des algorithmes de clustering non supervisÃ© les plus utilisÃ©s est k-means. On donne Ã  lâ€™algorithme tous les points de notre dataset et on a en sortie ces mÃªmes points regroupÃ©s en plusieurs catÃ©gories.</p><h2 class=\"wp-block-heading\" id=\"qu-est-ce-que-l-explicabilite-en-machine-learning\">Quâ€™est-ce que lâ€™explicabilitÃ© en machine learning ?</h2><p>Beaucoup de modÃ¨les que lâ€™on utilise aujourdâ€™hui sont ce quâ€™on appelle des boÃ®tes noires. Dans le sens oÃ¹ ils sont opaques et leur fonctionnement interne est trÃ¨s peu compris.</p><p>Le dilemme efficacitÃ©/<a href=\"https://larevueia.fr/explicabilite-des-modeles-ne-croyez-pas-aveuglement-ce-que-lia-vous-dit/\" target=\"_blank\" rel=\"noreferrer noopener\">explicabilitÃ©</a> est un dilemme bien connu en science des donnÃ©es. Bien souvent les modÃ¨les les plus efficaces sont des boÃ®tes noires dont le fonctionnement est le moins explicable.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"638\" height=\"479\" src=\"https://larevueia.fr/wp-content/uploads/2020/06/explainability_tradeoff.jpg\" alt=\"Ã©xplicabilitÃ© vs performance en machine learning\" class=\"wp-image-705\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/06/explainability_tradeoff.jpg 638w, https://larevueia.fr/wp-content/uploads/2020/06/explainability_tradeoff-300x225.jpg 300w\" sizes=\"auto, (max-width: 638px) 100vw, 638px\"><figcaption class=\"wp-element-caption\">Dilemme explicabilitÃ©/efficacitÃ©</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-etapes-d-un-projet-en-data-science\">Quelles sont les Ã©tapes dâ€™un projet en data science ?</h2><p>Lorsque jâ€™ai commencÃ© Ã  travailler sur des projets de data science, jâ€™ai Ã©tÃ© surpris de voir que la construction du modÃ¨le ne reprÃ©sentait quâ€™une petite Ã©tape dâ€™un long processus.</p><p>Les projets se divisent souvent de la sorte :</p><ul class=\"wp-block-list\"><li>Collecte et stockage des donnÃ©es</li><li>Preprocessing (nettoyage des donnÃ©es et Ã©tudes prÃ©alables)</li><li>Construction des modÃ¨les</li><li>Etudes de performances et choix du meilleur modÃ¨le</li><li>DÃ©ploiement du modÃ¨le</li></ul><h2 class=\"wp-block-heading\" id=\"comment-se-deroule-le-nettoyage-des-donnees-preprocessing\">Comment se dÃ©roule le nettoyage des donnÃ©es (preprocessing) ?</h2><p>Contrairement Ã  ce que lâ€™on pense, le nettoyage des donnÃ©es est la tÃ¢che principale lors dâ€™un projet de machine learning. Et câ€™est dommage (dâ€™aprÃ¨s moi en tout cas ğŸ™‚ ), car câ€™est beaucoup moins amusant que la conception du modÃ¨le ! Tous ce travail que lâ€™on fait en amont est ce que lâ€™on appelle le <em>preprocessing</em>.</p><p>Les techniques de preprocessing dÃ©pendent du projet et du types de donnÃ©es que lâ€™on Ã©tudie. Bien souvent on suit les Ã©tapes suivantes :</p><ul class=\"wp-block-list\"><li>Traitement des valeurs manquantes</li><li>Calcul de corrÃ©lations ou de variances</li><li>RÃ©duction de la dimension</li><li>Encodage des features</li><li>DÃ©coupage des donnÃ©es en train/test</li></ul><h2 class=\"wp-block-heading\" id=\"comment-evaluer-un-modele\">Comment Ã©valuer un modÃ¨le ?</h2><p>Avant de mettre un modÃ¨le en production, il y a toute une phase de validation qui dÃ©bute. Et pour ne rien faciliter cette phase de validation implique dâ€™Ãªtre minutieux.</p><p>Dâ€™abord, avant dâ€™entraÃ®ner un modÃ¨le on sâ€™assure de sÃ©parer les donnÃ©es disponibles en 2. DonnÃ©es dâ€™entraÃ®nements et donnÃ©es de tests. On parle de cross validation.</p><p>Cela permet de tester le modÃ¨le une fois entraÃ®nÃ©, cette Ã©tape est primordiale. Elle permet de sâ€™assurer de la fiabilitÃ© du modÃ¨le mais aussi de comparer plusieurs approches pour pouvoir dÃ©terminer la quelle est la plus intÃ©ressante.</p><h2 class=\"wp-block-heading\" id=\"comment-eviter-l-overfitting\">Comment Ã©viter lâ€™overfitting ?</h2><p>Lâ€™overfitting est le plus grand ennemi du data scientist. Il survient lorsque le modÃ¨le essaye de trop coller aux donnÃ©es. Si bien quâ€™il nâ€™est plus gÃ©nÃ©ralisable.</p><figure class=\"wp-block-image alignwide size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"356\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/overfiting-1024x356.png\" alt=\"Qu'est-ce que l'overfitting ?\" class=\"wp-image-1801\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/overfiting-1024x356.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/overfiting-300x104.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/overfiting-768x267.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/overfiting.png 1125w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Illustration de lâ€™overfitting dans le cas de la rÃ©gression</figcaption></figure><p>Avant de savoir comment lâ€™Ã©viter, nous devons apprendre Ã  le dÃ©tecter.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"450\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting.png\" alt=\"DÃ©tecter l'overfitting en machine learning\" class=\"wp-image-1809\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting.png 800w, https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/detecter-loverfitting-768x432.png 768w\" sizes=\"auto, (max-width: 800px) 100vw, 800px\"><figcaption class=\"wp-element-caption\">DÃ©tecter lâ€™overfitting sur une courbe de prÃ©cision</figcaption></figure></div><p>Sur cette courbe (que vous devrez toujours tracer pour vÃ©rifier les performances du modÃ¨le) on voit quâ€™Ã  partir dâ€™un certain point, notre prÃ©cision sur les donnÃ©es de test chutent. Cela veut dire que le modÃ¨le commence Ã  Ãªtre de moins en moins efficace. On fait de lâ€™overfitting.</p><p>Plusieurs mÃ©thodes existent pour Ã©viter lâ€™overfitting :</p><ul class=\"wp-block-list\"><li><a href=\"https://fr.wikipedia.org/wiki/Validation_crois%C3%A9e\" target=\"_blank\" rel=\"noreferrer noopener\">Cross validation</a></li><li>Ajouter plus de donnÃ©es pour lâ€™entraÃ®nement</li><li>Early stopping (arrÃªter lâ€™entrainement avant quâ€™ils ne se terminent)</li><li><a href=\"https://dataanalyticspost.com/Lexique/regularisation/#:~:text=Pour%20les%20r%C3%A9seaux%20de%20neurones,les%20mod%C3%A8les%20simples)%20ou%20la\" target=\"_blank\" rel=\"noreferrer noopener\">RÃ©gularisation</a> (par exemple le dropout pour les rÃ©seaux de neurones)</li></ul><p>On a un <a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">article entier</a> sur ce sujet ğŸ™‚</p><h2 class=\"wp-block-heading\" id=\"quels-sont-les-principaux-outils-utilises-en-machine-learning\">Quels sont les principaux outils utilisÃ©s en machine learning ?</h2><p>Les outils qui interviennent en machine learning sont nombreux. Pour le dÃ©veloppement de modÃ¨le on utilise des langages de programmation objets performants comme Python ou C.</p><p>Python reste le langage de rÃ©fÃ©rence. Il jouit dâ€™une communautÃ© open source trÃ¨s active ce qui permet dâ€™avoir des modules trÃ¨s puissants comme <a href=\"https://colab.research.google.com/drive/1yYWxg5oFk15qYW4aCsHj6kERzlZQAZzW?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">Pandas</a>, <a href=\"https://larevueia.fr/tensorflow/\" target=\"_blank\" rel=\"noreferrer noopener\">Tensorflow </a>ou <a href=\"https://scikit-learn.org/\" target=\"_blank\" rel=\"noreferrer noopener\">Scikit-learn</a>. Ils rendent les modÃ¨les de machine learning plus facile Ã  implÃ©menter. Ã‡a serait beaucoup trop longs de vous Ã©numÃ©rer tous les outils utilisÃ©s en machine learning. Si je devais en garder que 3 (pour la partie construction de modÃ¨les), je prendrais ceux lÃ .</p><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-principales-methodes-utilisees\">Quelles sont les principales mÃ©thodes utilisÃ©es ?</h2><p>Les modÃ¨les de machine learning sont nombreux. Ceux qui ont la cÃ´te aujourdâ€™hui sont les algorithmes de <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, ils sont fiables faciles Ã  entraÃ®ner et donnent dâ€™assez bons rÃ©sultats la plupart du temps.</p><p>Il y a un grand nombre de mÃ©thodes en fonction de ce que lâ€™on veut faire.</p><p>Pour le clustering :</p><ul class=\"wp-block-list\"><li>k-nn</li><li>k-means</li><li>DBScan</li><li>RÃ©gression logistique</li><li>SVM</li></ul><p>RÃ©seaux de neurones :</p><ul class=\"wp-block-list\"><li>LSTM</li><li>CNN</li><li><a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones-gan/\" target=\"_blank\" rel=\"noreferrer noopener\">GAN</a></li><li>Auto Encoder</li><li><a href=\"https://larevueia.fr/reseaux-de-neurones-toute-lhistoire-du-perceptron/\" target=\"_blank\" rel=\"noreferrer noopener\">Perceptron</a></li></ul><p>Arbres de dÃ©cisions :</p><ul class=\"wp-block-list\"><li><a href=\"https://larevueia.fr/random-forest/\" target=\"_blank\" rel=\"noreferrer noopener\">Random Forest</a></li><li>XGBoost</li><li>AdaBoost</li><li>LightGBM</li><li>CatBoost</li></ul><p>Avec tous ces algorithmes on est en droit de se demander lequel choisir. La transition avec la prochaine question est parfaite ğŸ™‚</p><h2 class=\"wp-block-heading\" id=\"comment-choisir-l-algorithme-a-utiliser\">Comment choisir lâ€™algorithme Ã  utiliser ?</h2><p>Le machine learning est une question de choix. Des donnÃ©es jusquâ€™Ã  lâ€™algorithme Ã  utiliser, le data scientist a de nombreuses dÃ©cisions Ã  prendre. Le choix de lâ€™algorithme Ã  utiliser est sans doute le plus crucial.</p><p>Plusieurs critÃ¨res sont Ã  prendre en compte pour choisir un modÃ¨le :</p><ul class=\"wp-block-list\"><li>Quelle tÃ¢che souhaitez vous effectuer ? PrÃ©diction ? RÃ©gression ? Clustering ?</li><li>Les donnÃ©es sont elles labellisÃ©es ?</li><li>De quel types sont les donnÃ©es ? Images ? Textes ? Audio ?</li><li>Quelle est la taille de votre dataset ?</li></ul><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube aligncenter wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Comment CHOISIR LE BON MODÃˆLE de Machine Learning ?\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/4mqKmTbAnHY?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div><figcaption class=\"wp-element-caption\">Comment choisir le bon modÃ¨le pour ses donnÃ©es ?</figcaption></figure><h2 class=\"wp-block-heading\" id=\"quelles-sont-les-limites-du-machine-learning\">Quelles sont les limites du machine learning ?</h2><p>Lâ€™intelligence artificielle est souvent vu comme une baguette magique capable de tout. En rÃ©alitÃ© ce nâ€™est pas si simple. Les modÃ¨les ont souvent besoin dâ€™Ã©normÃ©ment de donnÃ©es pour pouvoir donner de bons rÃ©sultats.</p><p>Dans mon article <em><a href=\"https://larevueia.fr/ce-que-lia-nest-pas/\" target=\"_blank\" rel=\"noreferrer noopener\">Ce que lâ€™IA nâ€™est pas</a></em>, jâ€™explique comment le marketing a rendu lâ€™intelligence artificielle plus impressionnante quâ€™elle ne lâ€™est rÃ©ellement. Les modÃ¨les dâ€™aujourdâ€™hui sont trÃ¨s limitÃ©s, ils demandent beaucoup dâ€™entraÃ®nement et sont assez peu gÃ©nÃ©ralisables.</p><h2 class=\"wp-block-heading\" id=\"quelles-competences-doit-avoir-un-data-scientist\">Quelles compÃ©tences doit avoir un data scientist ?</h2><p>Les data scientist sont aujourdâ€™hui trÃ¨s recherchÃ©s. Un ingÃ©nieur en machine learning doit avoir des compÃ©tences aussi bien thÃ©oriques que pratiques. Il doit Ãªtre un trÃ¨s bon statisticien, câ€™est indispensable pour comprendre correctement les diffÃ©rents algorithmes et leurs subtilitÃ©s. Dâ€™un point de vu plus pratique, il doit Ãªtre Ã  lâ€™aise avec les outils de programmation comme Python.</p></div>"},
{"url": "https://larevueia.fr/limpact-de-lia-et-des-data-centers-sur-lenvironnement/", "title": "Lâ€™impact de lâ€™IA et des data centers sur lâ€™environnement", "author": "Ilyes Talbi", "date": "\n9 avril 2023\n", "content": "<div class=\"entry-content\"><p>Lâ€™intelligence artificielle (IA) et les centres de donnÃ©es (data centers) ont considÃ©rablement stimulÃ© le dÃ©veloppement de lâ€™industrie numÃ©rique ces derniÃ¨res annÃ©es. Cependant, cette croissance rapide a Ã©galement eu un impact significatif sur lâ€™environnement.</p><p>Les demandes en Ã©nergie des data centers et de lâ€™IA ne cessent de croÃ®tre, ce qui accentue la dÃ©pendance aux combustibles fossiles, la consommation dâ€™eau et les Ã©missions de gaz Ã  effet de serre.</p><p>Cette situation prÃ©occupe de plus en plus les entreprises et les gouvernements, qui cherchent Ã  rÃ©duire lâ€™empreinte carbone de leurs opÃ©rations.</p><p>Pour faire face Ã  ce dÃ©fi environnemental, des efforts considÃ©rables ont Ã©tÃ© dÃ©ployÃ©s pour rendre lâ€™utilisation de lâ€™IA et des data centers plus efficace et plus respectueuse de lâ€™environnement.</p><p>Cet article explore ainsi lâ€™impact de lâ€™IA et des data centers sur lâ€™environnement et discutera des solutions existantes et en devenir pour rÃ©duire leur empreinte carbone.</p><h2 class=\"wp-block-heading\">Les data centers : des infrastructures Ã©nergivores</h2><p>Les data centers ont une consommation Ã©nergÃ©tique trÃ¨s Ã©levÃ©e pour assurer le stockage, le traitement et la gestion des donnÃ©es.</p><p>En effet, ils nÃ©cessitent non seulement une Ã©norme quantitÃ© dâ€™Ã©lectricitÃ© pour leur fonctionnement quotidien, mais Ã©galement des systÃ¨mes de refroidissement sophistiquÃ©s pour Ã©viter toute surchauffe de lâ€™Ã©quipement informatique.</p><p>Cette consommation dâ€™Ã©nergie est souvent couverte par des combustibles fossiles non renouvelables, ce qui contribue Ã  lâ€™augmentation des Ã©missions de gaz Ã  effet de serre.</p><p>Selon les estimations, les centres de donnÃ©es seraient responsables dâ€™environ 1% de la consommation mondiale dâ€™Ã©lectricitÃ©.</p><p>Cela en fait lâ€™un des plus grands consommateurs dâ€™Ã©nergie dans le secteur numÃ©rique et les experts estiment que cette proportion pourrait doubler dâ€™ici 2025.</p><p>Face Ã  cette problÃ©matique, plusieurs acteurs du secteur travaillent sur des solutions pour optimiser la consommation Ã©nergÃ©tique des data centers.</p><p>Des stratÃ©gies telles que lâ€™utilisation de sources dâ€™Ã©nergie renouvelables et la consolidation des infrastructures pourraient permettre de rÃ©duire significativement leur impact environnemental.</p><h2 class=\"wp-block-heading\">Lâ€™IA une technologie gourmande en Ã©nergie</h2><p>Lâ€™intelligence artificielle (IA) est une technologie Ã©mergente qui implique une grande quantitÃ© de calculs complexes pour faire fonctionner les algorithmes.</p><p>Pourtant, la puissance de traitement nÃ©cessaire pour exÃ©cuter ces calculs est considÃ©rablement Ã©levÃ©e, ce qui en fait une technologie gourmande en Ã©nergie.</p><p>En plus des data centers spÃ©cialisÃ©s, qui stockent et traitent les donnÃ©es nÃ©cessaires Ã  lâ€™entraÃ®nement et Ã  lâ€™utilisation constante de lâ€™IA, de nombreux appareils compatibles avec lâ€™IA, tels que les smartphones, les voitures autonomes, les drones et les robots, nÃ©cessitent Ã©galement des capacitÃ©s de traitement Ã©levÃ©es qui consomment beaucoup dâ€™Ã©nergie.</p><p>MalgrÃ© les avantages que peut offrir lâ€™IA, lâ€™impact environnemental de cette technologie est de plus en plus prÃ©occupant. Les dÃ©veloppeurs de technologies Ã©mergentes proposent des solutions pour rÃ©duire autant que possible lâ€™impact environnemental de lâ€™IA.</p><p>Des moyens tels que lâ€™optimisation des algorithmes et la mise en place de choix informatiques plus Ã©conomes en Ã©nergie sont envisagÃ©s pour rÃ©duire lâ€™empreinte carbone de cette technologie prometteuse.</p><h2 class=\"wp-block-heading\">Les consÃ©quences environnementales de lâ€™exploitation de lâ€™IA et des data centers</h2><p>Les impacts environnementaux de lâ€™utilisation de lâ€™IA et des data centers sont nombreux et variÃ©s. La forte demande Ã©nergÃ©tique de ces infrastructures numÃ©riques pourrait entraÃ®ner une augmentation significative de la production dâ€™Ã©nergie fossile, ce qui contribuerait Ã  lâ€™augmentation des niveaux de gaz Ã  effet de serre et Ã  lâ€™accÃ©lÃ©ration du changement climatique.</p><p>De plus, les besoins en refroidissement de lâ€™Ã©quipement informatique peuvent contribuer Ã  la pÃ©nurie dâ€™eau dans les rÃ©gions oÃ¹ les ressources sont limitÃ©es. En outre, la production et la gestion des Ã©quipements technologiques peuvent avoir un impact nÃ©gatif sur les ressources naturelles et sur la qualitÃ© de lâ€™air.</p><p>Enfin, lâ€™utilisation de lâ€™IA peut avoir des consÃ©quences Ã©thiques et sociales importantes, tels que la question de la protection de donnÃ©es personnelles et de la prÃ©servation de la vie privÃ©e.</p><p>Il est donc essentiel de prendre en compte tous ces facteurs et dâ€™apporter des changements significatifs pour rÃ©duire lâ€™impact environnemental de lâ€™exploitation de lâ€™IA et des data centers. Des solutions efficaces doivent Ãªtre mises en place, telles que lâ€™utilisation des sources dâ€™Ã©nergie renouvelables, la virtualisation de lâ€™informatique et la gestion efficace de lâ€™Ã©nergie.</p><h2 class=\"wp-block-heading\">Des solutions pour rÃ©duire lâ€™impact de lâ€™IA et des data centers sur lâ€™environnement</h2><p>Des solutions sont actuellement Ã©tudiÃ©es pour rÃ©duire lâ€™impact environnemental de lâ€™IA et des data centers. Lâ€™une des principales initiatives consiste Ã  utiliser des sources dâ€™Ã©nergie renouvelables, telles que lâ€™Ã©nergie solaire, Ã©olienne et hydraulique. Lâ€™utilisation de lâ€™Ã©nergie solaire pour alimenter les data centers est devenue une tendance croissante.</p><p>En outre, la virtualisation de lâ€™informatique est une autre solution efficace pour rÃ©duire la consommation Ã©nergÃ©tique des data centers. Cela implique la consolidation des infrastructures informatiques pour un meilleur usage des ressources et une rÃ©duction des coÃ»ts.</p><p>Enfin, de nouveaux systÃ¨mes de refroidissement pour les centres de donnÃ©es sont Ã©galement en cours de dÃ©veloppement. Les liquides de refroidissement Ã©vaporatifs permettent de rÃ©duire considÃ©rablement la consommation dâ€™Ã©nergie en utilisant lâ€™air extÃ©rieur pour rafraÃ®chir les Ã©quipements informatiques.</p><p>Lâ€™utilisation de lâ€™IA elle-mÃªme peut Ã©galement apporter une contribution significative Ã  la rÃ©duction de la consommation dâ€™Ã©nergie, par exemple en utilisant des algorithmes de gestion intelligente de lâ€™Ã©nergie pour mieux gÃ©rer les systÃ¨mes de refroidissement et de chauffage.</p><p>En somme, ces solutions doivent Ãªtre mises en Å“uvre de maniÃ¨re holistique, en prenant en compte tous les aspects de lâ€™utilisation de lâ€™IA et des data centers pour minimiser leur impact environnemental.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, lâ€™IA et les data centers ont apportÃ© de nombreux avantages au monde numÃ©rique, mais leur impact environnemental ne peut Ãªtre ignorÃ©. La forte consommation dâ€™Ã©nergie et les Ã©missions de gaz Ã  effet de serre rÃ©sultent en une empreinte carbone importante pour cette industrie.</p><p>Il est donc impÃ©ratif dâ€™opter pour des solutions Ã©co-responsables pour minimiser lâ€™impact environnemental de lâ€™utilisation de lâ€™IA et des centres de donnÃ©es.</p><p>Les initiatives visant Ã  utiliser des sources dâ€™Ã©nergie renouvelable, la virtualisation de lâ€™informatique et les nouveaux systÃ¨mes de refroidissement sont autant de pistes permettant de rÃ©duire la consommation dâ€™Ã©nergie et de limiter la production de gaz Ã  effet de serre.</p><p>Les entreprises doivent Ã©galement prendre des mesures pour la rÃ©cupÃ©ration et le recyclage de lâ€™Ã©quipement informatique.</p><p>Le dÃ©fi consiste Ã  innover et Ã  explorer de nouvelles solutions pour stimuler la transition vers une utilisation plus Ã©cologique des systÃ¨mes informatiques.</p><p>En investissant dans des technologies plus durables, les entreprises peuvent continuer Ã  tirer profit des avantages de lâ€™IA tout en faisant preuve de responsabilitÃ© Ã©cologique.</p></div>"},
{"url": "https://larevueia.fr/dans-la-course-a-lia-hardware-is-all-you-need/", "title": "Dans la course Ã  lâ€™IA : Hardware is all you need", "author": "Ilyes Talbi", "date": "\n24 juin 2023\n", "content": "<div class=\"entry-content\"><p>Dans lâ€™arÃ¨ne technologique contemporaine, une compÃ©tition effrÃ©nÃ©e se joue, un marathon oÃ¹ lâ€™Intelligence Artificielle (IA) tient le rÃ´le de la mÃ©daille dâ€™or tant convoitÃ©e.</p><p>Mais dans cette course, ce nâ€™est pas tant la vitesse qui importe, mais la puissance et lâ€™endurance. Dans le domaine de lâ€™IA, lâ€™endurance se mesure en termes de capacitÃ©s de calcul, et la puissance en termes de capacitÃ©s de traitement de donnÃ©es.</p><p>Autrement dit, en termes de hardware.</p><p>Câ€™est ce que nous allons explorer aujourdâ€™hui.</p><p>Bien loin des projecteurs, dans lâ€™ombre des algorithmes et des ensembles de donnÃ©es, le matÃ©riel informatique joue un rÃ´le dÃ©terminant dans la progression de lâ€™IA.</p><p>Data centers titanesques et puces graphiques de pointe constituent les rouages essentiels de cette machine complexe.</p><p>Les progrÃ¨s rÃ©alisÃ©s en IA ces derniÃ¨res annÃ©es ne sont pas uniquement dus Ã  des modÃ¨les plus intelligents, mais Ã  des modÃ¨les contenant toujours plus de paramÃ¨tres entraÃ®nables et entraÃ®nÃ©s sur des volumes de donnÃ©es sans cesse croissants.</p><p>Alors, attachez vos ceintures et prÃ©parez-vous pour un voyage Ã  travers les coulisses de la course Ã  lâ€™IA, oÃ¹ nous dÃ©couvrirons que dans ce marathon technologique, le hardware est bien plus quâ€™un simple accessoire : il est le cÅ“ur mÃªme de la machine.</p><h2 class=\"wp-block-heading\">Lâ€™importance des data centers</h2><h3 class=\"wp-block-heading\">A quoi sert un data center ?</h3><p>Imaginez un orchestre, oÃ¹ chaque instrument joue un rÃ´le crucial pour crÃ©er une harmonie parfaite. Dans lâ€™univers de lâ€™Intelligence Artificielle, les data centers sont le chef dâ€™orchestre.</p><p>Les data centers, ou centres de donnÃ©es, sont des infrastructures dÃ©diÃ©es oÃ¹ sont rassemblÃ©s des Ã©quipements de traitement et de stockage de donnÃ©es. Ces vÃ©ritables cerveaux numÃ©riques sont essentiels pour gÃ©rer, traiter et distribuer dâ€™Ã©normes volumes de donnÃ©es, et donc, pour la mise en Å“uvre de lâ€™IA.</p><p>Ces centres de donnÃ©es ne sont pas simplement des entrepÃ´ts remplis de serveurs, mais des Ã©cosystÃ¨mes technologiques complexes, oÃ¹ chaque composant, du serveur Ã  la puce, du routeur au systÃ¨me de refroidissement, joue un rÃ´le dans la gestion efficace des donnÃ©es.</p><p>Sans ces architectures sophistiquÃ©es, le traitement des grands volumes de donnÃ©es nÃ©cessaires Ã  lâ€™entraÃ®nement des modÃ¨les dâ€™IA serait une tÃ¢che herculÃ©enne, voire impossible.</p><h3 class=\"wp-block-heading\">Un meilleur hardware dans les data centers permet dâ€™amÃ©liorer notre faÃ§on de faire de lâ€™IA</h3><p>Mais ce nâ€™est pas tout. Les data centers sont en constante Ã©volution. Au fur et Ã  mesure que lâ€™IA progresse, la demande en capacitÃ© de calcul augmente, et les data centers doivent sâ€™adapter.</p><p>Les amÃ©liorations du hardware dans les data centers, quâ€™il sâ€™agisse de serveurs plus puissants, de mÃ©moires plus rapides ou de systÃ¨mes de refroidissement plus efficaces, ont Ã©tÃ© des facteurs clÃ©s de lâ€™Ã©volution de lâ€™IA.</p><p>En somme, le rÃ´le des data centers dans le domaine de lâ€™IA est comparable Ã  celui du chef dâ€™orchestre dans un orchestre : sans lui, chaque instrument pourrait Ãªtre performant, mais lâ€™harmonie serait absente. Il nâ€™y a pas de symphonie sans chef, et il nâ€™y a pas dâ€™IA sans data centers.</p><p>Câ€™est ici que la vraie magie de lâ€™IA prend vie, oÃ¹ les donnÃ©es sont transformÃ©es en informations, oÃ¹ les bits deviennent de la connaissance. Les data centers sont le cÅ“ur palpitant de lâ€™IA, orchestrant le rythme auquel avance cette rÃ©volution technologique.</p><h2 class=\"wp-block-heading\">Le rÃ´le crucial des GPUs</h2><p>Dans lâ€™orchestre des data centers, si le chef dâ€™orchestre est la structure organisatrice, alors les GPUs, ou unitÃ©s de traitement graphique, sont les violons solistes, les vÃ©ritables stars du spectacle. Sans ces GPUs, lâ€™entraÃ®nement des modÃ¨les de <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, une sous-catÃ©gorie de lâ€™IA, serait tout simplement impensable.</p><p>Les GPUs, initialement conÃ§us pour le rendu graphique dans les jeux vidÃ©o, se sont avÃ©rÃ©s exceptionnellement efficaces pour le calcul parallÃ¨le â€“ la capacitÃ© dâ€™exÃ©cuter plusieurs calculs simultanÃ©ment. Cette caractÃ©ristique sâ€™est rÃ©vÃ©lÃ©e Ãªtre une aubaine pour le deep learning, qui nÃ©cessite des opÃ©rations matricielles massives, une tÃ¢che pour laquelle les GPUs sont parfaitement adaptÃ©s.</p><p>Les GPUs sont donc devenus une pierre angulaire de lâ€™entraÃ®nement des modÃ¨les dâ€™IA. Ils permettent de traiter rapidement des volumes Ã©normes de donnÃ©es, dâ€™accÃ©lÃ©rer les temps dâ€™entraÃ®nement et dâ€™optimiser les performances des modÃ¨les. Sans eux, lâ€™entraÃ®nement dâ€™un seul modÃ¨le dâ€™IA pourrait prendre des mois, voire des annÃ©es.</p><p>Et comme les data centers, les GPUs ont Ã©galement Ã©voluÃ©. Les constructeurs, conscients de leur importance croissante dans le domaine de lâ€™IA, ont dÃ©veloppÃ© des GPUs de plus en plus puissants, capables de traiter des volumes de donnÃ©es toujours plus importants et de soutenir des modÃ¨les dâ€™IA de plus en plus complexes.</p><p>Et aujourdâ€™hui, les maestros du monde des GPUs pour le deep learning, sont incontestablement, Nvidia.</p><p>En fin de compte, lâ€™impact des GPUs sur lâ€™efficacitÃ© et la vitesse de lâ€™IA est incontestable. Ils sont les violons solistes de notre orchestre, jouant la mÃ©lodie du deep learning avec une virtuositÃ© sans prÃ©cÃ©dent. Sans les GPUs, le concert de lâ€™IA ne serait quâ€™un murmure. Avec eux, il devient une symphonie.</p><h2 class=\"wp-block-heading\">Toujours plus de paramÃ¨tres, toujours plus de data</h2><p>Reprenons notre analogie musicale. Si les data centers sont le chef dâ€™orchestre et les GPUs les violons solistes, alors les modÃ¨les dâ€™IA sont la partition musicale. Câ€™est Ã  travers eux que la symphonie de lâ€™IA prend forme. Cependant, ces partitions sont devenues de plus en plus complexes au fil du temps, gagnant en longueur et en dÃ©tails.</p><p>Au cours des derniÃ¨res annÃ©es, une tendance claire sâ€™est dÃ©gagÃ©e dans le dÃ©veloppement des modÃ¨les dâ€™IA : une augmentation constante du nombre de paramÃ¨tres et une soif insatiable de donnÃ©es. Ces modÃ¨les gigantesques, tels que <a href=\"https://larevueia.fr/introduction-a-gpt-3-lun-des-modeles-de-nlp-les-plus-avances/\" target=\"_blank\" rel=\"noreferrer noopener\">GPT-3</a> de <a href=\"https://openai.com/\" target=\"_blank\" rel=\"noreferrer noopener\">OpenAI</a> avec ses 175 milliards de paramÃ¨tres, GPT-4 en a potentiellement des dizaines de trillions, semblent suivre la loi de Moore de lâ€™IA, doublant (ou faisant x100) en taille tous les 16 mois environ. Cette croissance exponentielle a Ã©tÃ© rendue possible grÃ¢ce aux amÃ©liorations constantes du hardware.</p><p>Cependant, cette course au gigantisme soulÃ¨ve des questions dâ€™ordre Ã©conomique. Les entreprises qui possÃ¨dent les moyens de calcul nÃ©cessaires pour entraÃ®ner ces monstres de puissance ont un avantage compÃ©titif considÃ©rable. On peut craindre une concentration de pouvoir entre les mains de quelques gÃ©ants technologiques, avec le risque de crÃ©er des monopoles dans le domaine de lâ€™IA.</p><p>Par ailleurs, cette tendance Ã  la croissance nâ€™est pas sans susciter des divergences stratÃ©giques au sein de la communautÃ© de lâ€™IA.</p><p>Dâ€™un cÃ´tÃ©, il y a ceux qui poussent Ã  lâ€™augmentation de la taille des modÃ¨les, convaincus que la route vers lâ€™IA gÃ©nÃ©ralisÃ©e passe par toujours plus de donnÃ©es et de paramÃ¨tres. De lâ€™autre, il y a des voix dissidentes, comme celle de Yann LeCun, laurÃ©at du prix Turing et pionnier du deep learning, qui plaide pour une approche plus frugale. LeCun propose de se tourner vers des modes dâ€™apprentissage plus intelligents, tels que le self-supervised learning. Il souligne que contrairement Ã  une machine, un enfant nâ€™a pas besoin de voir des milliers dâ€™images dâ€™une girafe pour comprendre le concept de girafe.</p><p>Quelle que soit la voie que nous choisissons de suivre, une chose est certaine : le rÃ´le du hardware restera central. Quâ€™il sâ€™agisse de soutenir la croissance exponentielle des modÃ¨les ou de rendre possible des approches dâ€™apprentissage plus sophistiquÃ©es, le hardware est et restera le chef dâ€™orchestre de la symphonie de lâ€™IA.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, lâ€™importance du hardware dans la course Ã  lâ€™IA est indÃ©niable. Comme nous lâ€™avons vu, les data centers sont le chef dâ€™orchestre qui rÃ©git lâ€™orchestre de lâ€™IA, tandis que les GPUs sont les virtuoses solistes qui jouent la mÃ©lodie du deep learning. Quant aux modÃ¨les dâ€™IA, ils sont la partition complexe et toujours plus longue sur laquelle se joue la symphonie de lâ€™IA.</p><p>Cependant, il est important de souligner que cette course technologique nâ€™est pas sans consÃ©quences. Lâ€™un des enjeux les plus pressants est lâ€™impact environnemental de cette augmentation constante de la puissance de calcul. Les data centers consomment une quantitÃ© dâ€™Ã©nergie colossale, et leur empreinte carbone est loin dâ€™Ãªtre nÃ©gligeable. Il est donc essentiel de prendre en compte cet aspect dans notre quÃªte de lâ€™IA.</p><p>Finalement, que nous choisissions de suivre la voie de la croissance exponentielle des modÃ¨les ou celle de lâ€™apprentissage plus frugal, une chose est certaine : le hardware sera toujours au cÅ“ur de lâ€™IA. Alors que nous continuons Ã  explorer les possibilitÃ©s offertes par lâ€™IA, nâ€™oublions pas lâ€™importance de lâ€™infrastructure qui la rend possible. AprÃ¨s tout, dans la course Ã  lâ€™IA, le hardware nâ€™est pas seulement un accessoire : câ€™est le vÃ©ritable cÅ“ur de la machine.</p></div>"},
{"url": "https://larevueia.fr/comment-lia-transforme-le-domaine-de-la-sante/", "title": "Comment lâ€™IA transforme le domaine de la santÃ© ?", "author": "Ilyes Talbi", "date": "\n13 janvier 2023\n", "content": "<div class=\"entry-content\"><p>Lâ€™intelligence artificielle a conquis la plupart des domaines de la connaissance. Les modÃ¨les dâ€™aujourdâ€™hui savent parler, cuisiner, dessiner, et apprennent Ã  soigner.</p><p>Lâ€™intelligence artificielle intervient Ã  plusieurs endroits pour la mÃ©decine : de la dÃ©couverte de nouveaux mÃ©dicaments, Ã  lâ€™aide pour la recherche en passant par le diagnostic.</p><p>Dans cet article, jâ€™ai voulu regrouper le maximum dâ€™informations sur lâ€™IA en santÃ©. Ce document peut faire office dâ€™Ã©tat de lâ€™art non-exhaustif, avec des rÃ©fÃ©rences et un guide de lecture pour le futur de lâ€™IA dans la santÃ©.</p><h2 class=\"wp-block-heading\">NLP et santÃ©</h2><p>Les modÃ¨les de NLP sont de plus en plus robustes, ils permettent de saisir des subtilitÃ©s de langage, et comprendre la sÃ©mantique des phrases.</p><p>Pour le NLP, il y a clairement un avant et un aprÃ¨s GPT, le large langage model proposÃ© par OpenAI. Et comme tous les domaines, le monde de la santÃ© devrait beaucoup bÃ©nÃ©ficier de ces progrÃ¨s.</p><p>Dans cette section on explore les diffÃ©rents projets de NLP dans la santÃ©, mÃªme sâ€™il nâ€™y a pas de rÃ©volution, les prochaines annÃ©es devraient voir de jolies initiatives Ã©merger.</p><h3 class=\"wp-block-heading\">Lâ€™OCR pour lâ€™analyse dâ€™ordonnances</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances.webp\" alt=\"Comment l'IA transforme le domaine de la santÃ© ?\" class=\"wp-image-7974\" width=\"719\" height=\"275\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances.webp 1024w, https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances-300x115.webp 300w, https://larevueia.fr/wp-content/uploads/2023/01/ocr_ordonnances-768x294.webp 768w\" sizes=\"auto, (max-width: 719px) 100vw, 719px\"></figure></div><p>Les mÃ©decins ont leur faÃ§on Ã  eux dâ€™Ã©crire, ils se comprennent plutÃ´t bien entre eux et les pharmaciens nâ€™ont pas lâ€™air dâ€™Ã©prouver de difficultÃ©s Ã  dÃ©chiffrer les ordonnances.</p><p>NÃ©anmoins, il est clair que lâ€™on peut faire beaucoup mieux niveau process et fiabilitÃ©. En attendant le passage au tout numÃ©rique (fortement remis en question par la cyber-attaque subie par un hÃ´pital rÃ©cemment), lâ€™OCR (Optical Characters Recognition) semble Ãªtre une solution intÃ©ressante pour mieux dÃ©chiffrer les prescriptions mÃ©dicales.</p><p>Il est utile de noter que lâ€™OCR restera utile mÃªme aprÃ¨s le passage au tout numÃ©rique, puisquâ€™il permettra dâ€™extraire des donnÃ©es plus facilement ou encore de gÃ©nÃ©rer des rappels pour la prise de mÃ©dicaments de faÃ§on automatique (notamment pour les personnes Ã¢gÃ©es).</p><p>Jâ€™ai mis ce sujet dans la rubrique NLP car je suis convaincu que la partie liÃ©e au traitement de lâ€™image ne sera bientÃ´t plus un problÃ¨me en OCR, le problÃ¨me rÃ©side dans la comprÃ©hension et le traitement du texte rÃ©sultant : notamment sur la classification des types (par exemple nom du mÃ©decin/nom du mÃ©dicament/adresse, etc.).</p><h3 class=\"wp-block-heading\">Diagnostiquer des maladies par la voix</h3><p>Owkin travaille avec 12 partenaires sur un projet de diagnostic des maladies via la voix. Pour mener Ã  bien ce travail, le financement disponible sâ€™Ã©lÃ¨ve Ã  14 M dâ€™euros.</p><p>2 questions me viennent Ã  lâ€™esprit concernant ce projet :</p><ul class=\"wp-block-list\"><li>Dâ€™abord, jâ€™avoue que je suis un peu dubitatif. Câ€™est sans doute Ã  cause de mon ignorance du monde de la santÃ©, mais je ne vois pas comment un modÃ¨le pourrait dÃ©tecter une pathologie simplement en utilisant la voix du patient. Comment est-ce que Ã§a va marcher ?</li><li>Et si Ã§a marche, comment assurer le secret mÃ©dical ? On pourrait prÃ©dire la maladie dâ€™une personne au tÃ©lÃ©phone ou grÃ¢ce Ã  une vidÃ©o dâ€™elleâ€¦</li></ul><figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\"><blockquote class=\"twitter-tweet\" data-width=\"550\" data-dnt=\"true\"><p lang=\"en\" dir=\"ltr\">Today, we are launching Voice as a Biomarker of Health ï¼ a $14 million <a href=\"https://twitter.com/NIH?ref_src=twsrc%5Etfw\">@NIH</a>-funded project to use <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a> to help doctors diagnose cancer, depression and other diseases from the human voice.<br><br>Learn more at <a href=\"https://t.co/B5tZPHLhwP\">https://t.co/B5tZPHLhwP</a> <a href=\"https://t.co/9J8XBfGTE8\">pic.twitter.com/9J8XBfGTE8</a></p>â€” Owkin (@OwkinScience) <a href=\"https://twitter.com/OwkinScience/status/1569703379881926657?ref_src=twsrc%5Etfw\">September 13, 2022</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> </div></figure><h3 class=\"wp-block-heading\">Les limites de Google traduction</h3><p>La situation dans laquelle un patient et un mÃ©decin ne parle pas la mÃªme langue est plus frÃ©quente quâ€™on ne le pense.</p><p>Dans ces cas-lÃ , on utilise souvent des modÃ¨les de traduction gÃ©nÃ©ralistes comme Google traduction. Le problÃ¨me câ€™est que ces modÃ¨les nâ€™ont pas Ã©tÃ© entraÃ®nÃ©s pour le mÃ©dical et peuvent conduire Ã  des erreurs graves de traduction.</p><p>Un exemple dâ€™erreur faites par Google traduction (pas en situation rÃ©elle heureusement), est la traduction de â€œvotre enfant sâ€™adapteâ€ Ã  â€œvotre enfant est mortâ€. Je te laisse voir le papier en rÃ©f qui dÃ©crit lâ€™Ã©tude faite et recense quelques-unes des erreurs graves de traduction faites par Google traduction.</p><p>Afin dâ€™accÃ©lÃ©rer la prise en charge et limiter le risque dâ€™erreur, des modÃ¨les de traduction entraÃ®nÃ©s spÃ©cialement pour le mÃ©dical Ã©mergent.</p><p>Des rÃ©fÃ©rences sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://www.bmj.com/content/349/bmj.g7392\" target=\"_blank\" rel=\"noreferrer noopener\">Google traduction pour la santÃ©</a></li><li>Le site de <a href=\"https://www.aalia.tech/\" target=\"_blank\" rel=\"noreferrer noopener\">Aalia.tech</a>, une startup franÃ§aise qui travaille sur ce sujet</li><li><a href=\"https://www.presse-citron.net/google-traduction-est-toujours-un-risque-pour-la-medecine/\" target=\"_blank\" rel=\"noreferrer noopener\">Un article de presse-citron</a></li></ul><h2 class=\"wp-block-heading\">Vision par ordinateur et santÃ©</h2><p>MÃªme si le NLP commence Ã  contribuer Ã©normÃ©ment Ã  la discipline, câ€™est clairement la vision par ordinateur qui est aujourdâ€™hui lâ€™outil de prise de dÃ©cision le plus utilisÃ© dans le mÃ©dical.</p><p>Dans cette partie, jâ€™ai sÃ©lectionnÃ© des projets intÃ©ressants qui utilisent la vision par ordinateur.</p><h3 class=\"wp-block-heading\">Vision par ordinateur pour lâ€™imagerie mÃ©dicale</h3><p>Une des applications les plus matures de la vision par ordinateur, est lâ€™analyse dâ€™imagerie mÃ©dicale.</p><p>Les meilleurs modÃ¨les actuels sont capables de diagnostiquer un cancer avec une meilleure prÃ©cision que les mÃ©decins.</p><p>On peut aussi utiliser des modÃ¨les similaires pour la dÃ©tection dâ€™anomalies, câ€™est la mÃªme technique qui est utilisÃ©e que dans lâ€™industrie.</p><p>Par ailleurs, des mÃ©thodes de traitement des imageries mÃ©dicales sont utilisÃ©es pour rÃ©aliser des tÃ¢ches moins intÃ©ressantes et automatisables comme le calcul de lâ€™Ã¢ge osseux.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.24.01.png\" alt=\"Comment l'IA transforme le domaine de la santÃ© ?\" class=\"wp-image-7975\" width=\"368\" height=\"372\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.24.01.png 582w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.24.01-297x300.png 297w\" sizes=\"auto, (max-width: 368px) 100vw, 368px\"></figure></div><p>Enfin, pendant la crise du covid, une Ã©quipe de chercheurs Chinois a dÃ©veloppÃ© un modÃ¨le de vision par ordinateur pour diagnostiquer le covid Ã  partir du scanner thoracique.</p><p>Des rÃ©fÃ©rences sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://www.usine-digitale.fr/article/en-chine-des-medecins-utilisent-la-vision-par-ordinateur-pour-depister-le-coronavirus.N936199\" target=\"_blank\" rel=\"noreferrer noopener\">DÃ©pistage du covid</a></li><li>Un <a href=\"https://www.thelancet.com/journals/landig/article/PIIS2589-7500(20)30160-6/fulltext\" target=\"_blank\" rel=\"noreferrer noopener\">Ã©tat de lâ€™art</a> de The Lancet sur lâ€™IA pour lâ€™imagerie mÃ©dicale</li></ul><h3 class=\"wp-block-heading\">AmÃ©liorer le taux de rÃ©ussite des fÃ©condations im-vitro</h3><p>Jâ€™ai Ã©tÃ© Ã©tonnÃ© dâ€™apprendre que la vision par ordinateur Ã©tait utilisÃ©e pour le traitement dâ€™images dâ€™embryons, pour faciliter la prise de dÃ©cision avant une fÃ©condation in-vitro.</p><p>Avant une fÃ©condation in-vitro, les embryons sont cultivÃ©s en laboratoire, et le mÃ©decin doit choisir le ou les embryons Ã  injecter dans lâ€™utÃ©rus de la patiente (1 ou 2 embryons au maximum). Cette phase de prise de dÃ©cision est trÃ¨s critique, et elle est Ã  lâ€™origine de la majoritÃ© des Ã©checs de lâ€™opÃ©ration.</p><p>Les modÃ¨les de vision par ordinateur vont permettre dâ€™avoir une analyse plus pragmatique et systÃ©matique que le mÃ©decin.</p><p>Une des entreprises de rÃ©fÃ©rence sur ce sujet est Imvitro. Câ€™est une jeune start-up Parisienne qui a dÃ©veloppÃ© une plateforme SaaS Ã  destination des mÃ©decins pour calculer un score qui exprime le potentiel de rÃ©ussite de la fÃ©condation.</p><p>Des rÃ©fÃ©rences sur le sujet :</p><ul class=\"wp-block-list\"><li>Le site <a href=\"https://im-vitro.com/fr/\" target=\"_blank\" rel=\"noreferrer noopener\">dâ€™Imvitro</a></li><li>Mon <a href=\"https://larevueia.fr/lintelligence-artificielle-pour-la-fecondation-in-vitro/\" target=\"_blank\" rel=\"noreferrer noopener\">article</a> sur le sujet</li><li><a href=\"https://hal.archives-ouvertes.fr/hal-02882052/document\" target=\"_blank\" rel=\"noreferrer noopener\">Un papier en franÃ§ais</a></li></ul><h2 class=\"wp-block-heading\">Le deep learning pour la dÃ©couverte de nouveaux traitements</h2><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-1024x899.png\" alt=\"Comment l'IA transforme le domaine de la santÃ© ?\" class=\"wp-image-7976\" width=\"499\" height=\"438\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-1024x899.png 1024w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-300x263.png 300w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-768x674.png 768w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-1536x1348.png 1536w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03-168x147.png 168w, https://larevueia.fr/wp-content/uploads/2023/01/Capture-decran-2023-01-13-a-01.25.03.png 1600w\" sizes=\"auto, (max-width: 499px) 100vw, 499px\"></figure></div><p>Un des modÃ¨les les plus en vogue dans le monde de la biologie est AlphaFold. Le modÃ¨le dâ€™intelligence artificielle a Ã©tÃ© capable de prÃ©dire la structure de toutes les molÃ©cules connues Ã  partir de leurs acides aminÃ©s.</p><p>Ce modÃ¨le a permis de faire de grandes avancÃ©es dans la recherche de nouveaux traitements assistÃ©e par intelligence artificielle. En aidant Ã  comprendre les interactions entre les bactÃ©ries et les structures anti-bactÃ©riennes, AlphaFold pourrait aider Ã  dÃ©couvrir de nouveaux antibiotiques, mÃªme si une Ã©tude du MIT disponible en rÃ©fÃ©rence Ã  nuance cette affirmation.</p><p>Des rÃ©fÃ©rences sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe\" target=\"_blank\" rel=\"noreferrer noopener\">AlphaFold</a> reveals the structure of the universe</li><li><a href=\"https://news.mit.edu/2022/alphafold-potential-protein-drug-0906\" target=\"_blank\" rel=\"noreferrer noopener\">Lâ€™Ã©tude du MIT</a></li></ul><h2 class=\"wp-block-heading\">La question Ã©thique</h2><p>DÃ¨s quâ€™on traite des donnÃ©es, et quelque soit le domaine, lâ€™aspect Ã©thique est un gros sujet, câ€™est dâ€™autant plus vrai dans la santÃ©.</p><p>Dâ€™abord, on traite des donnÃ©es personnelles sensibles, ce qui implique des mesures de sÃ©curitÃ© avancÃ©es. Je suis assez surpris de voir que certains acteurs du monde de la santÃ© en France utilisent des solutions de cloud non-souverain, Ã  lâ€™heure du cloud act (la rÃ©glementation amÃ©ricaine qui permet au gouvernement dâ€™imposer aux entreprises de livrer leurs donnÃ©es).</p><p>MÃªme dâ€™un point de vue juridique, la dÃ©finition dâ€™une donnÃ©e de santÃ© nâ€™est pas trÃ¨s bien dÃ©finie. Avec la multiplication des sources de donnÃ©es, ces questions se posent : est-ce que les donnÃ©es de ma montre connectÃ©es sont des donnÃ©es de santÃ© ? le temps passÃ© devant lâ€™Ã©cran ? la distance que jâ€™ai parcourue Ã  pied cette semaine ? etc.</p><p>Par ailleurs, les modÃ¨les entraÃ®nÃ©s doivent Ãªtre explicables. En deep learning, les modÃ¨les sont opaques et peu interprÃ©tables. Câ€™est une caractÃ©ristique quâ€™on accepte en gÃ©nÃ©ral, mais en santÃ©, quand on doit diagnostiquer la maladie dâ€™une personne, le modÃ¨le doit nous expliquer sa prÃ©diction.</p><p>Des rÃ©fÃ©rences sur le sujet :</p><ul class=\"wp-block-list\"><li><a href=\"https://larevueia.fr/explicabilite-des-modeles-ne-croyez-pas-aveuglement-ce-que-lia-vous-dit/\" target=\"_blank\" rel=\"noreferrer noopener\">Mon article sur lâ€™explicabilitÃ© des modÃ¨les</a></li><li><a href=\"https://arxiv.org/abs/2206.15363\" target=\"_blank\" rel=\"noreferrer noopener\">Why we do need Explainable AI for Healthcare</a></li></ul><h2 class=\"wp-block-heading\">Conclusion : IoT + Blockchain + IA X santÃ©</h2><p>Je me suis fait un dÃ©lire en mode â€œformule magiqueâ€ sur ce titre, je trouvais Ã§a stylÃ© ahah ğŸ™‚</p><p>Je ne suis pas expert du domaine, je ne suis pas devin, mais je vois bien le domaine de lâ€™IA dans la santÃ© prendre les directions qui sâ€™Ã©noncent dans cette partie.</p><p>Dâ€™abord, la robotique sera un grand sujet pour les annÃ©es Ã  venir. On voit dÃ©jÃ  des systÃ¨mes automatisÃ©s dans les hÃ´pitaux.</p><p>De nombreuses tÃ¢ches pourraient Ãªtre automatisÃ©es, pour accorder plus de temps aux personnels soignants et se concentrer sur lâ€™essentiel : le contact humain.</p><p>Lâ€™avenir de la santÃ© sera technologique, lâ€™objectif sera de regrouper les techniques disponibles aujourdâ€™hui, les agrÃ©ger pour rÃ©soudre les problÃ¨mes actuels.</p><p>Avec lâ€™IoT pour la collecte et lâ€™agrÃ©gation des donnÃ©es, la blockchain pour la sÃ©curisation et la traÃ§abilitÃ©, et lâ€™intelligence artificielle pour le traitement, le tout sera beaucoup plus grand que la somme de ses parties.</p></div>"},
{"url": "https://larevueia.fr/travailler-en-tant-que-freelance-data-scientist-en-etant-etudiant/", "title": "Travailler en tant que freelance data scientist en Ã©tant Ã©tudiant", "author": "Ilyes Talbi", "date": "\n26 avril 2021\n", "content": "<div class=\"entry-content\"><p>Durant ma derniÃ¨re annÃ©e Ã  <a href=\"https://isup.sorbonne-universite.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">lâ€™ISUP</a> jâ€™ai eu la chance dâ€™Ãªtre freelance data scientist et Ã©tudiant en mÃªme temps. Cette experience inhabituelle mâ€™a Ã©tÃ© trÃ¨s bÃ©nÃ©fique. Dans cet article je vous prÃ©sente pourquoi et comment vous lancer.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Travailler en tant que freelance data scientist en Ã©tant Ã©tudiant\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"quels-sont-les-avantages-a-commencer-en-etant-etudiant\">Quels sont les avantages Ã  commencer en Ã©tant Ã©tudiant ?</h2><p>Lorsquâ€™on est Ã©tudiant on nâ€™a pas grand chose Ã  perdre, câ€™Ã©tait mon cas. Le fait de se mettre en freelance ne peut Ãªtre que bÃ©nÃ©fique (si on gÃ¨re les choses proprement). En dehors de lâ€™impact quâ€™une telle experience peut avoir sur votre CV, les bÃ©nÃ©fices sont nombreux.</p><h3 class=\"wp-block-heading\" id=\"monter-en-competences\">Monter en compÃ©tences</h3><p>En data science rien nâ€™est plus formateur que de travailler sur des projets concrets. Les projets scolaires vous permettront dâ€™apprÃ©hender les outils utilisÃ©s mais donnent une vision biaisÃ©e de ce quâ€™est le travail de data scientist en entreprise. En tant que data scientist freelance, vous devrez rÃ©pondre Ã  la volontÃ© de votre client et adapter votre faÃ§on de travailler.</p><p>Par exemple, jâ€™avais pour habitude de travailler uniquement sur Python, une fois que mon code Ã©tait Ã©crit je lâ€™exÃ©cutais sur un IDE que je savais utiliser. Evidemment lorsque vous Ãªtes freelance vous devez proposer un outil complet au client, les codes ne suffisent plus. Câ€™Ã©tait lâ€™occasion pour moi de travailler sur le dÃ©ploiement de modÃ¨les et mâ€™intÃ©resser Ã  lâ€™architecture data.</p><p>Au delÃ  de lâ€™aspect technique, on apprend Ã©normÃ©ment de choses sur la gestion de projets en general. En tant que freelance vous Ãªtes en charge de tout :</p><ul class=\"wp-block-list\"><li>Trouver des missions</li><li>Convaincre les clients</li><li>RÃ©diger des devis</li><li>RÃ©aliser la mission</li><li>PrÃ©senter votre travail</li><li>RÃ©diger la facture et gÃ©rer la comptabilitÃ©</li></ul><p> <span style=\"font-size: revert; color: initial;\">Câ€™est un travail Ã©norme quâ€™il ne faut pas nÃ©gliger mais qui mâ€™a permis dâ€™apprendre Ã©normÃ©ment.</span></p><h3 class=\"wp-block-heading\" id=\"rencontrer-des-personnes-interessantes-et-se-faire-des-contacts\">Rencontrer des personnes intÃ©ressantes et se faire des contacts</h3><p>RÃ©ussir une mission est le meilleur moyen de se faire des contacts qui nous font confiance. Quelque soit le chemin que vous emprunterez aprÃ¨s vos Ã©tudes, les contacts sont importants. Ce qui me plait vraiment dans le travail de freelance câ€™est quâ€™on rencontre tous les jours des gens formidables issus de diverses horizons. Et Ã  chaque rendez-vous, mÃªme sâ€™il nâ€™aboutit pas sur une collaboration, on apprend beaucoup.</p><h3 class=\"wp-block-heading\" id=\"financer-ses-etudes\">Financer ses Ã©tudes</h3><p>MÃªme si ma dÃ©marche Ã©tait surtout motivÃ©e par lâ€™envie dâ€™apprendre, je me suis rendu compte rapidement quâ€™Ã©conomiquement aucun job Ã©tudiant ne pouvait rivaliser avec le fais dâ€™Ãªtre freelance. En tant que dÃ©butant vous pouvez facturer jusquâ€™Ã  500â‚¬ H.T. la journÃ©e. MÃªme lorsque vous retirez les impÃ´ts et les cotisations URSAAF il vous reste un trÃ¨s bon salaire ! Vu le travail quâ€™il demande, ce salaire est amplement mÃ©ritÃ©.</p><h2 class=\"wp-block-heading\" id=\"comment-trouver-les-premieres-missions\">Comment trouver les premiÃ¨res missions ?</h2><p>Une fois que vous Ãªtes convaincus que cette expÃ©rience ne peut que vous Ãªtre bÃ©nÃ©fique, vous devez trouver vos premiÃ¨res missions.</p><p>Les premiÃ¨res missions sont les plus difficiles Ã  trouver. Personnellement jâ€™ai eu un peu de chance. DÃ¨s que jâ€™ai annoncÃ© sur LinkedIn que je me mettais en freelance jâ€™ai Ã©tÃ© contactÃ© par plusieurs personnes et jâ€™ai pu commencer mes premiÃ¨res missions.</p><p>Vous devez chercher vos premiÃ¨res missions dans votre propre rÃ©seau, câ€™est le meilleur moyen de commencer.</p><p>Vous pouvez aussi passer par des plateformes de mise en relation comme <a href=\"https://www.malt.fr/profile/ilyestalbi\" target=\"_blank\" rel=\"noreferrer noopener\">Malt</a>. Jâ€™ai trouvÃ© deux missions sur cette plateforme et Ã  chaque fois tout sâ€™est bien passÃ©.</p><p>Sur Malt vous devez attendre quâ€™un client trouve votre profil et vous envoie une demande de devis. Si vous prÃ©fÃ©rer choisir vos missions vous pouvez passer par <a href=\"https://www.upwork.com/\" target=\"_blank\" rel=\"noreferrer noopener\">UpWork</a>. Les clients publient une offre de mission et si la mission vous intÃ©resse vous pouvez postuler.</p><p>Une fois que vous avez pris contact avec un client potentiel vous devez le convaincre de vous choisir vous et pas quelquâ€™un dâ€™autre. Cette Ã©tape est un peu plus compliquÃ©e, soyez convaincants ! Si Ã§a vous intÃ©resse je peux vous fournir des exemples de propositions commerciales qui mâ€™ont aidÃ©es Ã  convaincre (<a href=\"https://www.linkedin.com/in/ilyes-talbi-ba2451135/\" target=\"_blank\" rel=\"noreferrer noopener\">contactez-moi</a>).</p><h2 class=\"wp-block-heading\" id=\"3-conseils-pour-reussir\">3 conseils pour rÃ©ussir</h2><p>Je suis freelance seulement depuis lâ€™Ã©tÃ© dernier mais jâ€™ai dÃ©jÃ  quelques conseils Ã  vous donner pour bien dÃ©marrer.</p><h3 class=\"wp-block-heading\" id=\"n-ayez-pas-peur-de-rater-une-mission\">Nâ€™ayez pas peur de rater une mission</h3><p>Parmi les craintes que jâ€™avais quand je me suis lancÃ©, il y avait la peur de rater une mission. Câ€™est le cas pour nâ€™importe quel freelance Ã  ses dÃ©buts et cette crainte est encore plus grande lorsque vous Ãªtes Ã©tudiant.</p><p>Cette crainte est naturelle mais elle ne doit pas vous bloquer. Le risque de rater une mission est rÃ©el mais si Ã§a arrive on doit Ãªtre en mesure de trouver une solution avec le client (jâ€™espÃ¨re quand mÃªme que Ã§a ne mâ€™arrivera pas ni Ã  vous ğŸ™‚ ; on nâ€™est pas obligÃ© dâ€™Ã©chouer pour apprendre mais au pire dites vous que lâ€™Ã©chec permet dâ€™apprendre).</p><h3 class=\"wp-block-heading\" id=\"ne-bradez-pas-vos-tarifs-sous-pretexte-que-vous-etes-etudiants\">Ne bradez pas vos tarifs sous prÃ©texte que vous Ãªtes Ã©tudiants</h3><p>Pour trouver des missions vous devez Ãªtre surs de vous. Le prix est un gage de qualitÃ© et dâ€™assurance pour le client. Paradoxalement, un prix trop faible risque de le faire fuir. Et mÃªme si vous Ãªtes Ã©tudiants vous prÃ©voyez de rendre un travail de qualitÃ© et mÃ©ritez dâ€™Ãªtre payÃ© au bon prix.</p><h3 class=\"wp-block-heading\" id=\"soyez-organises\">Soyez organisÃ©s</h3><p>En tant que freelance et Ã©tudiant vous devez conjuguer votre vie professionnelle et votre vie dâ€™Ã©tudiant. Il est important dâ€™Ãªtre organisÃ© pour ne pas compromettre vos Ã©tudes.</p><p>Pour mâ€™organiser au mieux jâ€™ai gardÃ© une checklist Ã  jour de ce que jâ€™avais Ã  faire, Ã§a permet de ne pas perdre le fil et se retrouvÃ© dÃ©bordÃ©. Pour Ã§a jâ€™utilise <a href=\"https://www.notion.so/\" target=\"_blank\" rel=\"noreferrer noopener\">Notion</a>, un outil formidable pour sâ€™organiser.</p><p>Jâ€™ai aussi synchronisÃ© mon emploi du temps des cours avec mon Google agenda, pour avoir tout ce que jâ€™avais Ã  faire au mÃªme endroit et ne pas me tromper au moment de proposer un crÃ©neau Ã  un client.</p><p>En dehors de lâ€™organisation de son temps, il faut gÃ©rer lâ€™aspect Ã©motionnel. Lorsque jâ€™ai commencÃ© les missions freelance, jâ€™avais de moins en moins de motivation pour travailler sur les projets de ma fac. Gardez en tÃªte que vos Ã©tudes doivent rester votre preoccupation centrale.</p><p></p><p>VoilÃ  pour ma petite expÃ©rience personnelle. Je ne garantis pas que ce soit la fÃªte pour vous aussi, mais je suis sÃ»r que la vie de freelance data scientist et Ã©tudiant pourra vous bÃ©nÃ©ficier Ã  vous aussi !</p></div>"},
{"url": "https://larevueia.fr/comment-lia-de-tiktok-a-embrase-la-france/", "title": "Comment lâ€™IA de Tiktok a embrasÃ© la France", "author": "Ilyes Talbi", "date": "\n2 juillet 2023\n", "content": "<div class=\"entry-content\"><p><em>Avant de commencer ce post, jâ€™aimerais dire que, mÃªme sâ€™il parle des Ã©meutes, il nâ€™a rien de politique. Je ne donnerais pas mon avis sur la question, je propose simplement un dÃ©cryptage <strong>algorithmique</strong> de la situation.</em></p><p>Depuis 2019 avec La revue IA, jâ€™explique la mÃªme chose : le premier danger des IA Ã§a nâ€™est pas Terminator et les robots tueurs qui vont prendre le contrÃ´le de lâ€™humanitÃ©. Le premier danger des IA câ€™est leurs utilisations dans les rÃ©seaux sociaux.</p><h2 class=\"wp-block-heading\">Les dangers des IA des rÃ©seaux sociaux</h2><p>Les algorithmes des gros rÃ©seaux sociaux comme Facebook, Tiktok ou Instagram, sont conÃ§us de la mÃªme maniÃ¨re Ã  lâ€™origine.</p><p>Ils ont un seul objectif, une seule mÃ©trique Ã  optimiser, câ€™est le temps que vous passez sur la plateforme. Ils doivent donc trouver le type de contenus qui vous plait et vous proposer des choses similaires.</p><p>Pour lâ€™instant je ne vous apprend rien.</p><p>Pour trouver le bon contenu pour vous, plusieurs stratÃ©gies sont utilisÃ©es :</p><p>Lâ€™algo de Tiktok va regarder le temps que vous passez sur chaque vidÃ©o, et grÃ¢ce Ã  Ã§a il va determiner si ces contenus vous plaisent ou non.</p><p>Lâ€™algo dâ€™Instagram est trÃ¨s sensible aux nombres de fois que le bouton Â«Â Copier le lienÂ Â» est utilisÃ©. Car si une vidÃ©o permet de ramener des gens sur la plateforme elle dessert bien lâ€™objectif attendu.</p><p>Lâ€™algo de Facebook est encore un peu plus vicieux. Il va dans le dÃ©tail de vos Ã©motions. En fonction des emojis de rÃ©actions que vous utilisez, il va savoir quel contenu vous rend heureux, quel contenu vous rend triste, quel contenu vous met en colÃ¨re, etc.</p><p>En plus de poser des questions sur la privacy des donnÃ©es (qui nâ€™existe plus dâ€™ailleurs mais câ€™est un autre sujet), on peut sâ€™inquiÃ©ter des addictions que ces algos peuvent causer.</p><p>Mais le problÃ¨me dont je veux parler est pire encore !</p><p>Les utilisateurs de chaque plateforme sont regroupÃ©s sous forme de <a href=\"https://larevueia.fr/clustering-les-3-methodes-a-connaitre/\">clusters</a> qui ont les mÃªmes prÃ©fÃ©rences sur des sujets diffÃ©rents (on peut Ãªtre dans le mÃªme cluster sur le foot mais sur des clusters diffÃ©rents en politique).</p><p>Et plus un cluster aime un type de contenu, plus ce contenu va lui Ãªtre proposÃ©, ce qui engendre la polarisation de chacun des clusters :</p><ul class=\"wp-block-list\"><li>les gens qui aiment Messi vont lâ€™aimer encore plus et encore plus detester Ronaldo, et inversement</li><li>les personnes de gauche vont devenir de plus en plus extrÃªmes, et pareil pour la droite</li><li>etc.</li></ul><p>Ce problÃ¨me est appelÃ©, dans le domaine des probabilitÃ©s, Â«Â la fixationÂ Â». Pour illustrer Ã§a jâ€™aime bien prendre lâ€™exemple suivant :</p><p>Imaginez une urne, qui contient 10 boules rouges et 10 boules bleues.</p><p>Vous tirez une boule au hasard :</p><p>ğŸ”µ Si elle est bleue vous remettez la boule et en ajoutez 2 bleues dans lâ€™urne<br>ğŸ”´ Si elle est rouge vous faites pareil mais en ajoutant des boules rouges cette fois</p><p>Si vous faites lâ€™expÃ©rience un nombre suffisamment grand de fois, il nâ€™y a quâ€™une seule issue possible : la probabilitÃ© de choisir une des 2 couleurs va tendre vers 1.</p><p>Si maintenant :</p><ul class=\"wp-block-list\"><li>lâ€™urne est votre feed YouTube</li><li>les boules bleues des vidÃ©os de droite</li><li>les boules rouges des vidÃ©os de gauche</li></ul><p>Au bout de quelques heures passÃ©es sur la plateforme, les vidÃ©os proposÃ©es seront largement polarisÃ©es.</p><p>Ce qui se traduira par des comportements toujours plus extrÃ©mistes et <a href=\"https://www.youtube.com/watch?v=utWMGi8HTjY\">polarisÃ©s</a>.</p><h2 class=\"wp-block-heading\">Quel est le lien entre lâ€™IA de Tiktok et les Ã©meutes ?</h2><p>En terme de polarisation, lâ€™IA de Tiktok est pire que celle de YouTube, et un feed Tiktok peut vous donner beaucoup dâ€™informations sur les centres dâ€™intÃ©rÃªts dâ€™une personne.</p><p>Les Â«Â Ã©meutiersÂ Â», sâ€™informent et Ã©changent principalement sur Tiktok. Lâ€™IA de Tiktok en terme de polarisation est pire que celle de YouTube, et a causÃ© une compÃ©tition entre quartier.</p><p>Les Ã©meutiers cherchent Ã  savoir quel quartier est le plus Â«Â chaudÂ Â».</p><ul class=\"wp-block-list\"><li>Chaque quartier va former un cluster dâ€™utilisateurs proches. En consÃ©quence, le fil dâ€™actualitÃ© de chacun des membres de ce cluster se ressemble beaucoup</li></ul><ul class=\"wp-block-list\"><li>Donc quand une vidÃ©o faite par un membre dâ€™un cluster A apparaÃ®t dans le fil dâ€™un membre dâ€™un cluster B, il y a de forte chance que tous le cluster B ait vu la mÃªme vidÃ©o</li></ul><ul class=\"wp-block-list\"><li>La gravitÃ© des actes commis est corrÃ©lÃ©e avec le succÃ¨s dâ€™un post. Car lâ€™IA de Tiktok regarde le temps passÃ© sur un contenu et le nombre de copies du lien. Donc on a un lien mathÃ©matique entre la Â«Â popularitÃ©Â Â» dâ€™un cluster dâ€™Ã©meutiers et la gravitÃ© de leurs actions</li></ul><p>Comme la plupart sont uniquement sur Tiktok, il ne voit pas ce qui se passe dans les autres clusters, ils sont dans un sous groupe fermÃ© de Tiktok et lâ€™algorithme ne leur montrera pas les vidÃ©os dâ€™appels, celles faites par les politiciens ou quoi que ce soit dâ€™autres.</p><p>Evidemment, Tiktok nâ€™est pas le seul facteur responsable de ces Ã©meutes, câ€™est simplement un catalyseur dangereux.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, il faut garder Ã  lâ€™esprit que lâ€™IA, dans son rÃ´le omniprÃ©sent sur les rÃ©seaux sociaux, peut potentiellement catalyser et amplifier les divisions dans la sociÃ©tÃ©.</p><p>Les algorithmes des rÃ©seaux sociaux, conÃ§us pour maximiser lâ€™engagement, peuvent mener Ã  une polarisation extrÃªme et Ã  des comportements radicaux.</p><p>Lâ€™IA de TikTok est particuliÃ¨rement dangereuse, dâ€™ailleurs lâ€™utilisation de Tiktok est limitÃ©e Ã  45 minutes pour les jeunes chinois de moins de 18 ans et le contenu est plus Ã©ducatif. A mÃ©diter pour nos politiciensâ€¦</p></div>"},
{"url": "https://larevueia.fr/mes-lectures-de-lete/", "title": "Mes lectures de lâ€™Ã©tÃ©", "author": "Ilyes Talbi", "date": "\n14 aoÃ»t 2021\n", "content": "<div class=\"entry-content\"><p>Les Ã©ditions ENI mâ€™ont gentiment envoyÃ© 3 ouvrages pour apprendre la data science et le machine learning, je vous en parle dans cet article.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Mes lectures de l'Ã©tÃ©\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>On nâ€™a pas encore de rÃ©fÃ©rence absolue en franÃ§ais pour lâ€™apprentissage du machine learning/deep learning mais ces 3 livres sont assez intÃ©ressants et peuvent constituer dâ€™excellentes portes dâ€™entrÃ©es dans le monde de la data science.</p><h2 class=\"wp-block-heading\" id=\"data-scientist-et-langage-r\">Data scientist et langage R</h2><p>Jâ€™ai plutÃ´t pour habitude dâ€™utiliser Python pour mes projets de data science. Câ€™est le langage que je connais le mieux, on a un grand nombre de packages aussi robustes les uns que les autres et des tutoriels et des cours trÃ¨s complets et bien Ã©crits. MalgrÃ© Ã§a je reste convaincu que la connaissance du langage R doit rester une de vos prioritÃ©s.</p><p>Dâ€™abord, R est un langage conÃ§u spÃ©cialement pour les statistiques et sera donc toujours plus intÃ©ressant que nâ€™importe quelle autre langage lorsque vous devez faire des stats. Pour les mÃªmes raisons câ€™est un langage qui va vous permettre de manipuler des datasets plus facilement.</p><p>R est aussi un langage trÃ¨s demandÃ© par les recruteurs dans les grandes entreprises et bÃ©nÃ©ficie, tout comme Python, dâ€™une large communautÃ© qui oeuvre pour amÃ©liorer les outils et les packages disponibles. Dans tous les cas, apprendre R vous permettra dâ€™ajouter un outil Ã  votre boÃ®te Ã  outils.</p><p>Jâ€™espÃ¨re vous avoir convaincu dâ€™apprendre R!</p><p>Si câ€™est le cas, le livre Data Scientist et langage R, Ã©crit par Henri et Eva Laude pourrait vous Ãªtre dâ€™une grande aide. Dans ce livre les auteurs ont voulu proposer un support<meta charset=\"utf-8\">de formation complet et dÃ©taillÃ© aux data science avec le langage R. Le livre couvre Ã  la fois toutes les mÃ©thodes de bases de data science et les bases du langage R, il vous montre ensuite comment appliquer R pour exploiter ces mÃ©thodes.</p><p>Le livre est assez gros et je vous conseille donc de prendre la version numÃ©rique qui sera beaucoup plus simple Ã  consulter. Vous pouvez vous le procurer directement sur le <a href=\"https://www.editions-eni.fr/livre/data-scientist-et-langage-r-autoformation-aux-bases-de-l-intelligence-artificielle-dans-l-univers-de-la-data-3e-edition-9782409030994\" target=\"_blank\" rel=\"noreferrer noopener\">site de lâ€™Ã©diteur</a>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><a href=\"https://www.editions-eni.fr/livre/data-scientist-et-langage-r-autoformation-aux-bases-de-l-intelligence-artificielle-dans-l-univers-de-la-data-3e-edition-9782409030994\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-842x1024.jpeg\" alt=\"Mes lectures de l'Ã©tÃ©\" class=\"wp-image-4036\" width=\"318\" height=\"386\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-842x1024.jpeg 842w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-247x300.jpeg 247w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-768x934.jpeg 768w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL-1263x1536.jpeg 1263w, https://larevueia.fr/wp-content/uploads/2021/08/81KMTlyCCUL.jpeg 1315w\" sizes=\"auto, (max-width: 318px) 100vw, 318px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"intelligence-artificielle-vulgarisee\">Intelligence artificielle vulgarisÃ©e</h2><p>Le <a href=\"https://www.editions-eni.fr/livre/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735?gclid=CjwKCAjw092IBhAwEiwAxR1lRiw1AdUlLhRrOM9uKsdBdjLBX4biKvdzed5ItrKxadAG6jMLZtbB1RoCDNwQAvD_BwE\" target=\"_blank\" rel=\"noreferrer noopener\">second livre</a>, Ã©crit par AurÃ©lien Vannieuwenhuyze, vous aidera Ã  comprendre les concepts fondamentaux en machine learning et deep learning de faÃ§on plus pratique et en sâ€™attardant un peu moins sur la thÃ©orie et les concepts mathÃ©matiques sous-jacents. Ce livre peut Ãªtre un excellent moyen de se plonger au coeur du monde de la data science.</p><p>Ce livre convient trÃ¨s bien aux dÃ©butants ou Ã  ceux qui veulent revoir leurs classiques.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://www.editions-eni.fr/livre/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735?gclid=CjwKCAjw092IBhAwEiwAxR1lRiw1AdUlLhRrOM9uKsdBdjLBX4biKvdzed5ItrKxadAG6jMLZtbB1RoCDNwQAvD_BwE\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/08/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735_XL.jpeg\" alt=\"Mes lectures de l'Ã©tÃ©\" class=\"wp-image-4039\" width=\"298\" height=\"353\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/08/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735_XL.jpeg 518w, https://larevueia.fr/wp-content/uploads/2021/08/intelligence-artificielle-vulgarisee-le-machine-learning-et-le-deep-learning-par-la-pratique-9782409020735_XL-253x300.jpeg 253w\" sizes=\"auto, (max-width: 298px) 100vw, 298px\"></a></figure></div><h2 class=\"wp-block-heading\" id=\"python-pour-la-data-science\">Python pour la data science</h2><p>Le dernier livre, Ã©crit par Amandine Velt, va vous permettre de progresser en data science avec Python, Ã  travers des quiz, des exemples de projets concrets et en jouant avec des datasets variÃ©s.</p><p>Il ne sera pas question de machine learning ou dâ€™entraÃ®nements de modÃ¨les dans cet ouvrage, par contre vous pourrez parcourir toutes les compÃ©tences nÃ©cessaires pour faire du preprocessing de data : slicing de matrices avec NumPy, manipulation de tableaux de donnÃ©es avec Pandas et visualisation avec Matplotlib et Seaborn.</p><p>On a souvent tendance Ã  croire que le machine learning se limite Ã  lâ€™entraÃ®nement de modÃ¨les, sauf que ce travail ne reprÃ©sente quâ€™environ 10% du travail dâ€™un data scientist. Une grande partie du travail repose sur du nettoyage de donnÃ©es, un peu de statistiques et de la visualisation. <a href=\"https://www.editions-eni.fr/livre/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263\" target=\"_blank\" rel=\"noreferrer noopener\">Ce livre</a> vous aidera Ã  developper les techniques essentielles de manipulation de datasets.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://www.editions-eni.fr/livre/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2021/08/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263_XL.jpeg\" alt=\"Mes lectures de l'Ã©tÃ©\" class=\"wp-image-4038\" width=\"307\" height=\"371\" srcset=\"https://larevueia.fr/wp-content/uploads/2021/08/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263_XL.jpeg 506w, https://larevueia.fr/wp-content/uploads/2021/08/python-pour-la-data-science-analysez-vos-donnees-par-la-pratique-avec-numpy-pandas-matplotlib-et-seaborn-9782409026263_XL-248x300.jpeg 248w\" sizes=\"auto, (max-width: 307px) 100vw, 307px\"></a></figure></div></div>"},
{"url": "https://larevueia.fr/vivatech-2022-france-is-un-peu-ai/", "title": "Vivatech 2022 : France is (un peu) AI", "author": "Ilyes Talbi", "date": "\n25 juin 2022\n", "content": "<div class=\"entry-content\"><p>La semaine derniÃ¨re, jâ€™Ã©tais au salon Viva technologie Ã  Paris. Le plus grand Ã©vÃ¨nement de la tech en France.</p><p>Beaucoup dâ€™innovations ont Ã©tÃ© prÃ©sentÃ©es, plusieurs pays Ã©taient reprÃ©sentÃ©s, et jâ€™ai rencontrÃ© pas mal de start-up prometteuses.</p><p>Le salon Ã©tait plutÃ´t bien organisÃ© et il y avait quelques confÃ©rences intÃ©ressantes, notamment celle de Yann LeCun sur le futur de lâ€™intelligence artificielle (par contre lâ€™appli du salon fonctionnait moyennement).</p><p>MÃªme si jâ€™ai toujours un peu de mal avec les Ã©vÃ¨nements trop gÃ©nÃ©ralistes, car <em>qui trop embrasse, mal Ã©treint</em>, lâ€™Ã©vÃ¨nement mâ€™a globalement bien plu.</p><p>Jâ€™ai sÃ©lectionnÃ© 5 start-ups parmi toutes celles que jâ€™ai vu, je vous en parle dans cet article.</p><h2 class=\"wp-block-heading\">Iâ€™m beside you : comment assurer la santÃ© mentale des employÃ©es, mÃªme Ã  distance ?</h2><p>Bon câ€™est innovant mais Ã§a fait un peu peur ğŸ˜…</p><p>La startup Japonaise Iâ€™m beside you a dÃ©veloppÃ© des modÃ¨les de vision par ordinateur et de traitements du langage, capables de dÃ©crire avec prÃ©cision lâ€™Ã©tat Ã©motionnel dâ€™un employÃ©.</p><p>Les modÃ¨les sont utilisÃ©s en temps rÃ©el sur les applications de visioconfÃ©rence comme Google meet ou Teams. Et les donnÃ©es sont visibles par les managers des Ã©quipes via des tableaux de bords personnalisÃ©s.</p><p>MÃªme si Ã§a part dâ€™une bonne intention, qui est dâ€™assurer la sÃ©curitÃ© mentale des employÃ©s, lâ€™utilisation de systÃ¨me de reconnaissance faciale et le fait que les donnÃ©es soient visibles par les mangers posent problÃ¨me dâ€™un point de vue Ã©thique.</p><h2 class=\"wp-block-heading\">Digantara : le GPS indien des satellites</h2><p>Comme chaque annÃ©e, Viva tech sÃ©lectionne un pays star pour prÃ©senter ses innovations pendant le salon. Cette annÃ©e, câ€™Ã©tait lâ€™Inde qui Ã©tait Ã  lâ€™honneur. Lâ€™Ã©cosystÃ¨me startup indien est trÃ¨s dÃ©veloppÃ©, notamment dans des villes comme Bengalore.</p><p>Sur des sujets comme lâ€™intelligence artificielle, lâ€™Inde est en train de devenir une rÃ©fÃ©rence internationale.</p><p>Jâ€™ai rencontrÃ© la startup <a href=\"https://www.digantara.co.in/\" target=\"_blank\" rel=\"noreferrer noopener\">Digantra</a>. Ils conÃ§oivent un GPS pour satellites qui repose sur lâ€™intelligence artificielle. Leurs modÃ¨les permettent de prÃ©dire Ã  chaque instant, la position de tous les satellites. Il est utilisÃ© par de nombreux clients comme des agences de tÃ©lÃ©communication ou des chaÃ®nes de tÃ©lÃ©vision.</p><h2 class=\"wp-block-heading\">3DFascination : le scanner 3D Ã  taille humaine</h2><p>Dans mon article sur lâ€™<a href=\"https://larevueia.fr/quels-liens-entre-blockchain-et-intelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">Intelligence artificielle au service de la blockchain</a>, jâ€™ai parlÃ© de comment la reconstruction 3D en vision par ordinateur pourrait Ãªtre utilisÃ©e pour construire le metaverse.</p><p>Pendant le salon jâ€™ai rencontrÃ© la startup <a href=\"https://3dfascination.com/\" target=\"_blank\" rel=\"noreferrer noopener\">3DFascination</a>, qui produit un scanner Ã  taille humaine. Je me suis mÃªme fait scanner ğŸ™‚</p><figure class=\"wp-block-video\"><video controls src=\"https://larevueia.fr/wp-content/uploads/2022/06/WhatsApp-Video-2022-06-18-at-14.50.52.mp4\"></video></figure><h2 class=\"wp-block-heading\">MyDataModels rend les IA moins gourmandes en donnÃ©es</h2><p>Une des grosses limitations de lâ€™Intelligence artificielle dâ€™aujourdâ€™hui, est la quantitÃ© de donnÃ©es requise pour lâ€™entraÃ®nement de modÃ¨les. En plus dâ€™Ãªtre un dÃ©sastre pour lâ€™environnement, la course aux modÃ¨les gourmands en donnÃ©es, a crÃ©Ã©e un club trÃ¨s fermÃ© de grandes entreprises. Ces entreprises monopolisent la data, et ont les meilleurs rÃ©sultats.</p><p>Jâ€™ai dÃ©jÃ  abordÃ© le problÃ¨me dans de prÃ©cÃ©dents articles. Jâ€™ai dit que de nouvelles approches comme lâ€™IA dÃ©centralisÃ©e pouvaient Ãªtre pertinentes.</p><p>Mais la solution ultime, serait de pouvoir entraÃ®ner des modÃ¨les fiables avec trÃ¨s peu de donnÃ©es. Câ€™est ce que la startup franÃ§aise MyDataModels fait. Ils travaillent sur de nombreux domaines et ont dÃ©veloppÃ©s une plateforme SaaS pour faciliter le preprocessing des donnÃ©es, lâ€™entraÃ®nement des modÃ¨les et le dÃ©ploiement. <a href=\"https://www.mydatamodels.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Je vous laisse regarder Ã§a</a>.</p><h2 class=\"wp-block-heading\">High wind : amÃ©liorer les systÃ¨mes dâ€™appels dâ€™urgences grÃ¢ce Ã  lâ€™intelligence artificielle</h2><p><a href=\"https://www.highwind-ems.com/fr/a-propos/\" target=\"_blank\" rel=\"noreferrer noopener\">High wind</a> est une autre startup franÃ§aise dans lâ€™intelligence artificielle. Ils conÃ§oivent une plateforme intelligente pour le traitement des appels dâ€™urgences.</p><p>Plusieurs modÃ¨les de <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a> sont utilisÃ©s. Ils vont, par exemple, permettre dâ€™analyser automatiquement le ton de la voix de la personne, lâ€™Ã©motion sur le visage ou encore des photos de la scÃ¨ne, pour essayer de dÃ©terminer la criticitÃ© de lâ€™urgence.</p><p>Un des modÃ¨les permet de dÃ©terminer la gravitÃ© dâ€™une plaie Ã  partir dâ€™une photo. Lâ€™idÃ©e est de pouvoir prioriser de faÃ§on plus robuste les interventions en fonction de la gravitÃ©.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En bref, le salon regroupait pas mal dâ€™acteurs de diffÃ©rents horizons, pour le networking câ€™est parfait.</p><p>Il est tout de mÃªme triste de voir que des sujets importants, comme la question de la souverainetÃ© des grandes entreprises franÃ§aises, ont Ã©tÃ© ignorÃ©s. Pour faire court : tout le monde sâ€™en moque.</p><p>Enfin, on voit dans les derniers salons gÃ©nÃ©ralistes que lâ€™intelligence artificielle prend moins de place, au profit de technologie comme la blockchain. La table ronde avec Vitalik et CZ a Ã©tÃ© lâ€™intervention phare de lâ€™Ã©vÃ¨nement, tandis que sur lâ€™intelligence artificielle jâ€™ai trouvÃ© que les confÃ©rences Ã©taient moins pertinentes que dâ€™habitude.</p></div>"},
{"url": "https://larevueia.fr/annoter-et-labelliser-des-series-temporelles/", "title": "Annoter et labelliser des sÃ©ries temporelles", "author": "Ilyes Talbi", "date": "\n24 novembre 2022\n", "content": "<div class=\"entry-content\"><p><em>Cet article a Ã©tÃ© rÃ©digÃ© par <strong>Julien Muller</strong>, CTO de <a href=\"https://ezako.com/fr/\" target=\"_blank\" rel=\"noreferrer noopener\">Ezako</a>.</em></p><p>Chez Ezako nous sommes des experts des donnÃ©es de type sÃ©ries temporelles. Les sÃ©ries temporelles sont des donnÃ©es de type spÃ©cifiques qui se diffÃ©rencient largement dâ€™autres types de donnÃ©es de par leur production, leur usage et leurs propriÃ©tÃ©s.</p><p>Ces donnÃ©es font partie de notre quotidien. On peut par exemple penser au suivi dâ€™une tempÃ©rature, Ã  un ECG ou au courant dâ€™un composant Ã©lectronique.</p><p>Les donnÃ©es peuvent Ãªtre suivies Ã  des fins de monitoring (pour des serveurs), de prÃ©diction (dans la finance) ou de maintenance prÃ©dictive (dans lâ€™industrie).</p><p>Les cas dâ€™applications sont extrÃªmement ouverts, et les nouveaux cas dâ€™usages apparaissent constamment avec lâ€™invention de nouveaux objets, tels que les IOT et la digitalisation des chaÃ®nes de production.</p><p>Les sÃ©ries temporelles ont des spÃ©cificitÃ©s techniques, qui les diffÃ©rencient des autres types de donnÃ©es, on peut constater notamment :</p><ul class=\"wp-block-list\"><li>Suite de valeurs qui Ã©voluent au cours du temps</li><li>Souvent un grand nombre de points (gÃ©nÃ©rÃ© par des machines), tant en frÃ©quence quâ€™en nombre de sÃ©riesÂ </li><li>Souvent un grand dÃ©sÃ©quilibre de labels et/ou de classes. Par exemple, le nombre de point en anomalie est trÃ¨s faible par rapport aux donnÃ©es normales</li></ul><h2 class=\"wp-block-heading\"><strong>La labellisation ou lâ€™annotation pour les sÃ©ries temporelles</strong></h2><p>Câ€™est lâ€™action dâ€™enrichir une ou plusieurs sÃ©ries temporelles ou dâ€™ajouter des mÃ©tadonnÃ©es sur des sÃ©ries. Elle sâ€™effectue point par point, pour une pÃ©riode, ou pour une sÃ©rie entiÃ¨re.</p><p>Le type de label et les techniques utilisÃ©es vont dÃ©pendre directement de lâ€™objectif recherchÃ©. En effet, on labellise dans un but spÃ©cifique et prÃ©cis. Une labellisation pour maintenance prÃ©dictive nâ€™est pas la mÃªme que pour classifier diffÃ©rents Ã©tats dâ€™un systÃ¨me. Dans le premier cas, le label sera peut-Ãªtre une durÃ©e de vie restante point par point, et dans le second, une simple classe comme â€œONâ€, â€œOFFâ€, â€œSWITCHINGâ€ â€¦</p><h3 class=\"wp-block-heading\"><strong>Pourquoi labeliser ?</strong></h3><p>Pour apporter plus dâ€™informations sur les sÃ©ries temporelles qui sont Ã  notre disposition. Lâ€™objectif peut Ãªtre la classification, formaliser la comprÃ©hension dâ€™un comportement, apprendre des anomalies pour les dÃ©tecter ou les expliquer.</p><p>En Machine Learning, lâ€™intÃ©rÃªt est presque Ã©vident. En effet, pour le data scientist, adresser une problÃ©matique supervisÃ©e est bien plus facile quâ€™une non supervisÃ©e. A jeu de donnÃ©es Ã©quivalent, les rÃ©sultats des approches supervisÃ©es sont incroyablement meilleurs que non supervisÃ©es.</p><p><strong>Pourquoi?Â </strong></p><p>Dâ€™abord parce que les 2 approches ne sont pas Ã  armes Ã©gales. Les approches supervisÃ©es disposent de beaucoup plus dâ€™informations que celles non supervisÃ©es.</p><p>Ensuite, les approches non supervisÃ©es proposent des qualitÃ©s qui sont censÃ©es dÃ©passer les approches supervisÃ©es. Par exemple, un algorithme de dÃ©tection dâ€™anomalies non supervisÃ© devrait Ãªtre Ã  mÃªme de dÃ©tecter des anomalies inconnues. Mais des approches hybrides peuvent Ã©galement atteindre cet objectif.</p><p>On peut considÃ©rer diffÃ©rents types dâ€™approches hybrides entre le non supervisÃ© et le supervisÃ©:</p><ul class=\"wp-block-list\"><li>ModÃ¨le non-supervisÃ©</li><li>Apprentissage non supervisÃ©, et Ã©valuation de la qualitÃ© de dÃ©tection sur la base des donnÃ©es labellisÃ©es (Ã©valuation supervisÃ©e)â€¦ autres actions supervisÃ©es</li><li>Semi-supervisÃ©: Approches telles que les algorithmes non supervisÃ©s qui font des hypothÃ¨ses sur les donnÃ©es : par exemple un auto encodeur qui considÃ¨re que tout un jeu dâ€™apprentissage est normal. Ou plus gÃ©nÃ©ralement, des algorithmes qui utilisent un ensemble restreint dâ€™annotations.Â Â Â </li><li>Self-supervised, ou le modÃ¨le effectue un apprentissage en 2 Ã©tapes, il constitue ses propres pseudo labels et apprend sur ses propres labels. Un exemple simple est lâ€™IA qui joue aux Ã©checs contre elle-mÃªme.</li><li>approche totalement supervisÃ©e</li></ul><p>En pratique en Machine learning, avoir un jeu de donnÃ©es labÃ©llisÃ© est avantageux parce que cela permet dâ€™Ã©valuer plusieurs approches supervisÃ©es clairement avec des mÃ©triques telles que la prÃ©cision, le rappel, le f-score, etc.</p><p>Toutefois, un Ã©cueil commun Ã  ces derniÃ¨res doit Ãªtre adressÃ©: le risque de sur-apprentissage ou <a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">overfitting</a>. Ce risque est dâ€™autant plus prÃ©sent lorsque lâ€™on a peu de labels, mais en Ãªtre conscient permet de mettre en place des mÃ©canismes qui le mitigent, telle que la validation croisÃ©e â€œk-fold cross validationâ€.</p><p>Si malgrÃ© celaÂ  on est confrontÃ© Ã  une situation de sur-apprentissage, on pourra changer dâ€™approche et passer par exemple de modÃ¨les supervisÃ©s Ã  des modÃ¨les Ã  apprentissage non supervisÃ© et une optimisation des hyper paramÃ¨tres. Mais lâ€™approfondissement de ce point mÃ©rite un article en soi!</p><h2 class=\"wp-block-heading\"><strong>Comment labelliser?</strong></h2><p>On peut penser Ã  diffÃ©rentes approches pour annoter son jeu de donnÃ©es. Entre autre:</p><ul class=\"wp-block-list\"><li>Approche manuelle</li><li>Lâ€™expertise mÃ©tier</li><li>Un peu de code (python)</li><li>Avec un outil de labellisation comme Upalgo Labeling</li></ul><p>Nous pouvons faire un petit cas pratique avec un fichier csv de timeseries de 50 000 lignes. Ce fichier comporte une colonne de timestamp et 4 capteurs. Les capteurs de vibration prÃ©sentent des pics importants que nous souhaitons annoter pour crÃ©er un modÃ¨le de classification. Lâ€™objectif est de crÃ©er une nouvelle colonne contenant un texte de classe â€œpic hautâ€, â€œpic basâ€ ou â€œnormalâ€.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"327\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.11.22-1024x327.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6850\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.11.22-1024x327.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.11.22-300x96.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.11.22-768x245.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.11.22-1536x490.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.11.22.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><h3 class=\"wp-block-heading\">Lâ€™approche manuelle</h3><p>Pour lâ€™approche manuelle, nous allons utiliser excel. AprÃ¨s avoir importÃ© le fichier CSV, excel propose une fonctionnalitÃ© de graphique, bien pratique pour faciliter le travail. NÃ©anmoins, elle se rÃ©vÃ¨le peu utilisable. Sur lesÂ  50 000 points, nous nâ€™avons pu afficher que 5 000 points simultanÃ©ment.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.12.46-1024x672.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6851\" width=\"693\" height=\"455\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.12.46-1024x672.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.12.46-300x197.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.12.46-768x504.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.12.46-1536x1008.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.12.46.png 1600w\" sizes=\"auto, (max-width: 693px) 100vw, 693px\"></figure></div><p>CrÃ©er une colonne â€œlabelâ€ est trÃ¨s simple, mais la tÃ¢che sâ€™avÃ¨re difficile. Il faut repÃ©rer sur le graphique le timestamp des pics pour les chercher ensuite dans le tableau et annoter la colonne. Puis passer aux 5 000 points suivants. Une fois cette tÃ¢che effectuÃ©e, le tableau est exportable au format CSV.</p><h3 class=\"wp-block-heading\">Lâ€™expertise mÃ©tier</h3><p>Pour cet exemple simpliste, on peut imaginer que lâ€™expert mÃ©tier nous a indiquÃ© que les pics sont souvent grands, donc on va poser une limite et lâ€™automatiser. Le langage dâ€™implÃ©mentation a peu dâ€™importance, python ou autre, pour des raisons graphiques, nous avons utilisÃ© une formule excel :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.13.49-1024x99.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6852\" width=\"691\" height=\"67\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.13.49-1024x99.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.13.49-300x29.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.13.49-768x75.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.13.49-1536x149.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.13.49.png 1600w\" sizes=\"auto, (max-width: 691px) 100vw, 691px\"></figure></div><p>Si cette solution a lâ€™avantage dâ€™Ãªtre trÃ¨s compacte et rapide Ã  mettre en Å“uvre, elle montre rapidement ses limites. En effet, les pics nâ€™Ã©tant pas constituÃ©s dâ€™une seule valeur, on a une labellisation de faible qualitÃ©. Pour le pattern suivant, on sâ€™attend Ã  avoir une 15aine de points en â€œpic basâ€, mais le rÃ©sultat est assez erratique.</p><p>De plus, cette rÃ¨gle nâ€™est applicable quâ€™Ã  ce jeux de donnÃ©e prÃ©cis, et doit Ãªtre redÃ©finie pour un nouveau jeu de donnÃ©e mÃªme si il sâ€™agit aussi de retrouver des pics dans la donnÃ©e :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.14.48-1024x690.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6853\" width=\"589\" height=\"397\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.14.48-1024x690.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.14.48-300x202.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.14.48-768x517.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.14.48-1536x1035.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.14.48.png 1588w\" sizes=\"auto, (max-width: 589px) 100vw, 589px\"></figure></div><p>Bien sÃ»r, on peut repasser sur chaque Ã©vÃ©nement et valider les donnÃ©es, mais cela sera long. De plus, on fait une hypothÃ¨se mÃ©tier forte en positionnant une limitÃ© Ã  2, ce qui amÃ¨nera probablement Ã  ignorer les Ã©vÃ©nements de petite taille.</p><h3 class=\"wp-block-heading\">La labellisation de sÃ©ries temporelles avec Python</h3><p>On va ici essayer dâ€™exploiter les capacitÃ©s de pandas pour faire une labellisation rapide de meilleure qualitÃ©. Cela adressera une partie des limites de lâ€™approche prÃ©cÃ©dente, en particulier la prÃ©dÃ©finition dâ€™un seuil dâ€™anomalie.</p><p>On identifie que les pics sont des valeurs aberrantes localement, câ€™est Ã  dire que tous les pics nâ€™ont pas la mÃªme amplitude, nous dÃ©finissons donc un algorithme qui cherche Ã  isoler les pics en dÃ©terminant la moyenne ainsi que lâ€™Ã©cart type normal sur des fenÃªtres glissantes pour ensuite dÃ©terminer un seuil variable en fonction de ces paramÃ¨tres :</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"257\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.16.19-1024x257.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6854\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.19-1024x257.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.19-300x75.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.19-768x193.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.19-1536x386.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.19.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure><p>Le choix de la taille de la fenÃªtre et du nombre de dÃ©viation Ã  la moyenne qui dÃ©clenche la sÃ©paration reste Ã  paramÃ©trer lors de lâ€™exÃ©cution de lâ€™algorithme de la â€œrolling_stdâ€, ici le couple (100,5) nâ€™est pas lâ€™unique bon paramÃ©trage, mais un parmi dâ€™autres. Lâ€™Ã©tape qui suit consiste Ã  crÃ©er la colonne â€˜classâ€™ et lui attribuer les annotations calculÃ©es.</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"245\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.16.31-1024x245.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6855\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.31-1024x245.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.31-300x72.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.31-768x183.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.31-1536x367.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.16.31.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure><p>Puis on plot le rÃ©sultat :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.17.51-1024x741.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6856\" width=\"678\" height=\"490\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.17.51-1024x741.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.17.51-300x217.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.17.51-768x556.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.17.51-1536x1111.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.17.51.png 1600w\" sizes=\"auto, (max-width: 678px) 100vw, 678px\"></figure></div><p>On procÃ©dera par la suite Ã  la transformation des annotations numÃ©riques qui sÃ©paraient nos donnÃ©es en deux classes (0,10) Ã©quivalentes Ã  (normal, pic) en triplet (normal, pic_haut, pic_bas).</p><p>Lâ€™ensemble de ce code est dans un notebook en annexe.</p><p>On constate une labellisation de plutÃ´t bonne qualitÃ© et plus gÃ©nÃ©ralisable que la rÃ¨gle mÃ©tier fixe pour la dÃ©tection de pics dans les donnÃ©es, si on fait confiance Ã  lâ€™algorithme utilisÃ©, on reporte donc la responsabilitÃ© sur le dÃ©veloppeur et la martingale quâ€™il a identifiÃ©.</p><h3 class=\"wp-block-heading\">Utilisation de lâ€™outil de labellisation Upalgo Labeling</h3><p>Upalgo Labeling est un outil avec une interface graphique permettant de visualiser les sÃ©ries temporelles et de labelliser rapidement les sÃ©ries avec une validation humaine. Cela permet dâ€™avoir plus de finesse dans lâ€™annotation tout en garantissant un travail plus rapide.</p><p>Voici les Ã©tapes dâ€™une bonne annotation avec lâ€™outil :</p><p><strong><em>Etape 1 :</em></strong> Dans lâ€™outil Upalgo Labeling il est possible de visualiser et de labelliser manuellement un Ã©vÃ©nement:</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.18.55-1024x692.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6857\" width=\"636\" height=\"429\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.18.55-1024x692.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.18.55-300x203.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.18.55-768x519.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.18.55.png 1222w\" sizes=\"auto, (max-width: 636px) 100vw, 636px\"></figure></div><p>Il est aussi possible dâ€™utiliser la fonctionnalitÃ© automatique de proposition de zones Ã  annoter, elle permettra de fournir rapidement plusieurs labels de qualitÃ© :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.20.24-1024x635.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6858\" width=\"641\" height=\"396\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.20.24-1024x635.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.20.24-300x186.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.20.24-768x476.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.20.24-404x250.png 404w\" sizes=\"auto, (max-width: 641px) 100vw, 641px\"></figure></div><p><strong><em>Etape 2 :</em> </strong>Puis on demande Ã  Upalgo Labeling de propager les classes â€œpic hautâ€ et â€œpic basâ€ prÃ©alablement dÃ©finis, ce qui finalise lâ€™annotation de lâ€™ensemble du fichier :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.21.45-1024x681.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6859\" width=\"676\" height=\"449\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.21.45-1024x681.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.21.45-300x200.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.21.45-768x511.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.21.45.png 1206w\" sizes=\"auto, (max-width: 676px) 100vw, 676px\"></figure></div><p><strong><em>Etape 3 :</em> </strong>On peut exporter le rÃ©sultat dans un fichier CSV contenant une nouvelle colonne â€œlabelâ€ :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-24-a%CC%80-09.22.37-1024x443.png\" alt=\"Annoter et labelliser des sÃ©ries temporelles\" class=\"wp-image-6860\" width=\"628\" height=\"271\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.22.37-1024x443.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.22.37-300x130.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.22.37-768x332.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-24-aÌ€-09.22.37.png 1198w\" sizes=\"auto, (max-width: 628px) 100vw, 628px\"></figure></div><p>Ici, on constate que lâ€™expert a un total contrÃ´le sur ce quâ€™il lâ€™annote, ce qui garantit une meilleure qualitÃ© de label.</p><h2 class=\"wp-block-heading\"><strong>Conclusion</strong></h2><p>On peut constater quâ€™avec les approches assistÃ©es dâ€™outils tels que excel, lâ€™annotation des sÃ©ries temporelles est possible, mais sera assez besogneuse.</p><p>Une approche programmatique en sâ€™appuyant sur lâ€™expertise mÃ©tier sera rapide, mais montre des lacunes assez Ã©videntes.</p><p>Lâ€™approche python est dÃ©jÃ  nettement plus intelligente mais demande un effort et des connaissances en programmation.</p><p>Lâ€™utilisation dâ€™un outil comme Upalgo Labeling est beaucoup plus efficace et facile. Cela permet une annotation automatique et rapide sans avoir Ã  coder des algorithmes dÃ©diÃ©es.</p><p>NÃ©anmoins il existe avec ces outils un risque de biais. Pour lever ce risque il est important dâ€™utiliser beaucoup de datasets, et une confirmation humaine.</p></div>"},
{"url": "https://larevueia.fr/introduction-a-limage-stitching-avec-opencv/", "title": "Introduction Ã  lâ€™image stitching avec OpenCV", "author": "Ilyes Talbi", "date": "\n16 fÃ©vrier 2023\n", "content": "<div class=\"entry-content\"><p>Lâ€™image stitching, est une technique de traitement dâ€™images qui permet de combiner plusieurs images en une seule image panoramique.</p><p>Cette technique est utilisÃ©e pour crÃ©er de grandes images Ã  partir de plusieurs images plus petites, en utilisant des modÃ¨les de features matching pour trouver les points communs entre les images et les assembler de maniÃ¨re cohÃ©rente.</p><p>Lâ€™image stitching est souvent utilisÃ©e pour crÃ©er des panoramas, mais elle peut Ã©galement Ãªtre utilisÃ©e pour combiner des images de diffÃ©rents angles de vue pour crÃ©er une image 3D ou pour crÃ©er des images de haute rÃ©solution Ã  partir de plusieurs images de basse rÃ©solution.</p><p>Cette technique est largement utilisÃ©e dans de nombreux domaines, notamment la photographie, la cartographie, la robotique et la rÃ©alitÃ© augmentÃ©e.</p><p>Dans cet article, je vous explique comment fonctionne lâ€™image stitching, je vous parle de ses applications et on verra comment faire de lâ€™image stitching avec Python et OpenCV.</p><h2 class=\"wp-block-heading\">Quelles sont les applications de lâ€™image stitching ?</h2><p>Lâ€™image stitching est largement utilisÃ© dans plusieurs applications.</p><ul class=\"wp-block-list\"><li>Image stitching et photomosaÃ¯ques : cette technique est celle qui est utilisÃ©e dans les smartphones pour crÃ©er des panoramas Ã  partir de plusieurs images prises de diffÃ©rents angles.</li><li>Mapping et surveillance : elle permet la crÃ©ation de cartes et de modÃ¨les en 3D Ã  partir de photos aÃ©riennes ou satellites. Elle est trÃ¨s utiles pour les images extra large, qui ne peuvent pas Ãªtre prises en une seule fois</li><li>RÃ©alitÃ© virtuelle et augmentÃ©e : lâ€™image stitching est utilisÃ© pour la crÃ©ation de mondes virtuels en combinant des images pour crÃ©er des scÃ¨nes immersives plus rapidement</li><li>Inspection industrielle : elle permet lâ€™Ã©valuation de la qualitÃ© et de lâ€™Ã©tat des Ã©quipements industriels en combinant des images prises de diffÃ©rents angles</li><li>Imagerie mÃ©dicale : pour la reconstruction de modÃ¨les en 3D et la visualisation de donnÃ©es mÃ©dicales telles que des scanners ou des IRM</li><li>Analyse de la biologie cellulaire : pour la reconstruction de modÃ¨les en 3D des structures cellulaires Ã  partir de plusieurs images prises Ã  diffÃ©rents angles et profondeurs</li><li>Imagerie scientifique : lâ€™image stitching va aussi beaucoup aider pour lâ€™analyse de grandes quantitÃ©s dâ€™images pour lâ€™Ã©tude de la morphologie, de la dynamique et de la distribution des objets dans diffÃ©rents domaines scientifiques tels que lâ€™astronomie, la microscopie Ã©lectronique et la microscopie confocale</li></ul><h2 class=\"wp-block-heading\">Comment faire de lâ€™image stitching avec Python et OpenCV ?</h2><p>Dans cette section, nous allons voir ensemble comment faire de lâ€™image stitching avec Python et OpenCV.</p><p>La technique repose sur des modÃ¨les dâ€™extraction de features qui sont beaucoup utilisÃ©s en <a href=\"https://larevueia.fr/focus-sur-6-sous-domaines-de-la-computer-vision-et-leurs-applications/\" target=\"_blank\" rel=\"noreferrer noopener\">computer vision</a>, comme le modÃ¨le SIFT.</p><p>Câ€™est dâ€™ailleurs ce modÃ¨le que nous allons utiliser dans ce tutoriel.</p><h3 class=\"wp-block-heading\">Choix de lâ€™image Ã  recoller</h3><p>Pour ce tutoriel, jâ€™ai choisi de travailler avec cette image gÃ©nÃ©rÃ©es par stable diffusion :</p><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"512\" height=\"768\" src=\"https://larevueia.fr/wp-content/uploads/2023/02/paysage_image_stitching.jpeg\" alt=\"Introduction Ã  l'image stitching avec OpenCV\" class=\"wp-image-8033\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/02/paysage_image_stitching.jpeg 512w, https://larevueia.fr/wp-content/uploads/2023/02/paysage_image_stitching-200x300.jpeg 200w\" sizes=\"auto, (max-width: 512px) 100vw, 512px\"></figure><p>Jâ€™ai commencÃ© par couper lâ€™image en 2 verticalement, en laissant une petite bande commune.</p><p>Je lâ€™ai fait en utilisant ce code lÃ  sur <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noreferrer noopener\">OpenCV</a> :</p><pre class=\"wp-block-code\"><code>import cv2\n\n# import de image\nimg = cv2.imread(\"./paysage_image_stitching.jpeg\")\nheight, width = img.shape[:2]\n\n# calcul du point central de l'image\nmidpoint = int(width / 2)\n\n# division de l'image en 2 parties en gardant une bande de 60 px commune\nleft_part = img[:, :midpoint + 60]\nright_part = img[:, midpoint:]\n\n# Enregistrement des images\ncv2.imwrite(\"./left_part.jpg\", left_part)\ncv2.imwrite(\"./right_part.jpg\", right_part)</code></pre><p>AprÃ¨s lâ€™execution de ce code on obtient les 2 images suivantes :</p><figure class=\"wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-8 is-layout-flex wp-block-gallery-is-layout-flex\"><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"316\" height=\"768\" data-id=\"8034\" src=\"https://larevueia.fr/wp-content/uploads/2023/02/left_part.jpg\" alt=\"Image de gauche pour l'image stitching avec python\" class=\"wp-image-8034\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/02/left_part.jpg 316w, https://larevueia.fr/wp-content/uploads/2023/02/left_part-123x300.jpg 123w\" sizes=\"auto, (max-width: 316px) 100vw, 316px\"></figure><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"256\" height=\"768\" data-id=\"8035\" src=\"https://larevueia.fr/wp-content/uploads/2023/02/right_part.jpg\" alt=\"Image de droite pour l'image stitching avec python\" class=\"wp-image-8035\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/02/right_part.jpg 256w, https://larevueia.fr/wp-content/uploads/2023/02/right_part-100x300.jpg 100w\" sizes=\"auto, (max-width: 256px) 100vw, 256px\"></figure></figure><p>Maintenant quâ€™on a 2 images de base sur lesquelles faire lâ€™image stitching, entrons dans le vif du sujet.</p><h3 class=\"wp-block-heading\">Image stitching avec OpenCV</h3><p>On commence par importer les librairies necÃ©ssaires :</p><pre class=\"wp-block-code\"><code>import cv2\nimport numpy as np</code></pre><p>On va maintenant dÃ©finir de la fonction Â«Â FindMatchesÂ Â».</p><p>Cette fonction prend en entrÃ©e deux images et utilise la mÃ©thode SIFT (Scale-Invariant Feature Transform) pour trouver les points clÃ©s et les descripteurs dans les images.</p><p>Il utilise Ã©galement un Â«Â Brute Force MatcherÂ Â» pour trouver des correspondances entre les points clÃ©s des images. Il sâ€™agit simplement de tester toutes les paires possibles de matchs pour conserver les meilleures, en utilisant un threshold.</p><pre class=\"wp-block-code\"><code>def FindMatches(BaseImage, SecImage):\n\n    # Using SIFT to find the keypoints and decriptors in the images\n    Sift = cv2.SIFT_create()\n    BaseImage_kp, BaseImage_des = Sift.detectAndCompute(cv2.cvtColor(BaseImage, cv2.COLOR_BGR2GRAY), None)\n    SecImage_kp, SecImage_des = Sift.detectAndCompute(cv2.cvtColor(SecImage, cv2.COLOR_BGR2GRAY), None)\n\n    # Using Brute Force matcher to find matches.\n    BF_Matcher = cv2.BFMatcher()\n    InitialMatches = BF_Matcher.knnMatch(BaseImage_des, SecImage_des, k=2)\n\n    # Applying ratio test and filtering out the good matches.\n    GoodMatches = []\n    for m, n in InitialMatches:\n        if m.distance &lt; 0.75 * n.distance:\n            GoodMatches.append([m])\n\n    return GoodMatches, BaseImage_kp, SecImage_kp</code></pre><p>On va maintenant dÃ©finir une fonction qui va permettre de trouver les Ã©ventuelles projections Ã  faire une fois quâ€™un match est trouvÃ©. Ceci se produit quand les images Ã  recoller ne sont pas exactement sur le mÃªme plan.</p><p>Cette fonction prend en entrÃ©e les matches trouvÃ©s et les points clÃ©s des images de droite et de gauche. Et elle utilise les correspondances pour trouver la matrice dâ€™homographie entre les images, qui dÃ©crit la transformation entre les images.</p><pre class=\"wp-block-code\"><code>def FindHomography(Matches, BaseImage_kp, SecImage_kp):\n    # If less than 4 matches found, exit the code.\n    if len(Matches) &lt; 4:\n        print(\"\\nNot enough matches found between the images.\\n\")\n        exit(0)\n\n    # Storing coordinates of points corresponding to the matches found in both the images\n    BaseImage_pts = []\n    SecImage_pts = []\n    for Match in Matches:\n        BaseImage_pts.append(BaseImage_kp[Match[0].queryIdx].pt)\n        SecImage_pts.append(SecImage_kp[Match[0].trainIdx].pt)\n\n    # Changing the datatype to \"float32\" for finding homography\n    BaseImage_pts = np.float32(BaseImage_pts)\n    SecImage_pts = np.float32(SecImage_pts)\n\n    # Finding the homography matrix(transformation matrix).\n    (HomographyMatrix, Status) = cv2.findHomography(SecImage_pts, BaseImage_pts, cv2.RANSAC, 4.0)\n\n    return HomographyMatrix, Status</code></pre><p>On dÃ©fini maintenant la fonction GetNewFrameSizeAndMatrix ci-dessous.</p><p>Elle calcule la nouvelle taille et la matrice de transformation pour lâ€™image qui sera recadrÃ©e. La taille de lâ€™image est dÃ©terminÃ©e en multipliant la largeur et la hauteur dâ€™origine de lâ€™image par le ratio de la nouvelle taille sur la taille originale.</p><p>La matrice de transformation est calculÃ©e Ã  partir de la position et de lâ€™orientation de lâ€™objet. Tout dâ€™abord, la fonction calcule le centre de lâ€™objet en utilisant les coordonnÃ©es x et y du coin supÃ©rieur gauche de lâ€™objet et sa largeur et sa hauteur. Ensuite, elle calcule lâ€™angle de rotation de lâ€™objet en utilisant la valeur de lâ€™orientation. La matrice de transformation est construite en utilisant ces informations.</p><p>La matrice dâ€™homographie est une matrice 3Ã—3 qui est utilisÃ©e pour transformer lâ€™image. Elle comprend des valeurs de rotation, de translation et de mise Ã  lâ€™Ã©chelle.</p><p>Les valeurs de rotation sont dÃ©terminÃ©es en utilisant lâ€™angle de rotation de lâ€™objet. Les valeurs de translation sont calculÃ©es en utilisant la position du centre de lâ€™objet. Les valeurs de mise Ã  lâ€™Ã©chelle sont dÃ©terminÃ©es en utilisant le rapport de la nouvelle taille sur la taille originale de lâ€™image.</p><p>En fin de compte, la fonction renvoie la nouvelle taille de lâ€™image ainsi que la matrice de transformation qui sera utilisÃ©e pour recadrer lâ€™image.</p><pre class=\"wp-block-code\"><code>def GetNewFrameSizeAndMatrix(HomographyMatrix, Sec_ImageShape, Base_ImageShape):\n    # Reading the size of the image\n    (Height, Width) = Sec_ImageShape\n\n    # Taking the matrix of initial coordinates of the corners of the secondary image\n    # Stored in the following format: [[x1, x2, x3, x4], [y1, y2, y3, y4], [1, 1, 1, 1]]\n    # Where (xi, yi) is the coordinate of the i th corner of the image.\n    InitialMatrix = np.array([[0, Width - 1, Width - 1, 0],\n                              [0, 0, Height - 1, Height - 1],\n                              [1, 1, 1, 1]])\n\n    # Finding the final coordinates of the corners of the image after transformation.\n    # NOTE: Here, the coordinates of the corners of the frame may go out of the\n    # frame(negative values). We will correct this afterwards by updating the\n    # homography matrix accordingly.\n    FinalMatrix = np.dot(HomographyMatrix, InitialMatrix)\n\n    [x, y, c] = FinalMatrix\n    x = np.divide(x, c)\n    y = np.divide(y, c)\n\n    # Finding the dimentions of the stitched image frame and the \"Correction\" factor\n    min_x, max_x = int(round(min(x))), int(round(max(x)))\n    min_y, max_y = int(round(min(y))), int(round(max(y)))\n\n    New_Width = max_x\n    New_Height = max_y\n    Correction = [0, 0]\n    if min_x &lt; 0:\n        New_Width -= min_x\n        Correction[0] = abs(min_x)\n    if min_y &lt; 0:\n        New_Height -= min_y\n        Correction[1] = abs(min_y)\n\n    # Again correcting New_Width and New_Height\n    # Helpful when secondary image is overlaped on the left hand side of the Base image.\n    if New_Width &lt; Base_ImageShape[1] + Correction[0]:\n        New_Width = Base_ImageShape[1] + Correction[0]\n    if New_Height &lt; Base_ImageShape[0] + Correction[1]:\n        New_Height = Base_ImageShape[0] + Correction[1]\n\n    # Finding the coordinates of the corners of the image if they all were within the frame.\n    x = np.add(x, Correction[0])\n    y = np.add(y, Correction[1])\n    OldInitialPoints = np.float32([[0, 0],\n                                   [Width - 1, 0],\n                                   [Width - 1, Height - 1],\n                                   [0, Height - 1]])\n    NewFinalPonts = np.float32(np.array([x, y]).transpose())\n\n    # Updating the homography matrix. Done so that now the secondary image completely\n    # lies inside the frame\n    HomographyMatrix = cv2.getPerspectiveTransform(OldInitialPoints, NewFinalPonts)\n    \n    return [New_Height, New_Width], Correction, HomographyMatrix</code></pre><p>Maintenant, nous devons assembler les images. Pour cela, nous utiliserons la matrice dâ€™homographie pour dÃ©former la 2Ã¨me image, pour quâ€™elle puisse se coller sur lâ€™image de base.</p><p>On utilise pour Ã§a la fonction Â«Â warpPerspectiveÂ Â» dans OpenCV. Cette fonction prend les arguments suivants :</p><ul class=\"wp-block-list\"><li>Lâ€™image source, qui est lâ€™image de droite dans notre cas</li><li>La matrice dâ€™homographie que nous avons calculÃ©e prÃ©cÃ©demment</li><li>Les dimensions de lâ€™image de sortie</li><li>Des indicateurs pour lâ€™interpolation</li></ul><p>Voici le code pour assembler les images :</p><pre class=\"wp-block-code\"><code>def StitchImages(BaseImage, SecImage):\n    # Finding matches between the 2 images and their keypoints\n    Matches, BaseImage_kp, SecImage_kp = FindMatches(BaseImage, SecImage)\n\n    # Finding homography matrix.\n    HomographyMatrix, Status = FindHomography(Matches, BaseImage_kp, SecImage_kp)\n\n    # Finding size of new frame and correction matrix\n    [New_Height, New_Width], Correction, NewHomographyMatrix = GetNewFrameSizeAndMatrix(HomographyMatrix, SecImage.shape, BaseImage.shape)\n\n    # Warping the secondary image onto the base image using homography matrix\n    WarpedImage = cv2.warpPerspective(SecImage, NewHomographyMatrix, (New_Width, New_Height))\n\n    # Combining the base and secondary image\n    BaseImage[Correction[1]:Correction[1] + WarpedImage.shape[0], Correction[0]:Correction[0] + WarpedImage.shape[1]] = WarpedImage\n\n    return BaseImage</code></pre><p>Pour utiliser ces fonctions en situation concrÃ¨te pour assembler 2 images, il ne reste plus quâ€™Ã  faire ceci :</p><pre class=\"wp-block-code\"><code># Reading in two images\nBaseImage = cv2.imread('image1.jpg')\nSecImage = cv2.imread('image2.jpg')\n\n# Stitching the images together\nStitchedImage = StitchImages(BaseImage, SecImage)\n\n# Displaying the final image\ncv2.imshow('Stitched Image', StitchedImage)\ncv2.waitKey(0)\ncv2.destroyAllWindows()</code></pre><h2 class=\"wp-block-heading\">Conclusion</h2><p>Dans ce tutoriel, nous avons appris Ã  rÃ©aliser lâ€™image stitching Ã  partir de deux images en utilisant la bibliothÃ¨que OpenCV en Python.</p><p>Nous avons commencÃ© par faire de lâ€™extraction de features sur les deux images, puis nous avons utilisÃ© lâ€™algorithme RANSAC pour estimer la matrice dâ€™homographie qui permet de projeter une image sur lâ€™autre. Enfin, nous avons fusionnÃ© les deux images en utilisant la fonction warpPerspective dâ€™OpenCV.</p><p>Si vous voulez rÃ©aliser lâ€™image stitching sur plus que deux images, il sera facile dâ€™adapter ce code de cette faÃ§on :</p><ul class=\"wp-block-list\"><li>Choisissez une image de base Ã  laquelle vous souhaitez ajouter dâ€™autres images</li><li>Pour chaque image supplÃ©mentaire, calculez la matrice dâ€™homographie qui correspond Ã  la transformation de lâ€™image pour lâ€™ajuster Ã  la base</li><li>Combinez les matrices dâ€™homographie des diffÃ©rentes images pour obtenir une matrice globale</li><li>Utilisez cette matrice globale pour projeter toutes les images sur la base</li><li>Enfin, fusionnez toutes les images en une seule image en utilisant des mÃ©thodes comme la moyenne pondÃ©rÃ©e ou la fusion pyramidale</li></ul></div>"},
{"url": "https://larevueia.fr/quest-ce-que-locr-optical-character-recognition/", "title": "Quâ€™est-ce que lâ€™OCR (Optical Character Recognition) ?", "author": "Ilyes Talbi", "date": "\n17 novembre 2022\n", "content": "<div class=\"entry-content\"><p>Lâ€™optical Character Recognition ou OCR, est une technique de traitements des images qui permet de dÃ©tecter et reconnaitre le texte contenu dans une image.</p><p>MÃªme si lâ€™OCR nâ€™a pas attendu le deep learning pour se dÃ©velopper, les rÃ©centes avancÃ©es sur ce domaine ont permis dâ€™amÃ©liorer de faÃ§on considÃ©rable les temps de traitement et la prÃ©cision.</p><p>Dans cet article, on explique le fonctionnement des mÃ©thodes dâ€™OCR, et on prÃ©sente certaines applications de cette technique.</p><h2 class=\"wp-block-heading\">Comment fonctionne lâ€™Optical Character Recognition ?</h2><p>Lâ€™OCR est une des techniques dâ€™analyse dâ€™images les plus anciennes.</p><h3 class=\"wp-block-heading\">Les mÃ©thodes classiques</h3><p>Les mÃ©thodes classiques reposaient quasiment exclusivement sur des mathÃ©matiques et permettaient dÃ©jÃ  dâ€™avoir des rÃ©sultats exploitables.</p><p>La mÃ©thode la plus simple consiste Ã  dÃ©tecter les contours du caractÃ¨re, en identifiant les pixels ou on a un changement brusque dâ€™intensitÃ©. On va ensuite calculer une distance mathÃ©matique entre la matrice rÃ©sultante, et des matrices de rÃ©fÃ©rences prÃ©-dÃ©finies pour chaque caractÃ¨re.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-de%CC%81cran-2022-11-17-a%CC%80-00.47.15-1024x514.png\" alt=\"Qu'est-ce que l'OCR (Optical Character Recognition) ?\" class=\"wp-image-6796\" width=\"586\" height=\"293\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-17-aÌ€-00.47.15-1024x514.png 1024w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-17-aÌ€-00.47.15-300x150.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-17-aÌ€-00.47.15-768x385.png 768w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-17-aÌ€-00.47.15-1536x770.png 1536w, https://larevueia.fr/wp-content/uploads/2022/11/Capture-deÌcran-2022-11-17-aÌ€-00.47.15.png 1600w\" sizes=\"auto, (max-width: 586px) 100vw, 586px\"></figure></div><p>Dans une forme un peu plus avancÃ©e, mais toujours en gardant le mÃªme esprit, on peut travailler avec des mÃ©thodes de gradients, qui sont largement utilisÃ©es pour la dÃ©tection de contour en gÃ©nÃ©ral.</p><h3 class=\"wp-block-heading\">Lâ€™arrivÃ©e des CNN</h3><p>Les <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">rÃ©seaux de neurones</a> de convolutions ont fait considÃ©rablement avancer le domaine de lâ€™OCR. Les techniques dâ€™aujourdâ€™hui sont beaucoup plus performantes et robustes. MÃªme si elles sont gourmandes en donnÃ©es dâ€™entraÃ®nement et en capacitÃ© de calcul.</p><p>Avec les CNN, on laisse le modÃ¨le trouver les caractÃ©ristiques et les pattern tout seul, on lui donne uniquement les images brutes sans aucune information sur les contours. En lâ€™alimentant avec plusieurs images reprÃ©sentants la lettre a, on le laisse comprendre seul ce qui caractÃ©rise la lettre a en trouvant les similaritÃ©s. Câ€™est le travail quâ€™il fera dans la phase dâ€™entraÃ®nement.</p><p>Dans la phase de dÃ©tection, le modÃ¨le va rechercher dans ce quâ€™il aura appris les caractÃ©ristiques du caractÃ¨re quâ€™il doit prÃ©dire.</p><h3 class=\"wp-block-heading\">Quels outils utiliser pour faire de lâ€™OCR ?</h3><p>Les solutions qui permettent de faire de lâ€™OCR sont nombreuses :</p><ul class=\"wp-block-list\"><li><strong><a href=\"https://github.com/tesseract-ocr/tesseract\" target=\"_blank\" rel=\"noreferrer noopener\">Tesseract</a> :</strong> câ€™est une solution open-source proposÃ©e par Google, câ€™est de loin la plus utilisÃ©e, la plus lÃ©gÃ¨re et la plus simple Ã  prendre en main</li><li><strong>GOCR</strong></li><li><strong>Kraken</strong> (rien Ã  voir avec la plateforme de crypto ahah)</li></ul><h2 class=\"wp-block-heading\">Quelles sont les applications de lâ€™OCR ?</h2><p>Lâ€™OCR est un des domaines de la vision par ordinateur les plus actifs et qui se renouvÃ¨le le plus. Ceci sâ€™explique par le fait quâ€™il soit facile Ã  mettre en place et Ã  forte valeur ajoutÃ©e dans beaucoup de domaines.</p><h3 class=\"wp-block-heading\">Tri automatisÃ© du courrier</h3><p>Une des applications les plus connues de lâ€™OCR est la lecture automatisÃ©e des adresses postales pour le tri des courriers.</p><p>Chaque annÃ©e, La Poste distribue plus de 14 milliards de lettres et colis Ã  travers la France. Pour trier rapidement et efficacement ces colis, et donc permettre une distribution plus rapide du courier, La Poste mise sur lâ€™OCR. Des modÃ¨les performants permettent de dÃ©tecter et lire les adresses quâ€™elles soient manuscrites ou non, pour les classer.</p><p>Câ€™est pour la reconnaissance de chiffres manuscrits que les CNN ont Ã©tÃ© proposÃ©s initialement. Et jusquâ€™Ã  aujourdâ€™hui, lâ€™un des premiers projets que lâ€™on rÃ©alise lorsque lâ€™on veut apprendre la vision par ordinateur et celui fait sur la base MNIST qui regroupe des images des chiffres manuscrits de 0 Ã  9.</p><h3 class=\"wp-block-heading\">KYC (Know Your Customer)</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"400\" height=\"294\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/passport-ocr.jpeg\" alt=\"L'OCR pour le contrÃ´le automatisÃ©e d'identitÃ©\" class=\"wp-image-6791\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/passport-ocr.jpeg 400w, https://larevueia.fr/wp-content/uploads/2022/11/passport-ocr-300x221.jpeg 300w\" sizes=\"auto, (max-width: 400px) 100vw, 400px\"></figure></div><p>Lorsque vous crÃ©ez un compte bancaire en ligne ou que vous faites une dÃ©marche administrative, il vous est demandÃ© de prendre en photo votre carte dâ€™identitÃ© ou autres documents. Se sont souvent des techniques dâ€™OCR qui sont utilisÃ©es pour faire une vÃ©rification dâ€™identitÃ© automatisÃ©e.</p><p>Elles permettent dâ€™extraire vos informations (nom, prÃ©nom, date et lieu de naissance, adresse, etc.).</p><h3 class=\"wp-block-heading\">Lâ€™OCR pour la gestion des documents administratifs</h3><p>Lâ€™OCR peut aider dans la gestion des documents administratifs. A lâ€™Ã©chelle dâ€™une famille dÃ©jÃ  la quantitÃ© de documents Ã  traiter est assez Ã©norme, je vous laisse imaginer ce que câ€™est Ã  lâ€™Ã©chelle dâ€™une grande entreprise.</p><p>Pour faciliter le traitement du courier, des modÃ¨les dâ€™OCR peuvent servir de premier tri qui permet de distribuer le courier plus facilement et de faÃ§on automatisÃ©e Ã  chaque service.</p><p>Les modÃ¨les les plus performants peuvent en plus de dÃ©tecter et reconnaitre le texte, comprendre ce que dit le message, le rÃ©sumÃ© et envoyer un note simplifiÃ©e ou ajouter une tÃ¢che. On pourrait mÃªme imaginer un systÃ¨me dans lequel la deadline est reconnue automatiquement et ajoutÃ©e Ã  un calendrier.</p><h3 class=\"wp-block-heading\">Traduction des panneaux et affichages et de signalisation</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/11/image.png\" alt=\"l'OCR pour la traduction\" class=\"wp-image-6793\" width=\"581\" height=\"326\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/11/image.png 950w, https://larevueia.fr/wp-content/uploads/2022/11/image-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2022/11/image-768x432.png 768w\" sizes=\"auto, (max-width: 581px) 100vw, 581px\"></figure></div><p>Google a proposÃ© il y a plusieurs annÃ©es une application qui permet de traduire un texte en utilisant la camÃ©ra. Cette application mâ€™a pas mal servie pendant mes voyages et câ€™est un exemple parfait dâ€™utilisation de lâ€™OCR.</p><h3 class=\"wp-block-heading\">Application de lâ€™OCR dans le domaine du retail</h3><p>Dans le domaine du retail aussi lâ€™OCR est de plus en plus utilisÃ©e.</p><p>Les entreprises de lâ€™agroalimentaires qui ont des contrats avec des grands distributeurs comme Carrefour, ont des clauses assez strictes sur le positionnement de leurs produits. Le simple fait dâ€™avoir une bouteille ou un paquet de gÃ¢teau disposÃ© Ã  lâ€™envers dans le rayon constitue un manque Ã  gagner pour lâ€™entreprise, et donc des contrÃ´les assez rÃ©guliers sont Ã©fÃ©ctuÃ©s.</p><p>Lâ€™OCR, et la vision par ordinateur en gÃ©nÃ©ral, vont permettre de vÃ©rifier si les produits sont correctement disposÃ©s et si la marque de lâ€™entreprise et bien lisible.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Lâ€™OCR est une technique assez simple Ã  mettre en oeuvre, peu couteuse et qui peut faire gagner beaucoup de temps. Câ€™est ce qui fait que câ€™est une des techniques de traitement dâ€™images les plus utilisÃ©es et les plus apprÃ©ciÃ©es.</p></div>"},
{"url": "https://larevueia.fr/clippinggpt-lia-bresilienne-qui-a-surpasse-gpt-4/", "title": "ClippingGPT : lâ€™IA brÃ©silienne qui a surpassÃ© GPT-4", "author": "Ilyes Talbi", "date": "\n26 juin 2023\n", "content": "<div class=\"entry-content\"><p><em><em>Article original Â« <a href=\"https://medium.com/@rafael_pinheiro/building-with-gpt-for-education-how-we-built-an-ai-tutor-that-aced-the-most-complex-exam-in-latam-19fabf8b746b\" target=\"_blank\" rel=\"noreferrer noopener\">Building with GPT for education: how we built an AI tutor that passed one of the toughest exams</a> Â« Â rÃ©digÃ© par <a href=\"https://www.linkedin.com/in/rafaelpinheirocosta\" target=\"_blank\" rel=\"noreferrer noopener\">Rafael Pinheiro Costa</a> et traduit par <a href=\"https://www.linkedin.com/in/a%C3%A9lia-maury-b77278223?trk=contact-info\" target=\"_blank\" rel=\"noreferrer noopener\">Aelia Maury</a>.</em></em></p><hr class=\"wp-block-separator has-alpha-channel-opacity\"><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Clipping est une startup qui aide les candidats Ã  exceller dans des examens hautement compÃ©titifs. Avec un taux dâ€™approbation de 94% Ã  lâ€™examen Â«Â Brazilian Diplomatic Career ExaminationÂ Â», nous construisons avec lâ€™IA et les interfaces conversationnelles dans lâ€™Ã©ducation depuis 2018, lorsque nous avons remportÃ© les Bot Awards Brazil en tant que meilleur chatbot pour lâ€™Ã©ducation aux cÃ´tÃ©s de marques telles que Magazina Luiza, PagSeguro et Rock in Rio.</em></p><p><em>Plus tÃ´t cette annÃ©e, nous avons lancÃ© notre systÃ¨me de correction automatique pour les questions de dissertation, un algorithme propriÃ©taire dÃ©veloppÃ© dans le cadre dâ€™un projet de recherche en collaboration avec le DÃ©partement dâ€™informatiqueÂ  de lâ€™UniversitÃ© de Minas Gerais (UFMG) et le Parc technologique de Bell Horizonte (BHTEC) oÃ¹ nous sommes Ã©galement une entreprise rÃ©sidente. Maintenant, nous lanÃ§ons </em><strong><em>ClippingGPT</em></strong><em> (bÃªta), un tuteur IA qui aide les Ã©tudiants Ã  rÃ©aliser leur plein potentiel grÃ¢ce Ã  un tutorat personnalisÃ©.</em></p></blockquote><p>Beaucoup de personnes nous ont contactÃ© pour obtenir des dÃ©tails sur la maniÃ¨re dont nous avons formÃ© un modÃ¨le qui a non seulement rÃ©ussi lâ€™examen dâ€™entrÃ©e dans la carriÃ¨re diplomatique, mais aussi <strong>surpassÃ© <a href=\"https://larevueia.fr/gpt-4/\" target=\"_blank\" rel=\"noreferrer noopener\">GPT-4</a> de 26% dans cet examen particulier</strong>, rÃ©putÃ© comme lâ€™un des plus difficile en AmÃ©rique latine. Jâ€™ai donc pensÃ© que ce serait une excellente occasion de documenter et de partager ce cas.</p><p><strong>TLDRÂ :</strong></p><p>a) Le principal problÃ¨me de lâ€™utilisation de ChatGPT et des LLM dans lâ€™Ã©ducation nâ€™est pas la triche, mais les risques de dÃ©sinformation pendant le processus dâ€™apprentissage en raison dâ€™hallucinations.</p><p>b) Il est possible dâ€™attÃ©nuer ces risques en formant un modÃ¨le sur une base de connaissances externe afin dâ€™amÃ©liorer lâ€™exactitude des rÃ©ponses.</p><p>c) AprÃ¨s avoir formÃ© ClippingGPT sur une base de connaissances externe, nous avons validÃ© sa rÃ©ussite Ã  lâ€™examen dâ€™entrÃ©e de carriÃ¨re diplomatique, surpassant les autres candidats et GPT-4.</p><p>d) Le fait quâ€™une IA formÃ©e sur une base de connaissances externe ait rÃ©ussi avec brio lâ€™un des examens les plus difficiles dÃ©montre le potentiel des LLM pour construire des tuteurs intelligents dans le domaine de lâ€™Ã©ducation.</p><p>Jâ€™espÃ¨re que cet article pourra Ãªtre utile Ã  ceux qui sâ€™intÃ©ressent Ã  lâ€™exploration de lâ€™utilisation responsable de lâ€™IA dans les contextes Ã©ducatifs.</p><h2 class=\"wp-block-heading\"><strong>Le problÃ¨me des LLMs dans lâ€™Ã©ducation</strong></h2><p>Bien que GPT et les grands modÃ¨les de langage (LLMs) reprÃ©sentent une avancÃ©e significative dans le domaine de lâ€™IA, leur utilisation dans lâ€™Ã©ducation pose de nombreux dÃ©fis.</p><p>Cela est principalement dÃ» au fait que les LLMs tels que <a href=\"https://larevueia.fr/chatgpt/\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> fonctionnent en tant que modÃ¨les de langage plutÃ´t que comme bases de connaissances, ce qui rend difficile de confirmer lâ€™exactitude des informations quâ€™ils fournissent.</p><h3 class=\"wp-block-heading\"><strong>Hallucinations</strong></h3><p>En termes simples, ces modÃ¨les statistiques reconnaissent des motifs dans les sÃ©quences de mots et prÃ©voient les mots suivants en se basant sur leurs donnÃ©es dâ€™entraÃ®nement. Au lieu dâ€™Ã©valuer la vÃ©racitÃ© des informations, le systÃ¨me est conÃ§u pour anticiper comment une question serait rÃ©pondue.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>ChatGPT Ã©crit parfois des rÃ©ponses qui semblent plausibles, mais qui sont incorrectes ou sans signification (OpenAI, sur les limites de ChatGPT).</em></p></blockquote><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"500\" height=\"213\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_GXzsUk3FoCIQ0wwujUPUJQ.gif\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8424\"></figure></div><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Bien que les modÃ¨les de langage soient impressionnants en termes de fluiditÃ©, ils ont tendance Ã  gÃ©nÃ©rer de fausses dÃ©clarations. Celles-ci vont des inexactitudes subtiles aux hallucinations extravagantes [1].</em></p></blockquote><p>Lorsquâ€™il sâ€™agit dâ€™apprendre une nouvelle compÃ©tence ou de prÃ©parer un examen Ã  enjeux Ã©levÃ©s, le fait de sembler plausible est contre-productif, voire dangereux.</p><p>Une grande partie des discussions actuelles sur lâ€™impact de ChatGPT dans lâ€™Ã©ducation porte sur la tricherie, mais les risques de <strong>dÃ©sinformation gÃ©nÃ©ralisÃ©e lors de lâ€™apprentissage</strong> sont bien plus prÃ©occupants.</p><p><em>GPT-4 prÃ©sente des limitations similaires aux modÃ¨les GPT prÃ©cÃ©dents. Plus important encore, il nâ€™est toujours pas entiÃ¨rement fiable (il Â«Â hallucineÂ Â» des faits et commet des erreurs de raisonnement). Il convient dâ€™Ãªtre trÃ¨s prudent lors de lâ€™utilisation des sorties du modÃ¨le de langage, en particulier dans des contextes Ã  enjeux Ã©levÃ©s (Rapport technique GPT-4, OpenAI)[2]</em>.</p><p>GPT-4 a obtenu un taux de prÃ©cision de 60 % sur le rÃ©fÃ©rentiel TruthfulQA, un test couvrant diffÃ©rentes catÃ©gories conÃ§u pour <strong>mesurer la vÃ©racitÃ© dâ€™un grand modÃ¨le de langage</strong> (LLM).</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"400\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_FXo63GlBfxb8fX6wO8WYeA.webp\" alt=\"PrÃ©cision sur des questions adverseriales, TruthfulQA mc1\" class=\"wp-image-8426\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_FXo63GlBfxb8fX6wO8WYeA.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_FXo63GlBfxb8fX6wO8WYeA-300x167.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"><figcaption class=\"wp-element-caption\">MalgrÃ© les avancÃ©es, les LLMs restent peu fiables.</figcaption></figure></div><h3 class=\"wp-block-heading\"><strong>Contenu obsolÃ¨te</strong></h3><p>Les informations obsolÃ¨tes posent un autre problÃ¨me. En gÃ©nÃ©ral, GPT-4 ne dispose pas de connaissances sur les Ã©vÃ©nements survenus aprÃ¨s la coupure de la grande majoritÃ© de ses donnÃ©es de prÃ©-entraÃ®nement en septembre 2021.</p><p>La base de connaissances de ChatGPT nâ€™a pas Ã©tÃ© mise Ã  jour de GPT 3.5 Ã  GPT-4. De nouvelles mises Ã  jour ne seront pas disponibles prochainement, car OpenAI a confirmÃ© que lâ€™entreprise ne forme pas GPT-5 et Â«Â ne le fera pas de sitÃ´tÂ Â».</p><h3 class=\"wp-block-heading\"><strong>Biais linguistique</strong></h3><p>Le biais linguistique est Ã©galement important.</p><p>GPT a tendance Ã  gÃ©nÃ©rer davantage dâ€™hallucinations dans des langues autres que lâ€™anglais, en raison de la prÃ©dominance de lâ€™anglais dans ses ensembles de donnÃ©es dâ€™entraÃ®nement.</p><p>Pourquoi est-ce un problÃ¨me ? Sur les prÃ¨s de 8 milliards de personnes dans le monde, seulement 5 % utilisent lâ€™anglais comme langue maternelle. Il y a des angles morts dans les donnÃ©es dâ€™entraÃ®nement de GPT et la plupart de ses utilisateurs sont significativement impactÃ©s par cela.</p><p>Essayez dâ€™approfondir des sujets tels que lâ€™histoire, la politique internationale, etc. Il suffit de quelques prompts (sollicitations) pour repÃ©rer des rÃ©sultats prÃ©occupants.</p><p>GPT-4 nâ€™a pas rÃ©ussi Ã  fournir une rÃ©ponse prÃ©cise Ã  une question assez simple sur lâ€™histoire du BrÃ©sil.</p><p><em>Des biais linguistiques se manifestent car la majoritÃ© du contenu sur Internet est en anglais ou dans quelques autres langues dominantes, ce qui rend les grands modÃ¨les de langage plus performants dans ces langues. Cela peut entraÃ®ner des performances biaisÃ©es et un manque de soutien pour les langues Ã  ressources limitÃ©es [3].</em></p><h3 class=\"wp-block-heading\"><strong>Les LLM ne sont quâ€™un point de dÃ©part</strong></h3><p>Il est peu probable quâ€™une solution aux hallucinations, au contenu obsolÃ¨te et aux biais se produise rapidement. Et câ€™est tout Ã  fait normal !</p><p>En rÃ©alitÃ©, ce sont plus des fonctionnalitÃ©s que des bugs.</p><p>Les LLM, tels que ChatGPT, ont Ã©tÃ© <strong>conÃ§us comme un point de dÃ©part</strong> pour dâ€™autres modÃ¨les plus petits qui rÃ©solvent des problÃ¨mes plus spÃ©cifiques.</p><p>Le potentiel de GPT et dâ€™autres grands modÃ¨les de langage rÃ©side dans le fait que leurs modÃ¨les gÃ©nÃ©riques permettent Ã  dâ€™autres de <strong>construire des systÃ¨mes plus petits reposant sur une base de connaissances externe</strong> afin de rÃ©soudre des problÃ¨mes spÃ©cifiques.</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Nous arrivons Ã  la fin de lâ€™Ã©poque de ces modÃ¨les gÃ©ants</em></p>\n<cite><em>Sam Altman, PDG dâ€™OpenAI, le 13 avril</em></cite></blockquote><p>Nous avons dÃ©veloppÃ© ClippingGPT pour valider le potentiel des modÃ¨les plus petits dans les environnements Ã©ducatifs.</p><p>Dans la section suivante, nous dÃ©taillons notre hypothÃ¨se.</p><h2 class=\"wp-block-heading\"><strong>ClippingGPT : Tester une hypothÃ¨se sur lâ€™utilisation des LLM dans lâ€™Ã©ducation</strong></h2><p>Notre hypothÃ¨se :</p><p><em>Un modÃ¨le plus petit formÃ© sur une base de connaissances spÃ©cifique et Ã  jour surpasse GPT-4 dans lâ€™examen dâ€™entrÃ©e de carriÃ¨re diplomatique au BrÃ©sil ?</em></p><p><strong>Pourquoi lâ€™examen dâ€™entrÃ©e de carriÃ¨re diplomatique brÃ©silienne ?</strong></p><p>(1) <strong>Nous disposons dÃ©jÃ  des donnÃ©es prÃ©traitÃ©es nÃ©cessaires pour le test </strong>: Clipping a Ã©tÃ© une rÃ©fÃ©rence pour les examens complexes au BrÃ©sil depuis plus de 5 ans et nous disposons de donnÃ©es exclusives prÃ©traitÃ©es pour la construction dâ€™une base de connaissances externe solide pour lâ€™expÃ©rience.</p><p>(2) <strong>Il sâ€™agit de lâ€™un des examens les plus complexes en AmÃ©rique latine</strong> : Lâ€™examen dâ€™entrÃ©e de carriÃ¨re diplomatique est gÃ©nÃ©ralement considÃ©rÃ© par les Ã©tudiants brÃ©siliens comme lâ€™examen le plus Ã©prouvant et sÃ©lectif, composÃ© dâ€™Ã©preuves Ã©crites Ã©valuant des connaissances approfondies dans une vaste gamme de matiÃ¨res, comprenant des domaines tels que : la politique internationale, lâ€™histoire du BrÃ©sil, la gÃ©ographie, le droit constitutionnel et le droit international public, lâ€™Ã©conomie, lâ€™anglais, le franÃ§ais, lâ€™espagnol et la langue portugaise.</p><p>(3) <strong>ÃŠtre Ã  jour est une partie essentielle de cet examen</strong> : les candidats sont censÃ©s <strong>se tenir au courant</strong> des dÃ©veloppements dans les domaines susmentionnÃ©s, notamment en ce qui concerne les derniers Ã©vÃ©nements en politique internationale.</p><p>(4) <strong>La majoritÃ© des connaissances est basÃ©e sur des textes en langue non anglaise</strong> : cette contrainte constitue un cas intÃ©ressant dâ€™utilisation au-delÃ  de lâ€™ensemble de donnÃ©es centrÃ© sur lâ€™anglais sur lequel GPT a Ã©tÃ© formÃ©.</p><p><strong>La mÃ©thodologie : comment avons-nous procÃ©dÃ© ?</strong></p><p>(1) Nous avons utilisÃ© GPT-4 pour gÃ©nÃ©rer des rÃ©ponses aux questions dâ€™examen de rÃ©daction contenues dans lâ€™examen de rÃ©daction officiel administrÃ© aux candidats Ã  la carriÃ¨re diplomatique en 2022 ;</p><p>(2) Ensuite, nous avons demandÃ© Ã  un groupe dâ€™enseignants spÃ©cialisÃ©s dans la prÃ©paration des candidats Ã  lâ€™examen diplomatique dâ€™Ã©valuer les rÃ©ponses sans savoir prÃ©alablement quâ€™elles Ã©taient gÃ©nÃ©rÃ©es par notre modÃ¨le dâ€™IA (notation aveugle) ;</p><p>(3) Nous avons formÃ© ClippingGPT sur une base de connaissances externe et gÃ©nÃ©rÃ© avec notre modÃ¨le de nouvelles rÃ©ponses au mÃªme examen, puis nous avons rÃ©pÃ©tÃ© le processus de lâ€™Ã©tape 2 (notation aveugle) ;</p><p>(4) Enfin, nous avons comparÃ© le score final obtenu par ClippingGPT selon 2 paramÃ¨tres : a) les scores obtenus par GPT-4 ; b) les scores obtenus par les candidats ayant Ã©tÃ© approuvÃ©s lors du dernier examen en 2022.</p><p><strong>Les rÃ©sultats : ce que nous avons dÃ©couvert ?</strong></p><p>Les rÃ©sultats globaux de ClippingGPT sont les suivants :</p><ul class=\"wp-block-list\"><li>23e place ;</li><li>score de 597,79 ;</li><li>surclassement de 26 % par rapport Ã  GPT-4.</li></ul><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"226\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_6x90t81lZo3jKt8zIOZtmA.webp\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8428\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_6x90t81lZo3jKt8zIOZtmA.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_6x90t81lZo3jKt8zIOZtmA-300x94.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"><figcaption class=\"wp-element-caption\"><em>ClippingGPT se classe Ã  la 23e place parmi les 35 premiers candidats approuvÃ©s Ã  lâ€™examen dâ€™entrÃ©e de carriÃ¨re diplomatique.</em></figcaption></figure><p>Quant Ã  GPT-4, il a obtenu un score de 473,8, se classant Ã  la 177e place et nâ€™ayant pas rÃ©ussi Ã  se hisser parmi les 35 candidats approuvÃ©s.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"693\" height=\"368\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_rgzgK4DkX7MV9mz1yVjm5Q.webp\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8430\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_rgzgK4DkX7MV9mz1yVjm5Q.webp 693w, https://larevueia.fr/wp-content/uploads/2023/06/1_rgzgK4DkX7MV9mz1yVjm5Q-300x159.webp 300w\" sizes=\"auto, (max-width: 693px) 100vw, 693px\"><figcaption class=\"wp-element-caption\"><em>Diagramme en barres de GPT-4 avec ClippingGPT dans les questions du dernier examen de rÃ©daction officiel.</em></figcaption></figure></div><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"400\" height=\"371\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_lZJ17kr1VoWUtbjsAdpWzA.webp\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8432\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_lZJ17kr1VoWUtbjsAdpWzA.webp 400w, https://larevueia.fr/wp-content/uploads/2023/06/1_lZJ17kr1VoWUtbjsAdpWzA-300x278.webp 300w\" sizes=\"auto, (max-width: 400px) 100vw, 400px\"><figcaption class=\"wp-element-caption\"><em>AperÃ§u de la comparaison dans le diagramme radar de GPT-4 avec ClippingGPT dans les questions du dernier examen de rÃ©daction officiel en 2022.</em></figcaption></figure></div><p><strong>Quelques informations sur les rÃ©sultats :</strong></p><p>(1) La plus grande diffÃ©rence entre GPT-4 et ClippingGPT se situe dans les domaines de la gÃ©ographie et de lâ€™histoire du BrÃ©sil. Dans ces deux matiÃ¨res, une grande partie du contenu nÃ©cessaire pour rÃ©pondre aux questions demande aux candidats une maÃ®trise de la littÃ©rature spÃ©cifique mettant en Ã©vidence des faits et des arguments locaux et rÃ©gionaux peu susceptibles de figurer dans lâ€™ensemble de donnÃ©es utilisÃ© pour former GPT-4. Il peut y avoir une corrÃ©lation ou cela peut signifier que notre modÃ¨le a <strong>surmontÃ© certains angles morts </strong>dans des sujets spÃ©cifiques, ce qui a conduit Ã  de meilleures performances. La prÃ©cision sâ€™est considÃ©rablement amÃ©liorÃ©e. Cependant, les hallucinations nâ€™ont pas Ã©tÃ© complÃ¨tement Ã©liminÃ©es.</p><p>(2) Le franÃ§ais et lâ€™espagnol sont des valeurs aberrantes avec une plus petite variation. Dans le cas de cet examen de rÃ©daction particulier, la structure diffÃ¨re, les candidats sont invitÃ©s Ã  traduire et Ã  rÃ©sumer. Contrairement aux autres examens, <strong>aucune connaissance externe nâ€™est requise</strong>. Cela explique les scores similaires.</p><p>(3) Pour lâ€™examen de langue portugaise, un rÃ©sultat curieux. Tant ClippingGPT que GPT-4 ont obtenu des scores <strong>infÃ©rieurs Ã  la moyenne </strong>des candidats admis. Selon Guilherme Aguiar, titulaire dâ€™un doctorat en langue portugaise et chargÃ© dâ€™Ã©valuer les examens de langue portugaise : Â«Â <em>Les rÃ©ponses au test de langue portugaise </em><strong><em>impressionnent par leur cohÃ©rence interne de lâ€™argumentation</em></strong><em>, mÃªme si les textes prÃ©sentent une sÃ©rie de </em><strong><em>dÃ©ficiences structurelles et grammaticales qui compromettent le score obtenu</em></strong><em>, qui reste nÃ©anmoins dans la plage de notes de passageÂ Â»</em>. Cela peut sâ€™expliquer par le fait que les essais sont Ã©valuÃ©s selon des rÃ¨gles conservatrices de ponctuation, de rÃ©gence de certains verbes et noms, ainsi que dâ€™autres normes qui ne font pas consensus parmi les experts en grammaire, et qui ont jouÃ© un rÃ´le dans les rÃ©sultats, nous le croyons.</p><p>ğŸ’¡<em>OpportunitÃ© : De nouvelles avancÃ©es peuvent Ãªtre rÃ©alisÃ©es grÃ¢ce Ã  des mesures pratiques visant Ã  rÃ©duire les hallucinations, telles que lâ€™ajustement de la tempÃ©rature du modÃ¨le (proche de 0), lâ€™ingÃ©nierie des instructions (nous avons utilisÃ© diffÃ©rentes instructions pour chaque sujet), la chaÃ®ne de rÃ©flexion, etc. [4]</em></p><p>Dans la section suivante, nous abordons plus en dÃ©tail sur le plan technique la maniÃ¨re dont nous avons entraÃ®nÃ© GPT avec des connaissances supplÃ©mentaires pour atteindre les rÃ©sultats mentionnÃ©s ci-dessus.</p><ol class=\"wp-block-list\"><li><strong>ClippingGPT : construction dâ€™un modÃ¨le dâ€™IA pour lâ€™Ã©ducation</strong></li></ol><p>Comme dans ChatGPT, notre utilisateur peut interagir de maniÃ¨re conversationnelle avec le modÃ¨le. La principale diffÃ©rence rÃ©side dans le fait que nous lâ€™avons entraÃ®nÃ© Ã  effectuer un <strong>rappel factuel dans une base de connaissances propriÃ©taire fiable</strong> avant de renvoyer les rÃ©ponses. Cela augmente la probabilitÃ© que sa rÃ©ponse finale soit cohÃ©rente et correcte.</p><p><em>ClippingGPT fournit une rÃ©ponse prÃ©cise Ã  la question sur lâ€™histoire du BrÃ©sil Ã  laquelle GPT-4 nâ€™a pas rÃ©ussi Ã  rÃ©pondre correctement.</em></p><p>Les techniques <em>dâ€™embeddings</em> et de <em>fine-tuning</em> sont utilisÃ©es pour entraÃ®ner GPT sur des donnÃ©es distinctes, mais elles servent Ã  des fins diffÃ©rentes et impliquent des mÃ©thodes dâ€™entraÃ®nement diffÃ©rentes. Le <em>fine-tuning</em> est plus adaptÃ© pour enseigner au modÃ¨le un <em>style</em>, tandis que les <em>embeddings</em> sont recommandÃ©s comme moyen dâ€™enseigner au modÃ¨le des <em>connaissances</em>. Dans notre cas dâ€™utilisation, nous cherchions Ã  Ã©viter les hallucinations et le contenu obsolÃ¨te. Il sâ€™agit principalement dâ€™un <strong>problÃ¨me liÃ© aux connaissances.</strong></p><p>Par consÃ©quent, les <em>embeddings</em> semblaient Ãªtre lâ€™approche naturelle. En rÃ©sumÃ©, <em>lâ€™embedding</em> consiste Ã  transformer du <strong>texte en nombres</strong>, ce qui permet Ã  GPT de comprendre les relations entre les mots et dâ€™identifier des schÃ©mas dans une sÃ©rie de mots pour prÃ©dire les mots suivants. En termes plus simples, câ€™est ainsi que GPT construit progressivement des rÃ©ponses, allant des plus basiques aux plus sophistiquÃ©es. Les <em>embeddings</em> sont Ã©galement extrÃªmement utiles pour stocker et rÃ©cupÃ©rer des informations grÃ¢ce Ã  la similaritÃ© sÃ©mantique.</p><p>Notre modÃ¨le a Ã©tÃ© construit en utilisant des Â«Â embeddingsÂ Â» pour rappeler les connaissances.</p><p><strong>Ã‰tape 1 : CrÃ©ation dâ€™embeddings pour une base de connaissances</strong></p><p>Tout dâ€™abord, nous avons prÃ©parÃ© la base de connaissances Ã  partir de laquelle nous voulons que notre modÃ¨le puise des informations fiables et actuelles. Ce faisant, nous prÃ©voyons que les rÃ©ponses seront obtenues Ã  partir dâ€™une <strong>source de confiance</strong>, ce qui permettra de <strong>rÃ©duire la possibilitÃ© dâ€™inexactitudes.</strong></p><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"247\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_9yPAVpN_BV7hmj1wlddjCg.webp\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8435\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_9yPAVpN_BV7hmj1wlddjCg.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_9yPAVpN_BV7hmj1wlddjCg-300x103.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"></figure><p>Pendant le traitement des donnÃ©es, nous avons :</p><p>â€“ divisÃ© les documents en sections (morceaux) ;</p><p>â€“ transformÃ© chaque morceau en embedding Ã  lâ€™aide de lâ€™API OpenAI ;</p><p>â€“ stockÃ© les embeddings dans une base de donnÃ©es vectorielle (nous avons utilisÃ© Redis) ;</p><p>ğŸ’¡<em> OpportunitÃ© : Si vous utilisez la reconnaissance optique de caractÃ¨res (OCR) pour certains documents, le nettoyage des donnÃ©es devient extrÃªmement important. Des informations clÃ©s telles que les dates et les nombres peuvent Ãªtre compromises lors de lâ€™Ã©tape de traitement.</em></p><p><strong>Ã‰tapes 2 et 3 : recherche et fourniture de rÃ©ponses</strong></p><p>Ã€ un niveau Ã©levÃ©, voici comment fonctionne le modÃ¨le :</p><p>1. Dans un premier temps, il rÃ©cupÃ¨re des informations pertinentes par rapport Ã  la requÃªte de lâ€™utilisateur.</p><p>2. Ces informations sont ensuite ajoutÃ©es Ã  la requÃªte de lâ€™utilisateur.</p><p>3. Enfin, la requÃªte enrichie est envoyÃ©e Ã  lâ€™API pour gÃ©nÃ©rer une rÃ©ponse.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"345\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ImpkSQ3V18wwqVkxhA2OFQ.webp\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8437\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ImpkSQ3V18wwqVkxhA2OFQ.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_ImpkSQ3V18wwqVkxhA2OFQ-300x144.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"></figure></div><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"720\" height=\"258\" src=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ruLWGvcHM3BBZXT1Efl7mw.webp\" alt=\"ClippingGPT : l'IA brÃ©silienne qui a surpassÃ© GPT-4\" class=\"wp-image-8438\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/06/1_ruLWGvcHM3BBZXT1Efl7mw.webp 720w, https://larevueia.fr/wp-content/uploads/2023/06/1_ruLWGvcHM3BBZXT1Efl7mw-300x108.webp 300w\" sizes=\"auto, (max-width: 720px) 100vw, 720px\"></figure></div><p><strong>Ã‰tape 2</strong> : Lorsque lâ€™utilisateur <strong>pose une question</strong> Ã  ClippingGPT, celui-ci traite lâ€™entrÃ©e de lâ€™utilisateur et la transforme en un vecteur Ã  lâ€™aide de lâ€™API dâ€™Embeddings dâ€™OpenAI. Il analyse ensuite la distance entre le vecteur de la requÃªte de lâ€™utilisateur et les vecteurs de diffÃ©rentes sections. Ensuite, il classe ces sections en fonction de leur pertinence, indiquant oÃ¹ la rÃ©ponse potentielle peut Ãªtre trouvÃ©e.</p><p><strong>Ã‰tape 3</strong> : Le modÃ¨le intÃ¨gre ces <strong>sections pertinentes en tant que contexte</strong> dans un message envoyÃ© Ã  GPT. Cette requÃªte enrichie est ensuite envoyÃ©e Ã  lâ€™API de ComplÃ©tion dâ€™OpenAI, qui gÃ©nÃ¨re et renvoie la rÃ©ponse.</p><p>ğŸ’¡<em> OpportunitÃ© : Diverses mÃ©thodes, telles que HyDE [5], Dera [6] et Reflexion [7], peuvent amÃ©liorer les rÃ©sultats. Notre plan est dâ€™itÃ©rer ces techniques en incorporant des modifications mineures dans lâ€™architecture ci-dessus.</em></p><ol class=\"wp-block-list\"><li><strong>Conclusion et prochaines Ã©tapes</strong></li></ol><p>Dans le domaine de lâ€™Ã©ducation, la principale prÃ©occupation liÃ©e Ã  lâ€™utilisation de ChatGPT et dâ€™autres LLM rÃ©side dans les <strong>risques de dÃ©sinformation liÃ©s aux hallucinations</strong>, aux informations obsolÃ¨tes et biaisÃ©es lors de lâ€™apprentissage. Ces risques, bien quâ€™importants, peuvent Ãªtre attÃ©nuÃ©s, comme notre expÃ©rience avec ClippingGPT lâ€™a dÃ©montrÃ©.</p><p><em>Former un modÃ¨le sur une base de connaissances externe peut considÃ©rablement amÃ©liorer lâ€™exactitude des rÃ©ponses de lâ€™IA.</em></p><p>Pour les prochaines Ã©tapes, nous allons <strong>itÃ©rer sur dâ€™autres techniques pour amÃ©liorer continuellement notre modÃ¨le</strong> (Hyde, Dera, Reflections, etc.), tout en explorant de nouvelles approches pour aborder les hallucinations.</p><p><strong>References:</strong></p><p>[1] S Lin, J Hilton, O Evans.Â <a href=\"https://arxiv.org/pdf/2109.07958.pdf\"><em>TruthfulQA: Measuring How Models Mimic Human Falsehoods</em></a><em>.Â </em>2021</p><p>[2]Â <a href=\"https://arxiv.org/abs/2303.08774\">OpenAI.Â <em>GPT-4 Technical Report.</em>Â 2023.</a></p><p>[3] E Ferrara.Â <a href=\"https://arxiv.org/pdf/2304.03738.pdf\"><em>Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models.Â </em></a><em>2023</em></p><p>[4] V Dibia.Â <a href=\"https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination\"><em>Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models.Â </em></a><em>2023</em></p><p>[5] Gao, Luyu, et al.Â <em>HYDE:Â </em><a href=\"https://arxiv.org/pdf/2212.10496.pdf\"><em>Precise Zero-Shot Dense Retrieval without Relevance Labels.</em></a>Â 2022</p><p>[6] Nair, Schumacher, Tso, Kannan.Â <a href=\"https://arxiv.org/pdf/2303.17071.pdf\"><em>DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents</em></a><em>.</em>Â 2023</p><p>[7] Shinn, Labash, Gopinath.Â <a href=\"https://arxiv.org/pdf/2303.11366.pdf\"><em>Reflexion: an autonomous agent with dynamic memory and self-reflection</em></a>. 2023</p></div>"},
{"url": "https://larevueia.fr/comment-faire-de-la-segmentation-dimages-avec-python/", "title": "Comment faire de la segmentation dâ€™images avec Python ?", "author": "Ilyes Talbi", "date": "\n23 avril 2023\n", "content": "<div class=\"entry-content\"><p>La segmentation dâ€™images est un enjeu crucial dans le domaine de la <a href=\"https://larevueia.fr/focus-sur-6-sous-domaines-de-la-computer-vision-et-leurs-applications/\" target=\"_blank\" rel=\"noreferrer noopener\">vision par ordinateur</a>, permettant une comprÃ©hension plus fine des Ã©lÃ©ments qui constituent une image.</p><p>Dans cet article, je vous propose de dÃ©couvrir comment faire de la segmentation dâ€™images avec Python en utilisant Segment Anything Model (SAM), un modÃ¨le de dÃ©veloppÃ© par Meta.</p><p>Alors que lâ€™actualitÃ© technologique est dominÃ©e par les modÃ¨les dâ€™intelligence artificielle gÃ©nÃ©rative tels que ChatGPT, il est important de ne pas nÃ©gliger le domaine de la vision par ordinateur, qui reste un sujet trÃ¨s actif et riche en innovations.</p><p>Et je ne dis pas Ã§a uniquement en tant que computer vision engineer !</p><p>La vision par ordinateur englobe un large Ã©ventail dâ€™applications et de techniques permettant de traiter et dâ€™analyser des images pour en extraire des informations pertinentes.</p><p>Ces avancÃ©es trouvent des applications dans divers domaines, tels que la santÃ©, la sÃ©curitÃ©, lâ€™automatisation industrielle, la robotique et bien dâ€™autres.</p><p>La segmentation dâ€™images, en particulier, est une technique essentielle pour amÃ©liorer la comprÃ©hension de notre environnement visuel, en dÃ©tectant et en classifiant les diffÃ©rents objets et Ã©lÃ©ments prÃ©sents dans une image.</p><p>Ainsi, mÃªme Ã  lâ€™Ã¨re des modÃ¨les gÃ©nÃ©ratifs, la vision par ordinateur continue dâ€™occuper une place de choix dans le paysage de lâ€™IA et du traitement de lâ€™information visuelle.</p><h2 class=\"wp-block-heading\">Comment fonctionne la segmentation dâ€™images ?</h2><p>La segmentation dâ€™images est un processus qui consiste Ã  diviser une image en plusieurs rÃ©gions ou segments, qui partagent des caractÃ©ristiques similaires, dans le but dâ€™extraire des informations pertinentes et de simplifier lâ€™analyse de lâ€™image.</p><p>En pratique, faire de la segmentation dâ€™image revient mathÃ©matiquement Ã  faire de la classification ou du clustering sur les pixels de lâ€™image.</p><p>Il existe diffÃ©rents types de segmentations :</p><ul class=\"wp-block-list\"><li><strong>Segmentation basÃ©e sur la couleur :</strong> Cette mÃ©thode utilise les informations de couleur pour sÃ©parer les diffÃ©rents objets ou rÃ©gions dâ€™une image. Les pixels ayant des couleurs similaires sont regroupÃ©s ensemble.</li><li><strong>Segmentation basÃ©e sur la texture :</strong> Cette mÃ©thode utilise les informations de texture pour identifier les rÃ©gions dans une image. Les textures sont analysÃ©es Ã  lâ€™aide de diverses techniques, comme les matrices de co-occurrence, les filtres de Gabor, ou les descripteurs de texture locaux.</li><li><strong>Segmentation basÃ©e sur lâ€™intensitÃ© :</strong> Cette mÃ©thode segmente une image en fonction des variations dâ€™intensitÃ© ou de niveaux de gris. Les contours des objets sont souvent identifiÃ©s par la dÃ©tection des gradients dâ€™intensitÃ© ou par la dÃ©tection des points de rupture dans lâ€™histogramme de lâ€™image.</li><li><strong>Segmentation basÃ©e sur la forme :</strong> Cette approche utilise les informations de forme pour sÃ©parer les objets ou les rÃ©gions dâ€™une image. Des mÃ©thodes de reconnaissance de formes, telles que les descripteurs de Fourier ou les moments invariants, sont souvent utilisÃ©es.</li><li><strong>Segmentation sÃ©mantique :</strong> Cette mÃ©thode vise Ã  attribuer une Ã©tiquette sÃ©mantique Ã  chaque pixel de lâ€™image, pour classer les objets ou les rÃ©gions en fonction de leur signification dans le monde rÃ©el.</li><li><strong>Segmentation par rÃ©gions :</strong> Cette approche consiste Ã  regrouper les pixels voisins ayant des caractÃ©ristiques similaires, pour former des rÃ©gions homogÃ¨nes. Les algorithmes courants incluent la croissance de rÃ©gion, la fusion de rÃ©gion, ou la segmentation par eau-forte.</li><li><strong>Segmentation par contours :</strong> Cette mÃ©thode se concentre sur la dÃ©tection des contours des objets ou des rÃ©gions dans une image. Les techniques courantes incluent la dÃ©tection de Canny, la transformÃ©e de Hough ou la dÃ©tection de contours actifs (snakes).</li><li><strong>Segmentation par deep learning :</strong> Ces derniÃ¨res annÃ©es, les rÃ©seaux de neurones profonds, tels que les rÃ©seaux de neurones convolutifs (CNN) et les rÃ©seaux de neurones rÃ©currents (RNN), ont Ã©tÃ© largement utilisÃ©s pour la segmentation dâ€™images. Les approches courantes incluent la segmentation sÃ©mantique avec les rÃ©seaux entiÃ¨rement convolutifs (FCN), la segmentation par instance avec les rÃ©seaux Mask R-CNN et la segmentation dâ€™objets avec les rÃ©seaux U-Net.</li></ul><h2 class=\"wp-block-heading\">Comment fonctionne le modÃ¨le SAM : Segment Anything Model ?</h2><p>Le modÃ¨le de rÃ©fÃ©rence pour la segmentation dâ€™images est Segment Anything Model. ProposÃ© par Meta en Avril 2023, il permet, comme son nom lâ€™indique, de faire la segmentation de tous les objets prÃ©sents dans une image.</p><p>La puissance de cet outil, est quâ€™il a compris de faÃ§on gÃ©nÃ©rale la notion dâ€™objet, il peut donc faire de la gÃ©nÃ©ralisation zero-shot, en dâ€™autres termes il est capable de dÃ©tecter un objet mÃªme lorsquâ€™il ne lâ€™a jamais vu dans son dataset dâ€™entraÃ®nement.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-1024x713.png\" alt=\"Segmentation d'images en utilisant SAM et Python\" class=\"wp-image-8284\" width=\"601\" height=\"418\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-1024x713.png 1024w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-300x209.png 300w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47-768x535.png 768w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.07.47.png 1132w\" sizes=\"auto, (max-width: 601px) 100vw, 601px\"></figure></div><p>Le modÃ¨le utilise un rÃ©seau de neurones convolutifs (CNN) prÃ©-entraÃ®nÃ© pour la classification dâ€™images et une approche appelÃ©e Â«Â zero-shot segmentationÂ Â». Lâ€™architecture du modÃ¨le est basÃ©e sur dees travaux antÃ©rieurs de Meta AI, tels que <a href=\"https://github.com/facebookresearch/MaskFormer\" target=\"_blank\" rel=\"noreferrer noopener\">MaskFormer</a> et ViT-Mixer.</p><p>La segmentation est effectuÃ©e en deux Ã©tapes : dâ€™abord, le modÃ¨le gÃ©nÃ¨re un masque initial pour chaque objet, puis il affine ce masque en utilisant des informations de contexte et de forme.</p><p>Lâ€™objectif principal de ce modÃ¨le est de rÃ©duire la dÃ©pendance Ã  des jeux de donnÃ©es de segmentation annotÃ©es spÃ©cifiques Ã  chaque domaine, qui sont coÃ»teux et chronophages.</p><p>SAM a Ã©tÃ© entraÃ®nÃ© sur une base de donnÃ©es open source de <a href=\"https://segment-anything.com/dataset/index.html\" target=\"_blank\" rel=\"noreferrer noopener\">11 million dâ€™images</a> et Ã©valuÃ© en utilisant plusieurs jeux de donnÃ©es de segmentation dâ€™images standard, tels que COCO, ADE20K et PASCAL VOC et dâ€™aprÃ¨s Meta il surpasse les modÃ¨les concurrents en termes de prÃ©cision et de polyvalence.</p><h2 class=\"wp-block-heading\">Faire de la segmentation dâ€™images avec Python</h2><p>Les codes qui ont Ã©tÃ© produits par Meta pour SAM sont complÃ¨tements open-source, ce qui permet dâ€™utiliser le modÃ¨le facilement depuis Python.</p><p>Je propose dâ€™utiliser <a href=\"https://larevueia.fr/15-astuces-pour-google-colab/\" target=\"_blank\" rel=\"noreferrer noopener\">Google colab</a> pour Ã§a, pour avoir un GPU et accÃ©lÃ©rer le traitement de lâ€™image.</p><p>On commence par cloner le projet SAM sur le rÃ©pertoire de travail :</p><pre class=\"wp-block-code\"><code>!git clone 'https://github.com/facebookresearch/segment-anything.git'</code></pre><p>Si vous nâ€™Ãªtes pas dans un notebook vous pouvez retirer le Â«Â !Â Â» et lancer les lignes sur votre terminal.</p><p>On va ensuite entrer Ã  lâ€™intÃ©rieur du dossier clonÃ© :</p><pre class=\"wp-block-code\"><code>%cd segment-anything</code></pre><p>On doit encore installer les poids du modÃ¨le qui ne sont pas dans le repo github :</p><pre class=\"wp-block-code\"><code>!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth</code></pre><p>On charge le modÃ¨le et on lâ€™initialise :</p><pre class=\"wp-block-code\"><code>import torch\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nMODEL_TYPE = \"vit_h\"\n\n\nfrom segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\nCHECKPOINT_PATH = \"./sam_vit_h_4b8939.pth\"\nsam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)</code></pre><p>On peut maintenant lancer la segmentation sur une image de test. Celle que jâ€™ai choisi sâ€™appelle Â«Â sample.jpgÂ Â»:</p><pre class=\"wp-block-code\"><code>mask_generator = SamAutomaticMaskGenerator(sam)\nIMAGE_PATH = \"./sample.jpg\"</code></pre><p>Pour la visualisation du rÃ©sultat on va utiliser la librairie Supervision dÃ©veloppÃ©e par Roboflow. On commence par lâ€™installer :</p><pre class=\"wp-block-code\"><code>!pip install supervision</code></pre><p>On lit lâ€™image avec OpenCV et on la converti en RGB, puis on gÃ©nÃ¨re les masques grÃ¢ce Ã  SAM :</p><pre class=\"wp-block-code\"><code>import cv2\nimport supervision as sv\n\nimage_bgr = cv2.imread(IMAGE_PATH)\nimage_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n\nsam_result = mask_generator.generate(image_rgb)</code></pre><p>Enfin, la visualisation du rÃ©sultat :</p><pre class=\"wp-block-code\"><code>mask_annotator = sv.MaskAnnotator()\n\ndetections = sv.Detections.from_sam(sam_result=sam_result)\n\nannotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n\nsv.plot_images_grid(\n    images=[image_bgr, annotated_image],\n    grid_size=(1, 2),\n    titles=['source image', 'segmented image']\n)</code></pre><p>Et voilÃ  le travail :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"351\" src=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-1024x351.png\" alt=\"Exemple de segmentation d'images en utilisant SAM et Python\" class=\"wp-image-8288\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-1024x351.png 1024w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-300x103.png 300w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-768x263.png 768w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14-1536x527.png 1536w, https://larevueia.fr/wp-content/uploads/2023/04/Capture-decran-2023-04-23-a-22.44.14.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div></div>"},
{"url": "https://larevueia.fr/comment-generer-des-images-avec-stable-diffusion/", "title": "Comment gÃ©nÃ©rer des images avec stable diffusion ?", "author": "Ilyes Talbi", "date": "\n25 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Tandis que des entreprises comme OpenAI sont en train progressivement de perdre leur objectif principal de vue, dâ€™autres comme Stability.ai, qui sâ€™est fait connaitre grÃ¢ce Ã  stable diffusion, pourraient reprendre le flambeau.</p><p>Lâ€™Ã©tÃ© 2022 nous aura montrÃ© le vrai visage dâ€™OpenAI. Une organisation censÃ©e faire de la recherche pour le bien communâ€¦ Non seulement le modÃ¨le DALL-E 2 a Ã©tÃ© entraÃ®nÃ© avec les donnÃ©es dâ€™artistes, de crÃ©ateurs de contenus, et dâ€™internautes qui nâ€™ont rien demandÃ©s, mais en plus ils ont dÃ©cidÃ© de faire payer et de limiter lâ€™accÃ¨s.</p><p>Heureusement, de brillants chercheurs nous ont proposÃ© un modÃ¨le similaire, plus lÃ©ger, plus performant et surtout open source. Il sâ€™agit de stable diffusion.</p><p>Je vous parle de son fonctionnement dans cet article, et on verra comment crÃ©er des images en utilisant Google Colab.</p><h2 class=\"wp-block-heading\">Comment fonctionne Stable diffusion ?</h2><p>Stable diffusion est un modÃ¨le proposÃ© par CompVis, Stability.ai et LAION. Câ€™est le premier projet de gÃ©nÃ©ration dâ€™images complÃ¨tement open source.</p><h3 class=\"wp-block-heading\">Quâ€™est-ce que la gÃ©nÃ©ration dâ€™images</h3><p>Avant dâ€™expliquer les particularitÃ© de stable diffusion, laissez moi rappeler ce quâ€™est la gÃ©nÃ©ration dâ€™images.</p><p>MalgrÃ© le sentiment de deception que jâ€™ai Ã  lâ€™Ã©gard dâ€™OpenAI, je reconnais tout le travail quâ€™ils ont fait pendant toutes ces annÃ©es. Câ€™est eux qui nous ont permis dâ€™entrer dans lâ€™Ã¨re des images gÃ©nÃ©rÃ©es par intelligence artificielle.</p><p>Les modÃ¨les les plus connus de gÃ©nÃ©ration dâ€™images sont <a href=\"https://larevueia.fr/dall-e-generation-des-images-a-partir-de-textes/\" target=\"_blank\" rel=\"noreferrer noopener\">DALL-E</a>, Craiyon, Imagen, Midjourney, et maintenant Stable diffusion.</p><p>Le concept est toujours le mÃªme, il sâ€™agit de transformer un texte en image. Le modÃ¨le va essayer de comprendre du mieux possible la requÃªte entrÃ©e, et construire son image Ã  partir de lÃ .</p><p>La tÃ¢che est trÃ¨s complexe, puisque elle est Ã  cheval entre la vision par ordinateur et le NLP.</p><h3 class=\"wp-block-heading\">Comment Ã§a fonctionne et pourquoi les rÃ©sultats sont si impressionnants ?</h3><p>Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur le dataset LAION-5B, qui contient quasiment 5 milliards de paires image/texte, disponible en plusieurs langues.</p><p>Lâ€™entraÃ®nement a durÃ© 150000 heures, et a Ã©tÃ© rÃ©alisÃ© en utilisant 256 GPU Nvidia A100. Le coÃ»t total de lâ€™entrainement est de 600,000â‚¬ selon Wikipedia.</p><p>Câ€™est un modÃ¨le de diffusion, dans le sens oÃ¹ la crÃ©ation de lâ€™image se fait en dÃ©bruitant progressivement une image. Câ€™est aussi comme Ã§a que ce fait lâ€™entrainement du modÃ¨le. On utilise des <a href=\"https://larevueia.fr/introduction-aux-auto-encodeurs/\" target=\"_blank\" rel=\"noreferrer noopener\">auto-encodeurs</a>, pour bruiter lâ€™image dâ€™un cÃ´tÃ© du rÃ©seau, et la dÃ©bruiter de lâ€™autre.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"636\" height=\"177\" src=\"https://larevueia.fr/wp-content/uploads/2022/09/diffusion_process.png\" alt=\"auto-encodeur utilisÃ© pour stable diffusion\" class=\"wp-image-6534\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/09/diffusion_process.png 636w, https://larevueia.fr/wp-content/uploads/2022/09/diffusion_process-300x83.png 300w\" sizes=\"auto, (max-width: 636px) 100vw, 636px\"></figure></div><p>Pour la partie comprehension de lâ€™image, le modÃ¨le utilise un rÃ©seau avec une architecture U-Net qui contient 860M de paramÃ¨tres, et un modÃ¨le de langage avec 123M de paramÃ¨tres.</p><h2 class=\"wp-block-heading\">GÃ©nÃ©rer des images avec Stable diffusion</h2><p>Vous pouvez utiliser stable diffusion facilement avec <a href=\"https://colab.research.google.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Google Colab</a>, en activant lâ€™exÃ©cution sur GPU. Vous pourriez le faire en local mais je vous le dÃ©conseille si vous nâ€™avez pas de GPU.</p><p>Commencez par installer la librairie <em>diffusers</em> :</p><pre class=\"wp-block-code\"><code>!pip install diffusers==0.3.0 transformers scipy ftfy</code></pre><p>Pour lancer ce code il vous faudra crÃ©er un compte sur Hugging face, câ€™est trÃ¨s rapide. Vous trouverez ensuite un access token dans vos paramÃ¨tres.</p><p><strong>âš ï¸ Votre token doit rester secret</strong></p><pre class=\"wp-block-code\"><code>YOUR_TOKEN = \"<em>VOTRE_TOKEN</em>\"</code></pre><p>La librairie diffusers permet dâ€™importer le modÃ¨le, les poids et toutes les dÃ©pendances trÃ¨s facilement :</p><pre class=\"wp-block-code\"><code>from diffusers import StableDiffusionPipeline\nimport torch\n\n# vous trouverez votre token ici : https://huggingface.co/settings/tokens\npipe = StableDiffusionPipeline.from_pretrained(\n\"CompVis/stable-diffusion-v1-4\", \nuse_auth_token=YOUR_TOKEN\n)</code></pre><p>Si vous Ãªtes sur Colab et que vous avez bien activÃ© lâ€™option GPU (<em>ExÃ©cution</em> puis <em>Modifier le type dâ€™exÃ©cution</em>), ou si vous avez un GPU Nvidia sur votre ordinateur, vous devez activer lâ€™option avec cette ligne :</p><pre class=\"wp-block-code\"><code>pipe.to(\"cuda\")</code></pre><p>Enfin, vous pouvez gÃ©nÃ©rer nâ€™importe quâ€™elle image en changeant la variable <em>prompt</em> ci-dessous :</p><pre class=\"wp-block-code\"><code>prompt = \"tech article illustration, concept art\"\n\nwith torch.autocast(\"cuda\"):\n    image = pipe(prompt)[\"sample\"][0]\n\nimage.save(f\"generated_image.png\")</code></pre><p>Avec le GPU de Google Colab lâ€™image met moins de 10 secondes Ã  Ãªtre gÃ©nÃ©rÃ©e, sans GPU Ã§a risque de prendre quelques minutes.</p><p>Câ€™est dâ€™ailleurs ce code qui a gÃ©nÃ©rÃ© lâ€™illustration principale de cette article ğŸ™‚</p><p>Vous pouvez retrouver les codes utilisÃ©s pour cet article <a href=\"https://huggingface.co/blog/stable_diffusion\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Pour en savoir plus sur le projet je vous invite Ã  vous rendre sur le <a href=\"https://github.com/CompVis/stable-diffusion\" target=\"_blank\" rel=\"noreferrer noopener\">github</a> du projet.</p><p>Pour conclure, il faut savoir que lâ€™open source a ses avantages, mais peut aussi avoir des limitations. MÃªme si on est forcÃ© dâ€™accepter la license dâ€™utilisation qui interdit lâ€™exploitation du modÃ¨le pour gÃ©nÃ©rer du contenu offensant, techniquement rien nâ€™empÃªche les utilisateurs de le faire.</p><p>Dâ€™ailleurs, dans une interview avec Sentdex, le CEO de Stability.ai expliquait quâ€™il considÃ©rait le fait dâ€™ajouter des restrictions techniques comme Ã©tant liberticide, et condamnait lâ€™avis dâ€™OpenAI qui pense mieux connaitre que lâ€™utilisateur ce qui est bien pour lui.</p><p>NÃ©anmoins, je pense que cette approche est plus viable sur le long terme. En donnant un accÃ¨s libre au modÃ¨le, on favorise la recherche et le dÃ©veloppement communautaire, notamment concernant les biais.</p></div>"},
{"url": "https://larevueia.fr/pourquoi-utiliser-python-pour-le-deep-learning/", "title": "Pourquoi utiliser Python pour le deep learning ?", "author": "Ilyes Talbi", "date": "\n17 janvier 2024\n", "content": "<div class=\"entry-content\"><p>Le <a href=\"https://larevueia.fr/deep-learning/\">deep learning</a> ou apprentissage profond est une mÃ©thode dâ€™apprentissage automatique qui se base sur des architectures de rÃ©seaux de neurones artificiels profonds pour traiter et modÃ©liser des donnÃ©es de grande complexitÃ©.</p><p>Avant de plonger dans les dÃ©tails de cette approche, il est important de comprendre le concept des <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\">rÃ©seaux de neurones</a>.</p><p>Ces rÃ©seaux sâ€™inspirent de la structure du cerveau humain, sans toutefois en Ãªtre des reproductions exactes, et sont constituÃ©s dâ€™unitÃ©s mathÃ©matiques organisÃ©es en couches successives.</p><p>En progressant Ã  travers ces couches, les informations sont transformÃ©es et des caractÃ©ristiques de plus en plus abstraites sont extraites.</p><p>Ã€ la diffÃ©rence dâ€™autres mÃ©thodes traditionnelles dâ€™apprentissage automatique, oÃ¹ lâ€™extraction de caractÃ©ristiques doit souvent Ãªtre manuellement orchestrÃ©e, le deep learning est reconnu pour sa capacitÃ© Ã  apprendre ces caractÃ©ristiques de maniÃ¨re autonome.</p><p>Il est trÃ¨s pertinent pour des applications oÃ¹ les relations entre les donnÃ©es sont complexes et difficilement dÃ©finissables par lâ€™humain, comme la reconnaissance dâ€™images ou la traduction automatique.</p><p>Pour entraÃ®ner des modÃ¨les de deep learning performants on doit suivre plusieurs Ã©tapes allant de la collecte de donnÃ©es, Ã  lâ€™analyse de performances du modÃ¨le en passant par lâ€™entraÃ®nement du modÃ¨le.</p><p>Dans cet article, on va voir pourquoi Python câ€™est imposÃ© comme le langage de rÃ©fÃ©rence pour le deep learning et pour la data en gÃ©nÃ©ral.</p><h2 class=\"wp-block-heading\">Python est un langage simple et cohÃ©rent</h2><p>La premiÃ¨re raison de lâ€™utilisation de python pour le deep learning est lâ€™expÃ©rience de dÃ©veloppement que propose ce language.</p><p>La simplicitÃ© et la cohÃ©rence de Python facilitent lâ€™apprentissage et lâ€™implÃ©mentation du code, permettant ainsi aux dÃ©veloppeurs de se concentrer davantage sur la rÃ©solution des problÃ¨mes de machine learning plutÃ´t que sur la syntaxe du langage.</p><p>La syntaxe intuitive de Python favorise une meilleure lisibilitÃ© et une maintenance simplifiÃ©e du code, rendant le processus de dÃ©veloppement plus fluide et efficace.</p><p>Voici quelques exemples illustrant la simplicitÃ© et la cohÃ©rence de Python :</p><ul class=\"wp-block-list\"><li><strong>Syntaxe Lisible</strong> : Python a une syntaxe claire et concise, ce qui facilite la lecture et la comprÃ©hension du code. Par exemple, lâ€™impression dâ€™un texte se fait simplement avec <code>print(\"Texte\")</code>.</li></ul><ul class=\"wp-block-list\"><li><strong>Indentation</strong> : Lâ€™indentation en Python est non seulement une bonne pratique, mais elle est obligatoire, ce qui encourage lâ€™Ã©criture dâ€™un code propre et bien structurÃ©.</li></ul><ul class=\"wp-block-list\"><li><strong>Code Concis</strong> : Avec Python, vous pouvez Ã©crire des fonctions complexes en moins de lignes de code par rapport Ã  dâ€™autres langages comme Java ou C++. Par exemple, une liste de comprÃ©hension peut Ãªtre crÃ©Ã©e en une seule ligne : <code>squares = [x**2 for x in range(10)]</code>.</li></ul><p>La simplicitÃ© et la cohÃ©rence de Python rÃ©duisent la courbe dâ€™apprentissage pour les nouveaux dÃ©veloppeurs et permettent une transition plus facile vers des projets de machine learning complexes.</p><h2 class=\"wp-block-heading\">Python est indÃ©pendant de tous les OS</h2><p>Lâ€™indÃ©pendance de la plateforme de Python signifie quâ€™il peut fonctionner sur divers systÃ¨mes dâ€™exploitation comme Windows, MacOS, et Linux sans nÃ©cessiter de modifications majeures du code.</p><p>Cela permet aux dÃ©veloppeurs de travailler sur des projets de machine learning et de deep learning dans des environnements variÃ©s, facilitant ainsi la collaboration et le partage des ressources entre les Ã©quipes.</p><p>Cette caractÃ©ristique fait de Python un choix populaire pour les projets qui nÃ©cessitent une portabilitÃ© entre diffÃ©rentes plateformes systÃ¨me.</p><h2 class=\"wp-block-heading\">Python contient Ã©normÃ©ment de librairies et de frameworks</h2><p>La diversitÃ© des bibliothÃ¨ques et cadres (frameworks) en Python offre aux dÃ©veloppeurs un large Ã©ventail dâ€™outils pour le machine learning et le deep learning.</p><p>Des bibliothÃ¨ques comme TensorFlow, Keras, et PyTorch fournissent des fonctionnalitÃ©s avancÃ©es pour la crÃ©ation et lâ€™entraÃ®nement de modÃ¨les.</p><p>Dâ€™autres bibliothÃ¨ques comme Scikit-learn, Pandas, et NumPy facilitent la manipulation de donnÃ©es et lâ€™analyse.</p><p>Cette riche collection dâ€™outils accÃ©lÃ¨re le dÃ©veloppement, simplifie lâ€™expÃ©rimentation et contribue Ã  lâ€™efficacitÃ© des projets de machine learning et deep learning.</p><h2 class=\"wp-block-heading\">Python a une trÃ¨s grande communautÃ©</h2><p>La grande communautÃ© de Python contribue activement au dÃ©veloppement et Ã  la maintenance de ces bibliothÃ¨ques et frameworks.</p><p>Cette communautÃ© propose des corrections de bugs, des amÃ©liorations, et partage des ressources Ã©ducatives, ce qui facilite lâ€™apprentissage et lâ€™utilisation de ces outils.</p><p>Lâ€™engagement de la communautÃ© assure que les bibliothÃ¨ques restent Ã  jour, performantes et adaptÃ©es aux exigences changeantes du domaine du machine learning et du deep learning.</p><h2 class=\"wp-block-heading\">Quelques chiffres et ressources sur Python pour le deep learning</h2><p>La diversitÃ© des bibliothÃ¨ques et des frameworks en Python est souvent mise en avant, et plusieurs sources listent les bibliothÃ¨ques les plus populaires et utiles pour le machine learning et le deep learning.</p><p>Python propose un large Ã©ventail de bibliothÃ¨ques pour diverses applications. Par exemple, certains articles listent les Â«Â Top 30Â Â» ou Â«Â Top 10Â Â» des bibliothÃ¨ques Python Ã  connaÃ®tre, mentionnant des bibliothÃ¨ques comme TensorFlow, Keras, PyTorch, Scikit-learn, Pandas et NumPy parmi dâ€™autres : â€‹<a href=\"https://www.mygreatlearning.com/blog/open-source-python-libraries/#:~:text=Top%2030%20Python%20Libraries%20To,for%20writing%20codes%20from%20scratch\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>1</sup></a>â€‹â€‹ <a href=\"https://www.turing.com/kb/best-python-libraries-for-ml-in-2023#:~:text=Top%2010%20Python%20machine%20learning,An%20overview%20of%20machine%20learning\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>2</sup></a> â€‹â€‹<a href=\"https://www.stratascratch.com/blog/top-18-python-libraries-a-data-scientist-should-know/#:~:text=Maximize%20your%20data%20science%20potential,which%20have%20too%20many\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>3</sup></a>â€‹.</p><p>Quant Ã  la taille de la communautÃ© Python, une source mentionne que la taille de la communautÃ© Python est de 15,7 millions, bien que le contexte de ce chiffre ne soit pas entiÃ¨rement clair â€‹<a href=\"https://www.statista.com/topics/9361/python/#:~:text=Python%20community%20Python%20was%20founded,7m\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>4</sup></a>â€‹.</p><p>Il existe des enquÃªtes annuelles menÃ©es auprÃ¨s des dÃ©veloppeurs Python qui permettent dâ€™obtenir des insights sur la communautÃ©, bien que des chiffres spÃ©cifiques sur la taille de la communautÃ© nâ€™aient pas Ã©tÃ© fournis dans lâ€™extrait disponibleâ€‹ <a href=\"https://blog.adafruit.com/2023/10/03/python-developers-survey-2022-results-python-community-thepsf/#:~:text=October%203%2C%202023%20AT%204%3A04,Python%20Software%20Foundation%20and%20JetBrains\" target=\"_blank\" rel=\"noreferrer noopener\"><sup>5</sup></a> â€‹.</p><p>Ces informations illustrent la richesse des ressources disponibles en Python et la vaste communautÃ© qui soutient son Ã©cosystÃ¨me, ce qui en fait une plateforme attrayante pour le dÃ©veloppement en machine learning et en deep learning.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>La montÃ©e en puissance du deep learning et du machine learning est indÃ©niable, et Python sâ€™est positionnÃ© comme un pilier central dans ce domaine, grÃ¢ce Ã  ses caractÃ©ristiques intrinsÃ¨ques et Ã  lâ€™Ã©cosystÃ¨me robuste quâ€™il a bÃ¢ti autour de ces technologies.</p><p>Sa simplicitÃ©, sa cohÃ©rence, et son indÃ©pendance vis-Ã -vis des systÃ¨mes dâ€™exploitation rendent lâ€™apprentissage et le dÃ©veloppement dans ce domaine beaucoup plus accessibles.</p><p>La richesse des bibliothÃ¨ques et frameworks disponibles accÃ©lÃ¨re la mise en Å“uvre des projets, permettant aux dÃ©veloppeurs dâ€™explorer, dâ€™innover et de dÃ©ployer des solutions efficaces.</p><p>La grande communautÃ© de Python, active et engagÃ©e, assure un support continu, des amÃ©liorations constantes des outils existants et une mise Ã  jour rÃ©guliÃ¨re face aux dÃ©fis Ã©mergents du domaine.</p><p>Lâ€™interaction entre la simplicitÃ© de Python et la complexitÃ© inhÃ©rente du machine learning et du deep learning crÃ©e un environnement propice Ã  lâ€™exploration, Ã  lâ€™apprentissage et Ã  lâ€™innovation, faisant de Python un choix de prÃ©dilection pour les professionnels et les organisations cherchant Ã  tirer profit de la puissance du machine learning et du deep learning.</p></div>"},
{"url": "https://larevueia.fr/yolo-nas/", "title": "Tout ce quâ€™il faut savoir sur YOLO-NAS", "author": "Adib Habbou", "date": "\n4 mai 2023\n", "content": "<div class=\"entry-content\"><p>La dÃ©tection dâ€™objet en temps rÃ©el est une technique dâ€™intelligence artificielle qui permet de dÃ©tecter et dâ€™identifier des objets dans une vidÃ©o ou une sÃ©quence dâ€™images en temps rÃ©el. Cela implique lâ€™utilisation de techniques de vision par ordinateur et dâ€™apprentissage automatique, telles que les rÃ©seaux de neurones convolutionnels, pour analyser en temps rÃ©el les images.</p><p>Pour ce faire, les algorithmes de dÃ©tection dâ€™objet recherchent des modÃ¨les spÃ©cifiques dans les images, tels que la forme, la couleur, la texture et la taille des objets, afin de les identifier avec prÃ©cision.</p><p>Ces derniÃ¨res annÃ©es, le modÃ¨le <strong><a href=\"https://larevueia.fr/top-5-des-projets-open-source-dintelligence-artificielle/\" target=\"_blank\" rel=\"noreferrer noopener\">YOLO</a> </strong>(You Only Look Once) a connu un grand succÃ¨s dans ce domaine en permettant une dÃ©tection rapide et prÃ©cise des objets sur une image ou une vidÃ©o.</p><p>Cependant, malgrÃ© ses performances impressionnantes, <strong>YOLO </strong>prÃ©sentait certaines limites en termes de prÃ©cision.</p><p>Câ€™est pourquoi de nombreux chercheurs se sont intÃ©ressÃ©s aux recherches automatiques dâ€™architectures neuronales, abrÃ©viÃ©e <strong>NAS </strong>pour Neural Architecture Search en anglais, afin dâ€™amÃ©liorer les performances de <strong>YOLO </strong>tout en conservant sa rapiditÃ© dâ€™exÃ©cution.</p><p>Ce modÃ¨le de dÃ©tection dâ€™objet en temps rÃ©el a Ã©tÃ© dÃ©veloppÃ©e par une Ã©quipe de chercheurs de lâ€™universitÃ© de PÃ©kin en Chine et amÃ©liorer en collaboration avec lâ€™entreprise <strong>Deci AI</strong>.</p><h2 class=\"wp-block-heading\">Câ€™est quoi un Neural Architecture Search ?</h2><p>Lâ€™architecture <strong>NAS </strong>est une mÃ©thode dâ€™apprentissage automatique qui permet dâ€™automatiser la recherche de la meilleure architecture de <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\">rÃ©seau de neurones</a> pour une tÃ¢che donnÃ©e.</p><p>Contrairement aux rÃ©seaux de neurones classiques, oÃ¹ lâ€™architecture est dÃ©finie Ã  lâ€™avance, lâ€™architecture <strong>NAS </strong>est gÃ©nÃ©rÃ©e automatiquement en utilisant des algorithmes dâ€™optimisation tels que la recherche par renforcement (Reinforcement Search) ou la recherche en grille (Grid Search). Cette approche permet dâ€™obtenir des architectures plus performantes que celles conÃ§ues manuellement.</p><p>Pour entrer plus dans le dÃ©tail, on peut voir ici sur la premiÃ¨re image une reprÃ©sentation sÃ©quentielle dâ€™un <strong>CNN </strong>et en dessous une reprÃ©sentation sÃ©quentielle de lâ€™arborescence dâ€™une cellule qui va donc servir Ã  trouver lâ€™architecture la plus optimale.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://lilianweng.github.io/posts/2020-08-06-nas/NAS-search-space.png\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><h2 class=\"wp-block-heading\">Ã‡a marche comment YOLO NAS ?</h2><p><strong>YOLO NAS</strong> est une version amÃ©liorÃ©e du modÃ¨le <strong>YOLO</strong>, qui utilise un <strong>NAS </strong>pour optimiser la recherche de la meilleure architecture de rÃ©seau de neurones pour la dÃ©tection dâ€™objets en temps rÃ©el. Le principe de la recherche dâ€™architecture pour <strong>YOLO </strong>consiste Ã  gÃ©nÃ©rer plusieurs architectures candidates et Ã  les entraÃ®ner sur des donnÃ©es dâ€™apprentissage.</p><p>Un algorithme de sÃ©lection est ensuite utilisÃ© pour dÃ©terminer la meilleure architecture en fonction de critÃ¨res tels que la prÃ©cision, la couverture dâ€™objets et le temps dâ€™exÃ©cution. Les rÃ©sultats obtenus par<strong> YOLO NAS</strong> montrent une amÃ©lioration significative des performances par rapport Ã  <strong>YOLO </strong>classique, avec une prÃ©cision accrue de <strong>2%</strong> et une rÃ©duction de lâ€™erreur de localisation de <strong>15%</strong>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://deci.ai/wp-content/uploads/2023/05/YOLO-NAS-Launch-Business-Blog2.jpg\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><h2 class=\"wp-block-heading\">Est-ce que YOLO NAS est performant ?</h2><p>Pour Ã©valuer les performances de <strong>YOLO NAS</strong>, plusieurs comparaisons ont Ã©tÃ© rÃ©alisÃ©es avec les modÃ¨les les plus performants Ã  ce jour en termes de dÃ©tection dâ€™objets en temps rÃ©el, tels que <strong>RetinaNet</strong>, <strong>Faster R-CNN</strong> ou <strong>Single-Shot Detector</strong>. Les rÃ©sultats montrent que <strong>YOLO NAS </strong>est capable de rivaliser voire de dÃ©passer ces modÃ¨les en termes de prÃ©cision, tout en conservant une vitesse dâ€™exÃ©cution similaire.</p><p>Les avantages de <strong>YOLO NAS</strong> par rapport Ã  ces modÃ¨les sont son architecture plus lÃ©gÃ¨re, son adaptation Ã  des scÃ¨nes complexes et sa capacitÃ© de dÃ©tection dâ€™objets de petite taille. Bien que le modÃ¨le<strong> </strong>prÃ©sente de nombreux avantages, il prÃ©sente cependant quelques inconvÃ©nients. Lâ€™un des principaux Ã©tant sa difficultÃ© Ã  dÃ©tecter des objets trÃ¨s proches, ce qui peut entraÃ®ner une confusion entre des objets voisins. De plus, le modÃ¨le peut avoir des difficultÃ©s Ã  distinguer des objets similaires, comme des voitures de couleur similaire, ce qui peut entraÃ®ner des erreurs de dÃ©tection.</p><p>Il reste toutefois plus performants que les anciennes versions de YOLO comme on peut le voir dans la vidÃ©o ci-dessous :</p><figure class=\"wp-block-video\"><video controls src=\"https://larevueia.fr/wp-content/uploads/2023/05/%F0%9F%8E%AF-mark-freeman-ii-on-linkedin-yolonas-computervision-ai-data-datascience-ml-deeplearning-python.mp4\"></video></figure><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p><em>Source : Mark Freeman (LinkedIn)</em></p></blockquote><p><strong>YOLO NAS</strong> rÃ©ussit Ã©galement Ã  surpasser toutes les versions dÃ©jÃ  existantes de <strong>YOLO </strong>en proposant une meilleure prÃ©cision et une latence plus faible.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*11VfHXRB2KEefut1rrSy4g.png\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><p>De plus, <strong>YOLO NAS</strong> dÃ©passe assez largement la <em>Mean Average Precision </em>des anciennes versions de <strong>YOLO</strong>.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://pbs.twimg.com/media/FvNkFTfaAAIA2sf?format=png&amp;name=large\" alt=\"Tout ce qu'il faut savoir sur YOLO-NAS\"></figure></div><h2 class=\"wp-block-heading\">Conclusion</h2><p><strong>YOLO NAS</strong> a permit de surpasser les performances du modÃ¨le <strong>YOLO </strong>classique, mais il lui reste tout de mÃªme un bon nombre de point Ã  amÃ©liorer.</p><p>GrÃ¢ce aux avancÃ©es dans la recherche dâ€™architectures et dans lâ€™entraÃ®nement des modÃ¨les de dÃ©tection dâ€™objets en temps rÃ©el, lâ€™utilisation de rÃ©seaux de neurones Ã  architecture <strong>NAS </strong>comme <strong>YOLO NAS</strong> offre des perspectives passionnantes pour des applications innovantes dans de nombreux domaines en partant de la conduite autonome pour arriver Ã  la vÃ©rification de conformitÃ© aux normes de sÃ©curitÃ© en passant par la recherche et sauvetage.</p><h2 class=\"wp-block-heading\">Pour aller plus loin</h2><p>Repo GitHub de Deci AI : <a href=\"https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md\">https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md</a></p><p>Article Medium sur YOLO NAS : <a href=\"http://How%20YOLO%20NAS%20is%20leaving%20YOLO%20V8%20in%20the%20dust!\">https://augmentedstartups.medium.com/how-yolo-nas-is-leaving-yolov8-in-the-dust-and-why-you-need-to-know-about-it-87f67a844bcb</a></p><p>Article sur les NAS : <a href=\"https://lilianweng.github.io/posts/2020-08-06-nas/\">https://lilianweng.github.io/posts/2020-08-06-nas/</a></p><p>Notebook dâ€™Intro Ã  YOLO NAS : <a href=\"https://colab.research.google.com/drive/1q0RmeVRzLwRXW-h9dPFSOchwJkThUy6d#scrollTo=m0SkK3bjMOqH\">https://colab.research.google.com/drive/1q0RmeVRzLwRXW-h9dPFSOchwJkThUy6d#scrollTo=m0SkK3bjMOqH</a></p></div>"},
{"url": "https://larevueia.fr/comment-fonctionne-les-rag-retrieval-augmented-generation-en-intelligence-artificielle/", "title": "Comment fonctionnent les RAG (Retrieval Augmented Generation) en intelligence artificielle ?", "author": "Ilyes Talbi", "date": "\n16 juin 2024\n", "content": "<div class=\"entry-content\"><p>Depuis lâ€™arrivÃ©e de ChatGPT et la dÃ©mocratisation des LLM, Large Language Models, les nombre de cas dâ€™usage concrets en entreprises ne cesse de croitre. On voit de plus en plus lâ€™intÃ©rÃªt de ces modÃ¨les et de lâ€™intelligence artificielle gÃ©nÃ©rative en gÃ©nÃ©ral dans un contexte professionnel, notamment pour de la productivitÃ© ou de lâ€™automatisation.</p><p>MalgrÃ© cet engouement on sent quâ€™il reste encore beaucoup de travail pour assurer une adoption plus large de ces outils lÃ . Les entreprises nâ€™ont pas rÃ©ellement besoin de modÃ¨les de langages gÃ©nÃ©ralistes, elles ont besoin de modÃ¨les de langages spÃ©cialisÃ©s sur certains corps de mÃ©tier bien spÃ©cifique et qui soient capable de comprendre le contexte en temps rÃ©el.</p><p>Actuellement, une des solutions les plus prometteuses Ã  ce problÃ¨me se base sur les systÃ¨mes de RAG, Retrieval Augmented Generation.</p><h2 class=\"wp-block-heading\" id=\"h-qu-est-ce-que-la-retrieval-augmented-generation-rag\">Quâ€™est-ce que la Retrieval Augmented Generation (RAG) ?</h2><p>Avant dâ€™explique le fonctionnement des RAG expliquons rapidement le fonctionnement dâ€™un modÃ¨le de langage classique.</p><p>Un LLM est un modÃ¨le de rÃ©seau de neurones basÃ© sur les <a href=\"https://larevueia.fr/introduction-aux-reseaux-de-neurones-transformers/\" target=\"_blank\" rel=\"noreferrer noopener\">Transformers</a> dont lâ€™objectif est de complÃ©ter une sÃ©quence de mot. MathÃ©matiquement il sâ€™agit de construire une distribution de probabilitÃ© sur les mots dâ€™un vocabulaire et dâ€™associer Ã  chaque mot sa probabilitÃ© dâ€™Ãªtre le prochain dans la sÃ©quence.</p><p>Pour faire cela, les textes sont transformÃ©s en tokens mathÃ©matiques pour pouvoir Ãªtre traitÃ©s de maniÃ¨re vectorielle et compris par le rÃ©seau de neurones.</p><p>Cette explication brÃ¨ve a simplement pour objectif de rappeler quâ€™un LLM nâ€™a aucune composante de logique ou de comprÃ©hension dans sa version de base. Câ€™est la qualitÃ© des donnÃ©es dâ€™entrÃ©es qui permette de feindre une logique et une comprÃ©hension sÃ©mantique.</p><p>Ce fonctionnement entraÃ®ne une baisse importantes des performances dans pas mal de situations. Si je demande Ã  un LLM Â«Â Qui a gagnÃ© la derniÃ¨re coupe du monde ?Â Â», son fonctionnement fait quâ€™il essayera de me donner le nom dâ€™un pays qui est mathÃ©matiquement souvent associÃ© Ã  la notion de Â«Â coupe du mondeÂ Â» dans son dataset. Il rÃ©pondra probablement Â«Â BrÃ©silÂ Â» ou Â«Â FranceÂ Â», mais sans aucune comprÃ©hension.</p><p>De la mÃªme maniÃ¨re, si je demande Ã  un LLM de me donner le rÃ©sultat de lâ€™opÃ©ration 1 + 1, certes il me rÃ©pondre 2 dans son premier message, mais si je lui explique dans le message suivant que la rÃ©ponse est 3 il demandera pardon et confirmera que la rÃ©ponse est bien 3.</p><p>Ce phÃ©nomÃ¨ne a un nom, câ€™est lâ€™hallucination. Elle existe surtout dans les premiers modÃ¨les de LLM, dans leurs versions brutes. Aujourdâ€™hui ce problÃ¨me est un peu attÃ©nuÃ© mais reste prÃ©sent.</p><p>Les modÃ¨les de RAG permettent de faire en sorte que la rÃ©ponse fournie par le LLM soit consolider par une base qui contient du contexte fiable sur le sujet en question.</p><p>Lorsque je pose ma question au modÃ¨le de langage avec un pipeline de RAG intÃ©grÃ©, lâ€™algorithme va dâ€™abord transformer ma question en tokens mathÃ©matiques pour la vectoriser. Il va ensuite faire une recherche sÃ©mantique dans la base de contexte pour trouver des paragraphes qui seraient proches mathÃ©matiquement (il sâ€™agit de calculer des distances entre des vecteurs). Une fois quâ€™il a trouvÃ© des paragraphes qui pourraient permettre de donner une rÃ©ponse plus prÃ©cise et fiable, il reformule le prompt initial de lâ€™utilisateur en y ajoutant le contexte trouvÃ©. Câ€™est comme Ã§a que la rÃ©ponse finale est fournie Ã  lâ€™utilisateur.</p><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-1024x576.png\" alt=\"Comment fonctionne les RAG ? Langchain.\" class=\"wp-image-8758\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-1024x576.png 1024w, https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-300x169.png 300w, https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain-768x432.png 768w, https://larevueia.fr/wp-content/uploads/2024/06/rag_langchain.png 1200w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Le fonctionnement des RAG (Source : <a href=\"https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2\">Towards data science</a>)</figcaption></figure><p>Les systÃ¨mes basÃ©s sur des pipelines de RAG sont assez performants et permettent de crÃ©er des assistants plus fiables et capable dâ€™intÃ©grer de nouvelles bases de connaissances en continu. Concernant le second point, on parle aussi de real-time training, <a href=\"https://larevueia.fr/llm-et-apprentissage-en-temps-reel/\" target=\"_blank\" rel=\"noreferrer noopener\">apprentissage en temps rÃ©el</a>.</p><h2 class=\"wp-block-heading\" id=\"h-quelles-sont-les-applications-de-la-retrieval-augmented-generation-rag\">Quelles sont les applications de la Retrieval Augmented Generation (RAG) ?</h2><p>Les pipelines de RAG sont utiles Ã  chaque fois que lâ€™on cherche Ã  crÃ©er un assistant qui soit fiable concernant lâ€™information quâ€™il donne Ã  lâ€™utilisateur. Câ€™est ce qui a rendu cette technique largement utilisÃ©e en entreprise.</p><h3 class=\"wp-block-heading\" id=\"h-resume-de-reunions-interactif\">RÃ©sumÃ© de rÃ©unions interactif</h3><p>Parmi les cas dâ€™usage les plus intÃ©ressants on trouve les rÃ©sumeur de rÃ©unions interactif. Les RAG permettent de poser des questions sur la base de transcription qui ont Ã©tÃ© faites automatiquement pendant une rÃ©union.</p><p>Des outils comme <a href=\"https://fireflies.ai/\">Fireflies.ai</a> par exemple, permettent de poser des questions du type : Â«Â quâ€™est ce que Martin a dit concernant les nouvelles features qui doivent Ãªtre lancÃ©es ?Â Â». Et le modÃ¨le peut non seulement vous donner une rÃ©ponse fiable, mais il pourra aussi vous donner ses sources en intÃ©grant dans sa rÃ©ponse lâ€™extrait audio du passage qui rÃ©pond Ã  la question.</p><h3 class=\"wp-block-heading\" id=\"h-documentation-interne-en-entreprise\">Documentation interne en entreprise</h3><p>La documentation interne en entreprise est lâ€™autre gros sujets que les RAG permettent de traiter.</p><p>Câ€™est le besoin qui revient le plus souvent quand on discute avec les grosses entreprises : construire un systÃ¨me de documentation interne fiable et qui permet de vraiment trouver lâ€™information.</p><p>Pourquoi la documentation interne en entreprise est un problÃ¨me aujourdâ€™hui ?</p><ul class=\"wp-block-list\"><li>On perd du temps en recherchant les informations</li><li>On refait/recode des choses qui ont dÃ©jÃ  Ã©tÃ© faites</li><li>On met en danger la sÃ©curitÃ© des donnÃ©es de lâ€™entreprise en se les partageant nâ€™importe oÃ¹ : Whatsapp/Gmail/WeTransfer/etc.</li></ul><p>Les LLM (et les modÃ¨les dâ€™IA en gÃ©nÃ©ral) vont permettre une interaction plus naturelle avec les donnÃ©es dâ€™une entreprise et faire gagner Ã©normÃ©ment de temps Ã  travers des pipelines de RAG.</p><p>Des outils comme <a href=\"https://dust.tt/\" target=\"_blank\" rel=\"noreferrer noopener\">Dust</a>, permettent dâ€™agrÃ©ger toutes les bases de connaissances dâ€™une entreprise au mÃªme endroit, via des interactions de type chat. On peut connecter le Github, le Slack, les emails, le Google Drive et tout un tas dâ€™autres outils au pipeline de RAG pour centraliser lâ€™information.</p><h3 class=\"wp-block-heading\" id=\"h-assistant-au-contact-des-clients\">Assistant au contact des clients</h3><p>Lorsque lâ€™on met un assistant au contact dâ€™un client la qualitÃ© des rÃ©ponses fournies doit Ãªtre irrÃ©prochable. On ne peut pas se permettre de laisser un assistant se tromper sur le prix dâ€™une prestation ou sortir de son cadre dâ€™intervention.</p><p>Dans ce cas prÃ©cis, les RAG vont amener de la pertinence aux rÃ©ponses fournies en extrayant le contexte de lâ€™entreprise directement dans les bases de connaissances.</p><p>La possibilitÃ© dâ€™avoir un apprentissage en temps rÃ©el est trÃ¨s intÃ©ressante pour ce cas dâ€™usage et permet de traiter plus facilement les donnÃ©es changeantes en continu.</p><p>Par exemple, si on est un site de e-commerce qui vend des t-shirts, il est impossible de rÃ©-entraÃ®ner un modÃ¨le de langage Ã  chaque fois que les produits, les prix ou le stock Ã©voluent, on doit pouvoir faire ce travail facilement et sans intervention humaine sur les pipelines algorithmiques et les modÃ¨les.</p><h2 class=\"wp-block-heading\" id=\"h-quelles-sont-les-limites-aux-systemes-de-rag-actuellement\">Quelles sont les limites aux systÃ¨mes de RAG actuellement ?</h2><p>MalgrÃ© les avancÃ©es significatives apportÃ©es par les systÃ¨mes de Retrieval Augmented Generation, il est important de reconnaÃ®tre quâ€™ils comportent des limites non nÃ©gligeables.</p><p>PremiÃ¨rement, la qualitÃ© et lâ€™actualitÃ© des donnÃ©es dans la base de contexte sont cruciales ; un corpus dÃ©suet ou de faible qualitÃ© peut conduire Ã  des rÃ©ponses inexactes ou trompeuses.</p><p>De plus, ces systÃ¨mes peuvent souffrir dâ€™une latence plus Ã©levÃ©e due au processus de rÃ©cupÃ©ration des informations pertinentes, ce qui peut Ãªtre problÃ©matique dans des applications nÃ©cessitant une rÃ©ponse en temps rÃ©el.</p><p>Enfin, il existe un risque de sur-spÃ©cialisation oÃ¹ le systÃ¨me devient tellement affinÃ© sur une niche spÃ©cifique quâ€™il perd de sa capacitÃ© Ã  gÃ©nÃ©raliser ou Ã  sâ€™adapter Ã  de nouvelles tÃ¢ches ou domaines, ce qui limite son utilitÃ© pour des applications plus gÃ©nÃ©rales ou en constante Ã©volution.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>En conclusion, au-delÃ  des systÃ¨mes de RAG, il est essentiel de mentionner lâ€™essor des techniques de Â«Â function callingÂ Â» qui rÃ©volutionnent la maniÃ¨re dont les modÃ¨les de langage interagissent avec des fonctions externes pour accomplir des tÃ¢ches spÃ©cifiques.</p><p>Cette approche sâ€™inscrit dans la continuitÃ© des modÃ¨les de RAG. Elle permet aux modÃ¨les de langage de non seulement comprendre et gÃ©nÃ©rer du texte, mais Ã©galement dâ€™exÃ©cuter des fonctions programmÃ©es qui Ã©tendent leurs capacitÃ©s au-delÃ  de la simple gÃ©nÃ©ration de texte.</p><p>Câ€™est dans ce contexte que des outils comme <a href=\"https://larevueia.fr/langchain-le-guide-essentiel/\" target=\"_blank\" rel=\"noreferrer noopener\">Langchain</a> ont Ã©mergÃ©s. Langchain est une plateforme open-source qui facilite la mise en place de pipelines de RAG en permettant aux dÃ©veloppeurs de facilement intÃ©grer et orchestrer ces fonctionnalitÃ©s avancÃ©es dans des applications concrÃ¨tes.</p><p>Cela ouvre la voie Ã  des modÃ¨les de langage encore plus puissants et adaptatifs, capables de fournir des rÃ©ponses non seulement contextuelles mais Ã©galement actionnables, en tirant parti de bases de donnÃ©es dynamiques et de fonctions spÃ©cifiques selon les besoins des utilisateurs.</p></div>"},
{"url": "https://larevueia.fr/llm-et-apprentissage-en-temps-reel/", "title": "LLM et apprentissage en temps rÃ©el", "author": "Claire Nouet", "date": "\n27 aoÃ»t 2023\n", "content": "<div class=\"entry-content\"><p><em>â€“ <strong>Utilisateur :</strong> Â«Â ChatGPT, qui a gagnÃ© la coupe du monde en 2022 ?Â Â»</em><br>â€“ <em><strong>ChatGPT :</strong> Â«Â Je suis dÃ©solÃ©, mais ma derniÃ¨re mise Ã  jour de connaissances date de septembre 2021, ce qui signifie que je nâ€™ai pas dâ€™informations sur les Ã©vÃ©nements survenus aprÃ¨s cette date.Â Â»</em></p><p><em>On a tous Ã©tÃ© confrontÃ©s un jour ou lâ€™autre Ã  ce problÃ¨me. Heureusement Claire Nouet, co-fondatrice de <a href=\"https://pathway.com/\">Pathway</a>, a la solution. Et câ€™est le sujet de cet article.</em></p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p class=\"has-medium-font-size\"><strong>A propos de Pathway</strong></p><p class=\"has-medium-font-size\"><em>Pathway dÃ©veloppe une technologie dâ€™intelligence artificielle en temps rÃ©el. Lâ€™apprentissage en temps rÃ©el est rendu possible par un moteur de traitement de donnÃ©es, qui alimente les larges modÃ¨les de langage et les modÃ¨les dâ€™apprentissage automatique.</em></p><p class=\"has-medium-font-size\"><em>Ces modÃ¨les sont automatiquement mis Ã  jour. Lâ€™Ã©quipe, dirigÃ©e par Zuzanna Stamirowska, est composÃ©e dâ€™experts de premier plan dans le domaine de lâ€™intelligence artificielle. Parmi eux figurent le CTO Jan Chorowski, co-auteur de Geoff Hinton et Yoshua Bengio, ainsi que le Business Angel Lukasz Kaiser (OpenAI), co-auteur de Tensor Flow et Ã©galement connu comme le Â«Â TÂ Â» dans ChatGPT.</em></p></blockquote><p>Les larges modÃ¨les de langage (LLM) sont la premiÃ¨re technologie ayant abouti commercialement qui soit capable de transformer des volumes importants de donnÃ©es dâ€™apprentissage, permettant Ã  une machine dâ€™agir en imitant ce quâ€™elle a vu dans les donnÃ©es.</p><p>Les LLMs sont entraÃ®nÃ©s sur des donnÃ©es statiques, ce qui rend lâ€™utilisation dâ€™un contexte obligatoire pour pouvoir prendre en compte des informations nouvelles ou corrigÃ©es.</p><p>La taille du contexte Ã©tant limitÃ©e, il est important de nâ€™inclure que les informations les plus pertinentes lors dâ€™une requÃªte, ce qui rend lâ€™utilisation des bases de donnÃ©es vectorielles intÃ©ressante.</p><p>Dans cet article, on explique les notions de contexte et on prÃ©sente une approche vectorielle permettant de contourner ces effets et amÃ©liorer les sorties proposÃ©es.</p><h2 class=\"wp-block-heading\" id=\"h-les-llms-et-la-delicate-gestion-des-mises-a-jour\"><strong>Les LLMs et la dÃ©licate gestion des mises Ã  jour</strong></h2><p>Les modÃ¨les dâ€™apprentissage automatique qui ont Ã©tÃ© entrainÃ©s sur des bases statiques ne peuvent pas sâ€™adapter Ã  des changements arrivant en temps rÃ©el.</p><p>En effet, en raison de la complexitÃ© de la gestion des donnÃ©es temps rÃ©el, les modÃ¨les dâ€™apprentissage automatique sont gÃ©nÃ©ralement entraÃ®nÃ©s sur des donnÃ©es statiques, y compris les LLMs tels que GPT-4 (un des modÃ¨les utilisÃ©s par ChatGPT).</p><p>Cela signifie que leur connaissance est limitÃ©e Ã  un moment donnÃ© dans le passÃ©.</p><p>Contrairement aux humains, les machines ne sont pas dans un Ã©tat dâ€™apprentissage continu et ne peuvent donc pas Â«Â oublierÂ Â» de maniÃ¨re itÃ©rative les informations qui leur ont Ã©tÃ© enseignÃ©es prÃ©cÃ©demment lorsquâ€™elles ne sont plus Ã  jour ou si elles sâ€™avÃ¨rent inexactes.</p><p>Il est extrÃªmement difficile de concevoir des systÃ¨mes efficaces qui combinent Ã  la fois les flux de donnÃ©es historiques et ceux des donnÃ©es en continu.</p><p>Lâ€™exercice est devenu encore plus complexe depuis lâ€™entrÃ©e en scÃ¨ne de lâ€™intelligence artificielle gÃ©nÃ©rative qui nÃ©cessite un apprentissage rapide et sÃ©curisÃ© du contexte afin dâ€™apporter de la valeur et de garantir la confiance des utilisateurs.Â </p><h2 class=\"wp-block-heading\" id=\"h-le-fine-tuning-ne-suffit-pas\"><strong>Le fine-tuning ne suffit pas</strong></h2><p>Le <a href=\"https://larevueia.fr/fine-tuner-chatgpt-grace-a-lapi-dopenai/\" target=\"_blank\" rel=\"noreferrer noopener\">fine-tuning</a> est la spÃ©cialisation dâ€™un modÃ¨le prÃ©-entraÃ®nÃ© grÃ¢ce Ã  un entraÃ®nement superficiel sur des donnÃ©es additionnelles et spÃ©cifiques Ã  un problÃ¨me donnÃ©.</p><p>Le fine-tuning permet de personnaliser un modÃ¨le et de lui faire prendre en compte des mises Ã  jour dont le modÃ¨le initial nâ€™avait pas connaissance.</p><p>NÃ©anmoins cette technique dâ€™apprentissage souffre du mÃªme souci que lâ€™entraÃ®nement standard dâ€™un modÃ¨le : elle se base sur un ensemble de donnÃ©es statiques, ce qui rend difficile une mise Ã  jour en temps rÃ©el, et elle ne permet pas dâ€™oublier des informations.</p><p>Une â€œfake newsâ€ qui serait retirÃ©e de lâ€™ensemble des documents dâ€™entraÃ®nement ne serait pas oubliÃ©e par le modÃ¨le pour autant. Il faudrait refaire le fine-tuning depuis le modÃ¨le dâ€™origine Ã  chaque requÃªte, ce qui est coÃ»teux.</p><h2 class=\"wp-block-heading\" id=\"h-le-contexte-un-facteur-cle\"><strong>Le contexte : un facteur clÃ©</strong></h2><p>Les LLM sont entraÃ®nÃ©s sur des donnÃ©es statiques. Lorsquâ€™il est nÃ©cessaire dâ€™inclure de nouvelles connaissances qui nâ€™ont pas Ã©tÃ© â€œvuesâ€ par un LLM au cours de son entraÃ®nement, la solution consiste Ã  introduire des connaissances nouvelles dans le <strong>contexte</strong> du LLM.</p><p>Cela signifie intÃ©grer ces informations nouvelles dans la question (le â€œpromptâ€). Le LLM utilise ensuite ces connaissances dans leur contexte.</p><p>Les <a href=\"https://arxiv.org/abs/2212.10559\">LLM apprennent bien avec des connaissances â€œIn-contextÂ Â»</a> et lâ€™Ã©tendue des choses quâ€™ils peuvent analyser de cette maniÃ¨re est Ã©tonnamment grande.</p><h2 class=\"wp-block-heading\" id=\"h-les-defis-lies-a-l-apport-de-nouvelles-connaissances-a-un-llm-nbsp\"><strong>Les dÃ©fis liÃ©s Ã  lâ€™apport de nouvelles connaissances Ã  un LLMÂ </strong></h2><p>Un LLM nâ€™a aucun moyen de transfÃ©rer les connaissances de son contexte dans sa Â«Â mÃ©moire Ã  long termeÂ Â». Ce que vous montrez au LLM est donc perdu Ã  la fin de votre Ã©change.</p><p>Par ailleurs, le contexte doit rester assez court, sous peine de voir le LLM se <a href=\"https://arxiv.org/abs/2307.03172v2\">comporter de maniÃ¨re Ã©trange</a>.</p><p>Alors quâ€™un modÃ¨le LLM prÃ©-entraÃ®nÃ© pÃ¨se des dizaines de gigaoctets, son contexte est limitÃ© Ã  quelques milliers de tokens qui peuvent Ãªtre introduits pendant la discussion. Cela correspond au mieux Ã  quelques pages de texte.Â </p><p><strong><em>De fait, dÃ©terminer les informations les plus rÃ©centes et les plus exactes Ã  prÃ©senter Ã  un LLM dans son contexte est devenu lâ€™un des vÃ©ritables dÃ©fis de la crÃ©ation dâ€™applications dâ€™intelligence artificielle en entreprise.</em></strong></p><h2 class=\"wp-block-heading\" id=\"h-gerer-le-contexte-en-temps-reel\"><strong>GÃ©rer le contexte en temps rÃ©el</strong></h2><p>Lâ€™un des principaux problÃ¨mes Ã  rÃ©soudre pour certains besoins mÃ©tier est de construire des systÃ¨mes capables de traiter lâ€™information de maniÃ¨re intelligente et en temps rÃ©el, par exemple pour assembler, traiter et enrichir les donnÃ©es.</p><p>Cela inclut la recherche de documents, pour retrouver des bribes dâ€™informations pertinentes parmi des milliards de documents qui traÃ®nent dans les entrepÃ´ts de donnÃ©es : textes, PDF, wikis internes, courriels, messages sur Teams ou flux de donnÃ©es circulant dans les systÃ¨mes de lâ€™entreprise.</p><p>Une gestion du contexte en temps rÃ©el ouvre la porte Ã  de nombreux cas dâ€™usage :</p><ul class=\"wp-block-list\"><li>Pouvoir poser des questions Ã  un LLM en utilisant une base de connaissances (privÃ©e ou non) frÃ©quemment mise Ã  jour.</li><li>Obtenir des donnÃ©es structurÃ©es en direct Ã  partir de flux temps rÃ©el de documents.</li><li>Surveiller les flux dâ€™informations en temps rÃ©el Ã  lâ€™aide dâ€™un LLM : actualitÃ©s et rÃ©seaux sociaux, dÃ©tection de fake news, perturbations des transportsâ€¦</li></ul><p>Supposons que vous rÃ©cupÃ©riez des mails dans un fil de discussion, ainsi que des courriels sÃ©mantiquement liÃ©s Ã  celui-ci. Par exemple, si quelquâ€™un Ã©crit Â«Â Comment avez-vous pu gÃ¢cher cela ?Â Â», vous ne voulez pas dâ€™exemples sÃ©mantiquement liÃ©s Ã  Â«Â gÃ¢cherÂ Â», vous voulez des documents sÃ©mantiquement liÃ©s au gÃ¢chis (Â«Â celaÂ Â»). Vous devez donc combiner diffÃ©rents types de raisonnement, ce quâ€™il est difficile de faire dans une base de donnÃ©es vectorielle.</p><h2 class=\"wp-block-heading\" id=\"h-les-base-de-donnees-vectorielles-une-necessite\"><strong>Les base de donnÃ©es vectorielles â€“ une nÃ©cessitÃ© ?</strong></h2><p>MalgrÃ© son entraÃ®nement poussÃ©, GPT-4 peut ne pas reconnaÃ®tre certains Ã©lÃ©ments spÃ©cifiques au contexte. Pour y parvenir, la solution consiste donc Ã  ajouter des documents pertinents au contexte : lorsquâ€™un utilisateur envoie une requÃªte, les documents qui lui sont les plus similaires sont rÃ©cupÃ©rÃ©s et ajoutÃ©s au contexte du LLM.</p><p>Câ€™est lÃ  que le rÃ´le dâ€™une base de donnÃ©es vectorielle devient crucial.</p><p>Les bases de donnÃ©es vectorielles permettent une recherche rapide des similaritÃ©s dans de trÃ¨s grands ensembles de donnÃ©es.</p><p>Une base de donnÃ©es vectorielle repose sur un index vectoriel pour organiser et rechercher rapidement les documents.</p><p>En plus de lâ€™index, la base de donnÃ©es fournit toutes les fonctionnalitÃ©s dâ€™une base de donnÃ©es classique. Ces fonctionnalitÃ©s ont un coÃ»t, et il peut Ãªtre judicieux de se contenter dâ€™utiliser lâ€™index au lieu de la base de donnÃ©es complÃ¨te.Â </p><p>Pour les applications LLM, recourir Ã  des index vectoriels peut simplifier lâ€™architecture par rapport aux bases de donnÃ©es vectorielles complÃ¨tes en attachant les vecteurs au stockage dÃ©jÃ  existant. Le choix entre index et bases de donnÃ©es dÃ©pend des besoins spÃ©cifiques, de lâ€™infrastructure existante et des exigences plus larges de lâ€™entreprise.</p><h2 class=\"wp-block-heading\" id=\"h-utiliser-une-base-de-donnees-vectorielles-complete-ou-uniquement-des-index-vectoriels-nbsp\"><strong>Utiliser une base de donnÃ©es vectorielles complÃ¨te ou uniquement des index vectoriels ?Â </strong></h2><p>Les bases de donnÃ©es vectorielles sont utiles lorsque lâ€™on a besoin de toutes les fonctionnalitÃ©s dâ€™une base de donnÃ©es complÃ¨te, et quand une ou plusieurs des conditions suivantes sont rÃ©unies :</p><ul class=\"wp-block-list\"><li>Vous avez un besoin spÃ©cifique de travailler avec des donnÃ©es vectorielles Ã  grande Ã©chelle.Â </li><li>Vous crÃ©ez une application autonome spÃ©cialement conÃ§ue pour les vecteurs</li><li>Vous ne prÃ©voyez pas dâ€™utiliser vos donnÃ©es stockÃ©es dans dâ€™autres types dâ€™applications.</li></ul><p>Les index vectoriels sont utiles lorsquâ€™on a besoin uniquement dâ€™un index auquel on va pouvoir rajouter les opÃ©rations spÃ©cifiques au cas dâ€™usage envisagÃ© (ce qui donnera une solution plus rapide dâ€™exÃ©cution), et que lâ€™une ou plusieurs des conditions suivantes sont rÃ©unies :Â </p><ul class=\"wp-block-list\"><li>Vous ne voulez pas faire confiance Ã  une nouvelle technologie pour le stockage de vos donnÃ©es</li><li>Votre stockage existant est facile dâ€™accÃ¨s depuis Python.</li><li>Votre recherche de similaritÃ© nâ€™est quâ€™une capacitÃ© parmi dâ€™autres besoins de BI et de bases de donnÃ©es plus vastes.Â </li><li>Vous avez besoin de la possibilitÃ© dâ€™attacher des vecteurs (utilisÃ©s pour indexer) aux documents existants.</li><li>Vous avez besoin dâ€™une faÃ§on unifiÃ©e de traiter les pipelines pour votre Ã©quipe dâ€™ingÃ©nierie des donnÃ©es.</li><li>Vous avez besoin de structures dâ€™index et de graphes sur les donnÃ©es pour vous aider dans vos <a href=\"https://github.com/pathwaycom/llm-app\">applications LLM</a> et avoir des pipelines pour vos LLM en production.Â </li><li>Vous avez besoin dâ€™une sortie augmentÃ©e ou dâ€™un contexte augmentÃ© provenant dâ€™autres sources</li><li>Vous voulez crÃ©er des rÃ¨gles Ã  partir de votre corpus qui peuvent sâ€™appliquer Ã  vos donnÃ©es transactionnelles.</li></ul><figure class=\"wp-block-table\"><table><tbody><tr><td><strong>Zoom sur les bases de donnÃ©es vectorielles</strong><br><br>Une base de donnÃ©es vectorielle stocke les donnÃ©es sous forme de vecteurs numÃ©riques dans un espace de coordonnÃ©es. Câ€™est avec ces coordonnÃ©es que seront calculÃ©es les similaritÃ©s entre les documents.Â <br><br>Les vecteurs les plus proches reprÃ©sentent les points de donnÃ©es les plus similaires. Le choix de la similaritÃ© (cosinus, Jaccard, etc.) est donc important car câ€™est la similaritÃ© qui dÃ©terminera les documents retournÃ©s lors dâ€™une recherche.<br><br>Contrairement aux bases de donnÃ©es relationnelles, les bases de donnÃ©es vectorielles sont optimisÃ©es pour les recherches de similaritÃ©s plutÃ´t que pour les requÃªtes ou transactions complexes. Lâ€™extraction de vecteurs similaires prend quelques millisecondes au lieu de quelques minutes, mÃªme pour des milliards de points de donnÃ©es.<br><br>Les bases de donnÃ©es vectorielles construisent des index pour interroger efficacement les vecteurs en fonction de leur proximitÃ©. Cette mÃ©thode est quelque peu analogue Ã  celle utilisÃ©e par les moteurs de recherche textuelle pour indexer les documents en vue dâ€™une recherche rapide.</td></tr></tbody></table></figure><h2 class=\"wp-block-heading\" id=\"h-simplifier-l-architecture-tout-en-ameliorant-le-contexte\"><strong>Simplifier lâ€™architecture tout en amÃ©liorant le contexte</strong></h2><p>Une solution comme <a href=\"https://github.com/pathwaycom/pathway\" target=\"_blank\" rel=\"noreferrer noopener\">Pathway</a> sâ€™adapte automatiquement aux changements et constitue ainsi un outil efficace et performant pour lâ€™indexation de documents en temps rÃ©el et la rÃ©ponse aux requÃªtes.</p><p>Une fois que le corpus est prÃ©-traitÃ© et lâ€™index crÃ©Ã©, Pathway dÃ©tecte automatiquement tout changement dans le rÃ©pertoire des documents et met Ã  jour lâ€™index vectoriel en consÃ©quence.</p><p>Cette rÃ©activitÃ© en temps rÃ©el garantit que les rÃ©ponses de lâ€™application sont toujours basÃ©es sur les informations les plus rÃ©centes et les plus pertinentes disponibles.Â </p><p>Lâ€™architecture de lâ€™application <a href=\"https://github.com/pathwaycom/llm-app\">LLM App</a> de Pathway repose sur le stockage de documents existant dans lâ€™entreprise â€“ aucune base de donnÃ©es vectorielle nâ€™est nÃ©cessaire, grÃ¢ce Ã  son index vectoriel intÃ©grÃ© en mÃ©moire, qui sâ€™adapte automatiquement aux volumes de requÃªtes, et peut-Ãªtre persistant en cas de besoin.</p><p>Elle rÃ©duit Ã©galement la complexitÃ© et les coÃ»ts de lâ€™infrastructure, tout en garantissant la synchronisation avec le corpus de documents.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\"><strong>Conclusion</strong></h2><p>La recherche vectorielle offre aux dÃ©veloppeurs de nouvelles possibilitÃ©s. Au fur et Ã  mesure que les modÃ¨les et les techniques sâ€™amÃ©liorent, il faudra dÃ©sormais sâ€™attendre Ã  ce que les bases de donnÃ©es vectorielles ou les index vectoriels fassent partie intÃ©grante de la stack dâ€™applications.</p></div>"},
{"url": "https://larevueia.fr/fine-tuner-chatgpt-grace-a-lapi-dopenai/", "title": "Fine-tuner ChatGPT grÃ¢ce Ã  lâ€™API dâ€™OpenAI", "author": "Ilyes Talbi", "date": "\n23 aoÃ»t 2023\n", "content": "<div class=\"entry-content\"><p>OpenAI a rendu possible le fine tuning de ChatGPT, via la version GPT-3.5, en aoÃ»t 2023.</p><p>Dans cet article je tâ€™explique tout ce que tu dois savoir et je tâ€™offre mÃªme un petit notebook Google colab Ã  la fin pour que tu puisses le faire toi mÃªme.</p><p>Avant de rentrer dans le vif du sujet, je vais reprendre les bases, expliquer ce quâ€™est le fine-tuning et quand est-ce quâ€™il sera utile dans ce cas lÃ .</p><p>Je donnerais des infos sur le pricing de lâ€™API de ChatGPT pour cette partie (je te rassure câ€™est pas trÃ¨s cher ahah).</p><p>Ensuite je te donne le code python pour :</p><ul class=\"wp-block-list\"><li><strong><em>prÃ©parer ton dataset</em></strong></li><li><strong><em>fine-tuner ChatGPT sur ce dataset</em></strong></li><li><strong><em>utiliser ton modÃ¨le</em></strong></li></ul><h2 class=\"wp-block-heading\">Ce quâ€™il faut savoir</h2><p>Avant de commencer le fine-tuning du modÃ¨le, je vais expliquer ce que câ€™est, quand est-ce quâ€™il est utile. Je parlerais aussi des spÃ©cificitÃ©s liÃ©es Ã  lâ€™API de ChatGPT et de son pricing.</p><h3 class=\"wp-block-heading\">Quâ€™est-ce que le fine-tuning et quand est-ce utile ?</h3><p>En <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, le fine tuning fait rÃ©fÃ©rence Ã  une technique oÃ¹ un modÃ¨le prÃ©-entraÃ®nÃ© sur une grande base de donnÃ©es est ensuite lÃ©gÃ¨rement rÃ©entraÃ®nÃ© (ou affinÃ©) sur un ensemble de donnÃ©es plus petit et spÃ©cifique Ã  une tÃ¢che donnÃ©e.</p><p>Cette mÃ©thode est particuliÃ¨rement utile lorsque lâ€™on dispose de peu de donnÃ©es pour une tÃ¢che spÃ©cifique, car elle permet de bÃ©nÃ©ficier des connaissances gÃ©nÃ©rales acquises par le modÃ¨le lors de son entraÃ®nement initial sur une grande base de donnÃ©es.</p><p>Dans le cas de ChatGPT et des LLM en gÃ©nÃ©ral, le fine tuning sera utile dans les cas oÃ¹ le prompting ne suffit pas et oÃ¹ le modÃ¨le a besoin de plus de connaissances spÃ©cifiques.</p><p>OpenAI prÃ©cise que le fine-tuning doit rester la derniÃ¨re option, lorsque le prompting classique nâ€™a pas suffit.</p><h3 class=\"wp-block-heading\">Combien faut-il de donnÃ©es ?</h3><p>Cette question est important, malheureusement je nâ€™ai pas de rÃ©ponse.</p><p>Ni moi ni personne dâ€™ailleurs, il y a un gros dÃ©bat dans la communautÃ© des chercheurs en deep learning sur les quantitÃ©s de donnÃ©es necÃ©ssaires pour le fine tuning dâ€™un modÃ¨le.</p><p>OpenAI fixe Ã  10 le nombre minimal dâ€™exemples (un exemple est une paire question â€“ rÃ©ponse), mais suggÃ¨re de donner entre 50 et 100 paires question / rÃ©ponse pour avoir de meilleurs rÃ©sultats.</p><h3 class=\"wp-block-heading\">Pricing de lâ€™API pour le fine-tuning</h3><p>Voici le pricing donnÃ© par OpenAI sur son site :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-1024x279.png\" alt=\"Fine-tuner ChatGPT grÃ¢ce Ã  l'API d'OpenAI\" class=\"wp-image-8548\" style=\"width:640px;height:174px\" width=\"640\" height=\"174\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-1024x279.png 1024w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-300x82.png 300w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-768x209.png 768w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45-1536x419.png 1536w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-22-a-23.43.45.png 1600w\" sizes=\"auto, (max-width: 640px) 100vw, 640px\"></figure></div><p>Une Ã©poque dâ€™entraÃ®nement coÃ»te 0.008$ pour 1000 tokens (environ 750 mots).</p><p>Donc un entraÃ®nement sur un dataset de 75000 mots (environ 100k tokens), couterait autour de 0,80$ par Ã©poque. Pour commencer Ã  avoir des rÃ©sultats on va faire 3 Ã©poques en moyenne ce qui fait 2,40$.</p><p>Il faut remarquer aussi que le coÃ»t dâ€™infÃ©rence est environ 2 fois plus cher sur un modÃ¨le fin-tunÃ© que sur le modÃ¨le de base.</p><p>OpenAI propose des outils qui permettent dâ€™Ã©valuer les coÃ»ts de fine-tuning et dâ€™infÃ©rence sur ces modÃ¨les.</p><h2 class=\"wp-block-heading\">Fine-tuner ChatGPT via Python et lâ€™API dâ€™OpenAI</h2><p>Maintenant quâ€™on connaÃ®t le principe du fine-tuning et les spÃ©cificitÃ©s introduites par OpenAI pour ChatGPT, on peut rentrer dans le vif du sujet.</p><h3 class=\"wp-block-heading\">Installation et import des librairies</h3><p>Pour que Ã§a soit plus simple je te conseille dâ€™utiliser Google Colab. Mais tous les codes proposÃ©s fonctionnent en local.</p><p>On commence par installer la librairie dâ€™OpenAI puis importer le module :</p><pre class=\"wp-block-code\"><code>!pip install openai\nimport openai</code></pre><h3 class=\"wp-block-heading\">Setup de la clÃ© API</h3><p>Maintenant, il faut se rendre sur son espace perso OpenAI pour gÃ©nÃ©rer une clÃ© API, et la copier-coller ici :</p><pre class=\"wp-block-code\"><code>openai.api_key = \"VOTRE_CLE_API\"</code></pre><p>Tu peux gÃ©nÃ©rer une clÃ© API <a href=\"https://platform.openai.com/\">ici</a> en allant dans Â«Â PersonalÂ Â» puis Â«Â View API keysÂ Â».</p><p>Sur lâ€™espace perso on peut aussi contrÃ´ler la facturation et fixer des limites de budget. Je conseille de le faire au cas oÃ¹ tu ferais une erreur dans ton code.</p><h3 class=\"wp-block-heading\">PrÃ©paration du dataset</h3><p>On va maintenant prÃ©parer notre dataset.</p><p>Pour cela il faut 2 choses :</p><ul class=\"wp-block-list\"><li><strong><em>crÃ©er un message system qui permet de dÃ©finir le rÃ´le de lâ€™assistant</em></strong></li><li><strong><em>crÃ©er des paires de questions rÃ©ponses</em></strong></li></ul><p>Pour le message system il suffit de dÃ©crire lâ€™assistant que lâ€™on souhaite au final, OpenAI donne lâ€™exemple suivant :</p><pre class=\"wp-block-code\"><code>Marv is a factual chatbot that is also sarcastic.</code></pre><p>En ajoutant les paires questions / rÃ©ponses le fichier dâ€™entraÃ®nement doit ressembler Ã  Ã§a :</p><pre class=\"wp-block-code\"><code>{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n\n{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n\n{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}</code></pre><p>Il faut le mettre dans un fichier .txt avec un exemple par ligne.</p><p>On change ensuite lâ€™extension en .jsonl .</p><p>Donc le fichier de data doit Ãªtre au format json lines (.jsonl), avec un exemple par ligne.</p><p>Je rappel quâ€™il faut au minimum 10 exemples.</p><p>Jâ€™ai appelÃ© mon fichier Â«Â ./train.jsonlÂ Â», je vÃ©rifie que mon fichier est bon en lâ€™enregistrant sur le server dâ€™OpenAI, ce code va me donner un id de fichier qui sera utilisÃ© au moment de lâ€™entraÃ®nement :</p><pre class=\"wp-block-code\"><code>openai.File.create(\n  file=open(\"./train.jsonl\", \"rb\"),\n  purpose='fine-tune'\n)</code></pre><h3 class=\"wp-block-heading\">Fine-tuner ChatGPT</h3><p>Une fois que le dataset est prÃªt et que lâ€™on a notre id de fichier, on lance le fine-tuning de cette maniÃ¨re :</p><pre class=\"wp-block-code\"><code>openai.FineTuningJob.create(training_file=\"VOTRE_FILE_ID\", model=\"gpt-3.5-turbo\")</code></pre><p>Le fine-tuning prend un peu de temps mais le code sâ€™execute en arriÃ¨re plan sur les serveurs dâ€™OpenAI. Tu recevras un email avec lâ€™id du modÃ¨le une fois celui-ci entraÃ®nÃ©.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-1024x500.png\" alt=\"Fine-tuner ChatGPT grÃ¢ce Ã  l'API d'OpenAI\" class=\"wp-image-8554\" style=\"width:662px;height:323px\" width=\"662\" height=\"323\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-1024x500.png 1024w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-300x146.png 300w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-768x375.png 768w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13-1536x749.png 1536w, https://larevueia.fr/wp-content/uploads/2023/08/Capture-decran-2023-08-23-a-00.33.13.png 1600w\" sizes=\"auto, (max-width: 662px) 100vw, 662px\"></figure></div><p>Une fois le ou le(s) modÃ¨le(s) entraÃ®nÃ©(s), on peut retrouver les informations avec ce code :</p><pre class=\"wp-block-code\"><code>openai.FineTuningJob.list(limit=10)</code></pre><h3 class=\"wp-block-heading\">Utilisation du modÃ¨le fine-tunÃ©</h3><p>Une fois lâ€™email reÃ§u avec lâ€™id de modÃ¨le (la partie avec les Ã©toiles sera incluse dans lâ€™email), on peut lâ€™utiliser comme Ã§a :</p><pre class=\"wp-block-code\"><code>completion = openai.ChatCompletion.create(\n  model=\"ft:gpt-3.5-turbo-************\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello! Descripe yourself in simple words\"}\n  ]\n)\n\nprint(completion.choices[0].message)</code></pre><p>VoilÃ , tu sais maintenant comment fine-tuner ChatGPT, jâ€™espÃ¨re que tu vas pouvoir crÃ©er des choses intÃ©ressantes, nâ€™hÃ©site pas Ã  me contacter sur <a href=\"https://www.linkedin.com/in/ilyes-talbi/\" target=\"_blank\" rel=\"noreferrer noopener\">Linkedin</a> si besoin.</p><p>Et comme promis, voici le lien du <a href=\"https://colab.research.google.com/drive/1ZA1RrHJc8B3ighY57mdaQHKFI4weW5P9?usp=sharing\">Colab</a>.</p></div>"},
{"url": "https://larevueia.fr/api-midjourney/", "title": "Comment utiliser lâ€™API de Midjourney avec Python ?", "author": "Ilyes Talbi", "date": "\n4 mai 2024\n", "content": "<div class=\"entry-content\"><p>Dans cet article je vous explique comment utiliser lâ€™API de Midjourney dans vos codes Python grÃ¢ce au service <a href=\"https://www.mymidjourney.ai/\">MyMidjourney</a>.</p><p>La gÃ©nÃ©ration dâ€™images est devenue en quelques mois une des techniques les plus performantes et abouties en <a href=\"https://larevueia.fr/introduction-a-lintelligence-artificielle-generative/\">IA gÃ©nÃ©rative</a>. Son principe est simple : transformer un texte (ou un prompt) en image.</p><p>De nombreux outils sont disponibles sur le marchÃ©, comme Dalle-3, Stable diffusion ou encore Leonardo. Mais le plus performant et impressionnant aujourdâ€™hui est de loin Midjourney.</p><p>La plupart des outils mentionnÃ©s sont disponibles sous forme dâ€™API faciles Ã  intÃ©grer en Python. Dalle-3 via la librairie <a href=\"https://pypi.org/project/openai/0.26.5/\">openai</a>. De mÃªme stable diffusion et Leonardo sont disponibles sans problÃ¨me avec des API officielles.</p><p>Midjourney est utilisable exclusivement sur Discord et il nâ€™y a ni dâ€™API ni de web app accessible pour cet outil. Une stratÃ©gie assez curieuse de la part des fondateurs de Midjourney mais qui a quand mÃªme lâ€™air de bien payer pour le moment.</p><p>Certains services ont Ã©mergÃ©s pour rÃ©soudre ce problÃ¨me et proposent des API non-officielle de Midjourney qui sont codÃ©es Ã  lâ€™aide de bot qui permettent lâ€™automatisation de lâ€™utilisation de Discord.</p><h2 class=\"wp-block-heading\">Fonctionnement de lâ€™API de Midjourney</h2><p>Lâ€™API de Midjourney proposÃ©e par MyMidjourney fonctionne via lâ€™automatisation de tÃ¢ches sur la plateforme Discord.</p><p>Lorsquâ€™une requÃªte est envoyÃ©e câ€™est le comportement dâ€™un utilisateur de Midjourney qui est simulÃ©. Exactement comme si quelquâ€™un tapait sur Discord la requÃªte Â«Â <em><strong>/imagine prompt</strong></em>Â«Â .</p><p>Il faut ensuite simuler le fait dâ€™appuyer sur un des boutons de lâ€™UI :</p><ul class=\"wp-block-list\"><li>U1, U2, U3, U4, pour upscaler une des images</li><li>V1, V2, V3, V4, pour faire varier une des images</li></ul><p>Une fois que ces Ã©tapes sont rÃ©alisÃ©es il ne reste plus quâ€™Ã  rÃ©cupÃ©rer le lien de lâ€™image et la tÃ©lÃ©charger.</p><h2 class=\"wp-block-heading\">Pricing de lâ€™API de Midjourney</h2><p>La tarification de MyMidjourney offre aux utilisateurs une gamme de plans adaptÃ©s Ã  leurs besoins, avec des frÃ©quences de paiement mensuelles ou annuelles.</p><p>Le Plan Standard Ã  30 $ par mois fournit un point de dÃ©part complet pour explorer lâ€™API de Midjourney, offrant des capacitÃ©s de gÃ©nÃ©ration dâ€™images complÃ¨tes avec jusquâ€™Ã  100 gÃ©nÃ©rations par mois, un processus dâ€™installation facile et des instructions dâ€™utilisation claires.</p><p>Pour ceux qui ont des besoins plus importants pour lâ€™API de Midjourney, le Plan Pro Ã  45 $ par mois dÃ©bloque des fonctionnalitÃ©s avancÃ©es telles que des gÃ©nÃ©rations illimitÃ©es, la possibilitÃ© dâ€™utiliser son propre compte Discord/Midjourney, et la gestion de plusieurs comptes pour une meilleure gestion.</p><p>MyMidjourney offre la possibilitÃ© dâ€™avoir un serveur dÃ©diÃ© qui offre un service prioritaire avec une infrastructure dÃ©diÃ©e, un support rapide et efficace, et des files dâ€™attente de traitement plus rapides pour des gÃ©nÃ©rations dâ€™images accÃ©lÃ©rÃ©es.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"692\" src=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-1024x692.png\" alt=\"pricing de l'API de Midjourney\" class=\"wp-image-8741\" style=\"width:771px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-1024x692.png 1024w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-300x203.png 300w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-768x519.png 768w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02-1250x845.png 1250w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.34.02.png 1265w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Les utilisateurs peuvent choisir dâ€™utiliser leur propre compte Midjourney ou de bÃ©nÃ©ficier de lâ€™assistance de MyMidjourney pour en configurer un. Il convient de noter que des frais supplÃ©mentaires sâ€™appliquent lorsque plusieurs comptes Discord sont liÃ©s au systÃ¨me.</p><p>Enfin, les quotas de gÃ©nÃ©ration dâ€™images varient en fonction du plan Midjourney de lâ€™utilisateur lors de la liaison, avec une limite de 600 gÃ©nÃ©rations par mois dans le cas contraire.</p><h2 class=\"wp-block-heading\">Utilisation de lâ€™API de Midjourney avec Python</h2><p>Vous allez avoir besoin dâ€™une clÃ© API pour lancer des requÃªtes sur MyMidjourney. Il faudra pour cela crÃ©er votre compte sur <a href=\"https://www.mymidjourney.ai/\" rel=\"nofollow\">leur site</a>. Puis cliquer sur votre image de profil en haut Ã  droite, puis Â«Â SetupÂ Â» :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"237\" height=\"198\" src=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.27.06.png\" alt=\"Rubrique setup MyMidjourney\" class=\"wp-image-8739\" style=\"width:237px;height:auto\"></figure></div><p>Une fois dans la page setup vous trouverez la rubrique Â«Â Your MyMidjourney TokenÂ Â», câ€™est votre clÃ© API. Copiez-lÃ  et garder la secrÃ¨te (dans un fichier .env de prÃ©fÃ©rence) :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"513\" src=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-1024x513.png\" alt=\"Votre clÃ© API pour l'API de Midjourney\" class=\"wp-image-8738\" style=\"width:604px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-1024x513.png 1024w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-300x150.png 300w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32-768x385.png 768w, https://larevueia.fr/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-00.25.32.png 1053w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Comme Ã©voquer Ã  la premiÃ¨re partie, la gÃ©nÃ©ration dâ€™une image se fait en plusieurs Ã©tapes. Ces Ã©tapes correspondent Ã  plusieurs endpoints quâ€™il faut appeler un par un :</p><ul class=\"wp-block-list\"><li>Le premier permet de lancer la gÃ©nÃ©ration de lâ€™image :<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/imagine</li><li>Il prend en entrÃ©e un prompt et nÃ©cessite votre clÃ© API</li><li>Il vous renverra un id de gÃ©nÃ©ration quâ€™il faut conserver</li></ul></li><li>Le second endpoint permet de vÃ©rifier le status de la gÃ©nÃ©ration :<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/message/{message_id}</li><li>Il prend en entrÃ©e un message ID qui correspond Ã  lâ€™ID de la gÃ©nÃ©ration obtenu aprÃ¨s lâ€™appel du premier endpoint, et nÃ©cessite une clÃ© API aussi</li><li>Ils vous renverra les informations sur le status de la gÃ©nÃ©ration (en attente, en cours, Ã©chec ou terminÃ©e)</li></ul></li><li>Le troisiÃ¨me endpoint permet de simuler un clic comme lorsque lâ€™on utilise Midjourney via Discord :<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/button</li><li>Il prend en entrÃ©e le message id et le nom du bouton sur lequel on veut cliquer</li><li>Il renverra une rÃ©ponse de status</li></ul></li><li>Enfin, le dernier endpoint de lâ€™API de Midjourney permet de rÃ©cupÃ©rer lâ€™URL de lâ€™image gÃ©nÃ©rÃ©e<ul class=\"wp-block-list\"><li>Le endpoint : https://api.mymidjourney.ai/api/v1/midjourney/message/{message_id}</li><li>Il prend en entrÃ©e le message id et renvoi lâ€™URL de lâ€™image gÃ©nÃ©rÃ©e</li></ul></li></ul><p>Pour coder Ã§a en python, on commence par les imports et dÃ©finir les liens des endpoints :</p><pre class=\"wp-block-code\"><code>import requests\nimport time\n\n# Constants\nGENERATION_API_URL = \"https://api.mymidjourney.ai/api/v1/midjourney/imagine\"\nRESULTS_API_URL = \"https://api.mymidjourney.ai/api/v1/midjourney/message/\"\nBUTTON_API_URL = \"https://api.mymidjourney.ai/api/v1/midjourney/button\"\n</code></pre><p>On va maintenant dÃ©finir le header qui contient la clÃ© API une bonne fois pour toutes :</p><pre class=\"wp-block-code\"><code>AUTHORIZATION_TOKEN = \"VOTRE CLÃ‰ pour l'API de Midjourney\"\n# Headers for requests\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": AUTHORIZATION_TOKEN\n}</code></pre><p>On Ã©crit aussi, une bonne fois pour toutes, la fonction qui permet dâ€™appeler les diffÃ©rents endpoints :</p><pre class=\"wp-block-code\"><code>def make_request(url, method='get', data=None):\n    try:\n        if method == 'post':\n            response = requests.post(url, json=data, headers=HEADERS)\n        else:\n            response = requests.get(url, headers=HEADERS)\n        response.raise_for_status()\n        print(f\"Request successful: {response.json()}\")\n        return response.json()\n    except requests.exceptions.RequestException as e:\n        print(f\"Request error: {e}\")\n        return None</code></pre><p>Les appels des diffÃ©rents endpoints sont faits de cette maniÃ¨re :</p><pre class=\"wp-block-code\"><code># Lancer la gÃ©nÃ©ration\ndef launch_generation(prompt):\n    data = {\"prompt\": prompt}\n    response = make_request(GENERATION_API_URL, 'post', data)\n    if response:\n        print(f\"Request successful: {response}\")\n        return response.get(\"messageId\")\n    else:\n        print(\"Request failed\")\n        return None\n\n# RÃ©cupÃ©rer de le status de gÃ©nÃ©ration\ndef get_status_from_message_id(message_id):\n    url = RESULTS_API_URL + message_id\n    response = make_request(url)\n    if response:\n        print(f\"Request successful: {response}\")\n        return response.get(\"status\")\n    else:\n        print(\"Request failed\")\n        return None\n\n# Cliquer sur un bouton\ndef click_button(message_id, button):\n    data = {\n        \"messageId\": message_id,\n        \"button\": button\n    }\n    response = make_request(BUTTON_API_URL, 'post', data)\n    if response:\n        print(f\"Request successful: {response}\")\n        return response.get(\"messageId\")\n    else:\n        print(\"Request failed\")\n        return None\n\n# RÃ©cupÃ©rer l'URL de l'image\ndef get_image_from_message_id(message_id):\n    url = RESULTS_API_URL + message_id\n    response = make_request(url)\n    if response:\n        print(f\"Request successful: {response}\")\n    else:\n        print(\"Request failed\")\n    return response.get(\"uri\") if response else None</code></pre><p>Comme lâ€™API de Midjourney nâ€™a pas de webhook, on doit utiliser des boucles while et des time.sleep pour attendre la fin de chaque Ã©tape, jâ€™ai dÃ©cidÃ© de le coder de cette maniÃ¨re :</p><pre class=\"wp-block-code\"><code>def generate_image_my_midjourney(prompt):\n\n    prompt += \" --v 6.0 --ar 16:9\"\n    message_id = launch_generation(prompt)\n    if not message_id:\n        return \"Failed to launch image generation\"\n\n    # Wait for the status to be 'DONE'\n    while True:\n        status = get_status_from_message_id(message_id)\n        if status == \"DONE\":\n            break\n\n    # Click the button and wait for the new message ID\n    message_id_after_click = None\n    while not message_id_after_click:\n        message_id_after_click = click_button(message_id, \"U1\")\n\n    print(\"Sleeping 10 seconds\")\n    time.sleep(10)\n    # Retrieve the final image URI\n    uri = None\n    while not uri:\n        uri = get_image_from_message_id(message_id_after_click)\n\n    return uri</code></pre><p>Ã€ la premiÃ¨re ligne jâ€™ajoute : Â Â» â€“v 6.0 â€“ar 16:9â€³ câ€™est la syntaxe qui permet de spÃ©cifier des paramÃ¨tres Ã  lâ€™API de Midjourney pour la gÃ©nÃ©ration.</p><p>Ici par exemple je lui demande dâ€™utiliser Midjourney V6 et de gÃ©nÃ©rer des images avec un ratio de 16:9.</p><p>Pour gÃ©nÃ©rer une image on va simplement appeler cette derniÃ¨re fonction avec le prompt voulu et on rÃ©cuperera en quelques secondes lâ€™output sous forme dâ€™URL :</p><pre class=\"wp-block-code\"><code>generate_image_my_midjourney(\"MbappÃ© inside the Parc des Princes\")</code></pre><p>Si vous avez des problÃ¨mes de blocage de prompt trop rÃ©guliÃ¨rement, vous pouvez mettre Ã  jour la liste des mots bannis par lâ€™API de Midjourney avec cette syntaxe :</p><pre class=\"wp-block-code\"><code>import requests\n\n# Bearer token for authorization\nbearer_token = \"VOTRE CLÃ‰ API\"\n\n# URL for the API endpoint\nurl = 'https://api.mymidjourney.ai/api/v1/discord/banwords/save'\n\n# Headers including the authorization token\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {bearer_token}'\n}\n\n# Liste des mots que vous voulez bannir, la liste peut Ãªtre vide comme ici\nban_words = [\n]\n\n# Data payload to be sent\npayload = {\n    'list': ban_words\n}\n\n# Making the POST request\nresponse = requests.post(url, json=payload, headers=headers)\n\n# Check if the request was successful\nif response.status_code == 200:\n    print(\"Ban list updated successfully!\")\n    print(\"Updated list:\", response.json())\nelse:\n    print(\"Failed to update ban list.\")\n    print(\"Status Code:\", response.status_code)\n    print(\"Response:\", response.text)\n</code></pre><h2 class=\"wp-block-heading\">Conclusion</h2><p><em>Disclaimer : lâ€™API de Midjourney que jâ€™ai prÃ©sentÃ© ici nâ€™est pas officielle et pensez Ã  vÃ©rifier que les conditions dâ€™utilisation de Midjourney et Discord vous permettent de lâ€™utiliser.</em></p><p>Cette API est assez performante globalement et le pricing est plutÃ´t raisonnable lorsque lâ€™on compte lâ€™utiliser assez rÃ©guliÃ¨rement.</p><p>Je vous ai montrÃ© uniquement la gÃ©nÃ©ration dâ€™image dans cet article mais sachez que toutes les fonctionnalitÃ©s de Midjourney sont proposÃ©es sous forme dâ€™API, comme lâ€™inpainting par exemple.</p><p>Lâ€™expÃ©rience de developpement nâ€™est pas optimale puisquâ€™on nâ€™a pas de webhook disponible et on doit multiplier les appels vers les diffÃ©rents endpoints. Mais au final, quand on comprend le rÃ´le de chaque endpoint on sâ€™en sort plutÃ´t bien.</p></div>"},
{"url": "https://larevueia.fr/les-cas-dusages-de-lia-dans-limmobilier/", "title": "Les cas dâ€™usages de lâ€™IA dans lâ€™immobilier", "author": "Ilyes Talbi", "date": "\n11 mars 2025\n", "content": "<div class=\"entry-content\"><p>Lâ€™intelligence artificielle transforme en profondeur le secteur immobilier, de lâ€™estimation dâ€™un bien jusquâ€™Ã  lâ€™amÃ©nagement urbain.</p><p>Lâ€™adoption de lâ€™IA dans lâ€™immobilier sâ€™accÃ©lÃ¨re. Selon JLL, seules 7Â % des sociÃ©tÃ©s immobiliÃ¨res utilisaient lâ€™IA en 2024, on atteindrait <strong>10Â % dâ€™ici fin 2025</strong>. (<a href=\"https://www.flatsy.fr/blog/intelligence-artificielle-immobilier/\" target=\"_blank\" rel=\"noreferrer noopener\">Flatsy</a>).</p><p>Lâ€™objectif de cet article est de proposer un tour dâ€™horizon des principaux usages de lâ€™IA dans lâ€™immobilier. On proposera des exemples concrets, les tendances actuelles et les perspectives dâ€™avenir.<a href=\"https://www.flatsy.fr/blog/intelligence-artificielle-immobilier/#:~:text=Au%20cours%20des%20cinq%20derni%C3%A8res,d%E2%80%99ici%20fin%202025\" target=\"_blank\" rel=\"noreferrer noopener\"></a></p><h2 class=\"wp-block-heading\" id=\"h-evaluation-et-estimation-des-prix-des-biens\">Ã‰valuation et estimation des prix des biens</h2><p>Ã‰valuer prÃ©cisÃ©ment la valeur dâ€™un bien immobilier est un dÃ©fi complexe. Lâ€™IA apporte des solutions <strong>dâ€™estimation automatisÃ©e</strong> trÃ¨s performantes. En analysant une multitude de donnÃ©es (ventes rÃ©centes, localisation, caractÃ©ristiques du bien, tendances du marchÃ©), les algorithmes peuvent fournir des estimations de prix <em>fiables et objectives</em>â€‹.</p><p>Ces systÃ¨mes surpassent souvent lâ€™expertise humaine en prÃ©cision. GrÃ¢ce Ã  leur capacitÃ© Ã  croiser des centaines de critÃ¨res sans biais dâ€™interprÃ©tationâ€‹, tout en optimisant le temps dâ€™analyse.</p><p>Aux Ã‰tats-Unis, la plateforme <a href=\"https://www.zillow.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Zillow</a> utilise un <a href=\"https://larevueia.fr/comprendre-les-reseaux-de-neurones/\" target=\"_blank\" rel=\"noreferrer noopener\">rÃ©seau de neurones</a> (lâ€™outil <em>Zestimate</em>) pour estimer la valeur des maisons en tenant compte de la saisonnalitÃ© et des tendances localesâ€‹.</p><figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"494\" src=\"https://larevueia.fr/wp-content/uploads/2025/03/zillow.webp\" alt=\"L'IA dans l'immobilier : la plateforme Zillow\" class=\"wp-image-8898\" srcset=\"https://larevueia.fr/wp-content/uploads/2025/03/zillow.webp 800w, https://larevueia.fr/wp-content/uploads/2025/03/zillow-300x185.webp 300w, https://larevueia.fr/wp-content/uploads/2025/03/zillow-768x474.webp 768w\" sizes=\"auto, (max-width: 800px) 100vw, 800px\"><figcaption class=\"wp-element-caption\">Lâ€™IA dans lâ€™immobilier : la plateforme Zillow</figcaption></figure><p>Les performances de prÃ©dictions se sont nettement amÃ©liorÃ©esÂ sur les derniÃ¨res annÃ©es. Lâ€™erreur mÃ©diane nâ€™est plus que dâ€™environ <strong>2,4Â %</strong> pour les biens en vente (et ~7,5Â % hors marchÃ©)â€‹. Lâ€™Ã©cart Ã©tant dÃ» principalement Ã  la quantitÃ© dâ€™accÃ¨s aux data pour un bien donnÃ©.</p><p>En France, des fintechs comme Homiwoo ou des sites dâ€™annonces intÃ¨grent Ã©galement des modÃ¨les prÃ©dictifs afin dâ€™aider agents et propriÃ©taires Ã  fixer un prix <em>Â«Â juste et compÃ©titifÂ Â»</em> tout en anticipant lâ€™Ã©volution du marchÃ©â€‹.</p><p>De plus, lâ€™IA ne se contente pas dâ€™une photo Ã  lâ€™instant <em>t</em>. Elle peut rÃ©aliser des <strong>analyses prÃ©dictives</strong> pour projeter la valeur dâ€™un bien dans le futur selon divers scÃ©narios Ã©conomiquesâ€‹.</p><p>Cette capacitÃ© de <em>forecast</em> est prÃ©cieuse pour les investisseurs qui fondent leurs dÃ©cisions sur le long terme.</p><p>Lâ€™estimation immobiliÃ¨re par IA va continuer de gagner en finesse Ã  mesure que de nouvelles sources de donnÃ©es sont exploitÃ©es (images satellite, donnÃ©es socio-Ã©conomiques en temps rÃ©el, etc.). Les professionnels anticipent des Ã©valuations instantanÃ©es toujours plus prÃ©cises et personnalisÃ©es, tout en restant vigilants sur la qualitÃ© des donnÃ©es pour Ã©viter les biais algorithmiques.</p><h2 class=\"wp-block-heading\" id=\"h-assistance-administrative-pour-les-transactions-immobilieres\">Assistance administrative pour les transactions immobiliÃ¨res</h2><p>Les transactions immobiliÃ¨res impliquent de nombreuses Ã©tapes administratives et juridiques oÃ¹ lâ€™IA peut apporter rapiditÃ© et fiabilitÃ©. Par exemple, des algorithmes de traitement de documents peuvent vÃ©rifier automatiquement les contrats, dÃ©tecter des anomalies ou incohÃ©rences et ainsi prÃ©venir les fraudesâ€‹.</p><p>De mÃªme, un systÃ¨me dâ€™IA saura signaler une clause manquante ou un paiement suspect dans un compromis de vente, Ã©vitant des erreurs coÃ»teuses.</p><p>Par ailleurs, certaines solutions analysent les dossiers des acheteurs/locataires (piÃ¨ces dâ€™identitÃ©, bulletins de salaire, etc.) pour repÃ©rer dâ€™Ã©ventuels faux documents, ce qui sÃ©curise les transactions en amontâ€‹.</p><p>Lâ€™IA permet aussi la <strong>gÃ©nÃ©ration automatique de documents juridiques</strong>. Ã€ partir de formulaires, le systÃ¨me peut rÃ©diger un bail ou un contrat conforme aux normes instantanÃ©ment.</p><p>On peut sâ€™attendre Ã  ce que dâ€™ici quelques annÃ©es, finaliser une transaction devienne beaucoup plus rapide et transparent. Lâ€™IA prenant en charge la vÃ©rification et la rÃ©daction, et les <em>smart contracts</em> lâ€™exÃ©cution sÃ©curisÃ©e.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-l-immobilier-pour-le-marketing-et-la-recherche-de-clients\">Lâ€™IA dans lâ€™immobilier pour le marketing et la recherche de clients</h2><p>Attirer des prospects et les convertir en clients est un domaine oÃ¹ lâ€™IA excelle grÃ¢ce Ã  la personnalisation.</p><p>Les agences et portails immobiliers exploitent lâ€™IA pour <em>gÃ©nÃ©rer des leads qualifiÃ©s</em>, cibler leur publicitÃ© et mieux cerner les prÃ©fÃ©rences des acheteursÂ :</p><ul class=\"wp-block-list\"><li><strong>Chatbots et assistants virtuels 24/7Â :</strong> Sur les sites dâ€™agences, des chatbots conversationnels accueillent les visiteurs en continu. Ils rÃ©pondent instantanÃ©ment aux questions frÃ©quentes (disponibilitÃ© dâ€™un bien, organiser une visite, etc.) et collectent au passage des informations sur le prospect.<br><br>Ainsi, un visiteur intÃ©ressÃ© par un appartement pourra obtenir les premiers renseignements via le bot. Enregistrant au passage ses critÃ¨res de recherche.<br><br>Si le prospect est qualifiÃ© (budget, projet sÃ©rieux), le chatbot peut le rediriger automatiquement vers une prise de rendez-vous avec un agent. Ces assistants virtuels font gagner du temps aux professionnels tout en offrant une rÃ©activitÃ© apprÃ©ciÃ©e des clients.</li><li><strong>Analyse des comportements en ligne</strong>. Chaque clic, chaque bien consultÃ© sur un site immobilier est une donnÃ©e que lâ€™IA analyse pour Ã©valuer un internauteâ€‹.<br><br>Si un utilisateur passe beaucoup de temps sur des annonces de studios dans tel quartier, le systÃ¨me peut en conclure ses critÃ¨res favoris (type de bien, localisation) et adapter en temps rÃ©el le contenu affichÃ© pour lui (biens similaires, promotions ciblÃ©es)â€‹.<br><br>Cette comprÃ©hension fine du parcours client permet dâ€™orienter le prospect vers les offres les plus pertinentes, augmentant les chances de conversion.</li><li><strong>Segmentation et ciblage marketing</strong>. Lâ€™IA aide Ã  segmenter automatiquement la base de prospects en groupes homogÃ¨nes selon leur profil. Par exemple par budget, type de bien recherchÃ©, ou localisation souhaitÃ©e.<br><br>Chaque segment reÃ§oit alors un message publicitaire adaptÃ© (luxe pour les hauts budgets, appartements familiaux pour les jeunes parents, etc.). Cette personnalisation des campagnes maximise leur impact, avec des relances <em>sur-mesure</em> pour chaque catÃ©gorie de clientâ€‹.<br><br>De plus, en croisant ces segments avec des donnÃ©es externes (dÃ©mographie, intention dâ€™achat dÃ©tectÃ©e sur les rÃ©seaux sociaux), lâ€™IA peut aider Ã  <strong>cibler la publicitÃ©</strong> vers les personnes ayant le plus fort potentiel (par exemple, identifier dans une zone les locataires ayant 90Â % de chances de vouloir acheter sous peu, et leur diffuser une annonce spÃ©cifique).</li><li><strong>Recommandations personnalisÃ©es de biens</strong>. Les mÃªmes techniques de machine learning permettent de suggÃ©rer automatiquement Ã  chaque prospect des biens susceptibles de lui plaire. Câ€™est un atout marketing pour garder lâ€™attention de lâ€™utilisateur et lâ€™amener Ã  concrÃ©tiser. <em>(Nous dÃ©taillons ce point plus loin.)</em></li><li><strong>Automatisation des relances commercialesÂ :</strong> Lâ€™IA optimise aussi le <em>timing</em> et le contenu des communications marketing. Elle peut dÃ©terminer <strong>le meilleur moment d</strong>â€˜<strong>envoi dâ€™email</strong> Ã  un prospect en se basant sur ses habitudes dâ€™ouverture des messagesâ€‹.<br><br>Un systÃ¨me intelligent va programmer lâ€™envoi dâ€™une nouvelle annonce le matin si câ€™est Ã  cette heure que le client consulte ses mails, amÃ©liorant ainsi le taux dâ€™engagementâ€‹.<br><br>De mÃªme, lâ€™IA peut gÃ©nÃ©rer automatiquement le texte dâ€™un mail ou dâ€™une annonce en adaptant le ton et les arguments aux intÃ©rÃªts perÃ§us du client (certains outils dâ€™IA gÃ©nÃ©rative savent dÃ©jÃ  rÃ©diger des annonces immobiliÃ¨res attrayantes ou crÃ©er des visuels de <em>home staging</em> virtuel Ã  partir de photos).</li></ul><p>Lâ€™IA dans lâ€™immobilier appliquÃ©e au marketing porte ses fruits. Elle amÃ©liore lâ€™expÃ©rience utilisateur et permet aux professionnels dâ€™augmenter Ã  la fois le taux de conversion et la fidÃ©lisation de leur clientÃ¨leâ€‹.</p><p>En pratique, cela se traduit par plus de contacts qualifiÃ©s gÃ©nÃ©rÃ©s. Un suivi plus rÃ©actif (grÃ¢ce aux bots). Des campagnes publicitaires au ROI accru. Une agence qui adopte ces outils peut vendre plus vite<em>,</em> moins cher (moins de coÃ»ts marketing gaspillÃ©s hors cible).</p><p>Ã€ lâ€™avenir, on peut sâ€™attendre Ã  une <strong>hyper-personnalisation</strong> du marketing immobilier. Les plateformes pourront anticiper les besoins des clients avant mÃªme quâ€™ils les expriment (grÃ¢ce au <em>machine learning</em> prÃ©dictif).</p><p>Lâ€™IA gÃ©nÃ©rative pourrait crÃ©er des visites virtuelles sur mesure. Le client pourrait demander Ã  voir le bien avec une dÃ©coration diffÃ©rente ou un amÃ©nagement optimisÃ©, et obtenir le visuel en temps rÃ©el.</p><p>Ces innovations garderont lâ€™humain au centre (le conseiller immobilier reste vital pour conclure et accompagner). Mais elles doteront les professionnels dâ€™<strong>outils efficaces</strong> pour capter et convaincre les acheteurs.</p><h2 class=\"wp-block-heading\" id=\"h-gestion-locative-optimisee-et-maintenance-predictive\">Gestion locative optimisÃ©e et maintenance prÃ©dictive</h2><p>Administrer des biens en location implique de multiples tÃ¢ches rÃ©pÃ©titives et une vigilance sur lâ€™Ã©tat du patrimoine.</p><p>Lâ€™IA dans lâ€™immobilier intervient de plus en plus pour <strong>faciliter la gestion locative</strong> au quotidien et anticiper les problÃ¨mes techniques avant quâ€™ils ne surviennent.</p><ul class=\"wp-block-list\"><li><strong>SÃ©lection des locataires et gestion des dossiers</strong>. Confier lâ€™analyse des candidatures Ã  une IA fait gagner un temps prÃ©cieux aux gestionnaires. Des outils peuvent vÃ©rifier automatiquement les piÃ¨ces justificatives des candidats (bulletins de salaire, piÃ¨ces dâ€™identitÃ©, avis dâ€™impositionâ€¦) et dÃ©tecter dâ€™Ã©ventuelles anomalies ou faux documents.<br><br>Par exemple, la startup toulousaine <a href=\"https://www.eazyrent.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">EazyRent</a> analyse grÃ¢ce Ã  lâ€™IA lâ€™authenticitÃ© et la cohÃ©rence des documents fournis par un candidat locataire, signalant en quelques secondes un dossier frauduleux.</li></ul><figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"535\" src=\"https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1024x535.png\" alt=\"L'IA dans l'immobilier EazyRent\" class=\"wp-image-8895\" srcset=\"https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1024x535.png 1024w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-300x157.png 300w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-768x402.png 768w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1536x803.png 1536w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11-1250x653.png 1250w, https://larevueia.fr/wp-content/uploads/2025/03/Screenshot-2025-03-11-at-00.14.11.png 1689w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Lâ€™IA dans lâ€™immobilier : la startup EazyRent</figcaption></figure><ul class=\"wp-block-list\"><li><strong>Optimisation des loyers et du taux dâ€™occupation</strong>. Fixer le loyer â€œjusteâ€ est une tÃ¢che dÃ©licate. Lâ€™IA peut aider les propriÃ©taires Ã  dÃ©terminer le loyer optimal dâ€™un logement en fonction de la demande en temps rÃ©el, de la saison, et des prix pratiquÃ©s dans le voisinage.<br><br>Elle peut analyser des milliers dâ€™annonces et de baux, un algorithme pourra recommander dâ€™ajuster lÃ©gÃ¨rement le loyer Ã  la baisse pour remplir plus vite une vacance, ou au contraire de le monter si la demande locale est forte, afin de maximiser le rendement sans perdre en compÃ©titivitÃ©.<br><br>Ces <strong>algorithmes de yield management</strong> (inspirÃ©s de lâ€™hÃ´tellerie) permettent dâ€™amÃ©liorer la rentabilitÃ© locative tout en assurant un haut taux dâ€™occupation des biens. Ã€ grande Ã©chelle (portefeuilles de centaines de logements), ce pilotage dynamique des loyers peut augmenter sensiblement les revenus des bailleurs.</li><li><strong>Maintenance prÃ©dictive des Ã©quipementsÂ :</strong> En Ã©quipant les immeubles de capteurs (ascenseurs connectÃ©s, chaudiÃ¨res, compteurs intelligentsâ€¦), lâ€™IA peut surveiller en continu lâ€™Ã©tat des installations et <strong>anticiper les pannes</strong> avant quâ€™elles nâ€™arrivent.<br><br>ConcrÃ¨tement, une plateforme IoT peut analyser la tempÃ©rature et les vibrations dâ€™une chaudiÃ¨reÂ ; en dÃ©tectant une dÃ©rive anormale par rapport aux schÃ©mas habituels, lâ€™algorithme alerte quâ€™une piÃ¨ce risque de lÃ¢cher sous peu.<br><br>On peut alors intervenir <em>proactivement</em>, planifier la rÃ©paration durant un crÃ©neau qui gÃªne le moins les occupants, et Ã©viter la panne subite.<br><br>Des Ã©tudes estiment que la maintenance prÃ©dictive peut diminuer <em>jusquâ€™Ã  30Â %</em> les dÃ©penses dâ€™entretien tout en allongeant la durÃ©e de vie des Ã©quipements (â€‹<a href=\"https://tw3partners.fr/fr/ia-dans-la-gestion-immobiliere-optimisation-des-operations\" target=\"_blank\" rel=\"noreferrer noopener\">tw3partners.fr</a>).</li><li><strong>Automatisation des Ã©changes courantsÂ :</strong> Outre les aspects techniques, lâ€™IA peut seconder les gestionnaires dans la relation avec les locataires.<br><br>Un chatbot dans une rÃ©sidence peut rÃ©pondre aux questions basiques des locataires (procÃ©dure pour une demande de rÃ©paration, solde du compte locataire, etc.) et dÃ©sengorger le standard.<br><br>De mÃªme, la gestion des <em>tickets</em> de maintenance (demandes dâ€™intervention) peut Ãªtre priorisÃ©e par IA en fonction de lâ€™urgence et de la gravitÃ©, pour traiter dâ€™abord les problÃ¨mes critiques (une fuite dâ€™eau) avant un dÃ©tail moins urgent (une ampoule grillÃ©e).</li></ul><p>Lâ€™IA dans lâ€™immobilier tend Ã  rendre la gestion locative <strong>plus rÃ©active, plus Ã©conomique et plus transparente</strong>. Les propriÃ©taires bÃ©nÃ©ficient dâ€™une rÃ©duction des risques et des coÃ»ts, tandis que les locataires profitent dâ€™un meilleur service (moins dâ€™attente et des logements en bon Ã©tat).</p><p>La prochaine Ã©tape pour lâ€™IA en gestion immobiliÃ¨re est lâ€™avÃ¨nement du <strong>bÃ¢timent intelligent auto-gÃ©rÃ©</strong>. On voit dÃ©jÃ  Ã©merger des systÃ¨mes intÃ©grÃ©s oÃ¹ lâ€™IA pilote aussi la <strong>consommation dâ€™Ã©nergie</strong> dâ€™un immeuble (chauffage, climatisation, Ã©clairage) en fonction de lâ€™occupation rÃ©elle des locaux, ce qui peut rÃ©duire drastiquement les chargesâ€‹.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-l-immobilier-pour-la-recherche-et-la-recommandation-de-biens\">Lâ€™IA dans lâ€™immobilier pour la recherche et la recommandation de biens</h2><p>Trouver la perle rare parmi des milliers dâ€™annonces est souvent fastidieux pour les acheteurs ou locataires. Les <strong>moteurs de recommandation intelligents</strong> viennent Ã  la rescousse en triant et proposant automatiquement les biens susceptibles de correspondre Ã  chaque client.</p><p>Le fonctionnement sâ€™apparente Ã  celui de Netflix ou Amazon, transposÃ© Ã  lâ€™immobilierÂ : des algorithmes de machine learning analysent vos critÃ¨res de recherche initiaux, vos filtres appliquÃ©s, ainsi que vos interactions passÃ©es (biens consultÃ©s, sauvegardÃ©s, refusÃ©s) afin de cerner vos goÃ»tsâ€‹</p><p>Ã€ partir de lÃ , le systÃ¨me <strong>suggÃ¨re des biens Â«Â qui vous vont bienÂ Â»</strong> : par exemple, si lâ€™IA dÃ©tecte quâ€™un utilisateur aime les <em>lofts trÃ¨s lumineux en centre-ville</em>, elle va mettre en avant de nouvelles annonces de lofts spacieux et bien exposÃ©s correspondant Ã  ce profilâ€‹.</p><p>Ces recommandations personnalisÃ©es sâ€™affichent sous forme de <em>Â«Â biens qui pourraient vous intÃ©resserÂ Â»</em> sur le site ou lâ€™appli, ou sont envoyÃ©es par email/app notification.</p><p>En France, Seloger, Leboncoin, PAP et consorts dÃ©veloppent aussi leurs algorithmes de recommandation, conscients que plus la recherche est facile et pertinente, plus lâ€™utilisateur restera sur leur plateforme.</p><p>Dâ€™ailleurs, <strong>91Â % des acquÃ©reurs</strong> commencent leurs recherches en ligne, dâ€™oÃ¹ lâ€™importance stratÃ©gique dâ€™une bonne recommandation pour capter la demande (chiffre <a href=\"https://www.fnaim.fr/\">FNAIM</a>, 2023).</p><p>Au-delÃ  des portails, les agences immobiliÃ¨res intÃ¨grent Ã©galement ces fonctionnalitÃ©s dans leurs CRM. Ainsi, un agent peut recevoir des alertes de son logiciel lui indiquant quâ€™un nouveau bien quâ€™il vient de rentrer correspond Ã  5 clients de sa base, avec un <em>scoring</em> indiquant lesquels sont les plus â€œchaudsâ€. Cela lui permet de faire une <strong>mise en relation proactive</strong> entre vendeurs et acheteurs <em>matchant</em>, accÃ©lÃ©rant les transactions.</p><p><strong>BÃ©nÃ©ficesÂ :</strong> Pour lâ€™utilisateur final, ces moteurs intelligents rendent la recherche beaucoup plus efficace. Pour les professionnels, câ€™est un moyen dâ€™<strong>augmenter le taux de conversion</strong>Â : un prospect qui reÃ§oit rapidement des suggestions pertinentes a plus de chances de visiter puis dâ€™acheter un bien via le service.</p><p>On constate Ã©galement une augmentation du temps passÃ© sur les sites immobiliers qui offrent de bonnes recommandations, car lâ€™interface devient plus <em>Â«Â accrocheuseÂ Â»</em> (on dÃ©couvre des biens quâ€™on nâ€™aurait pas cherchÃ© soi-mÃªme).</p><p>Les systÃ¨mes de recommandation continueront de gagner en sophistication. Lâ€™<strong>IA conversationnelle</strong> arrive dans la recherche immobiliÃ¨re. Au lieu de cocher des cases, lâ€™utilisateur pourra bientÃ´t dialoguer en langage naturel avec un assistant. Il pourra envoyer des requÃªtes comme : <em>Â«Â Je cherche une maison avec jardin dans un quartier calme, budget 400kÂ Â»</em>. Lâ€™IA comprendra la demande et posera Ã©ventuellement des questions de prÃ©cision, puis proposera directement une sÃ©lection.</p><p>Quoi quâ€™il en soit, lâ€™objectif reste le mÃªme. Raccourcir et faciliter la rencontre entre un bien et son futur occupant, grÃ¢ce Ã  lâ€™intelligence artificielle.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-l-immobilier-conclusion\">Lâ€™IA dans lâ€™immobilier : conclusion</h2><p>Quâ€™il sâ€™agisse dâ€™estimer un appartement, de signer un acte de vente, de trouver un acheteur ou de gÃ©rer un parc locatif, lâ€™intelligence artificielle sâ€™impose progressivement Ã  tous les Ã©tages de lâ€™immobilier. Les exemples actuels prouvent dÃ©jÃ  son efficacitÃ©. PrÃ©cision accrue des estimations, transactions accÃ©lÃ©rÃ©es et sÃ©curisÃ©es, marketing mieux ciblÃ©, gestion locative proactive, expÃ©rience client enrichie, et mÃªme aide Ã  la dÃ©cision stratÃ©gique pour les urbanistes.</p><p>Les <strong>tendances actuelles</strong> montrent une adoption grandissante de ces technologies autrefois futuristes. Les <strong>perspectives futures</strong> laissent entrevoir une transformation encore plus profonde du secteur.</p><p>Bien sÃ»r, lâ€™IA nâ€™est pas une panacÃ©e magiqueÂ : son dÃ©ploiement doit sâ€™accompagner de <em>garanties Ã©thiques</em> (protection des donnÃ©es personnelles, transparence des algorithmes) et elle ne remplacera pas la valeur ajoutÃ©e humaine lÃ  oÃ¹ elle est cruciale (conseil personnalisÃ©, expertise terrain, crÃ©ativitÃ© architecturale, etc.).</p><p>NÃ©anmoins, en automatisant les tÃ¢ches laborieuses et en exploitant de faÃ§on pertinente la data, lâ€™IA libÃ¨re du temps pour se concentrer sur lâ€™essentiel.</p><p>Lâ€™avenir de lâ€™immobilier sera sans doute <strong>hybride</strong>, alliant le meilleur de la technologie et de lâ€™humain. Les professionnels qui sauront embrasser cette rÃ©volution numÃ©rique, tout en gardant le sens du service et de lâ€™Ã©thique, disposeront dâ€™un atout dÃ©cisif pour rÃ©pondre aux dÃ©fis de demain dans un marchÃ© immobilier de plus en plus exigeant et connectÃ©.</p><p>Lâ€™IA ouvre lâ€™Ã¨re de lâ€™<strong>immobilier augmentÃ©</strong>.</p></div>"},
{"url": "https://larevueia.fr/quelles-sont-les-applications-de-lia-dans-le-btp/", "title": "Quelles sont les applications de lâ€™IA dans le BTP ?", "author": "Ilyes Talbi", "date": "\n22 mars 2024\n", "content": "<div class=\"entry-content\"><p>Lâ€™intelligence artificielle est en train de rÃ©volutionner Ã©normÃ©ment de mÃ©tiers et dâ€™industrie, parmi elles, lâ€™industrie du BTP. Dans cet article, je propose une revue complÃ¨te des applications de lâ€™IA dans le BTP.</p><p>Nous verrons que lâ€™IA peut intervenir dans diffÃ©rentes phases de la vie dâ€™un projet, allant de la rÃ©ponse aux appels dâ€™offres Ã  la maintenance des machines et bÃ¢timents.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-dans-le-btp-pour-la-conception-et-l-etude-de-faisabilite\">Lâ€™IA dans le BTP pour la conception et lâ€™Ã©tude de faisabilitÃ©</h2><p>Dans lâ€™univers exigeant de la construction, la prÃ©cision des Ã©tudes de faisabilitÃ© est primordiale. Ces Ã©valuations prÃ©liminaires dÃ©terminent la viabilitÃ© dâ€™un projet en analysant des Ã©lÃ©ments tels que les projections financiÃ¨res, la disponibilitÃ© des ressources, lâ€™analyse du site et la conformitÃ© rÃ©glementaire.</p><p>Un manquement, mÃªme mineur, dans ces Ã©tudes peut engendrer des dÃ©passements de coÃ»ts, des retards et dâ€™autres complications.</p><p>Lâ€™intelligence artificielle offre une solution prometteuse face Ã  ces dÃ©fis. GrÃ¢ce Ã  sa capacitÃ© Ã  traiter dâ€™Ã©normes volumes de donnÃ©es rapidement et Ã  reconnaÃ®tre des tendances subtiles, lâ€™IA dans le BTP augmente la prÃ©cision et accÃ©lÃ¨re les processus dÃ©cisionnels en construction.</p><h3 class=\"wp-block-heading\" id=\"h-l-importance-de-la-precision-dans-les-etudes-de-faisabilite\">Lâ€™importance de la prÃ©cision dans les Ã©tudes de faisabilitÃ©</h3><p>Les Ã©tudes de faisabilitÃ© sont le socle des projets de construction rÃ©ussis, guidant les parties prenantes Ã  travers une multitude de dÃ©cisions avant le dÃ©marrage des travaux. Une Ã©tude fiable Ã©claire tous les aspects du projet, de la planification Ã  lâ€™exÃ©cution.</p><h3 class=\"wp-block-heading\" id=\"h-risques-des-etudes-imprecises\">Risques des Ã©tudes imprÃ©cises</h3><p>Une Ã©valuation inexacte peut entraÃ®ner des dÃ©passements budgÃ©taires ou des retards :</p><ul class=\"wp-block-list\"><li>Ces dÃ©passements surviennent lorsque les coÃ»ts rÃ©els du projet dÃ©passent les estimations initiales. Cela peut Ãªtre dÃ» Ã  une mauvaise Ã©valuation des besoins en matÃ©riaux, des tarifs sous-estimÃ©s des sous-traitants, ou de la non-prÃ©vision de certains frais indirects</li><li>Les dÃ©passements budgÃ©taires peuvent contraindre lâ€™Ã©quipe projet Ã  solliciter des fonds supplÃ©mentaires, ce qui peut sâ€™avÃ©rer difficile et parfois mÃªme compromettre la viabilitÃ© financiÃ¨re du projet</li><li>Les imprÃ©cisions dans lâ€™Ã©valuation peuvent conduire Ã  des erreurs de planification, entraÃ®nant des retards dans le calendrier de construction. Ces retards peuvent Ãªtre le rÃ©sultat dâ€™une mauvaise coordination entre les Ã©quipes, dâ€™une insuffisance de ressources, ou de la non-prise en compte de dÃ©fis spÃ©cifiques au site</li><li>Les retards peuvent engendrer des coÃ»ts additionnels, comme des pÃ©nalitÃ©s contractuelles, et aussi allonger le dÃ©lai de rÃ©alisation des bÃ©nÃ©fices du projet</li></ul><p>De telles imprÃ©cisions peuvent aussi occasionner des pertes dâ€™opportunitÃ©s, des rÃ©percussions financiÃ¨res et nuire Ã  la rÃ©putation des acteurs impliquÃ©s :</p><ul class=\"wp-block-list\"><li>Un projet retardÃ© ou qui dÃ©passe son budget peut faire manquer des opportunitÃ©s de marchÃ©. Par exemple, un complexe rÃ©sidentiel qui nâ€™est pas prÃªt Ã  temps pour une pÃ©riode de forte demande peut perdre des clients potentiels</li><li>Les retards peuvent Ã©galement affecter la capacitÃ© dâ€™une entreprise Ã  dÃ©marrer de nouveaux projets, entravant ainsi sa croissance futur</li><li>Les retards et les dÃ©passements budgÃ©taires peuvent ternir la rÃ©putation des entreprises impliquÃ©es. Une mauvaise presse, des critiques nÃ©gatives, ou un bouche-Ã -oreille dÃ©favorable peuvent dÃ©courager de futurs clients ou investisseurs de collaborer avec les acteurs concernÃ©s</li><li>Ã€ long terme, une rÃ©putation endommagÃ©e peut rÃ©duire la compÃ©titivitÃ© de lâ€™entreprise sur le marchÃ©</li></ul><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"526\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-1024x526.png\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8707\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-1024x526.png 1024w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-300x154.png 300w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-768x394.png 768w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt-1250x642.png 1250w, https://larevueia.fr/wp-content/uploads/2023/10/const_chatgpt.png 1400w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><h3 class=\"wp-block-heading\" id=\"h-comment-l-ia-peut-ameliorer-le-process\">Comment lâ€™IA peut amÃ©liorer le process ?</h3><p>Lâ€™IA, capable dâ€™analyser rapidement de vastes ensembles de donnÃ©es, rÃ©duit les erreurs et amÃ©liore la prÃ©cision des Ã©tudes.</p><p>Elle peut Ã©valuer des donnÃ©es de projets prÃ©cÃ©dents, identifier des tendances et des dÃ©fis potentiels, offrant ainsi une vue plus complÃ¨te de la viabilitÃ© dâ€™un projet.</p><p>GrÃ¢ce Ã  lâ€™IA, les Ã©tudes de faisabilitÃ© deviennent plus agiles, adaptatives et exactes, posant ainsi les fondations solides nÃ©cessaires Ã  tout projet de construction rÃ©ussi.</p><p>Lâ€™intelligence artificielle se caractÃ©rise par sa capacitÃ© Ã  traiter et analyser de vastes quantitÃ©s de donnÃ©es Ã  une vitesse vertigineuse. ConcrÃ¨tement, cela se traduit par plusieurs avantages dans le domaine des Ã©tudes de faisabilitÃ© en construction :</p><ul class=\"wp-block-list\"><li><strong>RÃ©duction des erreurs</strong> : Lâ€™IA, en utilisant des techniques comme le <a href=\"https://larevueia.fr/deep-learning/\" target=\"_blank\" rel=\"noreferrer noopener\">deep learning</a>, peut dÃ©tecter et corriger des anomalies dans les donnÃ©es, assurant ainsi que les Ã©tudes soient basÃ©es sur des informations fiables. Par exemple, si une donnÃ©e de coÃ»t semble anormalement Ã©levÃ©e ou basse par rapport Ã  des donnÃ©es historiques similaires, lâ€™IA peut la signaler pour une vÃ©rification ultÃ©rieure.</li><li><strong>Analyse des donnÃ©es historiques</strong> : Lâ€™IA peut parcourir des annÃ©es de donnÃ©es de projets antÃ©rieurs en un temps record. En utilisant des techniques comme le <a href=\"https://larevueia.fr/clustering-les-3-methodes-a-connaitre/\" target=\"_blank\" rel=\"noreferrer noopener\">clustering</a>, elle peut regrouper des projets similaires et identifier des tendances, comme les saisons oÃ¹ les coÃ»ts de matÃ©riaux augmentent ou les rÃ©gions gÃ©ographiques prÃ©sentant des dÃ©fis spÃ©cifiques.</li><li><strong>Identification des dÃ©fis potentiels</strong> : Par lâ€™analyse prÃ©dictive, lâ€™IA peut anticiper les problÃ¨mes avant quâ€™ils ne surviennent. Par exemple, en analysant les donnÃ©es mÃ©tÃ©orologiques, lâ€™IA pourrait prÃ©voir les risques de retards dus Ã  des conditions climatiques dÃ©favorables.</li><li><strong>Vue dâ€™ensemble de la viabilitÃ©</strong> : Lâ€™IA peut intÃ©grer diverses sources de donnÃ©es, allant des informations de site aux rÃ©glementations locales, pour fournir une Ã©valuation complÃ¨te de la faisabilitÃ©. Des algorithmes comme lâ€™arbre de dÃ©cision peuvent Ãªtre utilisÃ©s pour peser divers facteurs et dÃ©terminer le meilleur chemin Ã  suivre pour un projet. Plus rÃ©cemment, les modÃ¨les dâ€™IA dits Â«Â multi-modauxÂ Â» peuvent comprendre Ã  la fois des donnÃ©es images, vidÃ©os, audio et texte et donc comprendre la donnÃ©e de faÃ§on la plus optimale possible.</li><li><strong>AdaptabilitÃ© et agilitÃ©</strong> : Lâ€™IA est intrinsÃ¨quement adaptative. Avec des mÃ©thodes comme lâ€™apprentissage par renforcement, elle peut sâ€™ajuster en fonction des retours dâ€™information, garantissant que les Ã©tudes de faisabilitÃ© sont constamment mises Ã  jour et amÃ©liorÃ©es.</li></ul><h2 class=\"wp-block-heading\" id=\"h-repondre-aux-appels-d-offres-grace-a-l-ia-dans-le-btp\">RÃ©pondre aux appels dâ€™offres grÃ¢ce Ã  lâ€™IA dans le BTP</h2><p>Dans le secteur du BTP, rÃ©pondre aux appels dâ€™offres est une Ã©tape cruciale pour dÃ©crocher de nouveaux projets. Cependant, cette tÃ¢che peut sâ€™avÃ©rer fastidieuse et complexe, compte tenu de la quantitÃ© dâ€™informations Ã  analyser et des dÃ©tails Ã  fournir.</p><p>Lâ€™intÃ©gration de lâ€™intelligence artificielle dans ce processus se prÃ©sente comme une solution innovante pour maximiser lâ€™efficacitÃ© et la prÃ©cision des rÃ©ponses. DÃ©couvrons ensemble les avantages quâ€™elle procure.</p><h3 class=\"wp-block-heading\" id=\"h-identification-rapide-des-opportunites\"><strong>Identification rapide des opportunitÃ©s</strong></h3><p>Face Ã  lâ€™abondance dâ€™appels dâ€™offres dans le secteur du BTP, distinguer les opportunitÃ©s les plus pertinentes devient un vÃ©ritable dÃ©fi. La capacitÃ© de lâ€™IA Ã  analyser en profondeur et en temps rÃ©el les appels dâ€™offres offre une solution novatrice pour rÃ©soudre ce problÃ¨me. Adoptons une mÃ©thodologie en cinq Ã©tapes pour exploiter au mieux cette technologie :</p><ul class=\"wp-block-list\"><li><strong>Centralisation des sources dâ€™appels dâ€™offres :</strong> La premiÃ¨re Ã©tape consiste Ã  centraliser toutes les sources dâ€™appels dâ€™offres dans une seule base de donnÃ©es. Cela inclut les plateformes officielles, les sites spÃ©cialisÃ©s, les publications rÃ©gionales et toute autre source pertinente. En crÃ©ant un flux dâ€™informations unifiÃ©, lâ€™IA dispose dâ€™un large Ã©ventail de donnÃ©es Ã  analyser.</li></ul><ul class=\"wp-block-list\"><li><strong>Profilage de lâ€™entreprise :</strong> Afin que lâ€™IA comprenne et identifie les opportunitÃ©s les plus appropriÃ©es, il est crucial de lui fournir un profil dÃ©taillÃ© de lâ€™entreprise. Cela comprend les domaines dâ€™expertise, les projets antÃ©rieurs, la capacitÃ© de production, le personnel technique disponible, et mÃªme les prÃ©fÃ©rences gÃ©ographiques.</li></ul><ul class=\"wp-block-list\"><li><strong>Analyse et tri en temps rÃ©el :</strong> GrÃ¢ce aux algorithmes avancÃ©s, lâ€™IA Ã©value chaque appel dâ€™offre en fonction du profil de lâ€™entreprise. Elle vÃ©rifie la concordance entre les exigences du projet et les compÃ©tences de lâ€™entreprise, Ã©liminant ainsi les appels dâ€™offres moins pertinents et mettant en avant les plus adaptÃ©s.</li></ul><ul class=\"wp-block-list\"><li><strong>Notification et visualisation :</strong> Lorsquâ€™un appel dâ€™offre est identifiÃ© comme Ã©tant dâ€™un intÃ©rÃªt particulier, le systÃ¨me peut envoyer des notifications en temps rÃ©el aux dÃ©cideurs concernÃ©s. Ces notifications peuvent Ãªtre accompagnÃ©es dâ€™un tableau de bord interactif, offrant une vue dâ€™ensemble du projet, des exigences clÃ©s et des Ã©ventuels dÃ©fis Ã  relever.</li></ul><p>La mÃ©thodologie ci-dessus, basÃ©e sur lâ€™utilisation de lâ€™IA, offre une approche systÃ©matique et efficace pour cibler les appels dâ€™offres les plus pertinents dans le domaine du BTP. En intÃ©grant cette technologie, les entreprises peuvent non seulement gagner du temps, mais aussi amÃ©liorer considÃ©rablement la qualitÃ© de leurs candidatures, augmentant ainsi leurs chances de succÃ¨s.</p><div class=\"calendly-inline-widget\" data-url=\"https://calendly.com/ilyestalbi75/brainstorm\" style=\"min-width:320px;height:700px;\"></div> <script type=\"text/javascript\" src=\"https://assets.calendly.com/assets/external/widget.js\" async></script> <h3 class=\"wp-block-heading\" id=\"h-analyse-detaillee-des-documents\"><strong>Analyse dÃ©taillÃ©e des documents</strong></h3><p>Les modÃ¨les dâ€™IA ont fait dâ€™Ã©normes progrÃ¨s ces derniÃ¨res annÃ©es, en particulier dans le domaine du traitement du langage naturel (NLP â€“ Natural Language Processing). Ces avancÃ©es permettent Ã  lâ€™IA dâ€™analyser des documents complexes comme ceux des appels dâ€™offres.</p><ul class=\"wp-block-list\"><li><strong>Analyse sÃ©mantique:</strong> GrÃ¢ce au NLP, les algorithmes dâ€™IA peuvent comprendre la signification des mots et des phrases dans un contexte donnÃ©. Cela signifie quâ€™ils peuvent identifier les sections dâ€™un document qui parlent dâ€™exigences techniques, de critÃ¨res de sÃ©lection, de dÃ©lais, etc., mÃªme si la terminologie ou la formulation varie dâ€™un document Ã  lâ€™autre.</li></ul><ul class=\"wp-block-list\"><li><strong>Extraction dâ€™Ã©lÃ©ments clÃ©s :</strong> Une fois que les sections pertinentes sont identifiÃ©es, lâ€™IA peut extraire les informations essentielles. Par exemple, pour les exigences techniques, elle peut lister les spÃ©cifications prÃ©cises, les normes Ã  respecter ou les certifications requises. Pour les dÃ©lais, elle peut extraire la date limite de soumission, la date de dÃ©marrage et la date dâ€™achÃ¨vement.</li></ul><ul class=\"wp-block-list\"><li><strong>Classification et structuration :</strong> AprÃ¨s extraction, les informations sont classÃ©es et structurÃ©es dans une forme facilement lisible et comprÃ©hensible. Cela pourrait prendre la forme dâ€™un tableau, dâ€™une liste ou dâ€™un diagramme, selon ce qui est le plus appropriÃ©.</li></ul><ul class=\"wp-block-list\"><li><strong>Comparaison avec les prÃ©cÃ©dents appels dâ€™offres:</strong> Lâ€™IA peut Ã©galement comparer le nouvel appel dâ€™offres avec ceux auxquels lâ€™entreprise a rÃ©pondu dans le passÃ©. Cela aide Ã  identifier les points communs, les anomalies ou les exigences inhabituelles qui pourraient nÃ©cessiter une attention particuliÃ¨re.</li></ul><ul class=\"wp-block-list\"><li><strong>Alertes et recommandations :</strong> En se basant sur lâ€™analyse, lâ€™IA peut gÃ©nÃ©rer des alertes pour les Ã©lÃ©ments qui semblent particuliÃ¨rement exigeants ou en dehors des compÃ©tences normales de lâ€™entreprise. Elle peut Ã©galement suggÃ©rer des rÃ©ponses basÃ©es sur des soumissions prÃ©cÃ©dentes Ã  des appels dâ€™offres similaires.</li></ul><p>Lâ€™utilisation des algorithmes dâ€™IA pour lâ€™analyse des appels dâ€™offres ne se limite pas Ã  une simple lecture des documents.</p><p>Elle offre une comprÃ©hension en profondeur, permettant aux entreprises de rÃ©pondre plus efficacement et avec une plus grande prÃ©cision aux exigences du cahier des charges.</p><p>Câ€™est un outil inestimable pour rester compÃ©titif dans le monde exigeant des appels dâ€™offres du BTP.</p><h3 class=\"wp-block-heading\" id=\"h-estimation-precise\"><strong>Estimation prÃ©cise</strong></h3><p>Lâ€™un des plus grands avantages de lâ€™IA est sa capacitÃ© Ã  analyser dâ€™immenses volumes de donnÃ©es et Ã  en extraire des tendances, des motifs et des prÃ©dictions.</p><p>Dans le domaine du BTP, cette capacitÃ© peut Ãªtre exploitÃ©e pour formuler des estimations plus prÃ©cises lors de la rÃ©ponse aux appels dâ€™offres. Examinons comment cela fonctionne Ã©tape par Ã©tape.</p><ul class=\"wp-block-list\"><li><strong>Collecte et nettoyage des donnÃ©es :</strong> La premiÃ¨re Ã©tape consiste Ã  rassembler toutes les donnÃ©es pertinentes des projets antÃ©rieurs de lâ€™entreprise. Cela peut inclure les coÃ»ts rÃ©els, la durÃ©e des projets, la main-dâ€™Å“uvre utilisÃ©e, les matÃ©riaux consommÃ©s, etc. Ces donnÃ©es sont ensuite nettoyÃ©es pour Ã©liminer les anomalies ou les erreurs.</li></ul><ul class=\"wp-block-list\"><li><strong>Analyse des tendances historiques :</strong> Une fois les donnÃ©es nettoyÃ©es, lâ€™IA se plonge dans lâ€™histoire pour identifier des tendances. Par exemple, elle pourrait dÃ©celer une augmentation constante du coÃ»t des matÃ©riaux sur une pÃ©riode de temps donnÃ©e ou observer que certains types de projets prennent toujours plus de temps en hiver.</li></ul><ul class=\"wp-block-list\"><li><strong>ModÃ©lisation prÃ©dictive :</strong> Avec les tendances en main, lâ€™IA utilise des techniques de modÃ©lisation prÃ©dictive pour estimer les coÃ»ts, la durÃ©e et les ressources pour de futurs projets. Ces modÃ¨les peuvent Ãªtre affinÃ©s en utilisant des techniques dâ€™apprentissage automatique, oÃ¹ lâ€™IA ajuste constamment ses prÃ©dictions en fonction des rÃ©sultats rÃ©els des projets.</li></ul><ul class=\"wp-block-list\"><li><strong>Ajustements basÃ©s sur des facteurs externes :</strong> Lâ€™IA prend Ã©galement en compte des variables externes qui pourraient influencer un projet. Cela pourrait inclure des choses comme la prÃ©vision Ã©conomique, les variations saisonniÃ¨res, ou les fluctuations du marchÃ© des matÃ©riaux de construction. Par exemple, si une pÃ©nurie de bois est prÃ©vue pour les prochains mois, lâ€™IA ajustera ses estimations de coÃ»t en consÃ©quence.</li></ul><ul class=\"wp-block-list\"><li><strong>Estimations personnalisÃ©es :</strong> Au-delÃ  des tendances gÃ©nÃ©rales, lâ€™IA peut personnaliser ses estimations en fonction du client, du lieu ou de la nature spÃ©cifique du projet. Si une entreprise a dÃ©jÃ  travaillÃ© pour un client donnÃ©, lâ€™IA peut utiliser ces donnÃ©es pour ajuster ses estimations, en prenant en compte les spÃ©cificitÃ©s propres Ã  ce client.</li></ul><ul class=\"wp-block-list\"><li><strong>Proposition dâ€™une offre compÃ©titive :</strong> Fort de ces informations prÃ©cises, les entreprises du BTP peuvent formuler des offres qui sont non seulement compÃ©titives, mais Ã©galement rÃ©alistes. Cela rÃ©duit le risque de sous-estimation, tout en garantissant que lâ€™offre reste attrayante pour le client.</li></ul><p>GrÃ¢ce Ã  lâ€™IA, les entreprises du BTP peuvent dÃ©sormais sâ€™appuyer sur des donnÃ©es concrÃ¨tes et des analyses avancÃ©es pour formuler leurs offres.</p><p>Cette approche axÃ©e sur les donnÃ©es permet de mieux anticiper les dÃ©fis et dâ€™optimiser les ressources, donnant ainsi aux entreprises un avantage certain dans le paysage concurrentiel des appels dâ€™offres.</p><h3 class=\"wp-block-heading\" id=\"h-redaction-assistee-des-propositions\"><strong>RÃ©daction assistÃ©e des propositions</strong></h3><p>Des outils dâ€™IA comme <a href=\"https://openai.com/blog/chatgpt\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> peuvent guider la rÃ©daction des propositions en suggÃ©rant des formulations optimales, en veillant Ã  ce que toutes les exigences soient abordÃ©es et en aidant Ã  structurer le document de maniÃ¨re logique et persuasive.</p><ul class=\"wp-block-list\"><li><strong>Suggestion de formulations optimales :</strong> Lâ€™importance de la communication claire et efficace dans une proposition ne peut Ãªtre sous-estimÃ©e. Les systÃ¨mes dâ€™IA, en ayant accÃ¨s Ã  une base de donnÃ©es de propositions rÃ©ussies et en utilisant lâ€™analyse sÃ©mantique, peuvent suggÃ©rer des tournures de phrases et des formulations qui ont eu un impact positif dans le passÃ©. Cela peut aider Ã  rendre le contenu plus convaincant.<br><br><em>Exemple</em> : Si une entreprise veut mettre en avant sa durabilitÃ©, lâ€™IA pourrait suggÃ©rer : Â«Â Nous utilisons des mÃ©thodes Ã©co-responsables, ayant rÃ©duit notre empreinte carbone de 20 % au cours des trois derniÃ¨res annÃ©es.Â Â»</li></ul><ul class=\"wp-block-list\"><li><strong>VÃ©rification de la couverture des exigences :</strong> Lâ€™un des piÃ¨ges courants lors de la rÃ©daction de propositions est de nÃ©gliger ou dâ€™omettre certaines exigences mentionnÃ©es dans le cahier des charges. Lâ€™IA, en scannant le document dâ€™appel dâ€™offres, peut crÃ©er une checklist des exigences. Ensuite, lors de la rÃ©daction, elle peut vÃ©rifier en temps rÃ©el que toutes ces exigences sont correctement abordÃ©es dans la proposition.</li></ul><ul class=\"wp-block-list\"><li><strong>Structuration logique du document :</strong> Lâ€™organisation et la structure du document sont cruciales pour sa lisibilitÃ© et son impact. Les systÃ¨mes dâ€™IA peuvent analyser la structure des propositions prÃ©cÃ©demment rÃ©ussies et suggÃ©rer un agencement optimal des sections. Cela garantit que le lecteur suit un flux dâ€™informations logique, facilitant la comprÃ©hension et renforÃ§ant lâ€™argumentation.<br><br><em>Exemple</em> : Introduction â€“ PrÃ©sentation de lâ€™entreprise â€“ RÃ©ponse aux exigences techniques â€“ MÃ©thodologie proposÃ©e â€“ Estimations de coÃ»ts et de dÃ©lais â€“ RÃ©fÃ©rences de projets similaires â€“ Conclusion.</li></ul><ul class=\"wp-block-list\"><li><strong>Persuasion et adaptation au client :</strong> Au-delÃ  de la simple rÃ©daction, il sâ€™agit de persuader le client que votre entreprise est le meilleur choix. En utilisant des algorithmes de traitement du langage naturel, lâ€™IA peut dÃ©tecter le ton et le style des documents prÃ©cÃ©dents du client pour suggÃ©rer une tonalitÃ© correspondante. Cette adaptation stylistique permet dâ€™Ã©tablir une connexion plus profonde avec le client.</li></ul><ul class=\"wp-block-list\"><li><strong>Relecture automatisÃ©e :</strong> Lâ€™IA peut Ã©galement jouer un rÃ´le crucial dans la phase de relecture. En plus de la vÃ©rification orthographique et grammaticale, elle peut identifier des passages ambigus, des redondances ou des contradictions dans la proposition, garantissant ainsi un document final de haute qualitÃ©.</li></ul><p>En intÃ©grant lâ€™IA dans le processus de rÃ©daction de propositions, les entreprises peuvent amÃ©liorer la prÃ©cision, lâ€™efficacitÃ© et la persuasion de leurs documents.</p><p>Cela maximise leurs chances de succÃ¨s dans les appels dâ€™offres, tout en Ã©conomisant du temps et des efforts.</p><p>Le futur de la rÃ©daction de propositions dans le BTP pourrait bien Ãªtre guidÃ© par des outils dâ€™IA sophistiquÃ©s, apportant une valeur ajoutÃ©e Ã  chaque Ã©tape du processus.</p><h2 class=\"wp-block-heading\" id=\"h-comment-utiliser-l-ia-pour-le-suivi-d-un-chantier\">Comment utiliser lâ€™IA pour le suivi dâ€™un chantier ?</h2><p>Le suivi dâ€™un chantier est une tÃ¢che complexe qui nÃ©cessite une attention constante aux dÃ©tails, une mise Ã  jour rÃ©guliÃ¨re des progrÃ¨s et une capacitÃ© Ã  anticiper et rÃ©soudre les problÃ¨mes rapidement.</p><p>Avec lâ€™Ã©volution de la technologie, lâ€™IA se prÃ©sente comme un alliÃ© inestimable pour amÃ©liorer lâ€™efficacitÃ© du suivi de chantier.</p><p>Voici comment lâ€™IA peut Ãªtre utilisÃ©e Ã  cet effet.</p><h3 class=\"wp-block-heading\" id=\"h-surveillance-en-temps-reel-grace-a-la-vision-par-ordinateur\"><strong>Surveillance en temps rÃ©el grÃ¢ce Ã  la vision par ordinateur</strong></h3><p>Les camÃ©ras Ã©quipÃ©es de systÃ¨mes dâ€™IA peuvent surveiller en continu un chantier. GrÃ¢ce Ã  la <a href=\"https://larevueia.fr/tout-ce-que-vous-pouvez-faire-avec-la-computer-vision/\" target=\"_blank\" rel=\"noreferrer noopener\">vision par ordinateur</a>, elles peuvent dÃ©tecter automatiquement des anomalies, comme un matÃ©riel dÃ©fectueux, des problÃ¨mes de sÃ©curitÃ© ou des retards dans certaines zones du chantier. Les responsables peuvent alors Ãªtre alertÃ©s en temps rÃ©el, permettant une intervention rapide.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"683\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/btp1-1024x683.png\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8704\" style=\"width:683px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/btp1-1024x683.png 1024w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-300x200.png 300w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-768x512.png 768w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-1536x1024.png 1536w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-1250x834.png 1250w, https://larevueia.fr/wp-content/uploads/2023/10/btp1-900x600.png 900w, https://larevueia.fr/wp-content/uploads/2023/10/btp1.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Les camÃ©ras qui intÃ¨grent des systÃ¨mes dâ€™intelligence artificielle jouent un rÃ´le croissant dans la surveillance moderne des chantiers de construction.</p><p>Contrairement aux camÃ©ras traditionnelles qui se contentent de capturer des images, ces dispositifs avancÃ©s vont bien au-delÃ .</p><p>Elles tirent parti de la vision par ordinateur, une branche de lâ€™IA spÃ©cialisÃ©e dans lâ€™interprÃ©tation et la comprÃ©hension du contenu visuel.</p><p>Dans le contexte dâ€™un chantier, cette capacitÃ© dâ€™analyse visuelle sâ€™avÃ¨re prÃ©cieuse.</p><p>Par exemple, la camÃ©ra peut identifier un Ã©quipement qui ne fonctionne pas correctement simplement en analysant les images quâ€™elle capture.</p><p>Elle peut aussi repÃ©rer des situations potentiellement dangereuses pour les ouvriers, comme des Ã©quipements mal placÃ©s ou des zones qui ne respectent pas les normes de sÃ©curitÃ©. De plus, si certaines zones du chantier ne progressent pas comme prÃ©vu, ces anomalies sont Ã©galement dÃ©tectables.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"640\" height=\"356\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/btp2.webp\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8706\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/btp2.webp 640w, https://larevueia.fr/wp-content/uploads/2023/10/btp2-300x167.webp 300w\" sizes=\"auto, (max-width: 640px) 100vw, 640px\"><figcaption class=\"wp-element-caption\">DÃ©tection dâ€™un travailleur sous une charge lourde</figcaption></figure></div><p>Lâ€™un des avantages majeurs de ces systÃ¨mes est leur capacitÃ© Ã  agir de maniÃ¨re proactive. Au lieu dâ€™attendre quâ€™un humain observe et identifie un problÃ¨me, le systÃ¨me dâ€™IA envoie des alertes automatiques aux responsables dÃ¨s quâ€™une anomalie est dÃ©tectÃ©e.</p><p>Cette rÃ©activitÃ© permet dâ€™Ã©viter de nombreux problÃ¨mes potentiels. Par exemple, si un Ã©quipement est identifiÃ© comme dÃ©fectueux, une intervention rapide peut empÃªcher des retards supplÃ©mentaires dans le projet ou, dans le pire des cas, un accident sur le chantier.</p><p>De cette faÃ§on, lâ€™IA se rÃ©vÃ¨le Ãªtre un outil essentiel pour assurer le bon dÃ©roulement des travaux, la sÃ©curitÃ© des employÃ©s et le respect des dÃ©lais.</p><h3 class=\"wp-block-heading\" id=\"h-prevision-et-gestion-des-retards\"><strong>PrÃ©vision et gestion des retards</strong></h3><p>En analysant les donnÃ©es des chantiers prÃ©cÃ©dents et en combinant ces informations avec le suivi en temps rÃ©el, lâ€™IA peut prÃ©dire les Ã©ventuels retards et leurs causes. Cela permet aux gestionnaires de prendre des mesures prÃ©ventives ou dâ€™ajuster les ressources en consÃ©quence.</p><p>Dans le secteur du BTP, le suivi des projets est dâ€™une importance cruciale, et lâ€™intÃ©gration de lâ€™IA dans ce processus ouvre la porte Ã  une gestion de chantier nettement plus efficace et prÃ©dictive. En tirant parti de lâ€™analyse des donnÃ©es issues des chantiers prÃ©cÃ©dents, lâ€™IA peut jouer un rÃ´le proactif, plutÃ´t que rÃ©actif, dans la gestion des projets.</p><p>Les donnÃ©es historiques dâ€™un chantier sont une mine dâ€™informations.</p><p>Elles peuvent renfermer des dÃ©tails sur les dÃ©lais dâ€™achÃ¨vement de certaines tÃ¢ches, les conditions mÃ©tÃ©orologiques ayant affectÃ© le travail, les problÃ¨mes de main-dâ€™Å“uvre ou de matÃ©riel, et bien dâ€™autres facteurs qui ont pu influencer la progression du projet.</p><p>En digÃ©rant et en analysant ces donnÃ©es, lâ€™IA peut identifier des tendances et des motifs rÃ©currents qui ont conduit Ã  des retards dans le passÃ©.</p><p>En parallÃ¨le, la surveillance en temps rÃ©el du chantier actuel fournit Ã  lâ€™IA des informations sur lâ€™Ã©tat actuel des travaux.</p><p>En combinant ces donnÃ©es en direct avec les enseignements tirÃ©s des chantiers prÃ©cÃ©dents, lâ€™IA est en mesure de prÃ©dire avec prÃ©cision oÃ¹ et quand des retards pourraient se produire Ã  lâ€™avenir.</p><p>Par exemple, si lâ€™IA reconnaÃ®t que des conditions mÃ©tÃ©orologiques similaires ont prÃ©cÃ©demment causÃ© des retards dans la livraison de matÃ©riaux, elle peut alerter les gestionnaires avant que le problÃ¨me ne survienne.</p><p>De mÃªme, si elle dÃ©tecte un ralentissement dans une zone spÃ©cifique du chantier qui, dans le passÃ©, a conduit Ã  des retards plus consÃ©quents, les responsables peuvent Ãªtre alertÃ©s pour quâ€™ils puissent intervenir rapidement.</p><p>Cette approche proactive, soutenue par lâ€™IA, permet aux gestionnaires de chantier dâ€™Ãªtre toujours un pas en avance sur les dÃ©fis potentiels.</p><p>Au lieu dâ€™attendre quâ€™un problÃ¨me survienne et de rÃ©agir Ã  la hÃ¢te, ils peuvent anticiper les obstacles et dÃ©ployer des ressources, ajuster les Ã©quipes ou rÃ©organiser le planning pour assurer un dÃ©roulement fluide du projet.</p><p>En fin de compte, cela conduit Ã  des projets plus efficaces, des coÃ»ts rÃ©duits et une meilleure satisfaction des parties prenantes.</p><h3 class=\"wp-block-heading\" id=\"h-autres-cas-d-usage-de-l-ia-pour-le-suivi-de-chantier\"><strong>Autres cas dâ€™usage de lâ€™IA pour le suivi de chantier</strong></h3><ul class=\"wp-block-list\"><li><strong>Optimisation de la logistique :</strong> lâ€™IA peut analyser les schÃ©mas de circulation des matÃ©riaux et des ouvriers sur le chantier, proposant des itinÃ©raires optimisÃ©s pour rÃ©duire les temps dâ€™attente, les mouvements inutiles et accÃ©lÃ©rer le processus de construction.</li></ul><ul class=\"wp-block-list\"><li><strong>Gestion des ressources humaines</strong> : en analysant les donnÃ©es sur la productivitÃ© des travailleurs, les systÃ¨mes dâ€™IA peuvent identifier les besoins en formation ou suggÃ©rer des rÃ©affectations dâ€™Ã©quipe pour maximiser lâ€™efficacitÃ©.</li></ul><ul class=\"wp-block-list\"><li><strong>ContrÃ´le qualitÃ© automatisÃ©</strong> : les drones Ã©quipÃ©s de camÃ©ras et de systÃ¨mes dâ€™IA peuvent survoler le chantier pour inspecter la qualitÃ© des travaux. Ils peuvent dÃ©tecter des dÃ©fauts, des malfaÃ§ons ou des Ã©carts par rapport aux plans initiaux, offrant ainsi un contrÃ´le qualitÃ© supplÃ©mentaire.</li></ul><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://larevueia.fr/wp-content/uploads/2023/10/btp3-1024x576.jpeg\" alt=\"Quelles sont les applications de l'IA dans le BTP ?\" class=\"wp-image-8705\" style=\"width:770px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/10/btp3-1024x576.jpeg 1024w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-300x169.jpeg 300w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-768x432.jpeg 768w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-1536x864.jpeg 1536w, https://larevueia.fr/wp-content/uploads/2023/10/btp3-1250x703.jpeg 1250w, https://larevueia.fr/wp-content/uploads/2023/10/btp3.jpeg 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><ul class=\"wp-block-list\"><li><strong>Suivi environnemental</strong> : lâ€™IA peut aider Ã  surveiller lâ€™impact environnemental du chantier en temps rÃ©el, en dÃ©tectant par exemple les Ã©missions de substances polluantes ou les perturbations de la faune locale. Cela aide les entreprises Ã  respecter les rÃ©glementations environnementales et Ã  adopter des pratiques plus durables.</li><li><strong>Communication automatisÃ©e avec les parties prenantes</strong> : les systÃ¨mes dâ€™IA peuvent gÃ©nÃ©rer des rapports automatisÃ©s sur lâ€™avancement du chantier, les problÃ¨mes rencontrÃ©s et les solutions apportÃ©es, assurant ainsi une communication transparente avec les clients, les fournisseurs et les autres parties prenantes.</li></ul><p>Lâ€™IA offre une multitude de possibilitÃ©s pour amÃ©liorer le suivi dâ€™un chantier, rendant le processus plus efficace, plus sÃ»r et plus conforme aux attentes. En adoptant ces technologies, les entreprises du BTP peuvent non seulement gagner en compÃ©titivitÃ©, mais aussi contribuer Ã  lâ€™Ã©dification de structures de meilleure qualitÃ©, dans le respect des dÃ©lais et des budgets.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>La rÃ©volution de lâ€™intelligence artificielle (IA) redessine de nombreux secteurs, et le BTP nâ€™y fait pas exception. Ã€ travers lâ€™ensemble des Ã©tapes dâ€™un projet, de la rÃ©ponse aux appels dâ€™offres jusquâ€™au suivi minutieux des chantiers, lâ€™IA se rÃ©vÃ¨le Ãªtre un alliÃ© puissant. Elle offre une prÃ©cision, une efficacitÃ© et une proactivitÃ© inÃ©galÃ©es, transformant ainsi la maniÃ¨re dont les projets sont gÃ©rÃ©s et exÃ©cutÃ©s.</p><p>Lâ€™intÃ©gration de lâ€™IA dans le BTP ne se limite pas Ã  une simple automatisation des tÃ¢ches. Elle implique une rÃ©interprÃ©tation des mÃ©thodes traditionnelles, une anticipation des dÃ©fis et une optimisation constante des ressources. Les entreprises qui adoptent ces technologies innovantes se positionnent non seulement en leaders sur le marchÃ© actuel, mais se prÃ©parent aussi Ã  modeler lâ€™avenir du secteur.</p><p>Lâ€™IA dans le BTP nâ€™est pas simplement une tendance Ã©phÃ©mÃ¨re ; câ€™est la prochaine Ã©tape logique de lâ€™Ã©volution du secteur. Les entreprises qui reconnaissent son potentiel aujourdâ€™hui se prÃ©parent Ã  un avenir plus compÃ©titif, efficient et, surtout, Ã  la pointe de lâ€™innovation. Embrasser lâ€™IA, câ€™est embrasser lâ€™avenir du BTP.</p></div>"},
{"url": "https://larevueia.fr/rag-et-documentation-interne-en-entreprise/", "title": "Lâ€™IA et les RAG au service de la documentation interne dâ€™entreprise", "author": "Ilyes Talbi", "date": "\n25 octobre 2024\n", "content": "<div class=\"entry-content\"><p>Au delÃ  du buzz autour de lâ€™intelligence artificielle et des RAG, certaines entreprises peinent Ã  trouver des cas dâ€™usages concrets qui peuvent rÃ©ellement Â«Â rÃ©volutionnerÂ Â» leur secteur.</p><p>Un des points communs entre toutes les entreprises câ€™est le besoin de structuration de la documentation interne.</p><p>La quantitÃ© de donnÃ©es gÃ©nÃ©rÃ©e et traitÃ©e par une entreprise est Ã©norme et Ã©normÃ©ment dâ€™informations se perdent dans la nature.</p><p>McKinsey estime le temps perdu liÃ© Ã  la recherche dâ€™informations Ã  plus de 20% du temps travaillÃ© dâ€™un employÃ©. Ils estiment Ã  plus de 10kâ‚¬ par an et par employÃ© le manque Ã  gagner liÃ©es Ã  des pertes de connaissances.</p><p>Cela inclus plusieurs choses, comme dans la tech le fait que des dÃ©veloppeurs doivent refaire plusieurs fois un mÃªme code Ã  cause dâ€™une mauvaise documentation ou une mauvaise structuration des informations.</p><p>Par ailleurs, une mauvaise documentation interne peut entraÃ®ner des risques liÃ©s Ã  la sÃ©curitÃ© de la donnÃ©e dâ€™entreprise. Des informations privÃ©es peuvent Ãªtre Ã©changÃ©es via Whatsapp, par tÃ©lÃ©phone, sur Slack, via des messageries Ã©lectroniques non-sÃ©curisÃ©es, etc.</p><p>Dâ€™oÃ¹ lâ€™importance pour lâ€™entreprise dâ€™optimiser lâ€™accÃ¨s Ã  la donnÃ©es interne au sein de lâ€™entreprise.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-peut-aider-la-notion-de-rag\">Lâ€™IA peut aider : la notion de RAG</h2><p>Les RAG : Retrieval Augmented Generation, sont des techniques qui permettent au LLM de baser leurs rÃ©ponses sur des bases de connaissances externes, au delÃ  de la simple base dâ€™entraÃ®nement du modÃ¨le.</p><p>Le principe est le suivant :</p><ul class=\"wp-block-list\"><li>On commence par crÃ©er notre base de connaissance qui contient toute la donnÃ©es de lâ€™entreprise. Cette donnÃ©e sera stockÃ©e sous la forme de vecteurs mathÃ©matiques, les vecteurs dâ€™embedding, et rangÃ©es par contexte. Les vecteurs doivent Ãªtre construits intelligemment en faisant en sorte que les documents avec un contexte proche soit proches au sens mathÃ©matique. Par ailleurs, on doit aussi faire en sorte que la base soit optimisÃ©e pour la recherche afin de permettre une rÃ©cupÃ©ration de donnÃ©es rapides. Une des entreprises de rÃ©fÃ©rence sur ce sujet est <a href=\"https://pathway.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Pathway</a>.</li><li>Une fois que la base vectorielle est construite, son utilisation est simple. On va rÃ©cupÃ©rer la recherche de lâ€™utilisateur, la transformer en vecteur dâ€™embedding et rÃ©cupÃ©rer dans la base vectorielle les morceaux de documents qui sont proches de la question sÃ©mantiquement. On va ensuite faire en sorte de compresser les documents rÃ©cupÃ©rÃ©es pour crÃ©er un contexte synthÃ©tique. Enfin, on va redonner au LLM la question initiale de lâ€™utilisateur et lui demander de baser sa rÃ©ponse sur le contexte que lâ€™on vient de construire.</li></ul><p>Le framework de rÃ©fÃ©rence qui permet de mettre en place ce genre de pipeline de RAG est <a href=\"https://larevueia.fr/langchain-le-guide-essentiel/\" target=\"_blank\" rel=\"noreferrer noopener\">Langchain</a>. Il permet de gÃ©rer tous le processus de la crÃ©ation de la base de connaissance Ã  la restitution des rÃ©ponses, en passant par la compression du contexte.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"665\" src=\"https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1024x665.png\" alt=\"Pipeline de RAG avec Langchain pour la documentation interne en entreprise\" class=\"wp-image-8829\" style=\"width:580px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1024x665.png 1024w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-300x195.png 300w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-768x499.png 768w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1536x998.png 1536w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18-1250x812.png 1250w, https://larevueia.fr/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-19.46.18.png 1644w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">Pipeline de RAG avec Langchain</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"h-comment-securiser-son-pipeline-de-rag\">Comment sÃ©curiser son pipeline de RAG</h2><p>Cette approche basÃ©e sur Langchain nâ€™est pas sans risque, lâ€™aspect sÃ©curitaire doit Ãªtre pris en considÃ©ration.</p><h3 class=\"wp-block-heading\" id=\"h-le-phenomene-d-hallucination\">Le phÃ©nomÃ¨ne dâ€™hallucination</h3><p>Dâ€™abord, il faut avoir en tÃªte que les LLM sont initialement conÃ§us comme des modÃ¨les mathÃ©matiques dont le rÃ´le est de prÃ©dire le mot suivant. Ils doivent proposer une sÃ©quence de mots qui parait juste et qui se rapproche de ce quâ€™un humain aurait pu dire.</p><p>A aucun moment du processus on ne prend en compte la vÃ©racitÃ© de lâ€™information transmise Ã  lâ€™utilisateur. Il est donc assez courant quâ€™un modÃ¨le de LLM donne une rÃ©ponse fausse avec assurance, ce phÃ©nomÃ¨ne est ce que lâ€™on appelle Â«Â lâ€™hallucinationÂ Â».</p><p>MalgrÃ© les amÃ©liorations rÃ©centes liÃ©es Ã  lâ€™hallucination dans les derniÃ¨res versions de LLM comme GPT-4, ce phÃ©nomÃ¨ne est encore prÃ©sent. Et il peut affecter votre pipeline dans le cas oÃ¹ le contexte extrait de votre base de connaissance serait trop vague. Le LLM peut Ãªtre tentÃ© de complÃ©ter la rÃ©ponse en inventant des informations.</p><p>La premiÃ¨re Ã©tape pour la rÃ©solution de ce problÃ¨me consiste Ã  mettre en place des mÃ©triques de performances basÃ©es sur du feedback humain, via des notes par exemple. Nâ€™hÃ©sitez pas Ã  essayer plusieurs LLM et les mettre en compÃ©tition sur ce point lÃ .</p><h3 class=\"wp-block-heading\" id=\"h-acces-et-infiltration-de-donnees-dans-le-pipeline-de-rag\">AccÃ¨s et infiltration de donnÃ©es dans le pipeline de RAG</h3><p>Lâ€™autre grand risque liÃ© aux pipelines de RAG rÃ©side dans la compartimentalisation des donnÃ©es de lâ€™entreprise. On ne veut pas que le LLM donne toutes les informations de lâ€™entreprise Ã  tous les employÃ©s.</p><p>On doit pouvoir dÃ©finir des pÃ©rimÃ¨tres dâ€™accÃ¨s Ã  la donnÃ©es comme on le ferait dans un drive classique.</p><p>Sur ce sujet la solution nâ€™a rien Ã  voir avec lâ€™IA en elle-mÃªme, elle repose entiÃ¨rement sur lâ€™infrastructure proposÃ©e et la qualitÃ© de la donnÃ©es en entrÃ©e. Tous les documents doivent Ãªtre labÃ©llisÃ©s et contenir dans leurs metadata les informations liÃ©es aux autorisations dâ€™accÃ¨s.</p><p>Par ailleurs, les risques cyber classique comme une injection de donnÃ©es par un acteur malveillant, peuvent Ãªtre plus difficiles Ã  dÃ©celer. Le LLM rÃ©pondra avec le contexte prÃ©sent dans la base de connaissance, sans savoir quâ€™elle a Ã©tÃ© inflitrÃ©e.</p><h3 class=\"wp-block-heading\" id=\"h-le-risque-de-mal-controler-les-couts-du-pipeline\">Le risque de mal contrÃ´ler les coÃ»ts du pipeline</h3><p>Contrairement Ã  une recherche classique dans une base de connaissance, la recherche par RAG fait intervenir plusieurs modÃ¨les de LLM qui sont potentiellement appelÃ©s plusieurs fois par requÃªte. Ils sont appelÃ©s une premiÃ¨re fois pour la comprÃ©hension de la requÃªte de lâ€™utilisateur, ils sont ensuite appelÃ©s plusieurs fois pour la compression du contexte en fonction de la quantitÃ© dâ€™informations, et enfin une derniÃ¨re fois pour rÃ©sumer la rÃ©ponse.</p><p>Si on utilise une API externe, avec une facturation par token (câ€™est lâ€™unitÃ© mathÃ©matique qui est utilisÃ©e pour lâ€™encodage du langage) les coÃ»ts peuvent trÃ¨s vite sâ€™envoler. Dâ€™oÃ¹ lâ€™importance de faire des tests et dâ€™avoir un contrÃ´le rigoureux des dÃ©penses.</p><h3 class=\"wp-block-heading\" id=\"h-souverainete-des-donnees\">SouverainetÃ© des donnÃ©es</h3><p>La souverainetÃ© des donnÃ©es constitue un dernier risque Ã  ne pas nÃ©gliger. En utilisant des API de LLM dâ€™entreprises externes vous exposez Ã  lâ€™extÃ©rieur les donnÃ©es de votre entreprise et les recherches de vos employÃ©s dans votre base interne.</p><p>En fonction de la politique de lâ€™entreprise vous pouvez passer par des clouds providers de confiance ou alors dÃ©cider de construire une architecture local en utilisant des modÃ¨les open-source comme LLAMA par exemple.</p></div>"},
{"url": "https://larevueia.fr/fine-tuner-chatgpt-depuis-le-dashboard-openai/", "title": "Fine-tuner ChatGPT depuis le dashboard OpenAI", "author": "Ilyes Talbi", "date": "\n19 juin 2024\n", "content": "<div class=\"entry-content\"><p>OpenAI a rÃ©volutionnÃ© le domaine de lâ€™intelligence artificielle en dÃ©mocratisant des techniques autrefois rÃ©servÃ©es aux experts. Aujourdâ€™hui, le fine-tuning de modÃ¨les de langage (LLM), tels que ChatGPT (3.5 ou 4o), est Ã  la portÃ©e de tous. Pour mieux comprendre comment Fine-tuner ChatGPT, continuez Ã  lire.</p><p>Que vous soyez un dÃ©veloppeur cherchant Ã  affiner les rÃ©ponses de votre assistant virtuel ou une entreprise souhaitant adapter un modÃ¨le Ã  des besoins spÃ©cifiques, OpenAI offre les outils nÃ©cessaires pour personnaliser ces assitants.</p><p>Dans cet article je vous explique comment prÃ©parer votre jeu de donnÃ©es, configurer votre compte OpenAI et lancer le processus de fine-tuning pour crÃ©er votre version personnalisÃ©e de ChatGPT.</p><h2 class=\"wp-block-heading\" id=\"h-preparation-du-dataset-pour-le-fine-tuning-de-chatgpt\">PrÃ©paration du dataset pour le fine-tuning de ChatGPT</h2><p>Le succÃ¨s du fine-tuning dâ€™un modÃ¨le de langage comme ChatGPT dÃ©pend largement de la qualitÃ© et de la pertinence de votre jeu de donnÃ©es. Voici comment vous pouvez prÃ©parer efficacement votre dataset pour obtenir les meilleurs rÃ©sultats possibles.</p><p>Le dataset que vous utilisez pour le fine-tuning doit Ãªtre soigneusement sÃ©lectionnÃ© et structurÃ©. Il doit contenir des paires dâ€™entrÃ©e/sortie qui reprÃ©sentent fidÃ¨lement les interactions que vous attendez entre lâ€™utilisateur et le modÃ¨le. Plus vos donnÃ©es seront reprÃ©sentatives des scÃ©narios rÃ©els dâ€™utilisation, meilleur sera le comportement de votre modÃ¨le personnalisÃ©.</p><p>Commencez par rassembler au moins 20 paires dâ€™interactions input/output. Lâ€™input doit reflÃ©ter ce que vous prÃ©voyez de demander au modÃ¨le, et lâ€™output doit illustrer la rÃ©ponse que vous souhaitez obtenir. Par exemple, si vous prÃ©parez un assistant pour aider avec des requÃªtes client spÃ©cifiques, chaque input pourrait Ãªtre une question frÃ©quente dâ€™un client, et lâ€™output serait la rÃ©ponse idÃ©ale que lâ€™assistant devrait fournir.</p><p>Une fois votre collection dâ€™exemples prÃªte, vous devrez organiser ces donnÃ©es dans un fichier au format <em>.jsonl</em>, oÃ¹ chaque ligne correspond Ã  un Ã©change spÃ©cifique entre lâ€™utilisateur et lâ€™assistant. Voici le format Ã  suivre pour chaque interaction :</p><pre class=\"wp-block-code\"><code>{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"Prompt du systÃ¨me ici\"},\n    {\"role\": \"user\", \"content\": \"EntrÃ©e de l'utilisateur ici\"},\n    {\"role\": \"assistant\", \"content\": \"RÃ©ponse de l'assistant ici\"}\n  ]\n}</code></pre><p>Chaque ligne doit reprÃ©senter une interaction complÃ¨te, et il est crucial que le format soit respectÃ© pour garantir le bon traitement des donnÃ©es par la plateforme OpenAI. Cela permettra une meilleure comprÃ©hension du contexte par le modÃ¨le et une personnalisation plus prÃ©cise de ses rÃ©ponses.</p><p>Maintenant que notre dataset est prÃªt on passe Ã  la prochaine Ã©tape. Dans la prochaine section nous allons gÃ©rer la configuration de votre compte OpenAI pour commencer le processus de fine-tuning.</p><h2 class=\"wp-block-heading\" id=\"h-configuration-du-compte-openai\">Configuration du compte OpenAI</h2><p>Pour commencer, vous devez avoir un compte OpenAI. Si ce nâ€™est pas dÃ©jÃ  fait, rendez-vous sur le site officiel <a href=\"https://platform.openai.com/login\">dâ€™OpenAI</a> et suivez les instructions pour crÃ©er un compte. Une fois votre compte crÃ©Ã©, vous pourrez accÃ©der Ã  votre dashboard personnel.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"657\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1024x657.png\" alt=\"Fine-tuner ChatGPT depuis le dashboard OpenAI\" class=\"wp-image-8767\" style=\"width:710px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1024x657.png 1024w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-300x192.png 300w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-768x492.png 768w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1536x985.png 1536w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12-1250x802.png 1250w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.13.12.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">UI connexion au dashboard OpenAI</figcaption></figure></div><p>AprÃ¨s vous Ãªtre connectÃ©, naviguez dans le tableau de bord OpenAI jusquâ€™Ã  la section Â«Â Fine-tuningÂ Â». Vous y trouverez toutes les options et les outils nÃ©cessaires pour dÃ©marrer le processus de personnalisation de votre modÃ¨le.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"446\" height=\"736\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.14.48.png\" alt=\"Fine-tuner ChatGPT depuis le dashboard OpenAI\" class=\"wp-image-8768\" style=\"width:270px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.14.48.png 446w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.14.48-182x300.png 182w\" sizes=\"auto, (max-width: 446px) 100vw, 446px\"><figcaption class=\"wp-element-caption\">Panneau latÃ©ral Ã  gauche sur le dashboard OpenAI</figcaption></figure></div><ul class=\"wp-block-list\"><li><strong>SÃ©lection du modÃ¨le</strong> : Choisissez le modÃ¨le de base que vous souhaitez fine-tuner, comme GPT-3.5 ou GPT-4o. Chaque modÃ¨le a des caractÃ©ristiques et des capacitÃ©s diffÃ©rentes, donc sÃ©lectionnez celui qui correspond le mieux Ã  vos besoins</li><li><strong>TÃ©lÃ©chargement du dataset</strong> : Chargez votre fichier .jsonl prÃ©parÃ© dans lâ€™Ã©tape prÃ©cÃ©dente. Assurez-vous que le fichier soit correctement formatÃ© comme dÃ©crit pour Ã©viter des erreurs pendant le processus de fine-tuning.</li><li><strong>Configuration des paramÃ¨tres de fine-tuning</strong> : Bien que les paramÃ¨tres par dÃ©faut fonctionnent gÃ©nÃ©ralement bien pour de nombreux cas dâ€™usage, vous avez la possibilitÃ© de personnaliser des aspects tels que la taille du lot (batch size), le nombre dâ€™Ã©poques (epochs), et le seed initial. Si vous Ãªtes familier avec ces paramÃ¨tres, ajustez-les selon les spÃ©cificitÃ©s de votre projet.</li></ul><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"869\" src=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-1024x869.png\" alt=\"Fine-tuner ChatGPT depuis le dashboard OpenAI\" class=\"wp-image-8770\" style=\"width:654px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-1024x869.png 1024w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-300x255.png 300w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-768x652.png 768w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10-1250x1061.png 1250w, https://larevueia.fr/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-01.16.10.png 1374w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption class=\"wp-element-caption\">ParamÃ¨trage du fine-tuning de ChatGPT</figcaption></figure></div><p>Une fois que tout est en place, vous pouvez lancer le processus de fine-tuning en cliquant sur le bouton Â«Â CreateÂ Â». OpenAI prendra en charge lâ€™entraÃ®nement de votre modÃ¨le avec les donnÃ©es fournies. Vous recevrez une notification par email une fois que le modÃ¨le sera prÃªt Ã  lâ€™emploi.</p><h2 class=\"wp-block-heading\" id=\"h-entrainement-et-utilisation-apres-le-fine-tuning-de-chatgpt\">EntraÃ®nement et utilisation aprÃ¨s le fine-tuning de ChatGPT</h2><p>AprÃ¨s avoir configurÃ© votre compte et lancÃ© le processus de fine-tuning, vous pourrez bientÃ´t tester votre modÃ¨le personnalisÃ©.</p><p>Une fois le fine-tuning initiÃ©, vous pouvez suivre lâ€™avancement via le tableau de bord OpenAI. Cela vous permet de voir le progrÃ¨s du modÃ¨le et de vous assurer que tout se dÃ©roule comme prÃ©vu. Lorsque lâ€™entraÃ®nement est terminÃ©, vous recevrez une notification indiquant que votre modÃ¨le est prÃªt Ã  Ãªtre utilisÃ©.</p><p>Une fois le fine-tuning de ChatGPT terminÃ©, votre modÃ¨le personnalisÃ© est maintenant accessible via lâ€™API dâ€™OpenAI ou directement dans le Playground OpenAI. Vous pouvez commencer Ã  lâ€™intÃ©grer dans vos applications ou Ã  lâ€™utiliser pour des tÃ¢ches spÃ©cifiques. Testez le modÃ¨le pour Ã©valuer ses performances et assurez-vous quâ€™il rÃ©pond bien Ã  vos attentes. Nâ€™hÃ©sitez pas Ã  faire des ajustements supplÃ©mentaires si nÃ©cessaire.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>Le fine-tuning de ChatGPT offre une opportunitÃ© incroyable dâ€™adapter les capacitÃ©s de pointe de lâ€™IA aux besoins spÃ©cifiques de votre projet ou de votre entreprise. En suivant les Ã©tapes de prÃ©paration du dataset, de configuration du compte, et de lancement du processus de fine-tuning, vous pouvez maximiser lâ€™efficacitÃ© de votre assistant virtuel.</p><p>Cette approche personnalisÃ©e non seulement amÃ©liore lâ€™interaction utilisateur mais ouvre Ã©galement de nouvelles possibilitÃ©s pour lâ€™innovation et lâ€™efficacitÃ© dans divers domaines.</p></div>"},
{"url": "https://larevueia.fr/lintelligence-artificielle-au-service-du-sport/", "title": "Lâ€™intelligence artificielle au service du sport", "author": "Ilyes Talbi", "date": "\n10 avril 2023\n", "content": "<div class=\"entry-content\"><p>Lâ€™intelligence artificielle a transformÃ© profondÃ©ment le monde du sport. Des terrains de football aux pistes dâ€™athlÃ©tisme, cette technologie rÃ©volutionne la faÃ§on dont les athlÃ¨tes sâ€™entraÃ®nent, se prÃ©parent, et atteignent leurs objectifs de performance.</p><p><strong>Pourquoi une telle rÃ©volution ?</strong> Lâ€™IA offre des capacitÃ©s inÃ©dites pour analyser des donnÃ©es complexes, personnaliser les entraÃ®nements, et anticiper les risques de blessures. Sa prÃ©sence est dÃ©sormais incontournable, que ce soit pour optimiser les programmes sportifs, affiner les tactiques de jeu ou encore amÃ©liorer la comprÃ©hension de la biomÃ©canique.</p><p>En plus de lâ€™amÃ©lioration des techniques dâ€™intelligence artificielle, on a observÃ© une augmentation considÃ©rable de la quantitÃ© de donnÃ©es extraites dans le sport. Les moindres gestes des athlÃ¨tes, en entraÃ®nement ou en compÃ©tition, sont mesurer et analyser avec un grand degrÃ© de prÃ©cision.</p><p>Par exemple, la <a href=\"https://larevueia.fr/tout-ce-que-vous-pouvez-faire-avec-la-computer-vision/\" target=\"_blank\" rel=\"noreferrer noopener\">computer vision</a> est utilisÃ©e pour dÃ©cortiquer les vidÃ©os de matchs ou dâ€™entraÃ®nements, fournissant aux entraÃ®neurs et athlÃ¨tes des insights dÃ©taillÃ©s sur les mouvements, stratÃ©gies, et tactiques. En parallÃ¨le, les algorithmes de machine learning identifient les schÃ©mas de performance, proposent des amÃ©liorations personnalisÃ©es, et mÃªme prÃ©disent les risques de blessures pour les prÃ©venir.</p><p>De plus, lâ€™IA sâ€™invite dans les Ã©tudes de biomÃ©canique pour aider Ã  comprendre les mouvements complexes et les contraintes physiques auxquels sont soumis les athlÃ¨tes, permettant ainsi dâ€™adapter les prÃ©parations physiques Ã  chaque sport.</p><p>Dans cet article, nous explorerons comment lâ€™IA redÃ©finit le monde du sport, les bÃ©nÃ©fices concrets quâ€™elle apporte aux athlÃ¨tes et aux Ã©quipes, ainsi que les dÃ©fis Ã©thiques quâ€™elle soulÃ¨ve.</p><h2 class=\"wp-block-heading\" id=\"h-ameliorer-les-performances-grace-a-l-intelligence-artificielle-dans-le-sport\">AmÃ©liorer les performances grÃ¢ce Ã  lâ€™intelligence artificielle dans le sport</h2><p>Lâ€™IA permet dâ€™amÃ©liorer les performances sportives en collectant et en analysant une grande quantitÃ© de donnÃ©es qui peuvent Ãªtre utilisÃ©es pour personnaliser lâ€™entraÃ®nement et visualiser la progression de lâ€™athlÃ¨te.</p><p>Par exemple, dans le domaine de la course Ã  pied, des capteurs intÃ©grÃ©s aux chaussures peuvent enregistrer des donnÃ©es sur la foulÃ©e, la cadence, la force de poussÃ©e ou lâ€™Ã©quilibre.</p><p>Ces donnÃ©es sont ensuite analysÃ©es par un algorithme dâ€™IA qui identifie les points dâ€™amÃ©lioration, comme une rÃ©partition de poids inÃ©gale pouvant causer des blessures. Sur cette base, des recommandations prÃ©cises sont fournies Ã  lâ€™athlÃ¨te pour corriger sa posture et amÃ©liorer son efficacitÃ©.</p><p>Dans le cadre des sports collectifs, comme le football, des camÃ©ras Ã  haute rÃ©solution couplÃ©es Ã  des systÃ¨mes dâ€™IA peuvent suivre chaque joueur sur le terrain et analyser leurs dÃ©placements.</p><p>Par exemple, les donnÃ©es peuvent rÃ©vÃ©ler quâ€™un joueur se fatigue trop vite lorsquâ€™il effectue des sprints. Les entraÃ®neurs peuvent alors adapter son programme dâ€™entraÃ®nement pour amÃ©liorer son endurance, et mieux organiser les tactiques de jeu en fonction de sa condition physique.</p><p>Pour les athlÃ¨tes de haut niveau, lâ€™IA peut Ã©galement analyser les donnÃ©es physiologiques recueillies par des outils comme les montres connectÃ©es : la variabilitÃ© de la frÃ©quence cardiaque, le sommeil, etc. pour ajuster les sessions dâ€™entraÃ®nement et optimiser la rÃ©cupÃ©ration.</p><p>Un athlÃ¨te de triathlon pourrait recevoir des recommandations pour rÃ©duire lâ€™intensitÃ© de lâ€™entraÃ®nement un jour donnÃ© afin de favoriser la rÃ©cupÃ©ration, suite Ã  une analyse dÃ©montrant un niveau de fatigue Ã©levÃ©.</p><p>Les programmes dâ€™entraÃ®nement personnalisÃ©s basÃ©s sur lâ€™IA fournissent ainsi des exercices spÃ©cifiques Ã  chaque athlÃ¨te. Lâ€™analyse des donnÃ©es collectÃ©es permet de comprendre les points faibles, les opportunitÃ©s dâ€™amÃ©lioration, et dâ€™adapter lâ€™entraÃ®nement en consÃ©quence.</p><p>De plus, lâ€™utilisation de lâ€™IA dans lâ€™analyse de la performance peut aider les athlÃ¨tes Ã  mieux comprendre leur corps et Ã  optimiser leurs mouvements. Par exemple, en natation, des camÃ©ras associÃ©es Ã  lâ€™IA peuvent dÃ©tecter des irrÃ©gularitÃ©s dans le mouvement des bras et des jambes, permettant au nageur de rectifier sa technique pour gagner en efficacitÃ©.</p><h2 class=\"wp-block-heading\" id=\"h-prevenir-les-blessures-avec-l-ia\">PrÃ©venir les blessures avec lâ€™IA</h2><p>La prÃ©vention des blessures est essentielle pour les athlÃ¨tes, car une blessure peut sâ€™avÃ©rer coÃ»teuse en termes de temps et de ressources financiÃ¨res.</p><p>Lâ€™IA est en train de rÃ©volutionner la maniÃ¨re dont les athlÃ¨tes sont protÃ©gÃ©s en aidant Ã  identifier les facteurs de risque de blessure.</p><p>Lâ€™IA peut aider Ã  prÃ©dire les futurs <a href=\"https://sport.cnrs.fr/sport-et-ia-modelisation-du-risque-de-blessure-chez-les-sportifs-professionnels/\" target=\"_blank\" rel=\"noreferrer noopener\">risques de blessures</a> en analysant les donnÃ©es collectÃ©es sur lâ€™athlÃ¨te, tels que lâ€™historique des blessures, des informations biomÃ©caniques et physiologiques du corps.</p><p>Ces donnÃ©es peuvent Ãªtre utilisÃ©es pour recommander des actions prÃ©ventives, telles que des exercices dâ€™Ã©tirements ou des programmes de prÃ©vention dâ€™insuffisance musculaire.</p><p>En outre, lâ€™utilisation de lâ€™IA pour la surveillance des mouvements peut aider les athlÃ¨tes Ã  Ã©viter les blessures en les informant de tout mouvement anormal.</p><p>Par exemple, lâ€™analyse de la biomÃ©canique et des mouvements lors de la course Ã  moteur aide les athlÃ¨tes Ã  sâ€™ajuster pour Ã©viter dâ€™endommager les tissus corporels.</p><h2 class=\"wp-block-heading\" id=\"h-utilisation-de-l-ia-en-matiere-d-analyse-video\">Utilisation de lâ€™IA en matiÃ¨re dâ€™analyse vidÃ©o</h2><p>Lâ€™utilisation de lâ€™Intelligence Artificielle a permis dâ€™obtenir des rÃ©sultats trÃ¨s intÃ©ressants dans lâ€™analyse vidÃ©o. Cela est possible grÃ¢ce Ã  lâ€™augmentation des capacitÃ©s de traitement de donnÃ©es de lâ€™IA, ainsi que des algorithmes dâ€™apprentissage automatique qui permettent Ã  lâ€™IA dâ€™apprendre Ã  partir de donnÃ©es et de prendre des dÃ©cisions.</p><p>Lâ€™analyse vidÃ©o assistÃ©e par IA peut Ãªtre utilisÃ©e pour diverses applications telles que la surveillance de la sÃ©curitÃ©, lâ€™analyse de comportement, la reconnaissance faciale et la comptabilisation du trafic.</p><p>GrÃ¢ce Ã  lâ€™IA, lâ€™analyse vidÃ©o atteint un niveau de prÃ©cision et de rapiditÃ© rarement atteint par les mÃ©thodes traditionnelles.</p><p>Cependant, la mise en place de telles solutions nÃ©cessite des compÃ©tences spÃ©cialisÃ©es et une comprÃ©hension des complexitÃ©s techniques reliÃ©es Ã  lâ€™IA.</p><p>Il est donc essentiel pour les entreprises intÃ©ressÃ©es par lâ€™analyse vidÃ©o IA de travailler avec des experts pour rÃ©ussir la mise en place de tels projets.</p><h2 class=\"wp-block-heading\" id=\"h-l-ia-et-la-personnalisation-de-l-experience-sportive\">Lâ€™IA et la personnalisation de lâ€™expÃ©rience sportive</h2><p>Lâ€™intelligence artificielle a rÃ©volutionnÃ© lâ€™expÃ©rience des fans dans lâ€™industrie du sport. Lâ€™IA est utilisÃ©e pour personnaliser lâ€™expÃ©rience du fan, en fournissant des recommandations et des offres qui correspondent Ã  leurs prÃ©fÃ©rences individuelles. Les entreprises de sport peuvent utiliser lâ€™IA pour suivre les habitudes dâ€™achat de chaque fan, leurs prÃ©fÃ©rences dâ€™Ã©quipe et dâ€™autres donnÃ©es pour crÃ©er des expÃ©riences personnalisÃ©es.</p><p>Lâ€™IA peut Ã©galement Ãªtre utilisÃ©e pour fournir aux fans des points de vue uniques sur les Ã©vÃ©nements sportifs en utilisant des donnÃ©es de capteurs et des images de camÃ©ras. Avec lâ€™IA, les entreprises peuvent offrir des perspectives nouvelles et intÃ©ressantes aux fans, tout en augmentant leur engagement.</p><p>De plus, lâ€™IA peut Ã©galement aider les entraÃ®neurs et les joueurs Ã  prendre des dÃ©cisions optimales. Les algorithmes dâ€™apprentissage automatique peuvent Ãªtre utilisÃ©s pour analyser des donnÃ©es telles que les performances passÃ©es, la mÃ©tÃ©o, le terrain et les statistiques des adversaires afin dâ€™optimiser les dÃ©cisions en matiÃ¨re de formation, de stratÃ©gie et de jeu.</p><p>Lâ€™utilisation de lâ€™IA dans lâ€™expÃ©rience sportive offre de nombreuses opportunitÃ©s passionnantes pour les fans, les entraÃ®neurs et les joueurs.</p><p>Câ€™est une tendance intÃ©ressante et en constante Ã©volution Ã  surveiller pour les fans de sport et les entreprises de lâ€™industrie du sport.</p><h2 class=\"wp-block-heading\" id=\"h-conclusion\">Conclusion</h2><p>En conclusion, lâ€™utilisation de lâ€™intelligence artificielle est une tendance Ã  la hausse dans de nombreuses industries, y compris lâ€™industrie du sport.</p><p>Les entreprises utilisent lâ€™IA pour amÃ©liorer lâ€™expÃ©rience des fans, augmenter lâ€™engagement et amÃ©liorer les performances des joueurs et des entraÃ®neurs.</p><p>Avec lâ€™augmentation de la puissance de traitement de lâ€™IA, les entreprises peuvent mieux comprendre leurs clients et leur offrir des expÃ©riences plus personnalisÃ©es.</p><p>Les algorithmes dâ€™apprentissage automatique permettent Ã©galement une analyse plus prÃ©cise des donnÃ©es et des performances, ce qui peut conduire Ã  des amÃ©liorations significatives dans les performances des joueurs et lâ€™efficacitÃ© des entreprises.</p><p>Cependant, il est important de noter que lâ€™utilisation de lâ€™IA doit Ãªtre accompagnÃ©e dâ€™une solide stratÃ©gie dâ€™entreprise et de responsabilitÃ©.</p><p>Les entreprises doivent travailler avec des experts pour dÃ©velopper des technologies AI robustes et Ã©thiques, et sâ€™assurer que lâ€™utilisation de lâ€™IA ne compromet pas ou ne viole pas la confidentialitÃ© ou la sÃ©curitÃ© des donnÃ©es des clients.</p><p>Dans lâ€™ensemble, lâ€™IA reprÃ©sente une opportunitÃ© passionnante pour lâ€™industrie du sport dâ€™amÃ©liorer lâ€™expÃ©rience des fans et dâ€™optimiser les performances des joueurs et des Ã©quipes, tout en restant Ã©thiques et responsables.</p></div>"},
{"url": "https://larevueia.fr/introduction-a-lintelligence-artificielle-generative/", "title": "Quâ€™est-ce que lâ€™intelligence artificielle gÃ©nÃ©rative ?", "author": "Ilyes Talbi", "date": "\n30 janvier 2023\n", "content": "<div class=\"entry-content\"><p>Lâ€™intelligence artificielle gÃ©nÃ©rative est un domaine du deep learning qui donne aux machines la capacitÃ© de gÃ©nÃ©rer du contenu (image, vidÃ©o, texte, etc.), Ã  partir de donnÃ©es crÃ©es manuellement.</p><p>AprÃ¨s les deep fake, la gÃ©nÃ©ration de visages ou de voitures, les derniers modÃ¨les conÃ§us sont capables de gÃ©nÃ©rer du texte ou des images trÃ¨s rÃ©alistes.</p><p>Dans cet article, on explique ce quâ€™est lâ€™intelligence artificielle gÃ©nÃ©rative, on prÃ©sente le fonctionnement de ces modÃ¨les, leurs applications, et on parle de lâ€™aspect Ã©thique.</p><h2 class=\"wp-block-heading\">Quelles sont les applications de lâ€™Intelligence artificielle gÃ©nÃ©rative ?</h2><p>Lâ€™IA gÃ©nÃ©rative a un nombre infini dâ€™applications. Dans cette section je vous prÃ©sente celles qui sont le plus impressionnantes et qui commencent Ã  se dÃ©mocratiser.</p><h3 class=\"wp-block-heading\">GÃ©nÃ©rer des images avec lâ€™IA gÃ©nÃ©rative</h3><p>Lâ€™application qui a le plus fait rÃ©agir derniÃ¨rement câ€™est cette capacitÃ© des modÃ¨les Ã  gÃ©nÃ©rer des images Ã  partir de textes simples. Jâ€™ai beaucoup Ã©crit sur le sujet, jâ€™ai mÃªme proposÃ© un tutoriel pour gÃ©nÃ©rer vos images rapidement.</p><p>Les images obtenues en sortie sont vraiment impressionnantes, et il faut se rappeler que nous ne sommes quâ€™au dÃ©but de cette technologie.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/image-generees.jpeg\" alt=\"exemple d'image gÃ©nÃ©rÃ©es grÃ¢ce Ã  l'intelligence artificielle gÃ©nÃ©rative\" class=\"wp-image-8004\" width=\"325\" height=\"488\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/image-generees.jpeg 512w, https://larevueia.fr/wp-content/uploads/2023/01/image-generees-200x300.jpeg 200w\" sizes=\"auto, (max-width: 325px) 100vw, 325px\"></figure></div><h3 class=\"wp-block-heading\">CrÃ©er du texte</h3><p>En plus de la crÃ©ation dâ€™images, les IA gÃ©nÃ©ratives sont de plus en plus performantes pour lâ€™Ã©criture de texte. En plus dâ€™Ãªtre capables de mener une discussion dâ€™un niveau humain sur la plupart des sujets, les meilleurs modÃ¨les dâ€™aujourdâ€™hui peuvent gÃ©nÃ©rer des paragraphes, des articles, voir des livres entiers.</p><p>Jâ€™ai gÃ©nÃ©rÃ© <a href=\"https://www.amazon.fr/dp/B0BRZ1J55N\" target=\"_blank\" rel=\"noreferrer noopener\">cet ebook</a> grÃ¢ce Ã  GPT-3 par exemple.</p><h3 class=\"wp-block-heading\">Ecrire du code</h3><p>Ce nâ€™est pas tout!</p><p>Des projets comme GitHub copilot, ont fait passer la gÃ©nÃ©ration de code par intelligence artificielle dans des sphÃ¨res nouvelles. Exemple :</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/codechatgpt.png\" alt=\"Qu'est-ce que l'intelligence artificielle gÃ©nÃ©rative ?\" class=\"wp-image-8006\" width=\"501\" height=\"588\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/codechatgpt.png 729w, https://larevueia.fr/wp-content/uploads/2023/01/codechatgpt-255x300.png 255w\" sizes=\"auto, (max-width: 501px) 100vw, 501px\"></figure></div><h2 class=\"wp-block-heading\">Comment fonctionne les modÃ¨les dâ€™intelligence artificielle gÃ©nÃ©rative ?</h2><p>Les mÃ©thodes les plus utilisÃ©es aujourdâ€™hui sont les GAN, les VAE et les <a href=\"https://larevueia.fr/introduction-aux-reseaux-de-neurones-transformers/\" target=\"_blank\" rel=\"noreferrer noopener\">transformers</a>.</p><h3 class=\"wp-block-heading\">GAN, ou Generative Adversarial Networks</h3><p>Les GANs sont des rÃ©seaux de neurones gÃ©nÃ©ratifs introduits pour produire du contenu rÃ©aliste Ã  partir de donnÃ©es dâ€™entrÃ©es. Leur fonctionnement ingÃ©nieux a Ã©tÃ© considÃ©rÃ© par Yann LeCun comme lâ€™idÃ©e la plus importante en machine learning de ces 10 derniÃ¨res annÃ©es.</p><p>Les GANs comprennent un gÃ©nÃ©rateur et un discriminant qui sâ€™entraÃ®nent en compÃ©tition. Le gÃ©nÃ©rateur gÃ©nÃ¨re le contenu, et le discriminant doit determiner si le contenu gÃ©nÃ©rÃ© est rÃ©el ou non. GrÃ¢ce Ã  cette concurrence, les deux modÃ¨les sâ€™amÃ©liorent simultanÃ©ment au fil de lâ€™entraÃ®nement.</p><h3 class=\"wp-block-heading\">VAE, ou Variational Auto-Encoders</h3><p>Les VAE sont une variantes des auto-encodeurs.</p><p>Ils ont une architecture de rÃ©seaux de neurones en entonnoir. La premiÃ¨re partie de lâ€™entonnoir, appelÃ©e encodeur, a pour but dâ€™encoder la donnÃ©e dâ€™entrÃ©e dans un vecteur de petite taille.</p><p>La seconde partie, appelÃ©e dÃ©codeur, permet de reconstruire la donnÃ©e dâ€™entrÃ©e Ã  partir de son encodage.</p><p>Lâ€™intÃ©rÃªt de cette approche, est de construire un espace latent dans lequel les encodages de toutes les donnÃ©es dâ€™entrÃ©es sont rangÃ©es de telle sorte que des opÃ©rations simples soient possibles.</p><p>On peut, avec cette mÃ©thode, gÃ©nÃ©rer de nouvelles donnÃ©es qui ressembleront Ã  lâ€™espace latent.</p><p>RÃ©cemment, les modÃ¨les dâ€™intelligence artificielle gÃ©nÃ©rative sont entraÃ®nÃ©s en utilisant des approches comme les Transformers qui utilisent les mÃ©canismes dâ€™attention, des approches dâ€™apprentissage par renforcement, ou encore des modÃ¨les plus traditionnels et moins gourmands comme les chaÃ®nes de Markov cachÃ©es.</p><h2 class=\"wp-block-heading\">Quelques exemples dâ€™utilisation de lâ€™intelligence artificielle gÃ©nÃ©rative</h2><p>ConcrÃ¨tement, voici 3 exemples de modÃ¨les qui utilisent les techniques vues dans la section prÃ©cÃ©dente pour faire de la gÃ©nÃ©ration de contenu automatisÃ©e.</p><h3 class=\"wp-block-heading\">Stable diffusion</h3><p>Stable diffusion est un modÃ¨le open-source, financÃ© par <a href=\"https://stability.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Stability AI</a>. Il permet de gÃ©nÃ©rer des images Ã  partir de textes. Câ€™est une version open-source, plus fiable et plus rapide de DALL-E 2, le modÃ¨le proposÃ© par OpenAI en 2022.</p><h3 class=\"wp-block-heading\">ChatGPT, lâ€™apogÃ©e de lâ€™intelligence artificielle gÃ©nÃ©rative</h3><p><a href=\"https://larevueia.fr/chatgpt/\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> est un modÃ¨le de traitement du langage dÃ©veloppÃ© par OpenAI. Il utilise le transfert de connaissances pour produire des rÃ©ponses Ã  des questions en utilisant une grande quantitÃ© de donnÃ©es textuelles prÃ©cÃ©demment vues.</p><figure class=\"wp-block-image size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/chatgpt.jpeg\" alt=\"chatgpt, l'apogÃ©e de l'intelligence artificielle gÃ©nÃ©rative\" class=\"wp-image-8002\" width=\"375\" height=\"210\"></figure><p>ChatGPT est capable de comprendre et de gÃ©nÃ©rer du texte dans divers domaines, allant des conversations informelles Ã  des sujets plus complexes tels que la science et la technologie.</p><h3 class=\"wp-block-heading\">Make-A-Video</h3><p>En plus du texte et des images, les derniÃ¨res avancÃ©es nous permettent dâ€™envisager des progrÃ¨s dans le domaine du text2video. Câ€™est Ã  dire la gÃ©nÃ©ration de vidÃ©os Ã  partir de texte.</p><p>Meta a proposÃ© un papier en 2022, appelÃ© <a href=\"https://larevueia.fr/make-a-video-generer-des-videos-avec-un-texte/\" target=\"_blank\" rel=\"noreferrer noopener\">Make-A-Video</a>, qui permet de gÃ©nÃ©rer de courtes vidÃ©os Ã  partir de texte.</p><h2 class=\"wp-block-heading\">Quid de lâ€™aspect Ã©thique ?</h2><p>Les modÃ¨les dâ€™intelligence artificielle gÃ©nÃ©rative progressent Ã©normÃ©ment sur lâ€™aspect technique. Dans pas mal de cas, le contenu gÃ©nÃ©rÃ© est quasiment aussi bons quâ€™un contenu humain.</p><p>NÃ©anmoins, sur la sÃ©curisation de ces modÃ¨les, il reste beaucoup Ã  faire, et plusieurs questions dâ€™ordre Ã©thiques restent en suspens.</p><h3 class=\"wp-block-heading\">Lâ€™impact environnemental de lâ€™entraÃ®nement de modÃ¨les dâ€™intelligence artificielle gÃ©nÃ©rative</h3><p>La plupart du temps, les modÃ¨les rÃ©cents proposÃ©s ne prÃ©sentent pas de grandes avancÃ©es dâ€™un point de vue algorithmique.</p><p>Elles consistent simplement Ã  rÃ©utiliser les modÃ¨les dÃ©jÃ  disponibles, mais avec des centaines de milliards de paramÃ¨tres, et des quantitÃ©s astronomiques de donnÃ©es.</p><p>Jâ€™ai parlÃ© de problÃ¨me de monopole dans de prÃ©cÃ©dents articles. Jâ€™expliquais que seules les trÃ¨s grandes entreprises pouvaient entraÃ®ner ce type de modÃ¨les dâ€™intelligence artificielle gÃ©nÃ©rative, et je proposais la dÃ©centralisation comme une des approches viables.</p><p>Lâ€™autre problÃ¨me de cette course Ã  la donnÃ©es et Ã  un nombre de paramÃ¨tres qui nâ€™a plus trop de sens, câ€™est mÃªme le problÃ¨me principal, câ€™est lâ€™impact sur lâ€™environnement.</p><p>Des datacenters de plus en plus grands, qui nÃ©cessitent de plus en plus dâ€™Ã©nergie pour fonctionner, et un dÃ©sastre de moins en moins contrÃ´lable sur le plan Ã©cologique.</p><h3 class=\"wp-block-heading\">La labellisation des donnÃ©es, Ã  la limite de lâ€™esclavage</h3><p>Pour crÃ©er des modÃ¨les dâ€™IA gÃ©nÃ©rative vraiment performants, le fait dâ€™avoir une grosse quantitÃ© de donnÃ©es ne suffit pas. Il faut aussi Ãªtre capables dâ€™associer ces donnÃ©es Ã  des labels.</p><p>Ce travail, qui est fait manuellement, est souvent chronophage et laborieux.</p><p>Et que font les grandes entreprises de la tech dans ces cas lÃ  ? Ils recrutent des petites mains, sous-payÃ©es, Ã  la limite de lâ€™esclavage, dans des pays en Afrique ou en Asie pour faire le travail.</p><p>Pire encore.</p><p>Lorsque les donnÃ©es Ã  annoter sont simplement des images dâ€™animaux, des textes littÃ©raires ou des pages WikipÃ©dia, la tÃ¢che est acceptable.</p><p>Mais dans le cas de modÃ¨les comme ChatGPT ou DALL-E, parmi le contenu qui devait Ãªtre annotÃ© on trouve du contenu trÃ¨s sensible voir vraiment hardcore.</p><p>Des images dâ€™esclavages, du contenu pÃ©do-pornographique, des textes insultants et qui dÃ©crivent des scÃ¨nes immondes.</p><p>Cette tÃ¢che permet de sÃ©curiser le modÃ¨le, et Ã©viter quâ€™il soit utiliser pour gÃ©nÃ©rer ce type de contenus. Mais il est inacceptable que des gens soient payÃ©s moins de 2 euros la journÃ©e pour regarder ce type de contenu pendant des jours et des jours.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>Quoi de mieux pour conclure cet article, que de laisser un modÃ¨le dâ€™IA gÃ©nÃ©rative gÃ©nÃ©rer la conclusion ?</p><p>Lâ€™IA gÃ©nÃ©rative est un domaine du deep learning permettant aux machines de gÃ©nÃ©rer du contenu Ã  partir de donnÃ©es manuelles. Les derniers modÃ¨les peuvent gÃ©nÃ©rer des images et du texte trÃ¨s rÃ©alistes.</p><p>Il existe un nombre infini dâ€™applications pour lâ€™IA gÃ©nÃ©rative, telles que la gÃ©nÃ©ration dâ€™images, dâ€™Ã©criture de texte et mÃªme de code.</p><p>Les mÃ©thodes les plus couramment utilisÃ©es sont les GAN, les VAE et les transformers. Les GAN utilisent un gÃ©nÃ©rateur et un discriminant pour produire du contenu rÃ©aliste, tandis que les VAE utilisent un encodage pour construire un espace latent pour gÃ©nÃ©rer de nouvelles donnÃ©es.</p><p>Les applications de lâ€™IA gÃ©nÃ©rative sont prometteuses, mais elles soulÃ¨vent Ã©galement des questions Ã©thiques importantes quant Ã  la fiabilitÃ© et la responsabilitÃ© de ces technologies.</p></div>"},
{"url": "https://larevueia.fr/farmbot/", "title": "FarmBot : lâ€™IA qui gÃ¨re votre potager", "author": "Ilyes Talbi", "date": "\n14 janvier 2023\n", "content": "<div class=\"entry-content\"><p><a href=\"https://farm.bot/\" target=\"_blank\" rel=\"noreferrer noopener\">FarmBot</a> est un projet open-source innovant qui vise Ã  rÃ©volutionner lâ€™agriculture en utilisant des technologies de pointe telles que la robotique et lâ€™intelligence artificielle.</p><p>Lâ€™objectif de FarmBot est de permettre de planter, cultiver et rÃ©colter des fruits et lÃ©gumes de maniÃ¨re plus efficace et prÃ©cise, tout en rÃ©duisant les coÃ»ts et en optimisant le rendement.</p><p>Ce projet est soutenu par une communautÃ© de dÃ©veloppeurs qui travaillent en continu pour amÃ©liorer les fonctionnalitÃ©s de la plateforme. Dans cet article, nous allons vous montrer comment FarmBot fonctionne, ses impacts sur lâ€™agriculture et les perspectives de dÃ©veloppement futur.</p><h2 class=\"wp-block-heading\">Principe et fonctionnement de Farmbot</h2><p>ConcrÃ¨tement, le FarmBot est un potager entiÃ¨rement autonome. Il se compose dâ€™un robot mobile Ã©quipÃ© dâ€™un ensemble dâ€™outils de plantation et de rÃ©colte, ainsi que dâ€™un systÃ¨me de guidage autonome pour une localisation prÃ©cise au sein du potager.</p><figure class=\"wp-block-video\"><video controls src=\"https://larevueia.fr/wp-content/uploads/2023/01/Farm_Designer_Loop_ultra_short.mp4\"></video></figure><p>La planification des cultures est lâ€™une des caractÃ©ristiques les plus importantes du robot. Il utilise des donnÃ©es en temps rÃ©el, telles que les prÃ©visions mÃ©tÃ©orologiques, les informations sur le sol et les donnÃ©es de croissance des plantes pour optimiser les rendements.Â </p><p>Les utilisateurs peuvent planifier les cultures de leurs fruits et lÃ©gumes via une interface en ligne ou une application mobile. Le robot est capable de planter et rÃ©colter des graines de maniÃ¨re prÃ©cise et en autonomie complÃ¨te, et il sait dÃ©tecter les fruits et lÃ©gumes mÃ»rs et de les rÃ©colter de maniÃ¨re prÃ©cise, Ã©vitant ainsi les pertes de rÃ©colte.</p><p>Par ailleurs, grÃ¢ce Ã  des mÃ©thodes de <a href=\"https://larevueia.fr/tout-ce-que-vous-pouvez-faire-avec-la-computer-vision/\" target=\"_blank\" rel=\"noreferrer noopener\">vision par ordinateur</a>, le Farmbot peut dÃ©tecter les mauvaises herbes et les nettoyer rÃ©guliÃ¨rement.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x.webp\" alt=\"FarmBot : l'IA qui gÃ¨re votre potager\" class=\"wp-image-7986\" width=\"365\" height=\"465\" srcset=\"https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x.webp 800w, https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x-236x300.webp 236w, https://larevueia.fr/wp-content/uploads/2023/01/FarmBot_Web_App_on_Tablet_800x-768x977.webp 768w\" sizes=\"auto, (max-width: 365px) 100vw, 365px\"></figure></div><h2 class=\"wp-block-heading\">Quâ€™est-ce que Farmbot change pour les utilisateurs ?</h2><p>Un potager autonome tel que celui offert par le projet FarmBot peut apporter de nombreux avantages en termes dâ€™indÃ©pendance alimentaire et de durabilitÃ©. Il permet aux gens de produire leur propre nourriture de qualitÃ©, de maniÃ¨re efficace, sans avoir Ã  dÃ©pendre de sources dâ€™approvisionnement extÃ©rieures. Cela peut Ãªtre particuliÃ¨rement bÃ©nÃ©fique pour les personnes vivant dans des zones plus isolÃ©es, oÃ¹ lâ€™accÃ¨s aux aliments frais peut Ãªtre limitÃ©.</p><p>En termes de durabilitÃ©, un potager autonome peut nous aider Ã  rÃ©duire notre impact environnemental en utilisant des mÃ©thodes de culture plus respectueuses de lâ€™environnement, telles que la rÃ©duction des pesticides et des engrais, la rÃ©utilisation de lâ€™eau, tout en amÃ©liorant les rendements.</p><p>Dâ€™un point de vue moins pragmatique, plus en lien avec lâ€™aspect Ã©motionnel, le fait de produire ses propres fruits et lÃ©gumes permet de se connecter Ã  la nature et de revenir Ã  lâ€™essentiel. MÃªme si Ã§a se fait avec du matÃ©riel technologique de pointe.</p><p>Lâ€™objectif de farmbot Ã©tait aussi Ã  vocation Ã©ducative, il peut permettre aux enfants et aux Ã©tudiants dâ€™apprendre sur lâ€™agriculture, lâ€™intelligence artificielle, la biologie et lâ€™environnement de maniÃ¨re interactive.</p><h2 class=\"wp-block-heading\">Le passage Ã  lâ€™Ã©chelle pour gÃ©rer de champs plus grands</h2><p>Je conÃ§ois ce projet de potager autonome de Farmbot comme une simple Ã©tape vers une automatisation de masse de lâ€™agriculture.</p><p>Passer dâ€™un potager autonome Ã  une agriculture autonome sur des champs parfois immenses, nÃ©cessite des investissements en matiÃ¨re de technologie et de ressources.</p><p>Des expÃ©rimentations sont dÃ©jÃ  en cours, et on commence Ã  bien maÃ®triser les sujets comme <a href=\"https://www.poolse.io/arrosage/\" target=\"_blank\" rel=\"noreferrer noopener\">lâ€™irrigation automatisÃ©e</a> et adaptÃ©e au besoin des plantes en temps rÃ©el.</p><p>On peut aussi dÃ©tecter lorsque des fruits et lÃ©gumes sont mÃ»rs, ou dÃ©tecter les insectes et les mauvaises herbes en utilisant des drones de surveillance.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>En conclusion, le projet FarmBot offre une solution innovante pour lâ€™agriculture de demain en utilisant lâ€™automatisation, la robotique et lâ€™intelligence artificielle pour planter, cultiver et rÃ©colter des aliments de maniÃ¨re plus efficace et prÃ©cise. Il permet de maximiser les rendements alimentaires tout en rÃ©duisant les coÃ»ts et les dÃ©chets, et en augmentant la durabilitÃ© de lâ€™agriculture.</p><p>Mais FarmBot ne se limite pas quâ€™Ã  un systÃ¨me de robotisation agricole, câ€™est aussi un projet qui rÃ©unit une communautÃ© de dÃ©veloppeurs passionnÃ©s pour continuer Ã  amÃ©liorer les fonctionnalitÃ©s de la plateforme. Il permet Ã©galement aux gens de produire leur propre nourriture de maniÃ¨re efficace, sans avoir Ã  dÃ©pendre de sources dâ€™approvisionnement extÃ©rieures, et de se connecter Ã  la nature en cultivant leurs propres aliments frais.</p></div>"},
{"url": "https://larevueia.fr/6-projets-pour-apprendre-la-data-science/", "title": "6 projets pour apprendre la data science", "author": "Ilyes Talbi", "date": "\n21 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Lâ€™apprentissage par la pratique est de loin le meilleur moyen pour monter en compÃ©tences. Câ€™est vrai dans nâ€™importe quel domaine, mais encore plus dans les domaines en liens avec la programmation.</p><p>Dans cet article jâ€™ai compilÃ© 10 projets, de simple Ã  difficile, qui permettent de monter rapidement en compÃ©tences sur le machine learning.</p><h2 class=\"wp-block-heading\">Titanic : machine learning from disaster</h2><p>Beaucoup de data scientist ont commencÃ© par lÃ . Câ€™est un des premiers projets que je propose Ã  ceux qui dÃ©butent en machine learning.</p><p>Le principe du projet est simple. On a un dataset qui rÃ©unit des donnÃ©es sur les passagers du Titanic pendant son naufrage : nom, prÃ©nom, classe, age, sexe, numÃ©ro de cabine, etc. Et pour chaque passager on a une variable qui nous dit sâ€™il a survÃ©cu au naufrage ou non.</p><p>Lâ€™idÃ©e est dâ€™utiliser ces donnÃ©es pour entraÃ®ner un modÃ¨le capable de prÃ©dire la survie ou le naufrage dâ€™un passager.</p><p>Ce projet permet de se familiariser avec des librairies comme Pandas et Scikitlearn, et dâ€™utiliser des algorithmes comme Random forest ou XGBoost.</p><p>Je vous laisse commencer Ã  vous amuser sur <a href=\"https://www.kaggle.com/competitions/titanic/data\" target=\"_blank\" rel=\"noreferrer noopener\">Kaggle</a> ğŸ™‚</p><h2 class=\"wp-block-heading\">PrÃ©dire la gravitÃ© dâ€™un accident</h2><p>Pour trouver des projets intÃ©ressants Ã  rÃ©aliser je me rend souvent sur <a href=\"https://www.data.gouv.fr/fr/reuses/machine-learning-pour-predire-la-gravite-des-accidents/\" target=\"_blank\" rel=\"noreferrer noopener\">datagouv</a>. Une base de donnÃ©es libre proposÃ©e par lâ€™Ã©tat.</p><p>Parmi les dataset avec lesquels vous pouvez jouer, il y a une base de donnÃ©es qui recense les accidents par gravitÃ©. On a des informations comme le nombre de vÃ©hicules impliquÃ©s, le lieu, le moment, et pour chaque accident on a un indice de gravitÃ© compris entre 1 et 5.</p><p>Lâ€™objectif est de construire un modÃ¨le qui puisse prÃ©dire ce degrÃ© de gravitÃ©.</p><p>En plus dâ€™apprendre Ã  manipuler des donnÃ©es plus complexes avec Pandas, vous verrez comment gÃ©rer les problÃ¨mes liÃ©s aux donnÃ©es manquantes ou au dÃ©sÃ©quilibre des classes.</p><h2 class=\"wp-block-heading\">PrÃ©dire le loyer dâ€™un appartement Ã  Paris</h2><p>Pour ce projet lÃ  aussi vous trouverez les donnÃ©es sur datagouv.</p><p>Contrairement aux 2 premiers projets, dans celui ci on ne fait pas de classification mais une rÃ©gression. Ce qui est lÃ©gÃ¨rement diffÃ©rent, mÃªme si les Ã©tapes de traitement des donnÃ©es et les algorithmes utilisÃ©s sont trÃ¨s similaires.</p><p>Lâ€™objectif sera de pouvoir prÃ©dire les loyers dâ€™appartements parisiens Ã  partir de localisation, de leur surface et dâ€™autres donnÃ©es.</p><p>Je vous propose de suivre mon tutoriel <a href=\"https://larevueia.fr/regression-avec-random-forest-predire-le-loyer-dun-logement-a-paris/\" target=\"_blank\" rel=\"noreferrer noopener\">ici</a>.</p><h2 class=\"wp-block-heading\">MNIST : le premier rÃ©seau de neurones</h2><p>Ce projet lÃ  est le hello world du deep learning.</p><p>Il sâ€™agit de classifier des images de chiffres manuscrits en utilisant des techniques simples de deep learning.</p><p>Ce projet permet de se familiariser avec la manipulation de donnÃ©es sous forme dâ€™images. Il permet aussi de travailler avec une librairie plus haut niveau comme Tensorflow ou PyTorch, et dâ€™entraÃ®ner un premier rÃ©seau de neurones simples.</p><p>Lâ€™intÃ©rÃªt de travailler sur ce projet est que les tutoriels et vidÃ©os sur ce dataset ne manquent pas, vous serez soutenu du dÃ©but Ã  la fin du projet.</p><p>Vous trouverez le dataset et des propositions de solutions sur <a href=\"https://www.kaggle.com/competitions/digit-recognizer\" target=\"_blank\" rel=\"noreferrer noopener\">Kaggle</a>.</p><h2 class=\"wp-block-heading\">Fashion MNIST</h2><p>Pour rester sur le mÃªme type de projets, vous pouvez enchaÃ®ner avec <a href=\"https://www.youtube.com/watch?v=uITtXg2zoHg\" target=\"_blank\" rel=\"noreferrer noopener\">Fashion MNIST</a>. Le principe est exactement le mÃªme, et les outils utilisÃ©s sont les mÃªmes.</p><p>Sauf que cette fois les donnÃ©es sont moins uniformes (on dit que la variance intra-classe est plus Ã©levÃ©e. Le modÃ¨le de classification devra donc Ãªtre un peu plus fin.</p><p>Cette fois lâ€™objectif est de construire un modÃ¨le de classification dâ€™images dâ€™articles de modes. Le dataset avait Ã©tÃ© proposÃ© par Zalando. Et comme pour la base MNIST classique vous trouverez beaucoup dâ€™articles et de tutoriels sur ce projet.</p><h2 class=\"wp-block-heading\">Classification des musiques</h2><p>Pour le dernier projet, encore un peu plus difficile, je vous propose de travailler avec des donnÃ©es sonores. Le travail sur les donnÃ©es sonores est similaire au traitement de sÃ©ries temporelles.</p><p>Lâ€™idÃ©e de ce projet est dâ€™entraÃ®ner un modÃ¨le pour classifier des sons en fonction de leur types (jazz, rock, hip-hop, etc.).</p><p>Pour ce projet je vous conseille de tester plusieurs modÃ¨les sur les mÃªmes donnÃ©es et de comparer les rÃ©sultats. Jâ€™ai fait ce travail pour vous dans le <a href=\"https://larevueia.fr/machine-learning-pour-la-classification-automatique-de-musiques-avec-python/\" target=\"_blank\" rel=\"noreferrer noopener\">tutoriel suivant</a> ğŸ™‚</p></div>"},
{"url": "https://larevueia.fr/algorithmes-de-gradient-boosting-et-introduction-a-xgboost/", "title": "Algorithmes de gradient boosting et introduction Ã  XGBoost", "author": "Adib Habbou", "date": "\n26 fÃ©vrier 2023\n", "content": "<div class=\"entry-content\"><p>Si vous avez dÃ©jÃ  participÃ© Ã  des compÃ©titions <strong><a href=\"https://www.kaggle.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Kaggle</a></strong>, vous avez sÃ»rement dÃ©jÃ  entendu parler de <strong>XGBoost </strong>(eXtreme Gradient Boosting) qui est parmi les algorithmes de <strong>Gradient Boosting </strong>les plus connus et les plus utilisÃ©s dans le monde. Mais est-ce que vous vous Ãªtes dÃ©jÃ  demandÃ© quâ€™est-ce quâ€™il se cache derriÃ¨re ses algorithmes quâ€™on utilise souvent comme des boÃ®tes noires ? Dans la suite, je vais essayer de lever le capot et de vous expliquer comment tout cela fonctionne !</p><h2 class=\"wp-block-heading\">Lâ€™intuition derriÃ¨re le gradient boosting</h2><p>Les algorithmes de<strong> Gradient Boosting</strong> sâ€™appuient sur une idÃ©e fondamentale : tenir compte des erreurs du modÃ¨le pour amÃ©liorer les performances en formant un nouveau modÃ¨le qui rÃ©ussisse Ã  prÃ©dire les erreurs faites par le modÃ¨le original.</p><p>GrÃ¢ce Ã  cette idÃ©e, pour tout modÃ¨le prÃ©dictif, nous pouvons amÃ©liorer sa prÃ©cision en formant un nouveau prÃ©dicteur pour prÃ©dire ses erreurs actuelles. Ensuite, on forme un nouveau modÃ¨le Â«Â amÃ©liorÃ©Â Â» qui va en quelque sorte Ãªtre une agrÃ©gation des deux modÃ¨les initiaux.</p><p>Pour un algorithme de <strong>Gradient Boosting</strong> comme <strong>XGBoost</strong>, ce processus est rÃ©pÃ©tÃ© un nombre arbitraire de fois pour amÃ©liorer continuellement la prÃ©cision du modÃ¨le. Ce processus rÃ©pÃ©tÃ© constitue lâ€™essence mÃªme du <strong>Gradient Boosting</strong> puisquâ€™on se base sur le principe que lâ€™erreur va continuellement converger vers 0 au fur et Ã  mesure quâ€™on rÃ©pÃ¨te le processus.</p><h2 class=\"wp-block-heading\">Quel est lâ€™intÃ©rÃªt des Weak Learners du coup ?</h2><p>Lors de la formation dâ€™un nouveau modÃ¨le prÃ©dicteur dâ€™erreurs pour prÃ©dire les erreurs actuelles dâ€™un modÃ¨le, nous rÃ©gularisons sa complexitÃ© pour Ã©viter de tomber dans de <a href=\"https://larevueia.fr/7-methodes-pour-eviter-loverfitting/\" target=\"_blank\" rel=\"noreferrer noopener\">lâ€™overfitting</a>. Ce modÃ¨le rÃ©gularisÃ© aura des Â«Â erreursÂ Â» lorsquâ€™il prÃ©dit les Â«Â erreursÂ Â» du modÃ¨le original. Nous rÃ©duisons notre confiance envers un seul prÃ©dicteur dâ€™erreur en appliquant un petit poids <strong>Î·</strong> Ã  sa sortie.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/720/1*7EhjRtzxSj5whkHf-MxjLA.png\" alt=\"Algorithmes de gradient boosting et introduction Ã  XGBoost\"></figure></div><h2 class=\"wp-block-heading\">Pourquoi on parle de Gradient alors ?</h2><p>Il sâ€™avÃ¨re que lâ€™erreur quâ€™on essaye de corriger avec les <strong>Weak Learners</strong> est le gradient de la fonction de coÃ»t par rapport Ã  la prÃ©diction du modÃ¨le.</p><p>MathÃ©matiquement, la dÃ©rivÃ©e de la fonction de coÃ»t nous donne la direction dans laquelle les prÃ©dictions peuvent Ãªtre ajustÃ©es pour maximiser la perte. Dans le <strong>Gradient Boosting</strong>, nous ajustons nos prÃ©dictions dans la direction opposÃ©e câ€™est-Ã -dire vers le gradient nÃ©gatif afin de pouvoir minimiser le coÃ»t et donc amÃ©liorer la performance.</p><p>Intuitivement, lâ€™idÃ©e derriÃ¨re le <strong>Gradient Boosting</strong> est que nous dÃ©plaÃ§ons les prÃ©dictions de notre modÃ¨le par petits pas vers des directions qui amÃ©liorent la performance globale de notre modÃ¨le.</p><h2 class=\"wp-block-heading\">Mais du coup câ€™est quoi au juste XGBoost ?</h2><p><strong>XGBoost </strong>est une variante des mÃ©thodes de <strong>Gradient Boosting</strong> qui utilise des arbres de dÃ©cisions dit <strong>Gradient Boosting Tree </strong>comme prÃ©dicteur dâ€™erreur. Il commence avec un prÃ©dicteur simple qui prÃ©dit un nombre arbitraire en gÃ©nÃ©rale 0.5 quelque soit lâ€™entrÃ©e. Inutile de vous dire que ce prÃ©dicteur commet beaucoup dâ€™erreurs. Le <strong>Gradient Boosting</strong> est ensuite appliquÃ©e jusquâ€™Ã  ce que lâ€™erreur soit ramenÃ©e Ã  un minimum.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/1400/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg\" alt=\"Algorithmes de gradient boosting et introduction Ã  XGBoost\"></figure></div><p>La dÃ©nomination <strong>eXtreme </strong>vient du fait que le <strong>XGBoost </strong>est une combinaison parfaite de techniques dâ€™optimisation logicielle et matÃ©rielle permettant dâ€™obtenir des rÃ©sultats supÃ©rieurs en utilisant moins de ressources informatiques et en un minimum de temps.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://miro.medium.com/max/1400/1*FLshv-wVDfu-i54OqvZdHg.png\" alt=\"Algorithmes de gradient boosting et introduction Ã  XGBoost\"></figure></div><p>Depuis dâ€™autres algorithmes de <strong>Gradient Boosting</strong> ont vu le jour comme <strong>LightGBM </strong>dÃ©veloppÃ© par <strong>Microsoft </strong>ou encore <strong>CatBoost </strong>dÃ©veloppÃ© par <strong>Yandex </strong>mais qui sait quel sera le prochain roi du Gradient Boostingâ€¦</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*i0CA9ho0WArOj-0UdpuKGQ.png\" alt=\"Algorithmes de gradient boosting et introduction Ã  XGBoost\"></figure></div><h2 class=\"wp-block-heading\">Comment implÃ©menter XGBoost avec Python</h2><p>En <strong>Python </strong>il existe toujours une super libraire pour faire ce que vous rechercher, dans notre cas câ€™est <strong>xgboost</strong> ! Mais comme pour tout bon modÃ¨le il faut chercher les bons hyperparamÃ¨tres pour obtenir le meilleur rÃ©sultat possible. Dans le code qui suit on va utiliser la fonction <strong>GridSearchCV </strong>de <strong>scikit-learn</strong> pour trouver les bons hyperparamÃ¨tres.</p><p><strong>Grid Search Cross Valildation</strong> Ã©tant un algorithme de recherche dâ€™hyperparamÃ¨tres qui effectue une recherche exhaustive sur une grille dâ€™hyperparamÃ¨tres spÃ©cifiÃ©e. Il teste toutes les combinaisons possibles des hyperparamÃ¨tres spÃ©cifiÃ©s pour dÃ©terminer les meilleures valeurs pour ce faire il utilise une validation croisÃ©e pour Ã©valuer les performances de chaque combinaison dâ€™hyperparamÃ¨tres.</p><pre class=\"wp-block-code\"><code>from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# ParamÃ¨tres Ã  tester pour le rÃ©glage des hyperparamÃ¨tres\nparam_grid = {\n    'learning_rate': [0.01, 0.1, 1],\n    'max_depth': [100, 200, 300],\n    'min_child_weight': [1, 3, 5],\n    'gamma': [1, 3, 5],\n    'n_estimators': [300, 500, 700],\n    'alpha': [0.01, 0.1, 1],\n    'colsample_bytree': [0.8, 0.9, 1]\n}\n\n# Initialisation du modÃ¨le XGBoost\nxgb = XGBClassifier(random_state=42)\n\n# Initialiser GridSearchCV pour ajuster les hyperparamÃ¨tres du modÃ¨le\ngrid_search = GridSearchCV(xgb, param_grid, cv=5)\n\n# Fit du modÃ¨le en utilisant les donnÃ©es d'entraÃ®nement\ngrid_search.fit(X_train, y_train)\n\n# Affichage des meilleurs hyperparamÃ¨tres trouvÃ©s\nprint(\"Meilleurs hyperparamÃ¨tres : \", grid_search.best_params_)\n\n# Sauvegarde des meilleurs hyperparamÃ¨tres trouvÃ©s\nxgb_best_param = grid_search.best_params_\n\n# Instanciation du modÃ¨le avec les meilleurs hyperparamÃ¨tres\nxgb_optimized = XGBClassifier(**grid_search.best_params_)\n\n# EntraÃ®nement du modÃ¨le sur les donnÃ©es d'entraÃ®nement\nxgb_optimized.fit(X_train, y_train)\n\n# Utilisation des hyperparamÃ¨tres pour faire des prÃ©dictions sur les donnÃ©es de test\ny_pred = xgb_optimized.predict(X_test)\n\n# Calcul de l'accuracy du modÃ¨le\naccuracy = accuracy_score(y_test, y_pred)\n\n# Affichage de l'accuracy du modÃ¨le\nprint(\"Accuracy XGBoost :\", accuracy)</code></pre><h2 class=\"wp-block-heading\">Pour aller plus loin</h2><p><strong>VidÃ©os sur le Gradient Boost de StatQuest :</strong></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Gradient Boost Part 1 (of 4): Regression Main Ideas\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/3CC4N4z3GJc?list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div></figure><p><strong>VidÃ©os sur le XGBoost de StatQuest :</strong></p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"XGBoost Part 1 (of 4): Regression\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/OtD8wVaFm6E?list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div></figure><h2 class=\"wp-block-heading\">Conclusion</h2><p>Maintenant que vous Ãªtes un peu plus familiers avec le <strong>Gradient Boosting</strong><em> </em>vous pouvez explorer toutes les possibilitÃ©s offertes par ces modÃ¨les et monter tout en haut du classement de votre compÃ©tition <strong>Kaggle </strong>prÃ©fÃ©rÃ©e !</p><p>Nâ€™hÃ©sitez pas Ã  me demander en commentaire si vous avez besoin dâ€™aide ğŸ™‚</p></div>"},
{"url": "https://larevueia.fr/larchitecture-seq2seq-en-deep-learning-fonctionnement-et-limites/", "title": "Lâ€™architecture Seq2Seq en deep learning : fonctionnement et limites", "author": "Ilyes Talbi", "date": "\n28 novembre 2024\n", "content": "<div class=\"entry-content\"><p>Les rÃ©seaux Seq2Seq sont des modÃ¨les dâ€™apprentissage automatique puissants qui transforment une sÃ©quence dâ€™entrÃ©e en une sÃ©quence de sortie, mÃªme lorsque les longueurs de ces sÃ©quences sont diffÃ©rentes. Ils permettent de rÃ©soudre les problÃ¨mes liÃ©es aux tailles figÃ©es des sorties des rÃ©seaux de neurones classiques.</p><p>Lâ€™architecture Seq2Seq est utilisÃ©e principalement en NLP (traitement du langage naturel), pour la rÃ©alisation de tÃ¢ches comme la traduction.</p><p>Dans cet article je vous explique tout ce quâ€™il y a Ã  savoir sur les Seq2Seq. On parlera de leurs applications concrÃ¨tes, de leur fonctionnement technique et des limites de cette architecture.</p><h2 class=\"wp-block-heading\" id=\"h-les-applications-des-seq2seq\">Les applications des Seq2Seq</h2><p>Les applications des Seq2Seq sont nombreuses et variÃ©es, notamment dans le domaine du traitement du langage naturel (NLP).</p><p>Les rÃ©seaux Seq2Seq sont Ã  la base des systÃ¨mes de traduction tels que <a href=\"https://research.google/blog/a-neural-network-for-machine-translation-at-production-scale/\">Google Translate</a>. Ils transforment une sÃ©quence de mots dans une langue source en une sÃ©quence Ã©quivalente dans une langue cible, mÃªme si les structures grammaticales diffÃ¨rent. Et permettent une comprÃ©hension linguistique du contexte plus prÃ©cise que beaucoup dâ€™autres architectures.</p><p>De maniÃ¨re gÃ©nÃ©rale, les Seq2Seq permettent dâ€™obtenir des performances intÃ©ressantes dans toutes les tÃ¢ches de gÃ©nÃ©ration ou transformation de texte :</p><ul class=\"wp-block-list\"><li>GÃ©nÃ©rer un rÃ©sumÃ© dâ€™un document est une autre application populaire des Seq2Seq. Ils lisent le texte source et produisent une version plus courte tout en conservant les points essentiels.</li><li>Dans les chatbots et assistants virtuels, les Seq2Seq sont souvent utilisÃ©s pour modÃ©liser les dialogues. En fonction dâ€™une requÃªte ou dâ€™un message, le modÃ¨le gÃ©nÃ¨re une rÃ©ponse appropriÃ©e.</li><li>Ces rÃ©seaux sont aussi utilisÃ©s pour des systÃ¨mes de questions-rÃ©ponses, en prenant une question en entrÃ©e et gÃ©nÃ©rant une rÃ©ponse en fonction du contexte fourni.</li></ul><p>Les Seq2Seq ont Ã©tÃ© proposÃ©s initialement pour rÃ©gler les problÃ¨mes liÃ©s aux donnÃ©es sÃ©quentielles. Le texte nâ€™est quâ€™un exemple de tous les types de donnÃ©es sÃ©quentielles que lâ€™on gÃ©nÃ¨re.</p><p>Ainsi, on pourrait reprendre les approches Seq2Seq, les combiner Ã  des rÃ©seaux de convolutions pour la comprÃ©hension dâ€™une image, pour pouvoir entraÃ®ner des modÃ¨les Ã  comprendre les scÃ¨nes dâ€™une vidÃ©o.</p><p>Les Seq2Seq ne se limitent pas uniquement Ã  la manipulation du texte, mais sont trÃ¨s polyvalents lorsquâ€™il sâ€™agit de transformer des sÃ©quences dâ€™informations complexes en dâ€™autres sÃ©quences comprÃ©hensibles.</p><h2 class=\"wp-block-heading\" id=\"h-le-fonctionnement-des-seq2seq\">Le fonctionnement des Seq2Seq</h2><p>Lâ€™architecture des Seq2Seq consiste en 2 parties : une partie dâ€™encodage et une partie de dÃ©codage.</p><p>Le rÃ´le de la partie encodeur sera de rÃ©sumer lâ€™information disponible dans la sÃ©quence dâ€™entrÃ©e sous forme dâ€™un vecteur de contexte.</p><p>Le rÃ´le du dÃ©codeur est de construire la sÃ©quence de sortie Ã©lÃ©ment par Ã©lÃ©ment.</p><h3 class=\"wp-block-heading\" id=\"h-comment-fonctionne-la-partie-encodeur\">Comment fonctionne la partie encodeur ?</h3><p>La partie encodeur dâ€™un modÃ¨le Seq2Seq est responsable de traiter la sÃ©quence dâ€™entrÃ©e et de la convertir en une reprÃ©sentation interne compacte, souvent appelÃ©e vecteur de contexte.</p><p>Cette reprÃ©sentation contient les caractÃ©ristiques essentielles de la sÃ©quence dâ€™entrÃ©e qui seront ensuite utilisÃ©es par le dÃ©codeur pour gÃ©nÃ©rer la sÃ©quence de sortie. Lâ€™encodeur est typiquement constituÃ© de plusieurs couches de rÃ©seaux rÃ©currents RNN, qui permettent dâ€™assimiler lâ€™information dans un format adaptÃ© pour le traitement ultÃ©rieur par le dÃ©codeur.</p><p>MathÃ©matiquement, le vecteur de contexte qui rÃ©sulte de lâ€™encodeur est une somme des Ã©tats cachÃ©s des diffÃ©rentes cellules de RNN qui le composent.</p><p>Dans certaines variantes des modÃ¨les Seq2Seq, comme les modÃ¨les utilisant le mÃ©canisme dâ€™attention, le vecteur de contexte est enrichi en mettant en Ã©vidence les parties les plus pertinentes de la sÃ©quence dâ€™entrÃ©e pour chaque Ã©tape de la gÃ©nÃ©ration de la sortie.</p><p>Cela permet au modÃ¨le de mieux se concentrer sur les informations cruciales Ã  chaque instant, en faisant une somme pondÃ©rÃ©e par lâ€™importance des diffÃ©rents Ã©lÃ©ments dâ€™une sÃ©quence donnÃ©e.</p><p>Par exemple, dans une phrase comme Â«Â Le chat dort sur le canapÃ©Â Â», un mÃ©canisme dâ€™attention pourrait permettre au modÃ¨le de se concentrer successivement sur Â«Â chatÂ Â», puis sur Â«Â dortÂ Â», et enfin sur Â«Â canapÃ©Â Â», afin de gÃ©nÃ©rer un vecteur mathÃ©matiques qui permet dâ€™extraire le contexte linguistique de maniÃ¨re prÃ©cise.</p><h3 class=\"wp-block-heading\" id=\"h-comment-fonctionne-la-partie-decodeur\">Comment fonctionne la partie dÃ©codeur ?</h3><p>La partie dÃ©codeur dâ€™un modÃ¨le Seq2Seq reÃ§oit la reprÃ©sentation interne gÃ©nÃ©rÃ©e par lâ€™encodeur, souvent appelÃ©e vecteur de contexte, et utilise cette information pour produire la sÃ©quence de sortie, un Ã©lÃ©ment Ã  la fois. Le dÃ©codeur est Ã©galement constituÃ© de rÃ©seaux rÃ©currents RNN (<a href=\"https://larevueia.fr/quest-ce-quun-reseau-lstm/\">LSTM</a> ou GRU), qui gÃ©nÃ¨rent chaque mot de la sÃ©quence de sortie en fonction de lâ€™Ã©tat prÃ©cÃ©dent et du vecteur de contexte.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"473\" height=\"149\" src=\"https://larevueia.fr/wp-content/uploads/2024/11/seq2seq.png\" alt=\"Le fonctionnement de l'architecture Seq2Seq en deep learning\" class=\"wp-image-8874\" style=\"width:695px;height:auto\" srcset=\"https://larevueia.fr/wp-content/uploads/2024/11/seq2seq.png 473w, https://larevueia.fr/wp-content/uploads/2024/11/seq2seq-300x95.png 300w\" sizes=\"auto, (max-width: 473px) 100vw, 473px\"><figcaption class=\"wp-element-caption\">Seq2Seq (Source : <a href=\"https://d2l.ai/chapter_recurrent-modern/seq2seq.html\" target=\"_blank\" rel=\"noreferrer noopener\">Dive into deep learning</a>)</figcaption></figure></div><p>En dâ€™autres termes, Ã  chaque fois quâ€™un nouvel Ã©lÃ©ment est gÃ©nÃ©rÃ© dans la sÃ©quence de sortie, le vecteur de contexte est mis Ã  jour. Par exemple, si je traduis la phrase Â«Â Le chat dort sur le canapÃ©Â Â» voici ce qui se passe :</p><ul class=\"wp-block-list\"><li>lâ€™encodeur me donne un vecteur de contexte pour cette phrase</li><li>je vais utiliser le dÃ©codeur une premiÃ¨re fois pour gÃ©nÃ©rer le premier Ã©lÃ©ment de ma sortie Â«Â TheÂ Â»</li><li>en consÃ©quence, le vecteur de contexte sera mis Ã  jour pour contenir aussi bien la phrase dâ€™entrÃ©e que le Â«Â TheÂ Â», ce qui permettra de gÃ©nÃ©ra le deuxiÃ¨me Ã©lÃ©ment de ma sÃ©quence Â«Â catÂ Â»</li><li>on rÃ©itÃ¨re ce processus, jusquâ€™a ce que le dÃ©codeur prÃ©dise le mot de fin de sÃ©quence , souvent la chaine de caractÃ¨re &lt;EOS&gt; (pour End Of Sequence)</li></ul><p>Lorsque le mÃ©canisme dâ€™attention est utilisÃ©, le dÃ©codeur peut accÃ©der directement aux parties spÃ©cifiques de la sÃ©quence dâ€™entrÃ©e via lâ€™attention, lui permettant ainsi de se concentrer sur les informations pertinentes Ã  chaque Ã©tape de la gÃ©nÃ©ration.</p><p>Cela amÃ©liore la qualitÃ© de la sortie, notamment pour des sÃ©quences longues ou complexes, oÃ¹ il est important de se rÃ©fÃ©rer Ã  diffÃ©rents Ã©lÃ©ments de la sÃ©quence dâ€™entrÃ©e.</p><p>Par exemple, pour traduire la phrase Â«Â Le chat dort sur le canapÃ©Â Â», le dÃ©codeur gÃ©nÃ¨rera chaque mot de la phrase cible en se basant sur le vecteur de contexte et les mots dÃ©jÃ  gÃ©nÃ©rÃ©s, tout en utilisant lâ€™attention pour se concentrer sur les parties pertinentes de la sÃ©quence source.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"407\" src=\"https://larevueia.fr/wp-content/uploads/2024/11/Seq2seq_with_RNN_and_attention_mechanism.gif\" alt=\"Le mÃ©canisme d'attention dans les Seq2Seq\" class=\"wp-image-8875\" style=\"width:635px;height:auto\"><figcaption class=\"wp-element-caption\">Seq2Seq avec le mÃ©canisme dâ€™attention (<a href=\"https://en.wikipedia.org/wiki/Seq2seq\" target=\"_blank\" rel=\"noreferrer noopener\">WikipÃ©dia</a>)</figcaption></figure></div><h2 class=\"wp-block-heading\" id=\"h-quelles-sont-les-limites-de-ces-architectures\">Quelles sont les limites de ces architectures ?</h2><p>Les modÃ¨les Seq2Seq, bien quâ€™efficaces pour de nombreuses tÃ¢ches, prÃ©sentent plusieurs limites importantes.</p><p>Dâ€™abord, les architectures Seq2Seq classiques, en particulier celles qui nâ€™utilisent pas de mÃ©canisme dâ€™attention, ont du mal Ã  gÃ©rer de trÃ¨s longues sÃ©quences. Le vecteur de contexte doit rÃ©sumer toute la sÃ©quence dâ€™entrÃ©e en une seule reprÃ©sentation fixe, ce qui peut entraÃ®ner une perte dâ€™information pour les longues phrases ou documents.</p><p>Pour cette mÃªme raison, les modÃ¨les Seq2Seq ont tendance Ã  Ãªtre biaisÃ©s vers les mots les plus rÃ©cents dans la sÃ©quence dâ€™entrÃ©e, ce qui peut affecter la qualitÃ© de la sortie, notamment pour les traductions ou rÃ©sumÃ©s oÃ¹ lâ€™ensemble de la phrase est important.</p><p>Par ailleurs, les rÃ©seaux Seq2Seq, en particulier lorsquâ€™ils sont combinÃ©s avec des mÃ©canismes dâ€™attention, peuvent Ãªtre coÃ»teux en termes de calcul, surtout pour des sÃ©quences longues et des modÃ¨les de grande taille. MÃªme si cela est aussi le cas pour dâ€™autres architectures comme les Transformers, le problÃ¨me dans les Seq2Seq est que toutes les opÃ©rations ne sont pas parallÃ©lisables, ce qui rend lâ€™entraÃ®nement dâ€™un Seq2Seq difficile aussi bien sur GPU que sur CPU.</p><p>Câ€™est pour pallier certaines de ces limites, des amÃ©liorations comme les mÃ©canismes dâ€™attention ou lâ€™utilisation de <a href=\"https://larevueia.fr/introduction-aux-reseaux-de-neurones-transformers/\">Transformers</a> ont Ã©tÃ© introduites, rendant les modÃ¨les plus performants pour traiter des sÃ©quences longues et complexes.</p><p>Les Transformers introduisent des mÃ©canismes comme la self-attention ou des mÃ©thodes qui rendent possible les calculs en parallÃ¨le.</p></div>"},
{"url": "https://larevueia.fr/deconfinement-le-role-de-lintelligence-artificielle-dans-le-maintien-de-la-distanciation-sociale/", "title": "DÃ©confinementÂ : le rÃ´le de lâ€™intelligence artificielle dans le maintien de la distanciation sociale", "author": "Dr. Rajae Ghanimi", "date": "\n21 mai 2020\n", "content": "<div class=\"entry-content custom-excerpt\"><p>Le confinement est une solution qui a dÃ©montrÃ© son efficacitÃ© dans la lutte contre la propagation des Ã©pidÃ©mies, mais, elle reste toujours une solution psychologiquement lourde et Ã©conomiquement trÃ¨s dommageable.</p></div>"},
{"url": "https://larevueia.fr/langchain-le-guide-essentiel/", "title": "LangChain: Le guide essentiel", "author": "Alexandre LavallÃ©e", "date": "\n26 avril 2023\n", "content": "<div class=\"entry-content\"><p><em>Article co-Ã©crit avec Ilyes Talbi</em></p><p>Nous allons voir dans cet article les fondamentaux de LangChain, pour une prise en main rapide de cette bibliothÃ¨que si particuliÃ¨re et si puissante pour quiconque sâ€™intÃ©ressant aux modÃ¨les de languages, ou autres agents augmentÃ©s/chatbots et de leurs dÃ©ploiements dans la sphÃ¨re du dÃ©veloppement grand public et du monde du business.</p><p>Bien que la bibliothÃ¨que nâ€™en soit quâ€™Ã  ses dÃ©buts, elle est dÃ©jÃ  remplie de fonctionnalitÃ©s incroyables permettant de construire des outils, des applications ou encore des plugin extraordinaires autour du cÅ“ur des modÃ¨les de language derniÃ¨re gÃ©nÃ©ration comme GPT-4.</p><p>Note: une fois cet article lu, nous vous recommandons dâ€™utiliser ce <a href=\"https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">notebook pour dÃ©butant sur langchain</a> pour reprendre tout les concepts mis en avant un Ã  un par vous mÃªmeâ€Šâ€”â€Šmis en place par le gÃ©nial <a href=\"https://github.com/gkamradt\" target=\"_blank\" rel=\"noreferrer noopener\">Greg Kamradt</a>.</p><h2 class=\"wp-block-heading\">AperÃ§u des use-cases possibles avec LangChain</h2><ul class=\"wp-block-list\"><li>crÃ©ation et dÃ©ploiement dâ€™assistants personnels (agents)</li><li>crÃ©ation dâ€™Agents autonomes (rendu Ã  la mode avec Auto-GPT, BabyAGI etc)</li><li>mise en place de Q&amp;A sur vos documents propres (en local, vos pdf, drive, notion etc) avec rÃ©cupÃ©ration des sources exactes</li><li>crÃ©ation de rÃ©sumÃ©s, dâ€™analyses et de synthÃ¨ses de tous vos documents et ce peu important la taille</li><li>crÃ©ation et personnalisation de Chatbots â€œvraimentâ€ crÃ©dibles avec lesquels vous interagissez en language naturel</li><li>interrogation de vos donnÃ©es tabulaires</li><li>crÃ©ation de plugin personnalisÃ©s pour faire de la comprÃ©hension de votre code</li><li>interaction multiples et variÃ©s avec dâ€™autres API (comme google search) pour combiner les LLM avec vos apps prÃ©fÃ©rÃ©es</li><li>etc etc etc</li></ul><p>La liste est beaucoup plus longue, et en Ã©volution permanente grÃ¢ce Ã  la flexibilitÃ© de LangChain dâ€™interagir et de suivre les derniÃ¨res Ã©volutions du GenerativeAI.</p><h2 class=\"wp-block-heading\">Historique: Lâ€™Ã©mergence de LangChain</h2><p>Les grands modÃ¨les de langage (LLM) sont apparus sur la scÃ¨ne mondiale avec la publication du GPT-3 dâ€™OpenAI en 2020. Depuis lors, leur popularitÃ© nâ€™a cessÃ© de croÃ®tre avec le couronnement de <a href=\"https://larevueia.fr/chatgpt/\" target=\"_blank\" rel=\"noreferrer noopener\">ChatGPT</a> en DÃ©cembre 2022 propulsant les LLM sous les feux des projecteurs.</p><p>Lâ€™intÃ©rÃªt pour les LLM et la discipline plus large de lâ€™IA gÃ©nÃ©rative est montÃ© en flÃ¨che. Ce progrÃ¨s est trÃ¨s rapide que lâ€™on peut rÃ©sumer comme suit :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*NjyH5uyad15dJBqMlsMswQ@2x.png\" alt=\"LangChain: Le guide essentiel\"></figure><p><a href=\"https://python.langchain.com/en/latest/\" rel=\"noreferrer noopener\" target=\"_blank\">LangChain</a> vient sâ€™insÃ©rer Ã  ce moment crucial de lâ€™histoire ou la commoditÃ© des modÃ¨les de languages et leur efficacitÃ© les rend tout Ã  fait matures pour Ãªtre utilisÃ©es dans le monde applicatif. En dâ€™autres termes, OpenAI a lancÃ© le mouvement des modÃ¨les de language comme GPT-4 consumables via API, LangChain crÃ©Ã©e le pont entre le monde des applications et les modÃ¨les de languageâ€” quâ€™ils soient dâ€™OpenAI ou votre propre version Open-Source <em>fine-tunÃ©</em> dâ€™un LLM comme celui de Stability.ai (<a href=\"https://github.com/Stability-AI/StableLM\" rel=\"noreferrer noopener\" target=\"_blank\">StableLM</a>).</p><h2 class=\"wp-block-heading\">La philosophie de LangChain</h2><p>La philosophie de LangChain est rÃ©sumÃ© par son fondateur <a href=\"https://twitter.com/hwchase17?lang=en\" rel=\"noreferrer noopener\" target=\"_blank\">Harrison Chase</a> comme suit:</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*XzYeDKpNWqU81Sw1sNtIeg@2x.png\" alt=\"LangChain: Le guide essentiel\"><figcaption class=\"wp-element-caption\">source: LangChain Python officialÂ doc</figcaption></figure><p>Ce qui est intÃ©ressant de prime abord, câ€™est ce parti pris trÃ¨s affirmÃ©, les applications les plus radicales de demain utiliseront des modÃ¨les de language via API, et ces modÃ¨les de language pourront se renforcer:</p><ol class=\"wp-block-list\"><li>en â€œapprenantâ€ de nouvelles sources de donnÃ©es non-vues lors de leur entraÃ®nement, mais aussi se connecter Ã  dâ€™autres flux de donnÃ©es via API</li><li>en â€œaugmentantâ€ leurs capacitÃ©s en Ã©tant capable dâ€™utiliser de nouveaux outils et dâ€™interagir avec son propre environnement de donnÃ©es â€“ le concept dâ€™agents si cher Ã  LangChain, que nous verrons en dÃ©tail lors de cet article</li></ol><p>Si on fait un schÃ©ma, LangChain vient donc pouvoir sâ€™interfacer avec de nouvelles donnÃ©es et vous permet de construire vos applications en unifiant le tout sous la banniÃ¨re dâ€™un modÃ¨le de language.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*ea1-4Tm0TCYGu0-rvXBiVg.png\" alt=\"LangChain: Le guide essentiel\"></figure><h2 class=\"wp-block-heading\">Les 3 concepts fondamentaux de LangChain</h2><p>Nous avons vu en introduction un petit aperÃ§u des use-cases possibles avec LangChain comme pour les chatbots, les questions-rÃ©ponses gÃ©nÃ©ratives (GQA), les rÃ©sumÃ©s etc</p><p>Lâ€™idÃ©e centrale de la bibliothÃ¨que est que nous pouvons â€œenchaÃ®nerâ€ diffÃ©rents composants pour crÃ©er des cas dâ€™utilisation plus avancÃ©s autour des LLM. Les <strong>chaÃ®nes</strong> peuvent Ãªtre constituÃ©es de plusieurs composants provenant de plusieurs modulesÂ :</p><h3 class=\"wp-block-heading\"><strong>Concept fondamental #1 Prompt TemplateÂ :</strong></h3><p>ce sont des modÃ¨les rÃ©-utilisables, des moules dÃ©jÃ  faits permettant de rÃ©utiliser simplement et dâ€™adapter ses prompts via un schÃ©ma prÃ©-dÃ©fini.</p><h3 class=\"wp-block-heading\"><strong>Concept fondamental #2 AgentsÂ :</strong></h3><p>les agents utilisent les LLM pour dÃ©cider des actions Ã  entreprendre. Des outils tels que la recherche sur le web ou les calculatrices peuvent Ãªtre utilisÃ©s, et tous sont intÃ©grÃ©s dans une boucle logique dâ€™opÃ©rations.</p><h3 class=\"wp-block-heading\"><strong>Concept fondamental #3 MÃ©moire</strong>Â :</h3><p>MÃ©moire Ã  court terme, mÃ©moire Ã  long terme pour les bots et agents que vous mettez en place, afin quâ€™ils se souviennent de leurs interactions passÃ©s avec vous.</p><h2 class=\"wp-block-heading\"><strong>Le principe des Â«Â Prompt TemplateÂ Â»dans LangChain</strong></h2><p>CommenÃ§ons par un exemple simple, afin de mettre en place un template de prompt pour effectuer de simple question-rÃ©ponse avec le modÃ¨le GPT 3.5 dâ€™OpenAI. Nous devons dâ€™abord installer la bibliothÃ¨que LangChain</p><pre class=\"wp-block-code\"><code>!pip install langchain</code></pre><pre class=\"wp-block-code\"><code>from langchain import PromptTemplate\n\ntemplate = \"\"\"Voila la question d'un utilisateur: {question}\n\nDonnez votre RÃ©ponse: \"\"\"\nprompt = PromptTemplate(\n        template=template,\n    input_variables=['question']\n)\n\n# user question\nquestion = \"Qui a gagnÃ© la coupe du monde 2022 au Qatar ?\"</code></pre><p>Dans lâ€™exemple ci-dessus, on ne fait simplement quâ€™injecter de maniÃ¨re dynamique le champ â€˜questionâ€ dans le prompt.</p><pre class=\"wp-block-preformatted\">Voila la question d'un utilisateur: {\"Qui a gagnÃ© la coupe du monde 2022 au Qatar ?\"}<br>Donnez votre rÃ©ponse</pre><p>Ã§a nâ€™a lâ€™air de rien, mais câ€™est un des features clefs majeurs de LangChain, car câ€™est ce qui vous permet de construire votre propre use-case en utilisant la <em>composabilitÃ©</em> de lâ€™outils et des prompts entre elles.</p><p>Les endpoints OpenAI dans LangChain se connectent Ã  OpenAI directement. Vous aurez besoin dâ€™un compte OpenAI et de <a href=\"https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\" rel=\"noreferrer noopener\" target=\"_blank\">votre clef secrÃ¨te API</a> pour aller plus loin si vous souhaitez utiliser le modÃ¨le de language</p><p>Une fois que vous avez une clÃ© API, nous lâ€™ajoutons Ã  la variable dâ€™environnement OPENAI_API_TOKEN. Nous pouvons le faire avec Python comme suitÂ :https://larevueia.fr/langchain-le-guide-essentiel/</p><pre class=\"wp-block-code\"><code>import os<br><br>os.environ['OPENAI_API_TOKEN'] = 'OPENAI_API_KEY'</code></pre><p>Ensuite, nous devons installer la bibliothÃ¨que OpenAI via Pip.</p><pre class=\"wp-block-code\"><code>!pip install openai</code></pre><p>Nous pouvons maintenant gÃ©nÃ©rer du texte en utilisant le template de prompt que nous avons crÃ©Ã© dans la prÃ©cÃ©dente partie. On va utiliser la capacitÃ© de gÃ©nÃ©ration (ou de complÃ©tion) de GPT-3 dâ€™OpenAI. Nous utiliserons text-davinci-003, pas de panique câ€™est juste le nom de code de GPT-3.</p><pre class=\"wp-block-code\"><code>from langchain.llms import OpenAI<br><br>davinci = OpenAI(model_name='text-davinci-003')</code></pre><pre class=\"wp-block-code\"><code>llm_chain = LLMChain(<br>    prompt=prompt,<br>    llm=davinci<br>)<br><br>print(llm_chain.run(question))</code></pre><p>Et voila donc votre premiÃ¨re chaÃ®ne, vous venez dâ€™exÃ©cuter votre requÃªte en utilisant la classe â€œtemplate de promptâ€ (PromptTemplate) et en faisant appel Ã  lâ€™API dâ€™OpenAI pour activer le modÃ¨le GPT 3.</p><p>Les classes de â€œtemplate de promptâ€ de LangChain sont donc conÃ§ues pour faciliter la construction de prompts avec des entrÃ©es dynamiques.</p><p>Voyons un exemple un prompt un peu plus compliquÃ© en lâ€™apparence mais reposant sur le mÃªme mÃ©chanisme.</p><pre class=\"wp-block-code\"><code>from langchain import PromptTemplate<br><br>template = \"\"\"RÃ©pondez Ã  la question en vous basant sur le contexte ci-dessous. <br>Si les informations fournies ne permettent pas de rÃ©pondre Ã  la question,<br>rÃ©pondez par \"Je ne sais pas\".<br><br><br>Contexte additionnelle : Les grands modÃ¨les de langage (LLM) sont les modÃ¨les les plus rÃ©cents utilisÃ©s dans le domaine du NLP.<br>Leurs performances supÃ©rieures Ã  celles des modÃ¨les plus petits les ont rendus incroyablement utiles pour les dÃ©veloppeurs d'applications NLP.<br>pour les dÃ©veloppeurs d'applications NLP. Ces modÃ¨les<br>Ces modÃ¨les sont accessibles via la bibliothÃ¨que `transformers` de Hugging Face, via OpenAI<br>en utilisant la bibliothÃ¨que `openai`, et via Cohere en utilisant la bibliothÃ¨que `cohere`.<br><br>Question : {requÃªte}<br><br>RÃ©ponse :\"\"\"<br><br>prompt_template = PromptTemplate(<br>    input_variables=[\"query\"],<br>    template=template<br>)</code></pre><p>Naturellement, nous pouvons passer la sortie de votre prompt_template directement dans un objet LLM comme ceci.</p><h2 class=\"wp-block-heading\">Le concept de <em>â€œfew shot Prompt Templateâ€</em>: LangChain et lâ€™art de lâ€™ingiÃ©nÃ©rie deÂ prompt</h2><p>Le succÃ¨s des LLM provient de leur grande taille et de leur capacitÃ© Ã  stocker la â€œconnaissanceâ€ dans les paramÃ¨tres du modÃ¨le, le stock des connaissances est faite pendant la phase dâ€™entraÃ®nement du modÃ¨le. Les deux mÃ©thodes principales pour transmettre des connaissances Ã  un modÃ¨le de language sont les suivantesÂ :</p><ul class=\"wp-block-list\"><li><strong>Connaissance paramÃ©triqueâ€Š</strong>â€”â€Šla connaissance mentionnÃ©e ci-dessus est tout ce qui a Ã©tÃ© appris par le modÃ¨le pendant le temps de formation et est stockÃ© dans les poids (ou paramÃ¨tres) du modÃ¨le.</li><li><strong>Connaissance extÃ©rieure</strong>â€” toute connaissances complÃ©mentaires fournies au modÃ¨le au moment de lâ€™infÃ©rence par lâ€™intermÃ©diaire des prompts</li></ul><p>Le modÃ¨le<em> F</em><a href=\"https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/few_shot_examples.html\" rel=\"noreferrer noopener\" target=\"_blank\"><em>ewShotPromptTemplate</em></a> de Langchain permet de spÃ©cialiser votre Bot, votre agent via des sources de connaissances extÃ©rieures, ou des indications dâ€™exemples que vous donnez au modÃ¨le via vos prompts.</p><p>Lâ€™idÃ©e est dâ€™â€entraÃ®nerâ€ le modÃ¨le sur quelques exemples que vous allez lui fournirâ€Šâ€”â€Šnous appelons cela lâ€™apprentissage Ã  la volÃ©e (Few Shot Learning)â€Šâ€”â€Šet ces exemples sont donnÃ©s au modÃ¨le dans le prompt directement.</p><p>Cette capacitÃ© est trÃ¨s pratique et idÃ©ale lorsque notre modÃ¨le a besoin dâ€™aide pour comprendre ce que nous lui demandons de faire. Câ€™est ce que montre lâ€™exemple suivantÂ :</p><pre class=\"wp-block-code\"><code>prompt = \"\"\"Voici des extraits de conversations avec un assistant d'IA<br>assistant. L'assistant est gÃ©nÃ©ralement sarcastique et plein d'esprit, <br>produisant des rÃ©ponses crÃ©atives et amusantes aux questions des utilisateurs. <br><br>Voici quelques exemples : <br><br>Utilisateur : Comment allez-vous ?<br>AI : Je n'ai pas Ã  me plaindre, mais il m'arrive de le faire.<br><br>Utilisateur : Quelle heure est-il ?<br>IA : Il est temps d'acheter une montre.<br><br>Utilisateur : Quel est le sens de la vie ?<br>IA :\"\"\"<br><br>print(openai(prompt))</code></pre><p>Si nos exemples renforcent les instructions que nous avons donnÃ©es dans le prompt, nous avons beaucoup plus de chances dâ€™obtenir une rÃ©ponse plus amusante et comme nous le souhaitons. Nous pouvons ensuite formaliser ce processus avec le FewShotPromptTemplate de LangchainÂ :</p><pre class=\"wp-block-code\"><code>from langchain import FewShotPromptTemplate<br><br># crÃ©ation de nos exemples perso pour base d'entrainement<br>examples = [<br>    {<br>        \"requÃªte\": \"How are you?\",<br>        \"rÃ©ponse\": \"I can't complain but sometimes I still do.\"<br>    }, {<br>        \"requÃªte\": \"What time is it?\",<br>        \"rÃ©ponse\": \"It's time to get a watch.\"<br>    }<br>]<br><br># crÃ©ation du template de nos exemples<br>example_template = \"\"\"<br>Utilisateur: {requÃªte}<br>AI: {rÃ©ponse}<br>\"\"\"<br><br># crÃ©ation d'un prompt d'example basÃ© sur notre template ci-dessus<br>example_prompt = PromptTemplate(<br>    input_variables=[\"requÃªte\", \"rÃ©ponse\"],<br>    template=example_template<br>)<br><br># dÃ©composons notre prÃ©cÃ©dent prompt en deux parties<br># le prefix qui sont nos instructions<br>prefix = \"\"\"The following are exerpts from conversations with an AI<br>assistant. The assistant is typically sarcastic and witty, producing<br>creative  and funny responses to the users questions. Here are some<br>examples: <br>\"\"\"<br># et le suffix qui sont la requÃªte en input de notre utilisateur et l'indicateur de sorties<br>suffix = \"\"\"<br>Utilisateur: {requÃªte}<br>AI: \"\"\"<br><br># now create the few shot prompt template<br>few_shot_prompt_template = FewShotPromptTemplate(<br>    examples=examples,<br>    example_prompt=example_prompt,<br>    prefix=prefix,<br>    suffix=suffix,<br>    input_variables=[\"requÃªte\"],<br>    example_separator=\"\\n\\n\"<br>)</code></pre><p>Naturellement, le prompt est lâ€™Ã©lement incontournable et essentiel du monde merveilleux des LLM. Il vaut la peine dâ€™explorer les <a href=\"https://python.langchain.com/en/latest/modules/chains/how_to_guides.html\" target=\"_blank\" rel=\"noreferrer noopener\">outils</a> disponibles dans LangChain et de se familiariser avec les diffÃ©rentes techniques dâ€™ingÃ©nierie de prompts.</p><p>Ici, nous nâ€™avons couvert que quelques exemples dâ€™outils disponible dans Langchain pour manipuler et crÃ©er vos prompts pour rÃ©pondre Ã  votre use-case prÃ©cis. Dans la prochaine section, nous explorerons une autre partie essentielle de Langchainâ€Šâ€”â€ŠappelÃ©e â€œAgentsâ€.</p><h2 class=\"wp-block-heading\"><strong>Le concept fondamental #2 </strong>de LangChain : les Agents</h2><p>Bien que trÃ¨s performants dans pas mal de cas, les LLM ont des limitations majeures, et une en particulier qui les rend inutilisable dans certains cas.</p><p>Ils ne sont pas capables de donner des rÃ©ponses toujours justes, sont limitÃ©s aux informations vues pendant leur training, ont tendance Ã  extrapoler sur plusieurs sujets et sont moins bons sur des choses simples comme le calcul.</p><p>Une solution Ã  ces problÃ¨mes est proposÃ©e par Langchain avec le concept dâ€™agents.</p><h3 class=\"wp-block-heading\"><strong>Quâ€™est-ce quâ€™un agent concrÃ¨tementÂ ?</strong></h3><p>Les agents peuvent Ãªtre considÃ©rÃ©s comme des â€œoutilsâ€ permettant aux LLMs de fonctionner. Tout comme un humain utiliserait une calculatrice pour les mathÃ©matiques ou effectuerait une recherche Google pour obtenir des informations, les agents permettent Ã  un LLM dâ€™Ã©tendre ses capacitÃ©s en faisant la mÃªme chose.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*hT2cpiCY6EmnoLmE.png\" alt=\"LangChain: Le guide essentiel\"><figcaption class=\"wp-element-caption\"><a href=\"https://www.pinecone.io/learn/langchain-agents/\" rel=\"noreferrer noopener\" target=\"_blank\">source: LangChain AI handbook deÂ Pinecone</a></figcaption></figure><p>En utilisant des agents, un LLM peut Ã©crire et exÃ©cuter du code Python, utiliser une calculatrice. Il peut Ã©galement rechercher des informations et interroger une base de donnÃ©es SQL.</p><p>Imaginez toutes les applications qui peuvent en dÃ©coulerÂ !</p><h3 class=\"wp-block-heading\"><strong>Comment fonctionnent les agents en pratiqueÂ ?</strong></h3><p>On va faire un exemple trÃ¨s concret en utilisant Python.</p><p>Pour utiliser les agents on doit avoir un modÃ¨le de langage de base, on va utiliser davinci dâ€™OpenAI ici, un â€œoutilâ€ au sens de LangChain et un agent qui va contrÃ´ler lâ€™interaction entre les 2.</p><p>CommenÃ§ons par initialiser notre LLMÂ :</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><pre class=\"wp-block-code\"><code>from langchain import OpenAI</code></pre><pre class=\"wp-block-code\"><code>llm = OpenAI(<br>    openai_api_key=\"OPENAI_API_KEY\",<br>    temperature=0,<br>    model_name=\"text-davinci-003\"<br>)</code></pre></blockquote><p>On va maintenant initialiser lâ€™outil, qui peut Ãªtre un outil dÃ©jÃ  dÃ©veloppÃ© par LangChain ou un outil custom que vous pouvez crÃ©er.</p><p>Ici, on va utiliser lâ€™outil llm_math, qui va permettre de faire des opÃ©rations mathÃ©matiquesÂ :</p><pre class=\"wp-block-code\"><code>from langchain.agents import load_tools</code></pre><pre class=\"wp-block-code\"><code>tools = load_tools(<br>    ['llm-math'],<br>    llm=llm<br>)</code></pre><p>Le 3Ã¨me ingrÃ©dient, câ€™est lâ€™agent, qui va gÃ©rer la connexion entre le llm et lâ€™outil.</p><p>On initialise lâ€™agent de cette maniÃ¨reÂ :</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><pre class=\"wp-block-preformatted\">from langchain.agents import initialize_agent</pre><pre class=\"wp-block-preformatted\">zero_shot_agent = initialize_agent(<br>    agent=\"zero-shot-react-description\",<br>    tools=tools,<br>    llm=llm,<br>    verbose=True,<br>    max_iterations=3<br>)</pre></blockquote><p>Lâ€™agent utilisÃ© <em>zero-shot-react-description</em> repose sur le framework ReAct (Reasoning + Acting), proposÃ© en 2022, dans <a href=\"https://arxiv.org/abs/2210.03629https://arxiv.org/abs/2210.03629\" rel=\"noreferrer noopener\" target=\"_blank\">ce papier</a> de recherche.</p><p>Câ€™est le framework qui va permettre au LLM de determiner quelle action il doit effectuer en fonction du prompt de lâ€™utilisateur et des descriptions des outils auxquels il accÃ¨s.</p><p>On peut tester notre agentÂ :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Combient fait (4.5*2.1)^2.2 ?\")</code></pre><p>Et voici le rÃ©sultat obtenuÂ :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*6qbB9-QPOo31F8HI8Ltlig.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>En laissant verbose Ã  <em>True</em>, on peut voir comment lâ€™agent â€œraisonneâ€ Ã©tape par Ã©tape.</p><p>On peut faire un nouvel exemple dans lequel on va aller un peu plus loin niveau raisonnementÂ :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Si Marie a 4 pommes et Georges en apporte 2\"<br>                \"et une moitiÃ© de boÃ®te\"<br>                \"(une boÃ®te contient 8 pommes), combien a-t-on de pommes ?\")</code></pre><p>Lâ€™agent rÃ©ussi parfaitement bien le test, voici sa rÃ©ponseÂ :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*opLj05T4rJmJgCgLaVePCQ.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Si vous avez bien suivi notre raisonnement, vous comprendrez quâ€™il manque quelque chose.</p><p>Notre agent, pour le moment, nâ€™a accÃ¨s quâ€™Ã  un seul outil, qui est lâ€™outil de calcul, Ã  chaque requÃªte il va tenter de lâ€™utiliser ce qui peut renvoyer des erreurs lorsquâ€™il nâ€™y a pas de calculs Ã  effectuer.</p><p>Par exempleÂ :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Quelle est la capitale de la NorvÃ©ge ?\")</code></pre><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*zoH3lP6sU69hAXultDNZBg.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Pour rÃ©soudre ce problÃ¨me, on peut ajouter lâ€™outil de modÃ¨le de langage Ã  notre agent.</p><p>On commence par initialiser lâ€™outilÂ :</p><pre class=\"wp-block-code\"><code>from langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.agents import Tool\n\nprompt = PromptTemplate(\n    input_variables=[\"query\"],\n    template=\"{query}\"\n)\n\nllm_chain = LLMChain(llm=llm, prompt=prompt)\n\n# initialize the LLM tool\nllm_tool = Tool(\n    name='Language Model',\n    func=llm_chain.run,\n    description='use this tool for general purpose queries and logic'\n)</code></pre><p>On lâ€™ajoute ensuite Ã  la â€œboÃ®te Ã  outilsâ€ de notre agent et on le rÃ©initialiseÂ :</p><pre class=\"wp-block-preformatted\">tools.append(llm_tool)</pre><pre class=\"wp-block-code\"><code># reinitialize the agent<br>zero_shot_agent = initialize_agent(<br>    agent=\"zero-shot-react-description\",<br>    tools=tools,<br>    llm=llm,<br>    verbose=True,<br>    max_iterations=3<br>)</code></pre><p>Si on repose la questionÂ :</p><pre class=\"wp-block-code\"><code>zero_shot_agent(\"Quelle est la capitale de la NorvÃ©ge ?\")</code></pre><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*pY5i_qWO934rr6DY0pmALA.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>A prÃ©sent nous avons la bonne rÃ©ponse, lâ€™agent dÃ©cide de prendre comme action par lui mÃªme dâ€™utiliser le modÃ¨le de language qui contient la rÃ©ponse Ã  cette question dans les poids du modÃ¨le.</p><h3 class=\"wp-block-heading\"><strong>Quels sont les diffÃ©rents agentsÂ ?</strong></h3><p>Comme nous lâ€™avons vu dans les 2 premiÃ¨res parties, les agents utilisent un LLM pour dÃ©terminer quelles actions entreprendre et dans quel ordre.</p><p>Une action peut consister Ã  utiliser un outil et observer sa sortie, ou retourner une rÃ©ponse Ã  lâ€™utilisateur.</p><p>Voici les agents qui sont disponibles dans LangChain de faÃ§on nativeÂ :</p><ul class=\"wp-block-list\"><li><em>zero-shot-react-description</em></li></ul><p>Cet agent utilise le framework ReAct, que jâ€™ai mentionnÃ© plus haut, pour dÃ©terminer lâ€™outil Ã  utiliser en se basant sur la description de lâ€™outil. On peut utiliser plusieurs outils avec cet agent et il nâ€™y a pas de limites de nombre, il faut par contre quâ€™une description soit fournie pour chacun des outils sÃ©lectionnÃ©s.</p><ul class=\"wp-block-list\"><li><em>react-docstore</em></li></ul><p>Cet agent utilise le framework ReAct pour interagir avec un docstore (un ensemble de documents). Deux outils doivent Ãªtre fournisÂ : un outil de recherche (Search tool) et un outil de consultation (Lookup tool) (ils doivent Ãªtre nommÃ©s exactement comme cela). Lâ€™outil de recherche doit rechercher un document, tandis que lâ€™outil de consultation doit rechercher un terme dans le document le plus rÃ©cemment trouvÃ©. Cet agent est Ã©quivalent Ã  lâ€™article ReAct original, spÃ©cifiquement lâ€™exemple de WikipÃ©dia.</p><ul class=\"wp-block-list\"><li><em>self-ask-with-search</em></li></ul><p>Cet agent utilise un seul outil qui doit Ãªtre nommÃ© Intermediate Answer. Cet outil doit Ãªtre capable de rechercher des rÃ©ponses factuelles aux questions. Cet agent est Ã©quivalent Ã  lâ€™article original self ask with search, oÃ¹ une API de recherche Google Ã©tait fournie en tant quâ€™outil.</p><ul class=\"wp-block-list\"><li><em>conversational-react-description</em></li></ul><p>Cet agent est conÃ§u pour Ãªtre utilisÃ© dans des contextes conversationnels. Lâ€™invite est conÃ§ue pour rendre lâ€™agent utile et conversationnel. Il utilise le framework ReAct pour dÃ©cider quel outil utiliser et se sert de la mÃ©moire pour se souvenir des interactions de conversation prÃ©cÃ©dentes.</p><h2 class=\"wp-block-heading\">Le concept fondamental #3 Â«Â MemoryÂ Â»Â dÃ©cortiquÃ©</h2><p>Une des grandes forces de ChatGPT, et des Transformers en gÃ©nÃ©ral, rÃ©side dans leur capacitÃ© Ã  garder les informations en mÃ©moire.</p><p>On avait ce comportement avec les LSTM mais câ€™Ã©tait une mÃ©moire court-terme qui fonctionnait le temps dâ€™une phrase ou dâ€™un court paragraphe.</p><p>Câ€™est un comportement que lâ€™on peut reproduire avec LangChain.</p><p>Par dÃ©faut les chains et les agents LangChain nâ€™ont pas de mÃ©moires, mais il y a des composantes proposer pour gÃ©rer les messages prÃ©cÃ©dents.</p><p>NÃ©anmoins, les interactions entre lâ€™utilisateur et le modÃ¨le de langage peuvent Ãªtre gardÃ©es en mÃ©moire grÃ¢ce au ChatMessages et construite avec les ConversationChains.</p><p>La mÃ©moire peut renvoyer plusieurs Ã©lÃ©ments dâ€™information (par exemple, les N messages les plus rÃ©cents et un rÃ©sumÃ© de tous les messages prÃ©cÃ©dents). Les informations renvoyÃ©es peuvent Ãªtre une chaÃ®ne de caractÃ¨res ou une liste de messages.</p><p>Nous allons dÃ©cortiquer quelques types de mÃ©moires ensemble, nâ€™hÃ©sitez pas Ã  creuser dâ€™avantage le sujet avec ces <a href=\"https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\" rel=\"noreferrer noopener\" target=\"_blank\">tutoriels</a> mis en ligne par LangChain.</p><h3 class=\"wp-block-heading\"><strong>Le concept de ConversationChain</strong> dans LangChain</h3><p>On va commencer par initialiser notre modÃ¨le de langage, on utilise GPT-3.5 pour cet exemple.</p><pre class=\"wp-block-code\"><code>from langchain import OpenAI\nfrom langchain.chains import ConversationChain\n\n# first initialize the large language model\n\nllm = OpenAI(\n\ttemperature=0,\n\topenai_api_key=\"OPENAI_API_KEY\",\n\tmodel_name=\"gpt-3.5-turbo\"\n)</code></pre><p>On initialise ensuite la ConversationChainÂ :</p><pre class=\"wp-block-code\"><code># now initialize the conversation chain<br>conversation = ConversationChain(llm=llm)</code></pre><p>Si on affiche lâ€™objet conversation, voici ce quâ€™on aÂ :</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*LG3PiK8CGWxTvuz-8Chwxw.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Lâ€™utilisateur est dÃ©fini par â€œHumanâ€ et lâ€™agent par â€œAIâ€. AprÃ¨s le prompt initial, nous voyons deux paramÃ¨tresÂ ; <strong>{history}</strong> et <strong>{input}</strong>.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*_FJu_49tOczk0KwTvTd2DQ.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>Le paramÃ¨tre<strong> {input}</strong> est lâ€™endroit oÃ¹ nous placerions la derniÃ¨re requÃªte humaineÂ ; il sâ€™agit de lâ€™entrÃ©e saisie dans une zone de texte du chatbot. Ici {history} fait donc rÃ©fÃ©rence Ã  la conversation initiÃ©e avec GPT comme montrÃ© ci-dessus.</p><p>Les diffÃ©rentes types de mÃ©moires</p><p>Comme lâ€™humain a diffÃ©rentes mÃ©moires (sensorielle, visuelle, sonore etc), nous pouvons utiliser plusieurs types de mÃ©moire conversationnelle avec la <em>ConversationChain</em>. En fonction du type de mÃ©moire choisie, le texte passÃ© au paramÃ¨tre {history} changera. On peut lister</p><h3 class=\"wp-block-heading\">Type de mÃ©moire #1: ConversationBufferMemory</h3><p>La mÃ©moire tampon de conversation (ConversationBufferMemory en anglais) fait exactement ce que son nom suggÃ¨reÂ : elle conserve une mÃ©moire tampon des extraits de conversation prÃ©cÃ©dents dans le cadre du contexte du prompt.</p><p><strong>CaractÃ©ristique PrincipaleÂ : </strong>la mÃ©moire tampon de conversation conserve les Ã©lÃ©ments de conversation prÃ©cÃ©dents sans aucune modification, dans leur forme brute.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*ErLc3N4e7L91gJ4C3EZ_Fg.png\" alt=\"LangChain: Le guide essentiel\"></figure><h3 class=\"wp-block-heading\">Type de mÃ©moire #2: ConversationSummaryMemory</h3><p>Le problÃ¨me avec la mÃ©moire tampon de la conversation est quâ€™au fur et Ã  mesure que la conversation progresse, le nombre de jetons (tokens) de lâ€™historique du contexte augmente. Câ€™est un problÃ¨me parce que nous pourrions Ã©puiser notre LLM avec une prompt qui est trop grande pour Ãªtre traitÃ©e. Pour rappel les longs historiques de conversations ne peuvent pas Ãªtre mÃ©morisÃ©es car nous avons une limite de jetons lorsquâ€™on utilise un LLM comme ChatGPT (4096 jetons pour text-davinci-003 et gpt-3.5-turbo).</p><p>Pas de panique, il y a une solution avec<em> ConversationSummaryMemory.</em></p><p>Encore une fois, nous pouvons dÃ©duire du nom ce qui se passeâ€¦ nous allons conserver un rÃ©sumÃ© de nos bribes de conversation prÃ©cÃ©dentes comme historique. Comment allons-nous les rÃ©sumerÂ ? LLM Ã  la rescousse.</p><p><strong>CaractÃ©ristique Principale:</strong> la mÃ©moire de rÃ©sumÃ© de conversation conserve les bribes de conversation prÃ©cÃ©dentes sous une forme rÃ©sumÃ©e, le rÃ©sumÃ© Ã©tant effectuÃ© par votre LLM.</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/1*MrKDQ5XRH3ppl3F9_Q4iKA.png\" alt=\"LangChain: Le guide essentiel\"></figure><h3 class=\"wp-block-heading\">Type de mÃ©moire #3: ConversationBufferWindowMemory</h3><p>Une autre option intÃ©ressante pour ces cas est le <em>ConversationBufferWindowMemory</em> oÃ¹ nous conserverons quelques-unes des derniÃ¨res interactions dans notre mÃ©moire, mais oÃ¹ nous laisserons intentionnellement tomber les plus anciennesâ€Šâ€”â€Šune mÃ©moire Ã  court terme si vous voulez. Ici, le nombre de jetons agrÃ©gÃ©s et le nombre de jetons par appel diminueront sensiblement.</p><p>Si nous nâ€™avons besoin que de la mÃ©moire des interactions rÃ©centes, câ€™est une excellente option.</p><p><strong>CaractÃ©ristique PrincipaleÂ </strong>: la mÃ©moire tampon de la conversation conserve les derniers Ã©lÃ©ments de la conversation sous forme brute.</p><p>Vous pouvez voir une analyse comparative dÃ©taillÃ©e sur ce <a href=\"https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/03a-token-counter.ipynb\" rel=\"noreferrer noopener\" target=\"_blank\">notebook</a> proposÃ© par Pinecone.</p><p>Il existe bien dâ€™autres types de mÃ©moires, nous voulions simplement vous en proposer quelques unes, pour aller plus loin câ€™est <a href=\"https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\" rel=\"noreferrer noopener\" target=\"_blank\">ici</a>.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>LangChain fournit un ensemble complet dâ€™outils, de fonctionnalitÃ©s et de capacitÃ©s qui simplifient le processus de combinaison des LLM avec des sources de donnÃ©es externes et des outils via API, ce qui rend plus facile que jamais lâ€™exploitation de la pleine puissance des LLM et la mise en Å“uvre de solutions et dâ€™apps rÃ©volutionnaires. GrÃ¢ce Ã  la prise en charge intÃ©grÃ©e de divers fournisseurs de LLM, dâ€™outils de gestion de prompts, de chaÃ®nes, dâ€™agents et dâ€™Ã©valuation, LangChain ouvre la voie aux dÃ©veloppeurs pour crÃ©er des applications sophistiquÃ©es, spÃ©cifiques Ã  un domaine, qui maximisent le potentiel des LLM.</p><p>Une des voies les plus prometteuses semblent la crÃ©ation dâ€™agents autonomes, des projets comme Auto-GPT ou BabyAGI (qui sont dâ€™ailleurs supportÃ©s par Langchain)</p><p>ConcrÃ¨tement, vous avez plus de use-casesÂ ?</p><p>Yes serâ€Šâ€”â€Š<a href=\"https://www.twitter.com/mattprd?utm_source=www.mattprd.com&amp;utm_medium=referral&amp;utm_campaign=the-complete-beginners-guide-to-autonomous-agents\" rel=\"noreferrer noopener\" target=\"_blank\">Matt Schlicht</a>, CEO dâ€™Octane AI, que nous vous recommandons de suivre et de lire, propose la petite analyse suivante des cas possibles ou LangChain devient hyper pertinent:</p><figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https://cdn-images-1.medium.com/max/800/0*Ss07UdgIep5zuQf4.png\" alt=\"LangChain: Le guide essentiel\"></figure><p>VoilÃ  on espÃ¨re que Ã§a vous a plu, et on vous dit Ã  bientÃ´t pour des tutoriels hands-on dÃ©diÃ©s Ã  LangChain maintenant que nous avons vu la thÃ©orie et les grands concepts fondamentaux ensemble.</p><h3 class=\"wp-block-heading\">Nos recos de YouTube Playlists</h3><ol class=\"wp-block-list\"><li><a href=\"https://www.youtube.com/watch?v=_v_fgW2SkkQ&amp;list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5&amp;index=1\" rel=\"noreferrer noopener\" target=\"_blank\">AperÃ§u complÃ¨te de LangChain par la chaÃ®ne â€œData Independantâ€</a></li><li><a href=\"https://www.youtube.com/watch?v=nE2skSRWTTs&amp;list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F\" rel=\"noreferrer noopener\" target=\"_blank\">Les tutos de James Briggsâ€Šâ€”â€ŠÃ©vangÃ©liste pour LangChain et Pinecone</a></li><li><a href=\"https://youtube.com/playlist?list=PLqQrRCH56DH82KNwvlWpgh3YJXu461q69\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAIâ€Šâ€”â€ŠStreamlit Web Apps</a></li><li><a href=\"https://youtube.com/playlist?list=PLqQrRCH56DH8JSoGC3hsciV-dQhgFGS1K\" rel=\"noreferrer noopener\" target=\"_blank\">Streamlit-Python-Tutorials</a></li></ol><h3 class=\"wp-block-heading\">Liens etÂ crÃ©dits:</h3><ol class=\"wp-block-list\"><li>LangChain DocsÂ : <a href=\"https://langchain.readthedocs.io/en/latest/index.html\" rel=\"noreferrer noopener\" target=\"_blank\">https://langchain.readthedocs.io/en/latest/index.html</a></li><li><a href=\"https://www.pinecone.io/learn/langchain/\" rel=\"noreferrer noopener\" target=\"_blank\">Pinecone AI handbook</a> (massive respect to James Brigg and the pinecone team for this)</li><li>LangChain GitHub RepoÂ : <a href=\"https://github.com/hwchase17/langchain\" rel=\"noreferrer noopener\" target=\"_blank\">https://github.com/hwchase17/langchain</a></li><li><a href=\"https://platform.openai.com/docs/api-reference/completions/create#completions/create-stream\" rel=\"noreferrer noopener\" target=\"_blank\">Open AI document</a></li><li><a href=\"https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents\" rel=\"noreferrer noopener\" target=\"_blank\">Matt schlicht blog sur les agents autonomes</a></li></ol></div>"},
{"url": "https://larevueia.fr/la-revue-ia-est-partenaire-du-salon-ai-big-data-paris/", "title": "La revue IA est partenaire du salon AI & Big Data Paris", "author": "Ilyes Talbi", "date": "\n2 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Plus de 15 000 porteurs de projets, startups et leaders de la tech participent Ã  lâ€™Ã©vÃ¨nement nÂ°1 en France dÃ©diÃ© Ã  lâ€™intÃ©gration du big data et de lâ€™intelligence artificielle en entreprise !</p><p>Pour cette 11Ã¨me Ã©dition du congrÃ¨s Big Data &amp; AI Paris, reconnu par lâ€™ensemble des acteurs de la scÃ¨ne techâ€™ franÃ§aise comme le rendez-vous le plus important de cette rentrÃ©e 2022, plus de 700 speakers, 250 entreprises exposantes et 100 partenaires ont dÃ©jÃ  rÃ©pondu prÃ©sents.</p><p>Offrant une programmation de choix aux directions et mÃ©tiers en quÃªte dâ€™impact tangibles et singuliers sur leurs Big Data &amp; AI journey.</p><p>Avec son positionnement unique de Â«Â facilitateur dâ€™adoptionÂ Â» rÃ©solument orientÃ© sur le partage de bonnes pratiques utiles, sans langues de bois et crÃ©atrices de valeurs entre pairs, Big Data &amp; AI Paris ne cesse de prendre de lâ€™ampleur auprÃ¨s des mÃ©tiers qui portent le big data et lâ€™intelligence artificielle au quotidien.Â </p><p>Cette concentration jamais vue en France de personnalitÃ©s, startups, talents, fournisseurs de solutions ou encore poids lourds de la techâ€™, fait aujourdâ€™hui de Big Data &amp; AI Paris la 1<sup>Ã¨re</sup> place de marchÃ© hexagonale oÃ¹ il faut Ãªtre.Â </p></div>"},
{"url": "https://larevueia.fr/compte-rendu-de-lai-et-big-data-paris-corp/", "title": "Compte rendu de lâ€™AI et Big Data Paris Corp", "author": "Ilyes Talbi", "date": "\n17 septembre 2020\n", "content": "<div class=\"entry-content\"><figure class=\"wp-block-image alignfull size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"631\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-1024x631.jpg\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-2139\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-1024x631.jpg 1024w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-300x185.jpg 300w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-768x473.jpg 768w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-1536x946.jpg 1536w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-2048x1262.jpg 2048w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-404x250.jpg 404w, https://larevueia.fr/wp-content/uploads/2020/09/banniere-compte-rendu-paris-corp-scaled.jpg 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Les participants sont unanimes, la data câ€™est lâ€™argent et le pouvoir ! Et vous quâ€™en pensez-vous ?</figcaption></figure><p>Les 14 et 15 septembre se tenait lâ€™<a href=\"https://aiparis.fr/2020/\" target=\"_blank\" rel=\"noreferrer noopener\">AI Paris Corp</a> au parc des expositions de la porte de Versailles. Câ€™Ã©tait lâ€™occasion pour les acteurs de lâ€™IA en France de se rÃ©unir de nouveau aprÃ¨s un long moment. Ã‡a mâ€™avait manquÃ© !</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>MalgrÃ© la situation sanitaire, les organisateurs ont tenus Ã  garder le format classique de lâ€™Ã©vÃ©nement. Les participants qui le souhaitaient pouvaient assister Ã  lâ€™Ã©vÃ©nement en ligne.</p><p>Câ€™Ã©tait ma premiÃ¨re expÃ©rience dâ€™un Ã©vÃ©nement hybride. Et je pense que câ€™est un format trÃ¨s intÃ©ressant. Mis Ã  part un bug des serveurs lundi aprÃ¨s-midi, la plateforme semble avoir fonctionnÃ© correctement. Bonne nouvelle, car je pense que ce genre de format va se dÃ©mocratiser !</p><p>Le salon Ã©tait divisÃ© en deux parties : <em>big data</em> et <em>intelligence artificielle</em>. Ne pouvant pas Ãªtre sur tous les fronts, je me suis naturellement concentrÃ© sur la partie IA.</p><p>Comme dâ€™habitude dans les Ã©vÃ©nements Corp, les speakers Ã©taient de grandes qualitÃ©s et de nombreuses entreprises Ã©taient reprÃ©sentÃ©es comme Airbus, Microsoft ou encore IBM.</p><h2 class=\"wp-block-heading\">Le NLP et lâ€™explicabilitÃ© Ã  lâ€™honneur</h2><p>Lâ€™Ã©vÃ©nement couvrait un large champ de domaines de lâ€™intelligence artificielle. Mais lâ€™accent a Ã©tÃ© mis sur le NLP et lâ€™explicabilitÃ© des modÃ¨les de machine learning.</p><h3 class=\"wp-block-heading\">En 2021 on mise tout sur lâ€™explicabilitÃ© !</h3><p>ENFIN ! <br>Les dirigeants de grandes entreprises ont enfin compris ! <a href=\"https://larevueia.fr/explicabilite-des-modeles-ne-croyez-pas-aveuglement-ce-que-lia-vous-dit/\" target=\"_blank\" rel=\"noreferrer noopener\">Lâ€™explicabilitÃ©</a> des modÃ¨les est devenue une prioritÃ© pour certains.</p><p>Que ce fut dur !</p><p>Lâ€™explicabilitÃ© nâ€™est plus un simple <em>buzz word</em>, des actions concrÃ¨tes sont misent en oeuvre pour rendre les IA explicables. MÃªme si les solutions proposÃ©es sont encore Ã  amÃ©liorer, je suis content de voir quâ€™il y a une rÃ©elle prise de conscience. Beaucoup sont prÃªts Ã  investir dans ce sens et plusieurs confÃ©renciers abordaient le sujet.</p><h3 class=\"wp-block-heading\">Le NLP vole la vedette aux systÃ¨mes de computer vision</h3><p>Depuis que jâ€™assiste Ã  des confÃ©rences sur le machine learning, la star incontestÃ©e Ã©tait la computer vision. Les exposants ressortaient Ã  chaque fois leurs systÃ¨mes de reconnaissances faciales, leurs outils de reconnaissances dâ€™objets et tous ces gadgets. Câ€™est vrai que ces sujets sont trÃ¨s importants, mais Ã§a fait 2-3 ans quâ€™on a pas vraiment progressÃ© dans ce domaine.</p><p>Cette fois câ€™Ã©tait diffÃ©rent. Le <a href=\"https://larevueia.fr/nlp/\" target=\"_blank\" rel=\"noreferrer noopener\">NLP</a> avait une plus grande place, et comme jâ€™aime Ã§a (pas plus que la computer vision non plus haha), je nâ€™ai pas Ã©tÃ© dÃ©Ã§u ğŸ™‚ . Il semblerait que lâ€™impact de <a href=\"https://larevueia.fr/introduction-a-gpt-3-lun-des-modeles-de-nlp-les-plus-avances/\" target=\"_blank\" rel=\"noreferrer noopener\">GPT-3</a> se fait ressentir dans les grands Ã©vÃ©nements !</p><h2 class=\"wp-block-heading\">Les entreprises cool ğŸ˜</h2><p>Lâ€™Ã©vÃ©nement Ã©tait une bonne occasion de rencontrer certaines entreprises de lâ€™intelligence artificielle. Voici celles que jâ€™ai retenus !</p><h3 class=\"wp-block-heading\">Malinblack : la solution franÃ§aise pour sÃ©curiser les communications internes</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"1024\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-1024x1024.png\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-2162\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-1024x1024.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-300x300.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-150x150.png 150w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-768x768.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-1536x1536.png 1536w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-2048x2048.png 2048w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack-500x500.png 500w, https://larevueia.fr/wp-content/uploads/2020/09/logo-mailinblack.png 1600w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"></figure></div><p>Jâ€™ai eu la chance de rencontrer Thomas Kerjean. Il est le CEO de <a href=\"https://www.mailinblack.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Mailinblack</a>. PassÃ© par ReciTal et Accenture, il a Ã©tÃ© responsable de la branche Cloud et IA chez Microsoft pendant prÃ©s de 3 ans. Autant dire que sur lâ€™intelligence artificielle, cet homme avait des choses Ã  mâ€™apprendre ! Il a pris les commandes de lâ€™entreprise marseillaise en 2019, au mÃªme moment lâ€™entreprise faisait une levÃ©e de fonds de 14Mâ‚¬.</p><p>Mailinblack propose des solutions pour sÃ©curiser les communications par mail en entreprise. Une entreprise de cybersÃ©curitÃ© classique me direz-vous. Sauf que Mailinblack mise tout sur le deep learning pour dÃ©velopper son produit. Au moins 30% de son effectif travaille sur des problÃ©matiques de machine learning, ils font surtout de la R&amp;D.</p><p>Jâ€™attendais la confÃ©rence de Thomas Kerjean â€˜<em>ProtÃ©ger ses donnÃ©es personnelles grÃ¢ce au machine learning et au deep learning</em>â€˜ avec impatience. Mais la plateforme a plantÃ© au mÃªme moment et jâ€™attends toujours de recevoir les rediffusionsâ€¦ Vous serez tenus au courant.</p><h3 class=\"wp-block-heading\">TIBCO : lâ€™IA de Lewis Hamilton, rien que Ã§a !</h3><p>Mon cÅ“ur palpite Ã  chaque fois que je dÃ©couvre de nouvelles applications du machine learning. Non je nâ€™exagÃ¨re pas ğŸ™‚ . Et câ€™est dâ€™autant plus vrai lorsque Ã§a touche au domaine du sport.</p><p>Jâ€™ai rencontrÃ© <a href=\"https://www.tibco.com/formula-one-competitive-advantage\" target=\"_blank\" rel=\"noreferrer noopener\">TIBCO</a> pendant le salon. Ils proposent des solutions de traitements de donnÃ©es aux entreprises. Et Ã  travers lâ€™outil Sportfire, un de leurs clients est Mercedes-AMG Petronas. Câ€™est la meilleure Ã©curie de Formule 1, celle de Lewis Hamilton.</p><p>Ils rÃ©cupÃ¨rent en direct des donnÃ©es pendant la course pour assister la prise de dÃ©cisions. Quand faut-il changer les roues ? Quelle stratÃ©gie de conduite adopter ? Et plein dâ€™autres questions auquel le machine learning sait rÃ©pondre.</p><figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"Mercedes AMG Petronas Motorsport Handles Constant Change\" width=\"1250\" height=\"703\" src=\"https://www.youtube.com/embed/bKdpWF95cFo?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe></div><figcaption>PrÃ©sentation du partenariat TIBCO-Mercedes</figcaption></figure><blockquote class=\"wp-block-quote is-style-default is-layout-flow wp-block-quote-is-layout-flow\"><p>Pour gagner vous devez comprendre ce qui est important et ce qui ne lâ€™est pas. Nous devons nous assurer de prendre la bonne dÃ©cision au bon moment.</p><cite>James Vowles, Directeur de la StratÃ©gie chez Mercedes-AMG Petronas</cite></blockquote><h3 class=\"wp-block-heading\">Talend calcule le Trust score : un score de confiance pour vos donnÃ©es</h3><p>Pour entraÃ®ner des modÃ¨les fiables et robustes, il faut des donnÃ©es propres, non biaisÃ©s et qui respectent certaines rÃ¨gles. Malheureusement pour la majoritÃ© des projets on a trÃ¨s peu dâ€™indicateurs de fiabilitÃ© pour nos donnÃ©es.</p><p>Pour rÃ©soudre ce problÃ¨me, <a href=\"https://www.talend.com/fr/\" target=\"_blank\" rel=\"noreferrer noopener\">Talend</a> a crÃ©e une mesure de fiabilitÃ© des donnÃ©es, le Trust Score. Ce score permet de donner un indicateur de la confiance quâ€™une entreprise peut avoir vis Ã  vis de ses donnÃ©es. Ils permettent au passage de rÃ©soudre un paradoxe rÃ©el lorsque lâ€™on traite des donnÃ©es en entreprise. Les donnÃ©es permettent de crÃ©er des mesures et des KPI pour tout ce qui est mesurable, mais nous ne disposons dâ€™aucun KPI qui nous permette dâ€™Ã©valuer nos donnÃ©es.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"693\" src=\"https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-1024x693.png\" alt=\"Compte rendu de l'AI et Big Data Paris Corp\" class=\"wp-image-2164\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-1024x693.png 1024w, https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-300x203.png 300w, https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data-768x520.png 768w, https://larevueia.fr/wp-content/uploads/2020/09/trust-score-data.png 1200w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"><figcaption>Trust Score pour mesurer la qualitÃ© des donnÃ©es</figcaption></figure></div><p><br><br>Pour conclure, cette expÃ©rience mâ€™a permis de voir que de rÃ©els progrÃ¨s sont faits. Lâ€™intelligence artificielle qui nâ€™Ã©tait autre fois quâ€™un argument marketing dont les journalistes raffolaient, est en train de devenir un vrai moteur de croissance pour beaucoup. Les solutions sont de mieux en mieux et les stratÃ©gies de traitements de donnÃ©es sont de plus en plus robustes.</p><p>A lâ€™Ã©chelle du pays aussi lâ€™IA progresse. Plusieurs initiatives ont permis de crÃ©er une stratÃ©gie globale de dÃ©veloppement de lâ€™IA en France. Finalement lâ€™Europe pourra peut-Ãªtre un jour rattraper son retard sur les Etats-Unis et la Chineâ€¦</p></div>"},
{"url": "https://larevueia.fr/la-revue-ia-est-partenaire-du-salon-ai-big-data-paris-2/", "title": "La revue IA est partenaire du salon AI & Big Data Paris", "author": "Ilyes Talbi", "date": "\n18 septembre 2023\n", "content": "<div class=\"entry-content\"><p>La 12Ã¨me Ã©dition du congrÃ¨s Big Data &amp; AI Paris ouvrira ses portes les 25 &amp; 26 septembre 2023 au Palais des CongrÃ¨s de Paris autour dâ€™une promesse ambitieuse : <em>offrir aux dÃ©cideurs et acteurs de lâ€™Ã©cosystÃ¨me 2 jours immersifs dans lâ€™univers du Big Data et de lâ€™intelligence artificielle en France.</em></p><p>Avec plus de 350 confÃ©rences et ateliers, 250 entreprises exposantes et 16 000 participants, Big Data &amp; AI Paris offrira une occasion unique de dÃ©couvrir en avant-premiÃ¨re les derniÃ¨res tendances du marchÃ© et dâ€™Ã©changer avec lâ€™ensemble des professionnels de la data et de lâ€™intelligence artificielle en France.</p><p>Il sâ€™agit du plus grand Ã©vÃ©nement dÃ©diÃ© Ã  lâ€™intelligence artificielle et aux data en Europe.</p><p>Jâ€™y serais les 2 jours, et je monte sur scÃ¨ne Mardi 26 pour parler de documentation interne dâ€™entreprise Ã  lâ€™heure de ChatGPT et des LLM.</p><p><a href=\"https://www.bigdataparis.com/fr\" target=\"_blank\" rel=\"noreferrer noopener\">Rejoindre lâ€™Ã©vÃ¨nement.</a></p></div>"},
{"url": "https://larevueia.fr/compte-rendu-de-big-data-ai-paris-2023/", "title": "Compte rendu de Big Data & AI Paris 2023", "author": "Ilyes Talbi", "date": "\n4 octobre 2023\n", "content": "<div class=\"entry-content\"><p>Cette annÃ©e le salon BigData &amp; AI Paris, partenaire de La revue IA pour la 2Ã¨me annÃ©e, a connu un record en termes de frÃ©quentation. Dâ€™aprÃ¨s les organisateurs, 16 500 visiteurs (dont 1000 en ligne) ont participÃ© Ã  cette 12Ã¨me Ã©dition qui a eu lieu les 25 et 26 septembre 2023, au Palais des CongrÃ¨s de Paris.</p><p>Cet Ã©vÃ©nement qui rÃ©unit des experts du Big Data et de lâ€™IA est organisÃ© autour de confÃ©rences, ateliers techniques, et expositions de professionnels.</p><h2 class=\"wp-block-heading\"><em>Organisation du salon</em></h2><p>Les confÃ©rences sont organisÃ©es selon 3 parcours : les confÃ©rences stratÃ©giques, les retours dâ€™expÃ©riences business, et lâ€™expertise.Â </p><p>La particularitÃ© de cet Ã©vÃ©nement est de mettre en avant le travail dâ€™experts et ainsi saisir les applications rÃ©elles des outils dâ€™IA et du Big Data dans la vie quotidienne des entreprises, notamment Ã  travers les confÃ©rences â€œretour dâ€™expÃ©riences businessâ€.</p><p>Les ateliers quant Ã  eux portent sur des sujets techniques et sont plutÃ´t orientÃ©s â€œpratiqueâ€. A lâ€™exception de tout de mÃªme de certains ateliers qui questionnent sur lâ€™Ã©thique Ã  lâ€™instar de celui deÂ  lâ€™association Latitudes â€œla bataille de lâ€™IAâ€ (sous forme de jeux permettant un dÃ©bat entre les participants, trÃ¨s intÃ©ressant au passage) ou celui de â€œWomen in Big Dataâ€ qui se demandent comment lâ€™IA peut-Ãªtre plus responsable et contribuer Ã  un monde plus â€œdÃ©sirableâ€.</p><p>Quant aux 250 exposants, ils venaient de plusieurs domaines et de tous horizons : Ã  la fois de grosses entreprises et des start-ups, en passant par des Ã©coles (ESCP â€¦)</p><h2 class=\"wp-block-heading\"><em>Tour dâ€™horizon des principaux thÃ¨mesÂ  abordÃ©s cette annÃ©e</em></h2><p>Une balade entre les diffÃ©rentes confÃ©rences, ateliers et exposants nous permet de nous imprÃ©gner de la tendance actuelle en termes de Big Data et dâ€™IA.</p><p>Contrairement Ã  ce Ã  quoi nous aurions pu nous attendre, les IA gÃ©nÃ©ratives nâ€™Ã©taient pas le principal sujet du salon. En effet, Ã©tant donnÃ© tout le vacarme mÃ©diatique autour de ChatGPT, que ce soit dans les mÃ©dias mainstream ou bien chez les crÃ©ateurs de contenus, nous aurions imaginÃ© un salon axÃ© sur la thÃ©matique des IA gÃ©nÃ©ratives et notamment la partie LLM (large language models).</p><p>MÃªme si le sujet a Ã©tÃ© abordÃ©, il a laissÃ©, cette annÃ©e encore, la place Ã  des solutions pour les entreprises basÃ©es sur des technologies dÃ©jÃ  existantes et en production depuis quelques annÃ©es comme les systÃ¨mes de dÃ©tection de faille sur les chaines de production ou les solutions de structuration et stockage de donnÃ©es.</p><p>Ce qui ressort principalement de ces confÃ©rences, ce sont les questions de lâ€™impact du Big Data et plus prÃ©cisÃ©ment cette annÃ©e de lâ€™IA avec ChatGPT, sur notre sociÃ©tÃ©. Ainsi, la rÃ©gulation de lâ€™IA, la sÃ©curisation de nos donnÃ©es, lâ€™impact Ã©cologique et enfin la transformation des mÃ©tiers par lâ€™IA ont Ã©tÃ© les thÃ¨mes centraux du parcours â€œconfÃ©rences stratÃ©giquesâ€.</p><p>Lâ€™intervention de Luc Julia a permis notamment dâ€™aborder le thÃ¨me des â€œPromesses et rÃ©alitÃ©s des IA gÃ©nÃ©rativesâ€.</p><p>Lors de ce salon, que ce soit au niveau des exposants ou des confÃ©rences type â€œretours dâ€™expÃ©riences business Big Data &amp; IAâ€ il a plutÃ´t Ã©tÃ© question de solutions trÃ¨s orientÃ©es business avec des rÃ©solutions de problÃ¨mes rencontrÃ©s au quotidien par les entreprises.</p><p>On peut citer Ã  titre dâ€™exemple lâ€™intervention de Technip en collaboration avec Google. Ces deux entreprises ont collaborÃ© ensemble pour sâ€™aider de lâ€™IA afin de gÃ©rer la documentation de Technip, et cela a pris plus de 2 ans de travail dâ€™Ã©quipe.</p><h2 class=\"wp-block-heading\"><em>â€œLes data, le Big Data, lâ€™IAâ€¦mais lâ€™humain avant toutâ€</em></h2><p>On constate que mÃªme si les outils sont considÃ©rÃ©s comme puissants, il nâ€™empÃªche que des Ã©quipes importantes qui travaillent des annÃ©es sont nÃ©cessaires pour trouver et dÃ©ployer des solutions dans un contexte dâ€™entreprise.</p><p>A lâ€™heure actuelle les entreprises concentrent leurs efforts afin de remettre lâ€™humain au centre, en redonnant notamment aux mÃ©tiers lâ€™accÃ¨s aux outils.Â </p><p>La notion de self-service est remise Ã  lâ€™ordre du jour, alors que la tendance Ã©tait plutÃ´t de laisser les experts des donnÃ©es gÃ©rer et exploiter les donnÃ©es des entreprises.Â </p><p>Les outils sont devenus tellement <em>user-friendly</em> que de plus en plus dâ€™entreprises, mÃªme traditionnelles comme Pierre Fabre, ont dÃ©cidÃ© de mettre en place des stratÃ©gies et des solutions afin que leurs employÃ©s puissent eux-mÃªmes les utiliser.Â </p><p>DÃ©sormais, les entreprises prÃ©fÃ¨rent Ã©liminer au maximum les biais liÃ©s au traitement des donnÃ©es par des personnes qui ne sont pas du mÃ©tier. Plusieurs entreprises ont aussi dÃ©cidÃ©, afin dâ€™Ã©viter lâ€™effet shadow IT, comme celui liÃ© Ã  ChatGPT et aux outils qui en dÃ©coulent, de mettre lâ€™accent sur la formation et lâ€™accompagnement du personnel.Â </p><p>Luc Julia a brillamment rappelÃ© lors de son intervention Ã  quel point jamais une IA ne pourra remplacer un humain. Un point quâ€™il relÃ¨ve sans cesse dans ses interventions et qui nÃ©cessiterait tout un article Ã  part entiÃ¨re, est le nom mÃªme dâ€™IA qui prÃªte Ã  confusion. Il nâ€™a de cesse de rappeler depuis des annÃ©es dÃ©jÃ , que ceÂ  ne sont que des outils et non pas une â€œintelligenceâ€ au sens humain du terme.</p><h2 class=\"wp-block-heading\"><em>Quelques moments forts du salon</em></h2><p>Lâ€™entreprise que jâ€™ai trouvÃ©e Ã©patante est IKTOS. Elle en a dâ€™ailleurs Ã©patÃ© plus dâ€™un(e), puisquâ€™elle a reÃ§u un prix BIG DATA &amp; AI for GOOD lors de la remise des trophÃ©es de lâ€™innovation BIG DATA &amp; AI PARIS 2023.</p><p>Sa spÃ©cialitÃ© est dâ€™utiliser lâ€™IA afin dâ€™aider Ã  la dÃ©couverte et la crÃ©ation de nouveaux mÃ©dicaments. IKTOS a rÃ©alisÃ© un travail impressionnant : Ã  la fois dâ€™un point de vue technique mais aussi dâ€™un point de vue de son dÃ©veloppement commercial Ã  la fois rapide et solide (partenariat avec des industriels pharmaceutiques comme Servier).</p><p>Lâ€™utilisation de lâ€™IA afin de trouver de nouveaux candidats mÃ©dicaments est un domaine extrÃªmement complexe, Ã  la fois scientifiquement et techniquement. Arriver Ã  de tels rÃ©sultats et rÃ©ussir Ã  travailler avec de grands laboratoires pharmaceutiques (qui possÃ¨dent des Ã©quipes R&amp;D performantes ainsi que des moyens colossaux) est un exploit qui mÃ©rite dâ€™Ãªtre soulignÃ©.</p><p>Un article Ã  propos de lâ€™IA pour la dÃ©couverte de nouveaux mÃ©dicaments arrive bientÃ´t sur la revue.</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>MÃªme si lâ€™IA generative est une rÃ©volution, il y a encore un dÃ©calage entre le changement de paradigme annoncÃ© par les influenceurs, la LinkedIn mania, et la frilositÃ© des grandes entreprises.</p><p>Les grands acteurs de lâ€™industrie franÃ§aise observent de prÃ©s ce qui passe mais ne passent pas encore Ã  lâ€™action. Enjeux de sÃ©curitÃ©, gouvernance, enjeux Ã©thiques, sociaux, beaucoup de barriÃ¨res restent Ã  casser pour faire passer lâ€™IA generative dâ€™une technologie prometteuse, cool, intÃ©ressante et Ã§ une technologie REVOLUTIONNAIRE.</p></div>"},
{"url": "https://larevueia.fr/compte-rendu-de-ai-big-data-paris-2022/", "title": "Compte rendu de AI & Big data Paris 2022", "author": "Ilyes Talbi", "date": "\n29 septembre 2022\n", "content": "<div class=\"entry-content\"><p>Les 26 et 27 septembre derniers jâ€™Ã©tais Ã  AI &amp; Big Data Paris. Câ€™Ã©tait lâ€™Ã©vÃ¨nement data de la rentrÃ©e Ã  ne pas manquer. Jâ€™ai rencontrÃ© pas mal dâ€™entreprises et assistÃ© Ã  quelques-unes des confÃ©rences proposÃ©es.</p><p>Jâ€™ai mÃªme rencontrÃ© Luc Julia pendant une sÃ©ance de dÃ©dicace ğŸ™‚</p><p>Jâ€™ai beaucoup aimÃ© la partie exposition, un peu moins la partie confÃ©rence, que jâ€™ai trouvÃ© trop marketing et pas assez technique.</p><p>Ca ne mâ€™intÃ©resse pas trop dâ€™Ã©couter les <em>data strategy</em> mise en place par les grandes entreprises pour gÃ©rer leurs <em>data transition</em> dans leurs <em>data warehouse</em> connectÃ©es Ã  leur <em>data platform</em> construites <em>data by design</em> (jâ€™ai peut-Ãªtre juste pas eu de chance sur les confÃ©rences choisies ahah).</p><p>Globalement le bilan est positif, jâ€™ai rencontrÃ© pas mal de gens, appris beaucoup de choses, et jâ€™ai trouvÃ© quelques partenaires potentiels pour La revue IA !</p><h2 class=\"wp-block-heading\">Lâ€™intelligence artificielle pour le mÃ©tavers</h2><p>Jâ€™ai rencontrÃ© pas mal dâ€™entreprise qui travaillaient sur le sujet Ã  Vivatech. Lâ€™avantage cette fois câ€™est quâ€™il y avait moins de folklore et plus de choses concretes.</p><p>On commence Ã  bien maitriser les techniques de jumeaux numÃ©rique, la gÃ©nÃ©ration de scÃ¨nes commencent Ã  se dÃ©velopper, et la France devient forte sur les sujets de vision par ordinateur, notamment grÃ¢ce Ã  des startups comme Picsellia ou <a href=\"https://www.xxii.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">XXII</a>.</p><p>Jâ€™ai mÃªme discutÃ© avec une entreprise qui faisait des jumeaux numÃ©riques dâ€™usines !</p><figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\"><blockquote class=\"twitter-tweet\" data-width=\"550\" data-dnt=\"true\"><p lang=\"fr\" dir=\"ltr\">[<a href=\"https://twitter.com/hashtag/BDAIP22?src=hash&amp;ref_src=twsrc%5Etfw\">#BDAIP22</a> : It's over ğŸ¤©]<br><br>Vous avez Ã©tÃ© + de 16 000 participants ! Big Data &amp; AI Paris ne serait rien sans vous, alors merci d'Ãªtre venus aussi nombreux !<br><br>Ã€ lâ€™annÃ©e prochaine pour la 12Ã¨me Ã©dition ğŸ¬ <br>TO BE CONTINUED â€¦ <a href=\"https://t.co/vrgIIgjL7V\">pic.twitter.com/vrgIIgjL7V</a></p>â€” BIG DATA &amp; AI PARIS (@bigdataparis) <a href=\"https://twitter.com/bigdataparis/status/1574818788842913794?ref_src=twsrc%5Etfw\">September 27, 2022</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> </div></figure><h2 class=\"wp-block-heading\">Le maillage de donnÃ©es ou Data mesh est sur toutes les langues</h2><p>La tendance Ã  la mode en ce moment dans le monde du big data est clairement cette histoire de data mesh. Beaucoup des entreprises que jâ€™ai rencontrÃ© travaillent sur le sujet.</p><p>Le data mesh, plus quâ€™un outil, est un nouveau paradigme prÃ´nÃ© par les grands groupes qui ont des donnÃ©es en grande quantitÃ© et trÃ¨s diverses. Il sâ€™agit de proposer une mÃ©thode de gestion des donnÃ©es en entreprise plus intelligente et moins centralisÃ©e.</p><p>Chaque corp de mÃ©tier dâ€™une entreprise a accÃ¨s Ã  ses donnÃ©es et est responsable de leur qualitÃ© et leur sÃ©curitÃ©. En mÃªme temps, des passerelles sont construites pour permettre aux autres Ã©quipes au sein de lâ€™entreprise de pouvoir accÃ©der de faÃ§on sÃ©curisÃ©e et contrÃ´lÃ©e aux donnÃ©es, pour Ã©viter de copier trop souvent les mÃªmes donnÃ©es et faciliter lâ€™accÃ¨s pour tout le monde.</p><p>Lâ€™objectif du data mesh est de proposer un fonctionnement plus efficace, plus sÃ©curisÃ© et plus flexible que les modÃ¨les traditionnels.</p><h2 class=\"wp-block-heading\">Les startups Ã  suivre</h2><p>Jâ€™ai rencontrÃ© Ã©normÃ©ment de gens pendant le salon, et bien profitÃ© de lâ€™exposition. Le village startup Ã©tait trÃ¨s intÃ©ressant, jâ€™ai fais TOUS les stands de cette zone, et je regrette vraiment pas.</p><p>Contrairement aux stands des grandes entreprises, les startups ne sont pas lÃ  que pour vendre et chaque stand est diffÃ©rent.</p><p>Le choix a Ã©tÃ© difficile jâ€™avoue, mais je tenais Ã  ne garder que 3 projets dans ce compte rendu.</p><h3 class=\"wp-block-heading\">Buster.ai : dÃ©tecter les fausses informations grÃ¢ce au NLP</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/09/buster_ai.png\" alt=\"Compte rendu de AI &amp; Big data Paris 2022\" class=\"wp-image-6572\" width=\"464\" height=\"380\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/09/buster_ai.png 692w, https://larevueia.fr/wp-content/uploads/2022/09/buster_ai-300x246.png 300w\" sizes=\"auto, (max-width: 464px) 100vw, 464px\"></figure></div><p><a href=\"https://buster.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Buster.ai</a> est une startup franÃ§aise spÃ©cialisÃ©e dans la dÃ©tection de fake news automatique.</p><p>Ils proposent une plateforme SAS, boostÃ©e au NLP, qui permet de donner des indications sur la fiabilitÃ© dâ€™une information en analysant son contenu et en proposant des sources qui confirment ou qui infirment lâ€™information.</p><p>Maintenant que les rÃ©gulateurs europÃ©ens ont imposÃ©s aux grandes entreprises comme Meta de combattre plus sÃ©rieusement les fake news, cette solution franÃ§aise pourrait sâ€™imposer rapidement.</p><h3 class=\"wp-block-heading\">Vocads : la solution de e-commerce par la voix</h3><p>Les interactions humains machines se font plus naturellement par la voix. Maintenant que les modÃ¨les de reconnaissances vocale et de NLP sont plus performants, il est temps de repenser toutes nos expÃ©riences sur internet.</p><p>Vocads, propose un assistant vocal intelligent qui permet dâ€™accompagner les utilisateurs pendant leur expÃ©rience dâ€™achat. Lâ€™assistant les aide Ã  trouver le bon produit, leur suggÃ¨re des produits complÃ©mentaires et les accompagne jusquâ€™Ã  la finalisation de lâ€™achat. Jâ€™imagine mÃªme Ã  terme la capacitÃ© dâ€™identifier lâ€™acheteur avec sa voix et ainsi assurer plus de sÃ©curitÃ©.</p><p>Par ailleurs, ce type dâ€™assistants pourra Ãªtre utilisÃ© pour rendre les sites internet plus accessibles. Qui sait, bientÃ´t on aura un assistant Vocads qui vous aidera dans votre expÃ©rience dâ€™apprentissage sur La revue IA ğŸ™‚</p><h3 class=\"wp-block-heading\">Selas studio : le (jâ€™espÃ¨re) futur leader europÃ©en de la gÃ©nÃ©ration dâ€™images par intelligence artificielle</h3><div class=\"wp-block-image\"><figure class=\"aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-1024x614.jpeg\" alt=\"Compte rendu de AI &amp; Big data Paris 2022\" class=\"wp-image-6574\" width=\"512\" height=\"306\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-1024x614.jpeg 1024w, https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-300x180.jpeg 300w, https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080-768x461.jpeg 768w, https://larevueia.fr/wp-content/uploads/2022/09/6298c1ac3fd33de02cfb9bdd_IMG1-p-1080.jpeg 1080w\" sizes=\"auto, (max-width: 512px) 100vw, 512px\"></figure></div><p>On vient Ã  peine dâ€™entrer dans lâ€™Ã¨re de lâ€™art gÃ©nÃ©ratif, beaucoup dâ€™applications doivent encore Ãªtre dÃ©veloppÃ©e et les modÃ¨les seront encore amÃ©liorÃ©s.</p><p>Sur ce sujet, jâ€™ai rencontrÃ© Selas studio, une startup franÃ§aise qui compte lâ€™un des contributeurs de <a href=\"https://larevueia.fr/comment-generer-des-images-avec-stable-diffusion/\" target=\"_blank\" rel=\"noreferrer noopener\">stable diffusion</a> parmi les co-fondateurs. StylÃ© !</p><p>Jâ€™ai bien aimÃ© lâ€™Ã©quipe et je pense quâ€™on pourra faire des choses intÃ©ressantes avec eux ğŸ™‚</p><h2 class=\"wp-block-heading\">Conclusion</h2><p>VoilÃ  pour ce compte rendu. Le salon Big data &amp; AI Paris a encore une fois tenu toutes ses promesses, jâ€™ai Ã©tÃ© ravi dâ€™Ãªtre partenaire de cette initiative et jâ€™attend lâ€™Ã©dition 2023 avec impatience !</p></div>"},
{"url": "https://larevueia.fr/mes-dernieres-lectures-en-data-science/", "title": "Mes derniÃ¨res lectures en data science", "author": "Ilyes Talbi", "date": "\n8 novembre 2020\n", "content": "<div class=\"entry-content\"><p>Les <a href=\"https://www.editions-eyrolles.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Ã©ditions Eyrolles</a> mâ€™ont gentiment envoyÃ©s plusieurs livres. Jâ€™ai profitÃ© du confinement et du fait que jâ€™ai un peu plus de temps libre pour me plonger dedans et vous en parler.</p><div class=\"wp-block-image\"><figure class=\"aligncenter size-full is-resized\"><a href=\"https://discord.gg/rKEPjj6ZDt\" target=\"_blank\" rel=\"noreferrer noopener\"><img loading=\"lazy\" decoding=\"async\" src=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-de%CC%81cran-2022-06-14-a%CC%80-17.27.27.png\" alt=\"Mes derniÃ¨res lectures en data science\" class=\"wp-image-5533\" width=\"521\" height=\"268\" srcset=\"https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27.png 754w, https://larevueia.fr/wp-content/uploads/2022/06/Capture-deÌcran-2022-06-14-aÌ€-17.27.27-300x154.png 300w\" sizes=\"auto, (max-width: 521px) 100vw, 521px\"></a></figure></div><p>Avant de commencer sachez que jâ€™ai mis des liens affiliÃ©s qui me permettent de rÃ©cupÃ©rer une petite commission sans que Ã§a ne vous coÃ»te plus cher. Si vous comptez acheter un livre et que vous souhaitez me soutenir faites le depuis ces liens ğŸ™‚</p><h2 class=\"wp-block-heading\"><a href=\"https://www.amazon.fr/gp/product/2212142439/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212142439&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=5941cec3d1634efb7b993c1c50f2e789\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Data Science : fondamentaux et Ã©tudes de cas</a></h2><p>Le premier livre de cette sÃ©lection a Ã©tÃ© Ã©crit par Eric Biernat et Michel Lutz. Cet ouvrage vous permettra de comprendre certains des algorithmes fondamentaux de la data science de faÃ§on poussÃ©e (RÃ©gressions, <a href=\"https://larevueia.fr/support-vector-machines-svm/\" target=\"_blank\" rel=\"noreferrer noopener\">SVM</a>, Naive Bayes, <a href=\"https://larevueia.fr/random-forest/\" target=\"_blank\" rel=\"noreferrer noopener\">Random Forest</a>, etc.).</p><p>Contrairement Ã  la majoritÃ© des autres ouvrages, qui vous donneront une prÃ©sentation rapide de tout ce qui se fait, ce livre rentre dans les dÃ©tails mais en traitant uniquement les modÃ¨les les plus utilisÃ©s.</p><p><a href=\"https://www.amazon.fr/gp/product/2212142439/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212142439&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=5941cec3d1634efb7b993c1c50f2e789\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Acheter</a></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://www.amazon.fr/gp/product/2212142439/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212142439&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=5941cec3d1634efb7b993c1c50f2e789\"><img loading=\"lazy\" decoding=\"async\" width=\"411\" height=\"500\" src=\"https://larevueia.fr/wp-content/uploads/2020/11/41e5vygI6jL._SX409_BO1204203200_.jpg\" alt=\"Mes derniÃ¨res lectures en data science\" class=\"wp-image-2700\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/11/41e5vygI6jL._SX409_BO1204203200_.jpg 411w, https://larevueia.fr/wp-content/uploads/2020/11/41e5vygI6jL._SX409_BO1204203200_-247x300.jpg 247w\" sizes=\"auto, (max-width: 411px) 100vw, 411px\"></a><figcaption>Data science : fondamentaux et Ã©tudes de cas</figcaption></figure></div><h2 class=\"wp-block-heading\"><a href=\"https://www.amazon.fr/gp/product/B08LMSGMN9/ref=as_li_tl?ie=UTF8&amp;tag=ilyeslarevuei-21&amp;camp=1642&amp;creative=6746&amp;linkCode=as2&amp;creativeASIN=B08LMSGMN9&amp;linkId=b7ad1b48a9dbf190488b763cd7d12a2a\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Data Science par la pratique</a></h2><p>Le second livre de cette liste a Ã©tÃ© Ã©crit par Joel Grus. La 2Ã¨me Ã©dition Ã©tÃ© publiÃ© le 22 Octobre, câ€™est tout frais ! Joel Grus est ingÃ©nieur Ã  Seattle chez Google et il est dÃ©jÃ  auteur de plusieurs ouvrages de data science.</p><p>Lâ€™auteur part dâ€™un principe, auquel jâ€™adhÃ¨re complÃ¨tement, lâ€™apprentissage de la data science se fait par la pratique. Il faut travailler sur des projets concrets pour progresser rÃ©ellement et câ€™est lâ€™approche qui est adoptÃ©e dans ce livre.</p><p>Les premiers chapitres consistent en une prÃ©sentation exhaustive des fondamentaux thÃ©oriques et un cours sur la programmation en Python. Lâ€™auteur prÃ©sente ensuite les diffÃ©rents outils de la data science avec plusieurs exemples concrets implÃ©mentÃ©s sur Python.</p><p><a href=\"https://www.amazon.fr/gp/product/B08LMSGMN9/ref=as_li_tl?ie=UTF8&amp;tag=ilyeslarevuei-21&amp;camp=1642&amp;creative=6746&amp;linkCode=as2&amp;creativeASIN=B08LMSGMN9&amp;linkId=b7ad1b48a9dbf190488b763cd7d12a2a\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Acheter</a></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://www.amazon.fr/gp/product/B08LMSGMN9/ref=as_li_tl?ie=UTF8&amp;tag=ilyeslarevuei-21&amp;camp=1642&amp;creative=6746&amp;linkCode=as2&amp;creativeASIN=B08LMSGMN9&amp;linkId=b7ad1b48a9dbf190488b763cd7d12a2a\"><img loading=\"lazy\" decoding=\"async\" width=\"408\" height=\"500\" src=\"https://larevueia.fr/wp-content/uploads/2020/11/41TpytEeAZL.jpg\" alt=\"Mes derniÃ¨res lectures en data science\" class=\"wp-image-2703\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/11/41TpytEeAZL.jpg 408w, https://larevueia.fr/wp-content/uploads/2020/11/41TpytEeAZL-245x300.jpg 245w\" sizes=\"auto, (max-width: 408px) 100vw, 408px\"></a><figcaption>Data science par la pratique</figcaption></figure></div><h2 class=\"wp-block-heading\"><a href=\"https://www.amazon.fr/gp/product/2212679513/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212679513&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=804e8a937eb95c873272ec44b32159e3\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Les Data Sciences en 100 questions/rÃ©ponses</a></h2><p><em>Last but not least !</em></p><div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><a href=\"https://www.amazon.fr/gp/product/2212679513/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212679513&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=804e8a937eb95c873272ec44b32159e3\"><img loading=\"lazy\" decoding=\"async\" width=\"405\" height=\"500\" src=\"https://larevueia.fr/wp-content/uploads/2020/11/41gu4Jei6TL._SX403_BO1204203200_.jpg\" alt=\"Mes derniÃ¨res lectures en data science\" class=\"wp-image-2701\" srcset=\"https://larevueia.fr/wp-content/uploads/2020/11/41gu4Jei6TL._SX403_BO1204203200_.jpg 405w, https://larevueia.fr/wp-content/uploads/2020/11/41gu4Jei6TL._SX403_BO1204203200_-243x300.jpg 243w\" sizes=\"auto, (max-width: 405px) 100vw, 405px\"></a><figcaption>Les data science en 100 questions/rÃ©ponses</figcaption></figure></div><p>Le dernier livre dont je voulais parler est celui de Younes Benzaki, lâ€™auteur de <a href=\"https://mrmint.fr/\" target=\"_blank\" rel=\"noreferrer noopener\">Mr Mint</a>, lâ€™un des premiers blogs de machine learning en France. Contrairement aux deux premiers, ce livre vise plutÃ´t un public dÃ©jÃ  familiariser avec les notions de bases du machine learning.</p><p>Jâ€™ai beaucoup aimÃ© lâ€™originalitÃ© de lâ€™ouvrage. MÃªme si le contenu est finalement assez classique, le fait dâ€™avoir structurÃ© la premiÃ¨re partie du livre sous forme de questions/rÃ©ponses facilite beaucoup la lecture. La seconde partie est plus orientÃ©e pratique. En plus de donner des Ã©lÃ©ments de mÃ©thodologies, lâ€™auteur explique pas Ã  pas la construction de modÃ¨les prÃ©dictifs.</p><p>Explications thÃ©oriques du fonctionnement des algorithmes classiques; mÃ©triques dâ€™Ã©valuations des performances des modÃ¨les; notions mathÃ©matiques fondamentales du machine learning, ce livre permet de couvrir de faÃ§on trÃ¨s large le domaine de la data science.</p><p>Cet ouvrage est trÃ¨s complÃ©mentaire des deux autres. Il vous permettra dâ€™avoir une comprÃ©hension un peu plus subtil de certains concepts du machine learning. Il est idÃ©al quelquâ€™un qui souhaite prÃ©parer un entretien par exemple.</p><p><a href=\"https://www.amazon.fr/gp/product/2212679513/ref=as_li_tl?ie=UTF8&amp;camp=1642&amp;creative=6746&amp;creativeASIN=2212679513&amp;linkCode=as2&amp;tag=ilyeslarevuei-21&amp;linkId=804e8a937eb95c873272ec44b32159e3\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">Acheter</a></p></div>"}
]